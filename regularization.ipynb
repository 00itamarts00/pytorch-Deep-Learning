{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation in NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "from tensorflow import keras as kr \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my plotting style\n",
    "plt.style.use(('dark_background', 'bmh'))\n",
    "plt.rc('axes', facecolor='none')\n",
    "plt.rc('figure', figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x115273510>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortcuts\n",
    "imdb = kr.datasets.imdb\n",
    "Tokeniser = kr.preprocessing.text.Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of features we want\n",
    "features_nb = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=features_nb)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokeniser = Tokeniser(num_words=features_nb)\n",
    "train_features = tokeniser.sequences_to_matrix(train_data, mode='binary')\n",
    "test_features = tokeniser.sequences_to_matrix(test_data, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploring the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (25000,)\n",
      "train_target.shape: (25000,)\n",
      "test_data.shape: (25000,)\n",
      "test_target.shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Check data set sizes\n",
    "print('train_data.shape:', train_data.shape)\n",
    "print('train_target.shape:', train_target.shape)\n",
    "print('test_data.shape:', test_data.shape)\n",
    "print('test_target.shape:', test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_data[0]): <class 'list'>\n",
      "type(train_target[0]): <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# Check format of first training sample\n",
    "print('type(train_data[0]):', type(train_data[0]))\n",
    "print('type(train_target[0]):', type(train_target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews length: [218, 189, 141, 550, 147, 43, 123, 562, 233, 130]\n",
      "Review sentiment (bad/good): [1 0 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Check size of first 10 training samples and corresponding target\n",
    "print('Reviews length:', [len(sample) for sample in train_data[:10]])\n",
    "print('Review sentiment (bad/good):', train_target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - machine format\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set text visualisation helper function\n",
    "def show_text(sample):\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "    word_to_id[\"<PAD>\"] = 0\n",
    "    word_to_id[\"<START>\"] = 1\n",
    "    word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "    id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "    print(' '.join(id_to_word[id_] for id_ in sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this film was just brilliant casting <UNK> <UNK> story direction <UNK> really <UNK> the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> <UNK> as myself so i loved the fact there was a real <UNK> with this film the <UNK> <UNK> throughout the film were great it was just brilliant so much that i <UNK> the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the <UNK> <UNK> was amazing really <UNK> at the end it was so sad and you know what they say if you <UNK> at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of <UNK> and paul they were just brilliant children are often left out of the <UNK> <UNK> i think because the stars that play them all <UNK> up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so <UNK> because it was true and was <UNK> life after all that was <UNK> with us all\n"
     ]
    }
   ],
   "source": [
    "# Show first review - human format\n",
    "show_text(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - neural net format\n",
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   2.   0.   4.   5.   6.   7.   8.   9.   0.   0.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.   0.  21.  22.   0.   0.  25.  26.   0.\n",
      "  28.   0.  30.   0.  32.  33.   0.  35.  36.   0.  38.  39.   0.   0.\n",
      "   0.  43.   0.   0.  46.   0.  48.   0.  50.  51.  52.   0.   0.   0.\n",
      "  56.   0.   0.   0.   0.   0.  62.   0.   0.  65.  66.   0.   0.   0.\n",
      "   0.  71.   0.   0.   0.   0.  76.  77.   0.   0.   0.   0.  82.   0.\n",
      "   0.   0.   0.  87.  88.   0.   0.   0.  92.   0.   0.   0.   0.   0.\n",
      "  98.   0. 100.   0.   0. 103. 104.   0. 106. 107.   0.   0.   0.   0.\n",
      " 112. 113.   0.   0.   0. 117.   0.   0.   0.   0.   0.   0. 124.   0.\n",
      "   0.   0.   0.   0. 130.   0.   0.   0. 134. 135.   0.   0.   0.   0.\n",
      "   0. 141.   0.   0. 144.   0.   0. 147.   0.   0. 150.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 167.\n",
      "   0.   0.   0.   0. 172. 173.   0.   0.   0.   0. 178.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 192.   0. 194.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 215.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 224.   0. 226.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 256.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 283. 284.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 297.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 316. 317.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 336.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 381.   0.   0.   0. 385. 386.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 400.   0.   0.   0.   0.   0.\n",
      "   0. 407.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 447.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 458.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 469.   0.   0.   0.   0.   0.   0.\n",
      " 476.   0.   0.   0. 480.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 515.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 530.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 546.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 619.   0.   0.   0.   0.   0.   0. 626.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 670.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 723.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 838.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 973.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - neural net format - explanation\n",
    "print(train_features[0] * np.arange(len(train_features[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring regularisation of NN\n",
    "\n",
    "Play with the code, especially the one marked `# toggle`.  \n",
    "Start from `# toggle 0`, and then, one at the time, `# toggle 1` to `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerDense(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, units_size):\n",
    "\n",
    "        super(ThreeLayerDense, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_size, units_size) #features_nb, 16\n",
    "        self.linear2 = torch.nn.Linear(units_size, units_size)\n",
    "        #self.dropout\n",
    "        self.linear3 = torch.nn.Linear(units_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.linear2(x) \n",
    "        x = F.relu(x)\n",
    "        return nn.Sigmoid()(self.linear3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "log_interval = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "model = ThreeLayerDense(features_nb,16)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 0 of 25000, training loss: 0.741060\n",
      "Train Epoch: 0, mini-batch 10 of 25000, training loss: 0.716671\n",
      "Train Epoch: 0, mini-batch 20 of 25000, training loss: 0.641829\n",
      "Train Epoch: 0, mini-batch 30 of 25000, training loss: 0.634434\n",
      "Train Epoch: 0, mini-batch 40 of 25000, training loss: 0.748209\n",
      "Train Epoch: 0, mini-batch 50 of 25000, training loss: 0.631697\n",
      "Train Epoch: 0, mini-batch 60 of 25000, training loss: 0.634775\n",
      "Train Epoch: 0, mini-batch 70 of 25000, training loss: 0.631318\n",
      "Train Epoch: 0, mini-batch 80 of 25000, training loss: 0.687322\n",
      "Train Epoch: 0, mini-batch 90 of 25000, training loss: 0.690306\n",
      "Train Epoch: 0, mini-batch 100 of 25000, training loss: 0.622003\n",
      "Train Epoch: 0, mini-batch 110 of 25000, training loss: 0.595997\n",
      "Train Epoch: 0, mini-batch 120 of 25000, training loss: 0.777372\n",
      "Train Epoch: 0, mini-batch 130 of 25000, training loss: 0.550216\n",
      "Train Epoch: 0, mini-batch 140 of 25000, training loss: 0.828558\n",
      "Train Epoch: 0, mini-batch 150 of 25000, training loss: 0.812309\n",
      "Train Epoch: 0, mini-batch 160 of 25000, training loss: 0.574027\n",
      "Train Epoch: 0, mini-batch 170 of 25000, training loss: 0.808832\n",
      "Train Epoch: 0, mini-batch 180 of 25000, training loss: 0.761230\n",
      "Train Epoch: 0, mini-batch 190 of 25000, training loss: 0.607532\n",
      "Train Epoch: 0, mini-batch 200 of 25000, training loss: 0.844303\n",
      "Train Epoch: 0, mini-batch 210 of 25000, training loss: 0.795270\n",
      "Train Epoch: 0, mini-batch 220 of 25000, training loss: 0.663023\n",
      "Train Epoch: 0, mini-batch 230 of 25000, training loss: 0.645046\n",
      "Train Epoch: 0, mini-batch 240 of 25000, training loss: 0.725034\n",
      "Train Epoch: 0, mini-batch 250 of 25000, training loss: 0.826792\n",
      "Train Epoch: 0, mini-batch 260 of 25000, training loss: 0.849808\n",
      "Train Epoch: 0, mini-batch 270 of 25000, training loss: 0.563786\n",
      "Train Epoch: 0, mini-batch 280 of 25000, training loss: 0.402408\n",
      "Train Epoch: 0, mini-batch 290 of 25000, training loss: 0.809607\n",
      "Train Epoch: 0, mini-batch 300 of 25000, training loss: 0.683607\n",
      "Train Epoch: 0, mini-batch 310 of 25000, training loss: 0.626948\n",
      "Train Epoch: 0, mini-batch 320 of 25000, training loss: 0.603000\n",
      "Train Epoch: 0, mini-batch 330 of 25000, training loss: 0.596573\n",
      "Train Epoch: 0, mini-batch 340 of 25000, training loss: 0.899522\n",
      "Train Epoch: 0, mini-batch 350 of 25000, training loss: 0.874189\n",
      "Train Epoch: 0, mini-batch 360 of 25000, training loss: 0.628848\n",
      "Train Epoch: 0, mini-batch 370 of 25000, training loss: 0.777716\n",
      "Train Epoch: 0, mini-batch 380 of 25000, training loss: 0.630601\n",
      "Train Epoch: 0, mini-batch 390 of 25000, training loss: 0.797743\n",
      "Train Epoch: 0, mini-batch 400 of 25000, training loss: 0.492379\n",
      "Train Epoch: 0, mini-batch 410 of 25000, training loss: 0.566039\n",
      "Train Epoch: 0, mini-batch 420 of 25000, training loss: 0.609827\n",
      "Train Epoch: 0, mini-batch 430 of 25000, training loss: 0.785390\n",
      "Train Epoch: 0, mini-batch 440 of 25000, training loss: 0.403918\n",
      "Train Epoch: 0, mini-batch 450 of 25000, training loss: 0.549533\n",
      "Train Epoch: 0, mini-batch 460 of 25000, training loss: 0.657826\n",
      "Train Epoch: 0, mini-batch 470 of 25000, training loss: 0.426919\n",
      "Train Epoch: 0, mini-batch 480 of 25000, training loss: 0.284144\n",
      "Train Epoch: 0, mini-batch 490 of 25000, training loss: 0.627829\n",
      "Train Epoch: 0, mini-batch 500 of 25000, training loss: 0.566094\n",
      "Train Epoch: 0, mini-batch 510 of 25000, training loss: 0.461405\n",
      "Train Epoch: 0, mini-batch 520 of 25000, training loss: 0.540176\n",
      "Train Epoch: 0, mini-batch 530 of 25000, training loss: 0.916221\n",
      "Train Epoch: 0, mini-batch 540 of 25000, training loss: 0.840781\n",
      "Train Epoch: 0, mini-batch 550 of 25000, training loss: 0.396222\n",
      "Train Epoch: 0, mini-batch 560 of 25000, training loss: 0.489759\n",
      "Train Epoch: 0, mini-batch 570 of 25000, training loss: 0.390035\n",
      "Train Epoch: 0, mini-batch 580 of 25000, training loss: 0.316650\n",
      "Train Epoch: 0, mini-batch 590 of 25000, training loss: 0.177842\n",
      "Train Epoch: 0, mini-batch 600 of 25000, training loss: 0.604201\n",
      "Train Epoch: 0, mini-batch 610 of 25000, training loss: 0.248418\n",
      "Train Epoch: 0, mini-batch 620 of 25000, training loss: 0.223321\n",
      "Train Epoch: 0, mini-batch 630 of 25000, training loss: 0.610220\n",
      "Train Epoch: 0, mini-batch 640 of 25000, training loss: 0.530041\n",
      "Train Epoch: 0, mini-batch 650 of 25000, training loss: 0.497137\n",
      "Train Epoch: 0, mini-batch 660 of 25000, training loss: 0.580445\n",
      "Train Epoch: 0, mini-batch 670 of 25000, training loss: 1.554489\n",
      "Train Epoch: 0, mini-batch 680 of 25000, training loss: 0.355637\n",
      "Train Epoch: 0, mini-batch 690 of 25000, training loss: 0.807897\n",
      "Train Epoch: 0, mini-batch 700 of 25000, training loss: 0.678785\n",
      "Train Epoch: 0, mini-batch 710 of 25000, training loss: 0.097133\n",
      "Train Epoch: 0, mini-batch 720 of 25000, training loss: 0.142277\n",
      "Train Epoch: 0, mini-batch 730 of 25000, training loss: 0.995473\n",
      "Train Epoch: 0, mini-batch 740 of 25000, training loss: 0.116460\n",
      "Train Epoch: 0, mini-batch 750 of 25000, training loss: 0.629871\n",
      "Train Epoch: 0, mini-batch 760 of 25000, training loss: 0.419850\n",
      "Train Epoch: 0, mini-batch 770 of 25000, training loss: 0.061442\n",
      "Train Epoch: 0, mini-batch 780 of 25000, training loss: 1.014531\n",
      "Train Epoch: 0, mini-batch 790 of 25000, training loss: 0.394573\n",
      "Train Epoch: 0, mini-batch 800 of 25000, training loss: 0.488490\n",
      "Train Epoch: 0, mini-batch 810 of 25000, training loss: 0.803258\n",
      "Train Epoch: 0, mini-batch 820 of 25000, training loss: 0.181209\n",
      "Train Epoch: 0, mini-batch 830 of 25000, training loss: 0.677240\n",
      "Train Epoch: 0, mini-batch 840 of 25000, training loss: 1.644811\n",
      "Train Epoch: 0, mini-batch 850 of 25000, training loss: 0.459453\n",
      "Train Epoch: 0, mini-batch 860 of 25000, training loss: 0.258079\n",
      "Train Epoch: 0, mini-batch 870 of 25000, training loss: 0.172034\n",
      "Train Epoch: 0, mini-batch 880 of 25000, training loss: 0.882242\n",
      "Train Epoch: 0, mini-batch 890 of 25000, training loss: 0.498468\n",
      "Train Epoch: 0, mini-batch 900 of 25000, training loss: 0.360006\n",
      "Train Epoch: 0, mini-batch 910 of 25000, training loss: 0.140169\n",
      "Train Epoch: 0, mini-batch 920 of 25000, training loss: 0.301726\n",
      "Train Epoch: 0, mini-batch 930 of 25000, training loss: 0.407427\n",
      "Train Epoch: 0, mini-batch 940 of 25000, training loss: 0.093469\n",
      "Train Epoch: 0, mini-batch 950 of 25000, training loss: 0.333384\n",
      "Train Epoch: 0, mini-batch 960 of 25000, training loss: 1.174423\n",
      "Train Epoch: 0, mini-batch 970 of 25000, training loss: 0.278945\n",
      "Train Epoch: 0, mini-batch 980 of 25000, training loss: 0.675226\n",
      "Train Epoch: 0, mini-batch 990 of 25000, training loss: 0.437573\n",
      "Train Epoch: 0, mini-batch 1000 of 25000, training loss: 0.548221\n",
      "Train Epoch: 0, mini-batch 1010 of 25000, training loss: 1.091669\n",
      "Train Epoch: 0, mini-batch 1020 of 25000, training loss: 0.125595\n",
      "Train Epoch: 0, mini-batch 1030 of 25000, training loss: 0.219212\n",
      "Train Epoch: 0, mini-batch 1040 of 25000, training loss: 1.175255\n",
      "Train Epoch: 0, mini-batch 1050 of 25000, training loss: 0.987493\n",
      "Train Epoch: 0, mini-batch 1060 of 25000, training loss: 0.089335\n",
      "Train Epoch: 0, mini-batch 1070 of 25000, training loss: 0.804133\n",
      "Train Epoch: 0, mini-batch 1080 of 25000, training loss: 0.416551\n",
      "Train Epoch: 0, mini-batch 1090 of 25000, training loss: 0.156476\n",
      "Train Epoch: 0, mini-batch 1100 of 25000, training loss: 0.156216\n",
      "Train Epoch: 0, mini-batch 1110 of 25000, training loss: 0.087622\n",
      "Train Epoch: 0, mini-batch 1120 of 25000, training loss: 0.314993\n",
      "Train Epoch: 0, mini-batch 1130 of 25000, training loss: 0.217520\n",
      "Train Epoch: 0, mini-batch 1140 of 25000, training loss: 0.219510\n",
      "Train Epoch: 0, mini-batch 1150 of 25000, training loss: 0.207569\n",
      "Train Epoch: 0, mini-batch 1160 of 25000, training loss: 1.267605\n",
      "Train Epoch: 0, mini-batch 1170 of 25000, training loss: 0.406719\n",
      "Train Epoch: 0, mini-batch 1180 of 25000, training loss: 0.113281\n",
      "Train Epoch: 0, mini-batch 1190 of 25000, training loss: 0.106730\n",
      "Train Epoch: 0, mini-batch 1200 of 25000, training loss: 0.180460\n",
      "Train Epoch: 0, mini-batch 1210 of 25000, training loss: 0.747837\n",
      "Train Epoch: 0, mini-batch 1220 of 25000, training loss: 1.273837\n",
      "Train Epoch: 0, mini-batch 1230 of 25000, training loss: 0.144877\n",
      "Train Epoch: 0, mini-batch 1240 of 25000, training loss: 0.210474\n",
      "Train Epoch: 0, mini-batch 1250 of 25000, training loss: 0.283701\n",
      "Train Epoch: 0, mini-batch 1260 of 25000, training loss: 0.130739\n",
      "Train Epoch: 0, mini-batch 1270 of 25000, training loss: 0.047181\n",
      "Train Epoch: 0, mini-batch 1280 of 25000, training loss: 0.503044\n",
      "Train Epoch: 0, mini-batch 1290 of 25000, training loss: 0.099388\n",
      "Train Epoch: 0, mini-batch 1300 of 25000, training loss: 0.361483\n",
      "Train Epoch: 0, mini-batch 1310 of 25000, training loss: 0.391481\n",
      "Train Epoch: 0, mini-batch 1320 of 25000, training loss: 0.184354\n",
      "Train Epoch: 0, mini-batch 1330 of 25000, training loss: 0.675158\n",
      "Train Epoch: 0, mini-batch 1340 of 25000, training loss: 0.435418\n",
      "Train Epoch: 0, mini-batch 1350 of 25000, training loss: 0.409498\n",
      "Train Epoch: 0, mini-batch 1360 of 25000, training loss: 0.530947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 1370 of 25000, training loss: 0.589652\n",
      "Train Epoch: 0, mini-batch 1380 of 25000, training loss: 0.125836\n",
      "Train Epoch: 0, mini-batch 1390 of 25000, training loss: 0.172541\n",
      "Train Epoch: 0, mini-batch 1400 of 25000, training loss: 0.669641\n",
      "Train Epoch: 0, mini-batch 1410 of 25000, training loss: 0.342450\n",
      "Train Epoch: 0, mini-batch 1420 of 25000, training loss: 0.390328\n",
      "Train Epoch: 0, mini-batch 1430 of 25000, training loss: 0.126586\n",
      "Train Epoch: 0, mini-batch 1440 of 25000, training loss: 0.506219\n",
      "Train Epoch: 0, mini-batch 1450 of 25000, training loss: 0.118727\n",
      "Train Epoch: 0, mini-batch 1460 of 25000, training loss: 0.251418\n",
      "Train Epoch: 0, mini-batch 1470 of 25000, training loss: 0.076189\n",
      "Train Epoch: 0, mini-batch 1480 of 25000, training loss: 0.016424\n",
      "Train Epoch: 0, mini-batch 1490 of 25000, training loss: 0.156109\n",
      "Train Epoch: 0, mini-batch 1500 of 25000, training loss: 0.043361\n",
      "Train Epoch: 0, mini-batch 1510 of 25000, training loss: 0.101089\n",
      "Train Epoch: 0, mini-batch 1520 of 25000, training loss: 0.159310\n",
      "Train Epoch: 0, mini-batch 1530 of 25000, training loss: 0.221438\n",
      "Train Epoch: 0, mini-batch 1540 of 25000, training loss: 0.480875\n",
      "Train Epoch: 0, mini-batch 1550 of 25000, training loss: 0.269041\n",
      "Train Epoch: 0, mini-batch 1560 of 25000, training loss: 0.821128\n",
      "Train Epoch: 0, mini-batch 1570 of 25000, training loss: 0.920438\n",
      "Train Epoch: 0, mini-batch 1580 of 25000, training loss: 1.183039\n",
      "Train Epoch: 0, mini-batch 1590 of 25000, training loss: 0.420161\n",
      "Train Epoch: 0, mini-batch 1600 of 25000, training loss: 0.027088\n",
      "Train Epoch: 0, mini-batch 1610 of 25000, training loss: 0.134918\n",
      "Train Epoch: 0, mini-batch 1620 of 25000, training loss: 0.464242\n",
      "Train Epoch: 0, mini-batch 1630 of 25000, training loss: 0.060370\n",
      "Train Epoch: 0, mini-batch 1640 of 25000, training loss: 0.074456\n",
      "Train Epoch: 0, mini-batch 1650 of 25000, training loss: 0.786008\n",
      "Train Epoch: 0, mini-batch 1660 of 25000, training loss: 0.180939\n",
      "Train Epoch: 0, mini-batch 1670 of 25000, training loss: 0.082325\n",
      "Train Epoch: 0, mini-batch 1680 of 25000, training loss: 0.143099\n",
      "Train Epoch: 0, mini-batch 1690 of 25000, training loss: 0.099595\n",
      "Train Epoch: 0, mini-batch 1700 of 25000, training loss: 0.090932\n",
      "Train Epoch: 0, mini-batch 1710 of 25000, training loss: 0.759123\n",
      "Train Epoch: 0, mini-batch 1720 of 25000, training loss: 0.123452\n",
      "Train Epoch: 0, mini-batch 1730 of 25000, training loss: 0.555885\n",
      "Train Epoch: 0, mini-batch 1740 of 25000, training loss: 0.237153\n",
      "Train Epoch: 0, mini-batch 1750 of 25000, training loss: 0.075104\n",
      "Train Epoch: 0, mini-batch 1760 of 25000, training loss: 0.015598\n",
      "Train Epoch: 0, mini-batch 1770 of 25000, training loss: 0.849106\n",
      "Train Epoch: 0, mini-batch 1780 of 25000, training loss: 0.400872\n",
      "Train Epoch: 0, mini-batch 1790 of 25000, training loss: 0.059894\n",
      "Train Epoch: 0, mini-batch 1800 of 25000, training loss: 0.068220\n",
      "Train Epoch: 0, mini-batch 1810 of 25000, training loss: 0.262422\n",
      "Train Epoch: 0, mini-batch 1820 of 25000, training loss: 0.792808\n",
      "Train Epoch: 0, mini-batch 1830 of 25000, training loss: 0.075371\n",
      "Train Epoch: 0, mini-batch 1840 of 25000, training loss: 0.827366\n",
      "Train Epoch: 0, mini-batch 1850 of 25000, training loss: 1.118204\n",
      "Train Epoch: 0, mini-batch 1860 of 25000, training loss: 0.175055\n",
      "Train Epoch: 0, mini-batch 1870 of 25000, training loss: 0.501937\n",
      "Train Epoch: 0, mini-batch 1880 of 25000, training loss: 2.221830\n",
      "Train Epoch: 0, mini-batch 1890 of 25000, training loss: 0.212075\n",
      "Train Epoch: 0, mini-batch 1900 of 25000, training loss: 0.407122\n",
      "Train Epoch: 0, mini-batch 1910 of 25000, training loss: 0.227329\n",
      "Train Epoch: 0, mini-batch 1920 of 25000, training loss: 0.106716\n",
      "Train Epoch: 0, mini-batch 1930 of 25000, training loss: 0.089143\n",
      "Train Epoch: 0, mini-batch 1940 of 25000, training loss: 0.023956\n",
      "Train Epoch: 0, mini-batch 1950 of 25000, training loss: 0.252462\n",
      "Train Epoch: 0, mini-batch 1960 of 25000, training loss: 0.145168\n",
      "Train Epoch: 0, mini-batch 1970 of 25000, training loss: 0.071665\n",
      "Train Epoch: 0, mini-batch 1980 of 25000, training loss: 1.441595\n",
      "Train Epoch: 0, mini-batch 1990 of 25000, training loss: 0.130462\n",
      "Train Epoch: 0, mini-batch 2000 of 25000, training loss: 0.170408\n",
      "Train Epoch: 0, mini-batch 2010 of 25000, training loss: 0.042534\n",
      "Train Epoch: 0, mini-batch 2020 of 25000, training loss: 1.049944\n",
      "Train Epoch: 0, mini-batch 2030 of 25000, training loss: 0.043765\n",
      "Train Epoch: 0, mini-batch 2040 of 25000, training loss: 0.012388\n",
      "Train Epoch: 0, mini-batch 2050 of 25000, training loss: 0.280720\n",
      "Train Epoch: 0, mini-batch 2060 of 25000, training loss: 0.223548\n",
      "Train Epoch: 0, mini-batch 2070 of 25000, training loss: 0.008803\n",
      "Train Epoch: 0, mini-batch 2080 of 25000, training loss: 0.153029\n",
      "Train Epoch: 0, mini-batch 2090 of 25000, training loss: 0.085493\n",
      "Train Epoch: 0, mini-batch 2100 of 25000, training loss: 0.169190\n",
      "Train Epoch: 0, mini-batch 2110 of 25000, training loss: 0.048652\n",
      "Train Epoch: 0, mini-batch 2120 of 25000, training loss: 0.062166\n",
      "Train Epoch: 0, mini-batch 2130 of 25000, training loss: 0.708109\n",
      "Train Epoch: 0, mini-batch 2140 of 25000, training loss: 0.100033\n",
      "Train Epoch: 0, mini-batch 2150 of 25000, training loss: 0.030672\n",
      "Train Epoch: 0, mini-batch 2160 of 25000, training loss: 0.131161\n",
      "Train Epoch: 0, mini-batch 2170 of 25000, training loss: 0.125044\n",
      "Train Epoch: 0, mini-batch 2180 of 25000, training loss: 0.263985\n",
      "Train Epoch: 0, mini-batch 2190 of 25000, training loss: 2.963578\n",
      "Train Epoch: 0, mini-batch 2200 of 25000, training loss: 0.799763\n",
      "Train Epoch: 0, mini-batch 2210 of 25000, training loss: 0.069005\n",
      "Train Epoch: 0, mini-batch 2220 of 25000, training loss: 0.231476\n",
      "Train Epoch: 0, mini-batch 2230 of 25000, training loss: 0.509260\n",
      "Train Epoch: 0, mini-batch 2240 of 25000, training loss: 0.451854\n",
      "Train Epoch: 0, mini-batch 2250 of 25000, training loss: 0.038595\n",
      "Train Epoch: 0, mini-batch 2260 of 25000, training loss: 0.275693\n",
      "Train Epoch: 0, mini-batch 2270 of 25000, training loss: 1.219566\n",
      "Train Epoch: 0, mini-batch 2280 of 25000, training loss: 0.141291\n",
      "Train Epoch: 0, mini-batch 2290 of 25000, training loss: 1.624347\n",
      "Train Epoch: 0, mini-batch 2300 of 25000, training loss: 0.663798\n",
      "Train Epoch: 0, mini-batch 2310 of 25000, training loss: 0.686060\n",
      "Train Epoch: 0, mini-batch 2320 of 25000, training loss: 0.122980\n",
      "Train Epoch: 0, mini-batch 2330 of 25000, training loss: 0.284864\n",
      "Train Epoch: 0, mini-batch 2340 of 25000, training loss: 0.096953\n",
      "Train Epoch: 0, mini-batch 2350 of 25000, training loss: 1.519442\n",
      "Train Epoch: 0, mini-batch 2360 of 25000, training loss: 0.976978\n",
      "Train Epoch: 0, mini-batch 2370 of 25000, training loss: 1.286805\n",
      "Train Epoch: 0, mini-batch 2380 of 25000, training loss: 0.121617\n",
      "Train Epoch: 0, mini-batch 2390 of 25000, training loss: 0.622917\n",
      "Train Epoch: 0, mini-batch 2400 of 25000, training loss: 2.251157\n",
      "Train Epoch: 0, mini-batch 2410 of 25000, training loss: 1.082021\n",
      "Train Epoch: 0, mini-batch 2420 of 25000, training loss: 0.067544\n",
      "Train Epoch: 0, mini-batch 2430 of 25000, training loss: 0.868562\n",
      "Train Epoch: 0, mini-batch 2440 of 25000, training loss: 0.040748\n",
      "Train Epoch: 0, mini-batch 2450 of 25000, training loss: 0.200384\n",
      "Train Epoch: 0, mini-batch 2460 of 25000, training loss: 0.868267\n",
      "Train Epoch: 0, mini-batch 2470 of 25000, training loss: 1.059646\n",
      "Train Epoch: 0, mini-batch 2480 of 25000, training loss: 0.027450\n",
      "Train Epoch: 0, mini-batch 2490 of 25000, training loss: 0.335887\n",
      "Train Epoch: 0, mini-batch 2500 of 25000, training loss: 1.020399\n",
      "Train Epoch: 0, mini-batch 2510 of 25000, training loss: 1.763810\n",
      "Train Epoch: 0, mini-batch 2520 of 25000, training loss: 0.078913\n",
      "Train Epoch: 0, mini-batch 2530 of 25000, training loss: 0.512090\n",
      "Train Epoch: 0, mini-batch 2540 of 25000, training loss: 3.678946\n",
      "Train Epoch: 0, mini-batch 2550 of 25000, training loss: 0.172902\n",
      "Train Epoch: 0, mini-batch 2560 of 25000, training loss: 0.075234\n",
      "Train Epoch: 0, mini-batch 2570 of 25000, training loss: 0.564367\n",
      "Train Epoch: 0, mini-batch 2580 of 25000, training loss: 0.264391\n",
      "Train Epoch: 0, mini-batch 2590 of 25000, training loss: 1.392934\n",
      "Train Epoch: 0, mini-batch 2600 of 25000, training loss: 0.837295\n",
      "Train Epoch: 0, mini-batch 2610 of 25000, training loss: 0.569942\n",
      "Train Epoch: 0, mini-batch 2620 of 25000, training loss: 0.032557\n",
      "Train Epoch: 0, mini-batch 2630 of 25000, training loss: 0.255715\n",
      "Train Epoch: 0, mini-batch 2640 of 25000, training loss: 0.000341\n",
      "Train Epoch: 0, mini-batch 2650 of 25000, training loss: 1.681459\n",
      "Train Epoch: 0, mini-batch 2660 of 25000, training loss: 0.089072\n",
      "Train Epoch: 0, mini-batch 2670 of 25000, training loss: 0.180397\n",
      "Train Epoch: 0, mini-batch 2680 of 25000, training loss: 0.106953\n",
      "Train Epoch: 0, mini-batch 2690 of 25000, training loss: 1.307421\n",
      "Train Epoch: 0, mini-batch 2700 of 25000, training loss: 0.125658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 2710 of 25000, training loss: 0.432132\n",
      "Train Epoch: 0, mini-batch 2720 of 25000, training loss: 0.009024\n",
      "Train Epoch: 0, mini-batch 2730 of 25000, training loss: 0.371265\n",
      "Train Epoch: 0, mini-batch 2740 of 25000, training loss: 0.578765\n",
      "Train Epoch: 0, mini-batch 2750 of 25000, training loss: 0.077705\n",
      "Train Epoch: 0, mini-batch 2760 of 25000, training loss: 0.277328\n",
      "Train Epoch: 0, mini-batch 2770 of 25000, training loss: 0.450903\n",
      "Train Epoch: 0, mini-batch 2780 of 25000, training loss: 0.019599\n",
      "Train Epoch: 0, mini-batch 2790 of 25000, training loss: 0.147169\n",
      "Train Epoch: 0, mini-batch 2800 of 25000, training loss: 0.181916\n",
      "Train Epoch: 0, mini-batch 2810 of 25000, training loss: 0.348726\n",
      "Train Epoch: 0, mini-batch 2820 of 25000, training loss: 1.184747\n",
      "Train Epoch: 0, mini-batch 2830 of 25000, training loss: 0.094559\n",
      "Train Epoch: 0, mini-batch 2840 of 25000, training loss: 0.043091\n",
      "Train Epoch: 0, mini-batch 2850 of 25000, training loss: 0.182814\n",
      "Train Epoch: 0, mini-batch 2860 of 25000, training loss: 0.137624\n",
      "Train Epoch: 0, mini-batch 2870 of 25000, training loss: 0.079748\n",
      "Train Epoch: 0, mini-batch 2880 of 25000, training loss: 0.261189\n",
      "Train Epoch: 0, mini-batch 2890 of 25000, training loss: 0.019835\n",
      "Train Epoch: 0, mini-batch 2900 of 25000, training loss: 0.279054\n",
      "Train Epoch: 0, mini-batch 2910 of 25000, training loss: 0.068681\n",
      "Train Epoch: 0, mini-batch 2920 of 25000, training loss: 0.035926\n",
      "Train Epoch: 0, mini-batch 2930 of 25000, training loss: 1.743763\n",
      "Train Epoch: 0, mini-batch 2940 of 25000, training loss: 0.331211\n",
      "Train Epoch: 0, mini-batch 2950 of 25000, training loss: 0.059861\n",
      "Train Epoch: 0, mini-batch 2960 of 25000, training loss: 0.061953\n",
      "Train Epoch: 0, mini-batch 2970 of 25000, training loss: 0.043327\n",
      "Train Epoch: 0, mini-batch 2980 of 25000, training loss: 1.835278\n",
      "Train Epoch: 0, mini-batch 2990 of 25000, training loss: 0.657277\n",
      "Train Epoch: 0, mini-batch 3000 of 25000, training loss: 0.863515\n",
      "Train Epoch: 0, mini-batch 3010 of 25000, training loss: 0.140037\n",
      "Train Epoch: 0, mini-batch 3020 of 25000, training loss: 0.070450\n",
      "Train Epoch: 0, mini-batch 3030 of 25000, training loss: 0.057342\n",
      "Train Epoch: 0, mini-batch 3040 of 25000, training loss: 0.155524\n",
      "Train Epoch: 0, mini-batch 3050 of 25000, training loss: 0.442486\n",
      "Train Epoch: 0, mini-batch 3060 of 25000, training loss: 0.064612\n",
      "Train Epoch: 0, mini-batch 3070 of 25000, training loss: 0.328728\n",
      "Train Epoch: 0, mini-batch 3080 of 25000, training loss: 0.054552\n",
      "Train Epoch: 0, mini-batch 3090 of 25000, training loss: 0.073572\n",
      "Train Epoch: 0, mini-batch 3100 of 25000, training loss: 1.510799\n",
      "Train Epoch: 0, mini-batch 3110 of 25000, training loss: 0.206855\n",
      "Train Epoch: 0, mini-batch 3120 of 25000, training loss: 0.029614\n",
      "Train Epoch: 0, mini-batch 3130 of 25000, training loss: 0.253091\n",
      "Train Epoch: 0, mini-batch 3140 of 25000, training loss: 0.097984\n",
      "Train Epoch: 0, mini-batch 3150 of 25000, training loss: 0.020578\n",
      "Train Epoch: 0, mini-batch 3160 of 25000, training loss: 0.751938\n",
      "Train Epoch: 0, mini-batch 3170 of 25000, training loss: 0.518507\n",
      "Train Epoch: 0, mini-batch 3180 of 25000, training loss: 0.080229\n",
      "Train Epoch: 0, mini-batch 3190 of 25000, training loss: 0.526310\n",
      "Train Epoch: 0, mini-batch 3200 of 25000, training loss: 0.119069\n",
      "Train Epoch: 0, mini-batch 3210 of 25000, training loss: 0.047584\n",
      "Train Epoch: 0, mini-batch 3220 of 25000, training loss: 0.125466\n",
      "Train Epoch: 0, mini-batch 3230 of 25000, training loss: 1.288506\n",
      "Train Epoch: 0, mini-batch 3240 of 25000, training loss: 0.039436\n",
      "Train Epoch: 0, mini-batch 3250 of 25000, training loss: 0.085612\n",
      "Train Epoch: 0, mini-batch 3260 of 25000, training loss: 0.413041\n",
      "Train Epoch: 0, mini-batch 3270 of 25000, training loss: 0.007977\n",
      "Train Epoch: 0, mini-batch 3280 of 25000, training loss: 0.146447\n",
      "Train Epoch: 0, mini-batch 3290 of 25000, training loss: 0.071930\n",
      "Train Epoch: 0, mini-batch 3300 of 25000, training loss: 1.149166\n",
      "Train Epoch: 0, mini-batch 3310 of 25000, training loss: 0.068140\n",
      "Train Epoch: 0, mini-batch 3320 of 25000, training loss: 0.004094\n",
      "Train Epoch: 0, mini-batch 3330 of 25000, training loss: 0.060144\n",
      "Train Epoch: 0, mini-batch 3340 of 25000, training loss: 0.083276\n",
      "Train Epoch: 0, mini-batch 3350 of 25000, training loss: 0.007326\n",
      "Train Epoch: 0, mini-batch 3360 of 25000, training loss: 0.001471\n",
      "Train Epoch: 0, mini-batch 3370 of 25000, training loss: 0.055074\n",
      "Train Epoch: 0, mini-batch 3380 of 25000, training loss: 0.157966\n",
      "Train Epoch: 0, mini-batch 3390 of 25000, training loss: 0.137543\n",
      "Train Epoch: 0, mini-batch 3400 of 25000, training loss: 0.199424\n",
      "Train Epoch: 0, mini-batch 3410 of 25000, training loss: 0.148472\n",
      "Train Epoch: 0, mini-batch 3420 of 25000, training loss: 0.138501\n",
      "Train Epoch: 0, mini-batch 3430 of 25000, training loss: 0.008992\n",
      "Train Epoch: 0, mini-batch 3440 of 25000, training loss: 0.075413\n",
      "Train Epoch: 0, mini-batch 3450 of 25000, training loss: 0.048948\n",
      "Train Epoch: 0, mini-batch 3460 of 25000, training loss: 2.834974\n",
      "Train Epoch: 0, mini-batch 3470 of 25000, training loss: 0.055152\n",
      "Train Epoch: 0, mini-batch 3480 of 25000, training loss: 0.069890\n",
      "Train Epoch: 0, mini-batch 3490 of 25000, training loss: 0.080111\n",
      "Train Epoch: 0, mini-batch 3500 of 25000, training loss: 0.964443\n",
      "Train Epoch: 0, mini-batch 3510 of 25000, training loss: 0.502472\n",
      "Train Epoch: 0, mini-batch 3520 of 25000, training loss: 1.592635\n",
      "Train Epoch: 0, mini-batch 3530 of 25000, training loss: 0.590067\n",
      "Train Epoch: 0, mini-batch 3540 of 25000, training loss: 0.080507\n",
      "Train Epoch: 0, mini-batch 3550 of 25000, training loss: 0.024722\n",
      "Train Epoch: 0, mini-batch 3560 of 25000, training loss: 0.047046\n",
      "Train Epoch: 0, mini-batch 3570 of 25000, training loss: 1.477055\n",
      "Train Epoch: 0, mini-batch 3580 of 25000, training loss: 0.469861\n",
      "Train Epoch: 0, mini-batch 3590 of 25000, training loss: 0.339254\n",
      "Train Epoch: 0, mini-batch 3600 of 25000, training loss: 0.125613\n",
      "Train Epoch: 0, mini-batch 3610 of 25000, training loss: 0.736299\n",
      "Train Epoch: 0, mini-batch 3620 of 25000, training loss: 0.075324\n",
      "Train Epoch: 0, mini-batch 3630 of 25000, training loss: 0.050739\n",
      "Train Epoch: 0, mini-batch 3640 of 25000, training loss: 0.835228\n",
      "Train Epoch: 0, mini-batch 3650 of 25000, training loss: 3.844493\n",
      "Train Epoch: 0, mini-batch 3660 of 25000, training loss: 0.059978\n",
      "Train Epoch: 0, mini-batch 3670 of 25000, training loss: 0.051978\n",
      "Train Epoch: 0, mini-batch 3680 of 25000, training loss: 0.140845\n",
      "Train Epoch: 0, mini-batch 3690 of 25000, training loss: 1.004739\n",
      "Train Epoch: 0, mini-batch 3700 of 25000, training loss: 3.693288\n",
      "Train Epoch: 0, mini-batch 3710 of 25000, training loss: 0.319699\n",
      "Train Epoch: 0, mini-batch 3720 of 25000, training loss: 0.085387\n",
      "Train Epoch: 0, mini-batch 3730 of 25000, training loss: 0.082371\n",
      "Train Epoch: 0, mini-batch 3740 of 25000, training loss: 0.909725\n",
      "Train Epoch: 0, mini-batch 3750 of 25000, training loss: 2.058203\n",
      "Train Epoch: 0, mini-batch 3760 of 25000, training loss: 0.033530\n",
      "Train Epoch: 0, mini-batch 3770 of 25000, training loss: 0.154785\n",
      "Train Epoch: 0, mini-batch 3780 of 25000, training loss: 0.117498\n",
      "Train Epoch: 0, mini-batch 3790 of 25000, training loss: 2.013545\n",
      "Train Epoch: 0, mini-batch 3800 of 25000, training loss: 0.756677\n",
      "Train Epoch: 0, mini-batch 3810 of 25000, training loss: 0.134948\n",
      "Train Epoch: 0, mini-batch 3820 of 25000, training loss: 0.202001\n",
      "Train Epoch: 0, mini-batch 3830 of 25000, training loss: 0.071029\n",
      "Train Epoch: 0, mini-batch 3840 of 25000, training loss: 0.794975\n",
      "Train Epoch: 0, mini-batch 3850 of 25000, training loss: 0.119131\n",
      "Train Epoch: 0, mini-batch 3860 of 25000, training loss: 0.469036\n",
      "Train Epoch: 0, mini-batch 3870 of 25000, training loss: 0.863953\n",
      "Train Epoch: 0, mini-batch 3880 of 25000, training loss: 0.013365\n",
      "Train Epoch: 0, mini-batch 3890 of 25000, training loss: 0.158804\n",
      "Train Epoch: 0, mini-batch 3900 of 25000, training loss: 0.025683\n",
      "Train Epoch: 0, mini-batch 3910 of 25000, training loss: 1.336832\n",
      "Train Epoch: 0, mini-batch 3920 of 25000, training loss: 0.172246\n",
      "Train Epoch: 0, mini-batch 3930 of 25000, training loss: 1.062986\n",
      "Train Epoch: 0, mini-batch 3940 of 25000, training loss: 0.031386\n",
      "Train Epoch: 0, mini-batch 3950 of 25000, training loss: 0.507972\n",
      "Train Epoch: 0, mini-batch 3960 of 25000, training loss: 0.045982\n",
      "Train Epoch: 0, mini-batch 3970 of 25000, training loss: 0.046299\n",
      "Train Epoch: 0, mini-batch 3980 of 25000, training loss: 0.031528\n",
      "Train Epoch: 0, mini-batch 3990 of 25000, training loss: 1.612645\n",
      "Train Epoch: 0, mini-batch 4000 of 25000, training loss: 0.780811\n",
      "Train Epoch: 0, mini-batch 4010 of 25000, training loss: 1.098417\n",
      "Train Epoch: 0, mini-batch 4020 of 25000, training loss: 0.222708\n",
      "Train Epoch: 0, mini-batch 4030 of 25000, training loss: 0.017613\n",
      "Train Epoch: 0, mini-batch 4040 of 25000, training loss: 0.086995\n",
      "Train Epoch: 0, mini-batch 4050 of 25000, training loss: 0.013640\n",
      "Train Epoch: 0, mini-batch 4060 of 25000, training loss: 0.501349\n",
      "Train Epoch: 0, mini-batch 4070 of 25000, training loss: 0.343201\n",
      "Train Epoch: 0, mini-batch 4080 of 25000, training loss: 0.044564\n",
      "Train Epoch: 0, mini-batch 4090 of 25000, training loss: 2.035727\n",
      "Train Epoch: 0, mini-batch 4100 of 25000, training loss: 0.131548\n",
      "Train Epoch: 0, mini-batch 4110 of 25000, training loss: 1.137479\n",
      "Train Epoch: 0, mini-batch 4120 of 25000, training loss: 0.105684\n",
      "Train Epoch: 0, mini-batch 4130 of 25000, training loss: 0.349206\n",
      "Train Epoch: 0, mini-batch 4140 of 25000, training loss: 0.051288\n",
      "Train Epoch: 0, mini-batch 4150 of 25000, training loss: 0.081796\n",
      "Train Epoch: 0, mini-batch 4160 of 25000, training loss: 0.025518\n",
      "Train Epoch: 0, mini-batch 4170 of 25000, training loss: 0.547478\n",
      "Train Epoch: 0, mini-batch 4180 of 25000, training loss: 0.028638\n",
      "Train Epoch: 0, mini-batch 4190 of 25000, training loss: 1.672314\n",
      "Train Epoch: 0, mini-batch 4200 of 25000, training loss: 0.065930\n",
      "Train Epoch: 0, mini-batch 4210 of 25000, training loss: 0.007586\n",
      "Train Epoch: 0, mini-batch 4220 of 25000, training loss: 0.195957\n",
      "Train Epoch: 0, mini-batch 4230 of 25000, training loss: 0.328727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 4240 of 25000, training loss: 0.375515\n",
      "Train Epoch: 0, mini-batch 4250 of 25000, training loss: 0.118049\n",
      "Train Epoch: 0, mini-batch 4260 of 25000, training loss: 0.075126\n",
      "Train Epoch: 0, mini-batch 4270 of 25000, training loss: 0.578917\n",
      "Train Epoch: 0, mini-batch 4280 of 25000, training loss: 0.103251\n",
      "Train Epoch: 0, mini-batch 4290 of 25000, training loss: 0.177213\n",
      "Train Epoch: 0, mini-batch 4300 of 25000, training loss: 0.086183\n",
      "Train Epoch: 0, mini-batch 4310 of 25000, training loss: 0.114434\n",
      "Train Epoch: 0, mini-batch 4320 of 25000, training loss: 0.006419\n",
      "Train Epoch: 0, mini-batch 4330 of 25000, training loss: 0.808411\n",
      "Train Epoch: 0, mini-batch 4340 of 25000, training loss: 1.847954\n",
      "Train Epoch: 0, mini-batch 4350 of 25000, training loss: 0.055592\n",
      "Train Epoch: 0, mini-batch 4360 of 25000, training loss: 0.068986\n",
      "Train Epoch: 0, mini-batch 4370 of 25000, training loss: 0.694376\n",
      "Train Epoch: 0, mini-batch 4380 of 25000, training loss: 0.534204\n",
      "Train Epoch: 0, mini-batch 4390 of 25000, training loss: 0.127222\n",
      "Train Epoch: 0, mini-batch 4400 of 25000, training loss: 0.360508\n",
      "Train Epoch: 0, mini-batch 4410 of 25000, training loss: 0.064231\n",
      "Train Epoch: 0, mini-batch 4420 of 25000, training loss: 0.027369\n",
      "Train Epoch: 0, mini-batch 4430 of 25000, training loss: 0.000457\n",
      "Train Epoch: 0, mini-batch 4440 of 25000, training loss: 0.086811\n",
      "Train Epoch: 0, mini-batch 4450 of 25000, training loss: 0.005482\n",
      "Train Epoch: 0, mini-batch 4460 of 25000, training loss: 0.950502\n",
      "Train Epoch: 0, mini-batch 4470 of 25000, training loss: 0.018749\n",
      "Train Epoch: 0, mini-batch 4480 of 25000, training loss: 0.426480\n",
      "Train Epoch: 0, mini-batch 4490 of 25000, training loss: 0.034632\n",
      "Train Epoch: 0, mini-batch 4500 of 25000, training loss: 0.007328\n",
      "Train Epoch: 0, mini-batch 4510 of 25000, training loss: 0.511476\n",
      "Train Epoch: 0, mini-batch 4520 of 25000, training loss: 0.273318\n",
      "Train Epoch: 0, mini-batch 4530 of 25000, training loss: 0.169601\n",
      "Train Epoch: 0, mini-batch 4540 of 25000, training loss: 3.096744\n",
      "Train Epoch: 0, mini-batch 4550 of 25000, training loss: 1.557461\n",
      "Train Epoch: 0, mini-batch 4560 of 25000, training loss: 0.107148\n",
      "Train Epoch: 0, mini-batch 4570 of 25000, training loss: 0.112820\n",
      "Train Epoch: 0, mini-batch 4580 of 25000, training loss: 0.565576\n",
      "Train Epoch: 0, mini-batch 4590 of 25000, training loss: 0.941725\n",
      "Train Epoch: 0, mini-batch 4600 of 25000, training loss: 0.025710\n",
      "Train Epoch: 0, mini-batch 4610 of 25000, training loss: 0.011666\n",
      "Train Epoch: 0, mini-batch 4620 of 25000, training loss: 0.058989\n",
      "Train Epoch: 0, mini-batch 4630 of 25000, training loss: 0.221820\n",
      "Train Epoch: 0, mini-batch 4640 of 25000, training loss: 0.979824\n",
      "Train Epoch: 0, mini-batch 4650 of 25000, training loss: 0.309126\n",
      "Train Epoch: 0, mini-batch 4660 of 25000, training loss: 0.051225\n",
      "Train Epoch: 0, mini-batch 4670 of 25000, training loss: 0.115667\n",
      "Train Epoch: 0, mini-batch 4680 of 25000, training loss: 0.351574\n",
      "Train Epoch: 0, mini-batch 4690 of 25000, training loss: 0.262468\n",
      "Train Epoch: 0, mini-batch 4700 of 25000, training loss: 0.071481\n",
      "Train Epoch: 0, mini-batch 4710 of 25000, training loss: 0.496068\n",
      "Train Epoch: 0, mini-batch 4720 of 25000, training loss: 0.468511\n",
      "Train Epoch: 0, mini-batch 4730 of 25000, training loss: 2.102845\n",
      "Train Epoch: 0, mini-batch 4740 of 25000, training loss: 0.088654\n",
      "Train Epoch: 0, mini-batch 4750 of 25000, training loss: 0.172442\n",
      "Train Epoch: 0, mini-batch 4760 of 25000, training loss: 0.007268\n",
      "Train Epoch: 0, mini-batch 4770 of 25000, training loss: 0.078000\n",
      "Train Epoch: 0, mini-batch 4780 of 25000, training loss: 0.188455\n",
      "Train Epoch: 0, mini-batch 4790 of 25000, training loss: 2.439769\n",
      "Train Epoch: 0, mini-batch 4800 of 25000, training loss: 0.183898\n",
      "Train Epoch: 0, mini-batch 4810 of 25000, training loss: 0.091382\n",
      "Train Epoch: 0, mini-batch 4820 of 25000, training loss: 0.178932\n",
      "Train Epoch: 0, mini-batch 4830 of 25000, training loss: 0.583444\n",
      "Train Epoch: 0, mini-batch 4840 of 25000, training loss: 0.249442\n",
      "Train Epoch: 0, mini-batch 4850 of 25000, training loss: 0.095367\n",
      "Train Epoch: 0, mini-batch 4860 of 25000, training loss: 0.169914\n",
      "Train Epoch: 0, mini-batch 4870 of 25000, training loss: 0.393010\n",
      "Train Epoch: 0, mini-batch 4880 of 25000, training loss: 0.679113\n",
      "Train Epoch: 0, mini-batch 4890 of 25000, training loss: 0.358367\n",
      "Train Epoch: 0, mini-batch 4900 of 25000, training loss: 0.099927\n",
      "Train Epoch: 0, mini-batch 4910 of 25000, training loss: 1.052329\n",
      "Train Epoch: 0, mini-batch 4920 of 25000, training loss: 0.015313\n",
      "Train Epoch: 0, mini-batch 4930 of 25000, training loss: 0.052023\n",
      "Train Epoch: 0, mini-batch 4940 of 25000, training loss: 0.549141\n",
      "Train Epoch: 0, mini-batch 4950 of 25000, training loss: 2.455142\n",
      "Train Epoch: 0, mini-batch 4960 of 25000, training loss: 0.098591\n",
      "Train Epoch: 0, mini-batch 4970 of 25000, training loss: 0.251812\n",
      "Train Epoch: 0, mini-batch 4980 of 25000, training loss: 0.033263\n",
      "Train Epoch: 0, mini-batch 4990 of 25000, training loss: 1.467793\n",
      "Train Epoch: 0, mini-batch 5000 of 25000, training loss: 0.081141\n",
      "Train Epoch: 0, mini-batch 5010 of 25000, training loss: 0.335165\n",
      "Train Epoch: 0, mini-batch 5020 of 25000, training loss: 0.007547\n",
      "Train Epoch: 0, mini-batch 5030 of 25000, training loss: 0.636324\n",
      "Train Epoch: 0, mini-batch 5040 of 25000, training loss: 0.007607\n",
      "Train Epoch: 0, mini-batch 5050 of 25000, training loss: 0.100424\n",
      "Train Epoch: 0, mini-batch 5060 of 25000, training loss: 0.018939\n",
      "Train Epoch: 0, mini-batch 5070 of 25000, training loss: 0.126335\n",
      "Train Epoch: 0, mini-batch 5080 of 25000, training loss: 0.042060\n",
      "Train Epoch: 0, mini-batch 5090 of 25000, training loss: 0.032545\n",
      "Train Epoch: 0, mini-batch 5100 of 25000, training loss: 1.491827\n",
      "Train Epoch: 0, mini-batch 5110 of 25000, training loss: 1.632705\n",
      "Train Epoch: 0, mini-batch 5120 of 25000, training loss: 0.116954\n",
      "Train Epoch: 0, mini-batch 5130 of 25000, training loss: 0.182387\n",
      "Train Epoch: 0, mini-batch 5140 of 25000, training loss: 0.258168\n",
      "Train Epoch: 0, mini-batch 5150 of 25000, training loss: 0.051576\n",
      "Train Epoch: 0, mini-batch 5160 of 25000, training loss: 0.020429\n",
      "Train Epoch: 0, mini-batch 5170 of 25000, training loss: 0.835972\n",
      "Train Epoch: 0, mini-batch 5180 of 25000, training loss: 0.053775\n",
      "Train Epoch: 0, mini-batch 5190 of 25000, training loss: 0.076787\n",
      "Train Epoch: 0, mini-batch 5200 of 25000, training loss: 0.658789\n",
      "Train Epoch: 0, mini-batch 5210 of 25000, training loss: 0.677927\n",
      "Train Epoch: 0, mini-batch 5220 of 25000, training loss: 0.363396\n",
      "Train Epoch: 0, mini-batch 5230 of 25000, training loss: 0.007175\n",
      "Train Epoch: 0, mini-batch 5240 of 25000, training loss: 0.094751\n",
      "Train Epoch: 0, mini-batch 5250 of 25000, training loss: 0.343102\n",
      "Train Epoch: 0, mini-batch 5260 of 25000, training loss: 0.053529\n",
      "Train Epoch: 0, mini-batch 5270 of 25000, training loss: 0.351276\n",
      "Train Epoch: 0, mini-batch 5280 of 25000, training loss: 0.015829\n",
      "Train Epoch: 0, mini-batch 5290 of 25000, training loss: 0.156623\n",
      "Train Epoch: 0, mini-batch 5300 of 25000, training loss: 0.144118\n",
      "Train Epoch: 0, mini-batch 5310 of 25000, training loss: 0.011682\n",
      "Train Epoch: 0, mini-batch 5320 of 25000, training loss: 0.010197\n",
      "Train Epoch: 0, mini-batch 5330 of 25000, training loss: 0.039763\n",
      "Train Epoch: 0, mini-batch 5340 of 25000, training loss: 1.357418\n",
      "Train Epoch: 0, mini-batch 5350 of 25000, training loss: 0.688657\n",
      "Train Epoch: 0, mini-batch 5360 of 25000, training loss: 0.575175\n",
      "Train Epoch: 0, mini-batch 5370 of 25000, training loss: 0.117151\n",
      "Train Epoch: 0, mini-batch 5380 of 25000, training loss: 0.021494\n",
      "Train Epoch: 0, mini-batch 5390 of 25000, training loss: 0.038889\n",
      "Train Epoch: 0, mini-batch 5400 of 25000, training loss: 0.164997\n",
      "Train Epoch: 0, mini-batch 5410 of 25000, training loss: 0.128564\n",
      "Train Epoch: 0, mini-batch 5420 of 25000, training loss: 1.119773\n",
      "Train Epoch: 0, mini-batch 5430 of 25000, training loss: 0.063931\n",
      "Train Epoch: 0, mini-batch 5440 of 25000, training loss: 0.110997\n",
      "Train Epoch: 0, mini-batch 5450 of 25000, training loss: 0.223071\n",
      "Train Epoch: 0, mini-batch 5460 of 25000, training loss: 2.047160\n",
      "Train Epoch: 0, mini-batch 5470 of 25000, training loss: 0.538947\n",
      "Train Epoch: 0, mini-batch 5480 of 25000, training loss: 0.031971\n",
      "Train Epoch: 0, mini-batch 5490 of 25000, training loss: 0.026213\n",
      "Train Epoch: 0, mini-batch 5500 of 25000, training loss: 0.036776\n",
      "Train Epoch: 0, mini-batch 5510 of 25000, training loss: 0.057071\n",
      "Train Epoch: 0, mini-batch 5520 of 25000, training loss: 0.070544\n",
      "Train Epoch: 0, mini-batch 5530 of 25000, training loss: 0.109446\n",
      "Train Epoch: 0, mini-batch 5540 of 25000, training loss: 0.010461\n",
      "Train Epoch: 0, mini-batch 5550 of 25000, training loss: 0.104756\n",
      "Train Epoch: 0, mini-batch 5560 of 25000, training loss: 0.109591\n",
      "Train Epoch: 0, mini-batch 5570 of 25000, training loss: 0.396353\n",
      "Train Epoch: 0, mini-batch 5580 of 25000, training loss: 0.063088\n",
      "Train Epoch: 0, mini-batch 5590 of 25000, training loss: 0.070968\n",
      "Train Epoch: 0, mini-batch 5600 of 25000, training loss: 0.160122\n",
      "Train Epoch: 0, mini-batch 5610 of 25000, training loss: 0.978780\n",
      "Train Epoch: 0, mini-batch 5620 of 25000, training loss: 0.156053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 5630 of 25000, training loss: 0.035715\n",
      "Train Epoch: 0, mini-batch 5640 of 25000, training loss: 0.007826\n",
      "Train Epoch: 0, mini-batch 5650 of 25000, training loss: 0.055135\n",
      "Train Epoch: 0, mini-batch 5660 of 25000, training loss: 0.030104\n",
      "Train Epoch: 0, mini-batch 5670 of 25000, training loss: 0.057552\n",
      "Train Epoch: 0, mini-batch 5680 of 25000, training loss: 0.167198\n",
      "Train Epoch: 0, mini-batch 5690 of 25000, training loss: 0.440067\n",
      "Train Epoch: 0, mini-batch 5700 of 25000, training loss: 0.168357\n",
      "Train Epoch: 0, mini-batch 5710 of 25000, training loss: 0.633475\n",
      "Train Epoch: 0, mini-batch 5720 of 25000, training loss: 0.122149\n",
      "Train Epoch: 0, mini-batch 5730 of 25000, training loss: 0.058213\n",
      "Train Epoch: 0, mini-batch 5740 of 25000, training loss: 0.122332\n",
      "Train Epoch: 0, mini-batch 5750 of 25000, training loss: 0.037699\n",
      "Train Epoch: 0, mini-batch 5760 of 25000, training loss: 0.031356\n",
      "Train Epoch: 0, mini-batch 5770 of 25000, training loss: 0.068774\n",
      "Train Epoch: 0, mini-batch 5780 of 25000, training loss: 0.046376\n",
      "Train Epoch: 0, mini-batch 5790 of 25000, training loss: 0.218847\n",
      "Train Epoch: 0, mini-batch 5800 of 25000, training loss: 0.026842\n",
      "Train Epoch: 0, mini-batch 5810 of 25000, training loss: 0.031946\n",
      "Train Epoch: 0, mini-batch 5820 of 25000, training loss: 0.294361\n",
      "Train Epoch: 0, mini-batch 5830 of 25000, training loss: 0.119016\n",
      "Train Epoch: 0, mini-batch 5840 of 25000, training loss: 0.089685\n",
      "Train Epoch: 0, mini-batch 5850 of 25000, training loss: 0.267209\n",
      "Train Epoch: 0, mini-batch 5860 of 25000, training loss: 0.247909\n",
      "Train Epoch: 0, mini-batch 5870 of 25000, training loss: 0.500957\n",
      "Train Epoch: 0, mini-batch 5880 of 25000, training loss: 0.622095\n",
      "Train Epoch: 0, mini-batch 5890 of 25000, training loss: 0.034532\n",
      "Train Epoch: 0, mini-batch 5900 of 25000, training loss: 0.025690\n",
      "Train Epoch: 0, mini-batch 5910 of 25000, training loss: 0.213890\n",
      "Train Epoch: 0, mini-batch 5920 of 25000, training loss: 0.048569\n",
      "Train Epoch: 0, mini-batch 5930 of 25000, training loss: 0.116930\n",
      "Train Epoch: 0, mini-batch 5940 of 25000, training loss: 1.171237\n",
      "Train Epoch: 0, mini-batch 5950 of 25000, training loss: 0.004199\n",
      "Train Epoch: 0, mini-batch 5960 of 25000, training loss: 0.993135\n",
      "Train Epoch: 0, mini-batch 5970 of 25000, training loss: 0.051351\n",
      "Train Epoch: 0, mini-batch 5980 of 25000, training loss: 0.037111\n",
      "Train Epoch: 0, mini-batch 5990 of 25000, training loss: 0.091469\n",
      "Train Epoch: 0, mini-batch 6000 of 25000, training loss: 0.029254\n",
      "Train Epoch: 0, mini-batch 6010 of 25000, training loss: 0.159939\n",
      "Train Epoch: 0, mini-batch 6020 of 25000, training loss: 0.222720\n",
      "Train Epoch: 0, mini-batch 6030 of 25000, training loss: 3.162538\n",
      "Train Epoch: 0, mini-batch 6040 of 25000, training loss: 0.162800\n",
      "Train Epoch: 0, mini-batch 6050 of 25000, training loss: 1.015868\n",
      "Train Epoch: 0, mini-batch 6060 of 25000, training loss: 0.039990\n",
      "Train Epoch: 0, mini-batch 6070 of 25000, training loss: 0.222448\n",
      "Train Epoch: 0, mini-batch 6080 of 25000, training loss: 0.636731\n",
      "Train Epoch: 0, mini-batch 6090 of 25000, training loss: 0.397088\n",
      "Train Epoch: 0, mini-batch 6100 of 25000, training loss: 0.097339\n",
      "Train Epoch: 0, mini-batch 6110 of 25000, training loss: 0.045196\n",
      "Train Epoch: 0, mini-batch 6120 of 25000, training loss: 0.089308\n",
      "Train Epoch: 0, mini-batch 6130 of 25000, training loss: 0.041401\n",
      "Train Epoch: 0, mini-batch 6140 of 25000, training loss: 0.035772\n",
      "Train Epoch: 0, mini-batch 6150 of 25000, training loss: 1.586823\n",
      "Train Epoch: 0, mini-batch 6160 of 25000, training loss: 0.830578\n",
      "Train Epoch: 0, mini-batch 6170 of 25000, training loss: 0.052029\n",
      "Train Epoch: 0, mini-batch 6180 of 25000, training loss: 0.345322\n",
      "Train Epoch: 0, mini-batch 6190 of 25000, training loss: 0.033653\n",
      "Train Epoch: 0, mini-batch 6200 of 25000, training loss: 0.020242\n",
      "Train Epoch: 0, mini-batch 6210 of 25000, training loss: 0.072554\n",
      "Train Epoch: 0, mini-batch 6220 of 25000, training loss: 0.057675\n",
      "Train Epoch: 0, mini-batch 6230 of 25000, training loss: 0.031932\n",
      "Train Epoch: 0, mini-batch 6240 of 25000, training loss: 0.043019\n",
      "Train Epoch: 0, mini-batch 6250 of 25000, training loss: 1.071677\n",
      "Train Epoch: 0, mini-batch 6260 of 25000, training loss: 0.030300\n",
      "Train Epoch: 0, mini-batch 6270 of 25000, training loss: 0.121915\n",
      "Train Epoch: 0, mini-batch 6280 of 25000, training loss: 0.070907\n",
      "Train Epoch: 0, mini-batch 6290 of 25000, training loss: 0.049022\n",
      "Train Epoch: 0, mini-batch 6300 of 25000, training loss: 0.234587\n",
      "Train Epoch: 0, mini-batch 6310 of 25000, training loss: 0.016364\n",
      "Train Epoch: 0, mini-batch 6320 of 25000, training loss: 0.091256\n",
      "Train Epoch: 0, mini-batch 6330 of 25000, training loss: 1.294774\n",
      "Train Epoch: 0, mini-batch 6340 of 25000, training loss: 0.035499\n",
      "Train Epoch: 0, mini-batch 6350 of 25000, training loss: 0.106369\n",
      "Train Epoch: 0, mini-batch 6360 of 25000, training loss: 0.135914\n",
      "Train Epoch: 0, mini-batch 6370 of 25000, training loss: 0.101367\n",
      "Train Epoch: 0, mini-batch 6380 of 25000, training loss: 0.079978\n",
      "Train Epoch: 0, mini-batch 6390 of 25000, training loss: 1.927753\n",
      "Train Epoch: 0, mini-batch 6400 of 25000, training loss: 0.014593\n",
      "Train Epoch: 0, mini-batch 6410 of 25000, training loss: 0.335741\n",
      "Train Epoch: 0, mini-batch 6420 of 25000, training loss: 0.098678\n",
      "Train Epoch: 0, mini-batch 6430 of 25000, training loss: 0.009435\n",
      "Train Epoch: 0, mini-batch 6440 of 25000, training loss: 0.021452\n",
      "Train Epoch: 0, mini-batch 6450 of 25000, training loss: 0.008743\n",
      "Train Epoch: 0, mini-batch 6460 of 25000, training loss: 0.227047\n",
      "Train Epoch: 0, mini-batch 6470 of 25000, training loss: 0.169290\n",
      "Train Epoch: 0, mini-batch 6480 of 25000, training loss: 1.286918\n",
      "Train Epoch: 0, mini-batch 6490 of 25000, training loss: 0.015215\n",
      "Train Epoch: 0, mini-batch 6500 of 25000, training loss: 0.007629\n",
      "Train Epoch: 0, mini-batch 6510 of 25000, training loss: 0.839528\n",
      "Train Epoch: 0, mini-batch 6520 of 25000, training loss: 0.518505\n",
      "Train Epoch: 0, mini-batch 6530 of 25000, training loss: 0.014112\n",
      "Train Epoch: 0, mini-batch 6540 of 25000, training loss: 0.312044\n",
      "Train Epoch: 0, mini-batch 6550 of 25000, training loss: 0.376407\n",
      "Train Epoch: 0, mini-batch 6560 of 25000, training loss: 0.017262\n",
      "Train Epoch: 0, mini-batch 6570 of 25000, training loss: 0.554694\n",
      "Train Epoch: 0, mini-batch 6580 of 25000, training loss: 0.170959\n",
      "Train Epoch: 0, mini-batch 6590 of 25000, training loss: 0.023425\n",
      "Train Epoch: 0, mini-batch 6600 of 25000, training loss: 0.214351\n",
      "Train Epoch: 0, mini-batch 6610 of 25000, training loss: 0.079731\n",
      "Train Epoch: 0, mini-batch 6620 of 25000, training loss: 0.009583\n",
      "Train Epoch: 0, mini-batch 6630 of 25000, training loss: 0.910643\n",
      "Train Epoch: 0, mini-batch 6640 of 25000, training loss: 0.043036\n",
      "Train Epoch: 0, mini-batch 6650 of 25000, training loss: 0.084672\n",
      "Train Epoch: 0, mini-batch 6660 of 25000, training loss: 0.541746\n",
      "Train Epoch: 0, mini-batch 6670 of 25000, training loss: 0.143442\n",
      "Train Epoch: 0, mini-batch 6680 of 25000, training loss: 0.339742\n",
      "Train Epoch: 0, mini-batch 6690 of 25000, training loss: 1.921636\n",
      "Train Epoch: 0, mini-batch 6700 of 25000, training loss: 0.026286\n",
      "Train Epoch: 0, mini-batch 6710 of 25000, training loss: 0.058705\n",
      "Train Epoch: 0, mini-batch 6720 of 25000, training loss: 0.022213\n",
      "Train Epoch: 0, mini-batch 6730 of 25000, training loss: 0.016746\n",
      "Train Epoch: 0, mini-batch 6740 of 25000, training loss: 0.272335\n",
      "Train Epoch: 0, mini-batch 6750 of 25000, training loss: 0.025416\n",
      "Train Epoch: 0, mini-batch 6760 of 25000, training loss: 0.071135\n",
      "Train Epoch: 0, mini-batch 6770 of 25000, training loss: 0.002386\n",
      "Train Epoch: 0, mini-batch 6780 of 25000, training loss: 0.013533\n",
      "Train Epoch: 0, mini-batch 6790 of 25000, training loss: 0.011590\n",
      "Train Epoch: 0, mini-batch 6800 of 25000, training loss: 0.021543\n",
      "Train Epoch: 0, mini-batch 6810 of 25000, training loss: 0.076499\n",
      "Train Epoch: 0, mini-batch 6820 of 25000, training loss: 0.043874\n",
      "Train Epoch: 0, mini-batch 6830 of 25000, training loss: 0.032981\n",
      "Train Epoch: 0, mini-batch 6840 of 25000, training loss: 0.028533\n",
      "Train Epoch: 0, mini-batch 6850 of 25000, training loss: 0.026384\n",
      "Train Epoch: 0, mini-batch 6860 of 25000, training loss: 0.198954\n",
      "Train Epoch: 0, mini-batch 6870 of 25000, training loss: 1.415671\n",
      "Train Epoch: 0, mini-batch 6880 of 25000, training loss: 0.047213\n",
      "Train Epoch: 0, mini-batch 6890 of 25000, training loss: 0.058773\n",
      "Train Epoch: 0, mini-batch 6900 of 25000, training loss: 0.013373\n",
      "Train Epoch: 0, mini-batch 6910 of 25000, training loss: 0.467577\n",
      "Train Epoch: 0, mini-batch 6920 of 25000, training loss: 0.025339\n",
      "Train Epoch: 0, mini-batch 6930 of 25000, training loss: 1.113416\n",
      "Train Epoch: 0, mini-batch 6940 of 25000, training loss: 1.246116\n",
      "Train Epoch: 0, mini-batch 6950 of 25000, training loss: 0.038435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 6960 of 25000, training loss: 0.229888\n",
      "Train Epoch: 0, mini-batch 6970 of 25000, training loss: 0.005206\n",
      "Train Epoch: 0, mini-batch 6980 of 25000, training loss: 0.159398\n",
      "Train Epoch: 0, mini-batch 6990 of 25000, training loss: 0.022556\n",
      "Train Epoch: 0, mini-batch 7000 of 25000, training loss: 0.277373\n",
      "Train Epoch: 0, mini-batch 7010 of 25000, training loss: 0.174773\n",
      "Train Epoch: 0, mini-batch 7020 of 25000, training loss: 1.450884\n",
      "Train Epoch: 0, mini-batch 7030 of 25000, training loss: 1.103633\n",
      "Train Epoch: 0, mini-batch 7040 of 25000, training loss: 0.477950\n",
      "Train Epoch: 0, mini-batch 7050 of 25000, training loss: 0.135970\n",
      "Train Epoch: 0, mini-batch 7060 of 25000, training loss: 0.463283\n",
      "Train Epoch: 0, mini-batch 7070 of 25000, training loss: 0.073511\n",
      "Train Epoch: 0, mini-batch 7080 of 25000, training loss: 0.109352\n",
      "Train Epoch: 0, mini-batch 7090 of 25000, training loss: 0.989030\n",
      "Train Epoch: 0, mini-batch 7100 of 25000, training loss: 0.038590\n",
      "Train Epoch: 0, mini-batch 7110 of 25000, training loss: 0.088012\n",
      "Train Epoch: 0, mini-batch 7120 of 25000, training loss: 0.146817\n",
      "Train Epoch: 0, mini-batch 7130 of 25000, training loss: 0.237833\n",
      "Train Epoch: 0, mini-batch 7140 of 25000, training loss: 0.843379\n",
      "Train Epoch: 0, mini-batch 7150 of 25000, training loss: 0.223169\n",
      "Train Epoch: 0, mini-batch 7160 of 25000, training loss: 1.058237\n",
      "Train Epoch: 0, mini-batch 7170 of 25000, training loss: 0.426397\n",
      "Train Epoch: 0, mini-batch 7180 of 25000, training loss: 0.705682\n",
      "Train Epoch: 0, mini-batch 7190 of 25000, training loss: 0.055716\n",
      "Train Epoch: 0, mini-batch 7200 of 25000, training loss: 0.035262\n",
      "Train Epoch: 0, mini-batch 7210 of 25000, training loss: 0.260474\n",
      "Train Epoch: 0, mini-batch 7220 of 25000, training loss: 0.449397\n",
      "Train Epoch: 0, mini-batch 7230 of 25000, training loss: 0.005833\n",
      "Train Epoch: 0, mini-batch 7240 of 25000, training loss: 0.145761\n",
      "Train Epoch: 0, mini-batch 7250 of 25000, training loss: 0.043123\n",
      "Train Epoch: 0, mini-batch 7260 of 25000, training loss: 0.336055\n",
      "Train Epoch: 0, mini-batch 7270 of 25000, training loss: 0.040566\n",
      "Train Epoch: 0, mini-batch 7280 of 25000, training loss: 0.560171\n",
      "Train Epoch: 0, mini-batch 7290 of 25000, training loss: 0.015877\n",
      "Train Epoch: 0, mini-batch 7300 of 25000, training loss: 0.004642\n",
      "Train Epoch: 0, mini-batch 7310 of 25000, training loss: 1.175245\n",
      "Train Epoch: 0, mini-batch 7320 of 25000, training loss: 0.504952\n",
      "Train Epoch: 0, mini-batch 7330 of 25000, training loss: 0.881118\n",
      "Train Epoch: 0, mini-batch 7340 of 25000, training loss: 4.874786\n",
      "Train Epoch: 0, mini-batch 7350 of 25000, training loss: 0.726634\n",
      "Train Epoch: 0, mini-batch 7360 of 25000, training loss: 0.331915\n",
      "Train Epoch: 0, mini-batch 7370 of 25000, training loss: 0.019506\n",
      "Train Epoch: 0, mini-batch 7380 of 25000, training loss: 0.000581\n",
      "Train Epoch: 0, mini-batch 7390 of 25000, training loss: 0.061267\n",
      "Train Epoch: 0, mini-batch 7400 of 25000, training loss: 0.058712\n",
      "Train Epoch: 0, mini-batch 7410 of 25000, training loss: 0.510967\n",
      "Train Epoch: 0, mini-batch 7420 of 25000, training loss: 0.056588\n",
      "Train Epoch: 0, mini-batch 7430 of 25000, training loss: 0.104000\n",
      "Train Epoch: 0, mini-batch 7440 of 25000, training loss: 0.039921\n",
      "Train Epoch: 0, mini-batch 7450 of 25000, training loss: 0.632299\n",
      "Train Epoch: 0, mini-batch 7460 of 25000, training loss: 0.172074\n",
      "Train Epoch: 0, mini-batch 7470 of 25000, training loss: 1.758117\n",
      "Train Epoch: 0, mini-batch 7480 of 25000, training loss: 0.278046\n",
      "Train Epoch: 0, mini-batch 7490 of 25000, training loss: 0.360667\n",
      "Train Epoch: 0, mini-batch 7500 of 25000, training loss: 0.415048\n",
      "Train Epoch: 0, mini-batch 7510 of 25000, training loss: 0.242258\n",
      "Train Epoch: 0, mini-batch 7520 of 25000, training loss: 0.067785\n",
      "Train Epoch: 0, mini-batch 7530 of 25000, training loss: 0.394742\n",
      "Train Epoch: 0, mini-batch 7540 of 25000, training loss: 0.493678\n",
      "Train Epoch: 0, mini-batch 7550 of 25000, training loss: 0.032798\n",
      "Train Epoch: 0, mini-batch 7560 of 25000, training loss: 0.525120\n",
      "Train Epoch: 0, mini-batch 7570 of 25000, training loss: 0.081251\n",
      "Train Epoch: 0, mini-batch 7580 of 25000, training loss: 0.005219\n",
      "Train Epoch: 0, mini-batch 7590 of 25000, training loss: 0.508254\n",
      "Train Epoch: 0, mini-batch 7600 of 25000, training loss: 0.021914\n",
      "Train Epoch: 0, mini-batch 7610 of 25000, training loss: 0.219901\n",
      "Train Epoch: 0, mini-batch 7620 of 25000, training loss: 0.402499\n",
      "Train Epoch: 0, mini-batch 7630 of 25000, training loss: 1.165969\n",
      "Train Epoch: 0, mini-batch 7640 of 25000, training loss: 0.936888\n",
      "Train Epoch: 0, mini-batch 7650 of 25000, training loss: 0.985431\n",
      "Train Epoch: 0, mini-batch 7660 of 25000, training loss: 0.122173\n",
      "Train Epoch: 0, mini-batch 7670 of 25000, training loss: 0.011086\n",
      "Train Epoch: 0, mini-batch 7680 of 25000, training loss: 0.323327\n",
      "Train Epoch: 0, mini-batch 7690 of 25000, training loss: 0.212380\n",
      "Train Epoch: 0, mini-batch 7700 of 25000, training loss: 0.016571\n",
      "Train Epoch: 0, mini-batch 7710 of 25000, training loss: 2.272857\n",
      "Train Epoch: 0, mini-batch 7720 of 25000, training loss: 2.733386\n",
      "Train Epoch: 0, mini-batch 7730 of 25000, training loss: 0.240791\n",
      "Train Epoch: 0, mini-batch 7740 of 25000, training loss: 1.085831\n",
      "Train Epoch: 0, mini-batch 7750 of 25000, training loss: 0.056901\n",
      "Train Epoch: 0, mini-batch 7760 of 25000, training loss: 0.904364\n",
      "Train Epoch: 0, mini-batch 7770 of 25000, training loss: 0.075820\n",
      "Train Epoch: 0, mini-batch 7780 of 25000, training loss: 0.771525\n",
      "Train Epoch: 0, mini-batch 7790 of 25000, training loss: 1.245274\n",
      "Train Epoch: 0, mini-batch 7800 of 25000, training loss: 0.157590\n",
      "Train Epoch: 0, mini-batch 7810 of 25000, training loss: 0.045630\n",
      "Train Epoch: 0, mini-batch 7820 of 25000, training loss: 0.124096\n",
      "Train Epoch: 0, mini-batch 7830 of 25000, training loss: 0.044530\n",
      "Train Epoch: 0, mini-batch 7840 of 25000, training loss: 0.007508\n",
      "Train Epoch: 0, mini-batch 7850 of 25000, training loss: 0.284979\n",
      "Train Epoch: 0, mini-batch 7860 of 25000, training loss: 0.207100\n",
      "Train Epoch: 0, mini-batch 7870 of 25000, training loss: 0.148575\n",
      "Train Epoch: 0, mini-batch 7880 of 25000, training loss: 0.048551\n",
      "Train Epoch: 0, mini-batch 7890 of 25000, training loss: 0.068166\n",
      "Train Epoch: 0, mini-batch 7900 of 25000, training loss: 0.916827\n",
      "Train Epoch: 0, mini-batch 7910 of 25000, training loss: 0.012689\n",
      "Train Epoch: 0, mini-batch 7920 of 25000, training loss: 0.001057\n",
      "Train Epoch: 0, mini-batch 7930 of 25000, training loss: 0.297489\n",
      "Train Epoch: 0, mini-batch 7940 of 25000, training loss: 0.031225\n",
      "Train Epoch: 0, mini-batch 7950 of 25000, training loss: 0.389792\n",
      "Train Epoch: 0, mini-batch 7960 of 25000, training loss: 0.036722\n",
      "Train Epoch: 0, mini-batch 7970 of 25000, training loss: 0.265159\n",
      "Train Epoch: 0, mini-batch 7980 of 25000, training loss: 0.118107\n",
      "Train Epoch: 0, mini-batch 7990 of 25000, training loss: 0.008449\n",
      "Train Epoch: 0, mini-batch 8000 of 25000, training loss: 0.104309\n",
      "Train Epoch: 0, mini-batch 8010 of 25000, training loss: 0.156589\n",
      "Train Epoch: 0, mini-batch 8020 of 25000, training loss: 0.052984\n",
      "Train Epoch: 0, mini-batch 8030 of 25000, training loss: 0.186949\n",
      "Train Epoch: 0, mini-batch 8040 of 25000, training loss: 0.317772\n",
      "Train Epoch: 0, mini-batch 8050 of 25000, training loss: 0.022115\n",
      "Train Epoch: 0, mini-batch 8060 of 25000, training loss: 0.509139\n",
      "Train Epoch: 0, mini-batch 8070 of 25000, training loss: 0.018926\n",
      "Train Epoch: 0, mini-batch 8080 of 25000, training loss: 0.338289\n",
      "Train Epoch: 0, mini-batch 8090 of 25000, training loss: 0.082241\n",
      "Train Epoch: 0, mini-batch 8100 of 25000, training loss: 0.737749\n",
      "Train Epoch: 0, mini-batch 8110 of 25000, training loss: 0.005370\n",
      "Train Epoch: 0, mini-batch 8120 of 25000, training loss: 1.106055\n",
      "Train Epoch: 0, mini-batch 8130 of 25000, training loss: 1.585133\n",
      "Train Epoch: 0, mini-batch 8140 of 25000, training loss: 0.107150\n",
      "Train Epoch: 0, mini-batch 8150 of 25000, training loss: 0.072279\n",
      "Train Epoch: 0, mini-batch 8160 of 25000, training loss: 2.436935\n",
      "Train Epoch: 0, mini-batch 8170 of 25000, training loss: 2.630891\n",
      "Train Epoch: 0, mini-batch 8180 of 25000, training loss: 0.251901\n",
      "Train Epoch: 0, mini-batch 8190 of 25000, training loss: 0.044447\n",
      "Train Epoch: 0, mini-batch 8200 of 25000, training loss: 0.291655\n",
      "Train Epoch: 0, mini-batch 8210 of 25000, training loss: 0.113082\n",
      "Train Epoch: 0, mini-batch 8220 of 25000, training loss: 0.574064\n",
      "Train Epoch: 0, mini-batch 8230 of 25000, training loss: 0.971479\n",
      "Train Epoch: 0, mini-batch 8240 of 25000, training loss: 0.002695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 8250 of 25000, training loss: 0.021264\n",
      "Train Epoch: 0, mini-batch 8260 of 25000, training loss: 0.557723\n",
      "Train Epoch: 0, mini-batch 8270 of 25000, training loss: 0.078777\n",
      "Train Epoch: 0, mini-batch 8280 of 25000, training loss: 0.031971\n",
      "Train Epoch: 0, mini-batch 8290 of 25000, training loss: 0.105045\n",
      "Train Epoch: 0, mini-batch 8300 of 25000, training loss: 0.051605\n",
      "Train Epoch: 0, mini-batch 8310 of 25000, training loss: 0.089248\n",
      "Train Epoch: 0, mini-batch 8320 of 25000, training loss: 0.012993\n",
      "Train Epoch: 0, mini-batch 8330 of 25000, training loss: 0.089026\n",
      "Train Epoch: 0, mini-batch 8340 of 25000, training loss: 0.266008\n",
      "Train Epoch: 0, mini-batch 8350 of 25000, training loss: 0.131792\n",
      "Train Epoch: 0, mini-batch 8360 of 25000, training loss: 0.400798\n",
      "Train Epoch: 0, mini-batch 8370 of 25000, training loss: 3.762007\n",
      "Train Epoch: 0, mini-batch 8380 of 25000, training loss: 0.749384\n",
      "Train Epoch: 0, mini-batch 8390 of 25000, training loss: 0.241829\n",
      "Train Epoch: 0, mini-batch 8400 of 25000, training loss: 0.078748\n",
      "Train Epoch: 0, mini-batch 8410 of 25000, training loss: 0.003169\n",
      "Train Epoch: 0, mini-batch 8420 of 25000, training loss: 0.709157\n",
      "Train Epoch: 0, mini-batch 8430 of 25000, training loss: 0.053916\n",
      "Train Epoch: 0, mini-batch 8440 of 25000, training loss: 0.038468\n",
      "Train Epoch: 0, mini-batch 8450 of 25000, training loss: 0.002345\n",
      "Train Epoch: 0, mini-batch 8460 of 25000, training loss: 0.001708\n",
      "Train Epoch: 0, mini-batch 8470 of 25000, training loss: 0.088278\n",
      "Train Epoch: 0, mini-batch 8480 of 25000, training loss: 0.010899\n",
      "Train Epoch: 0, mini-batch 8490 of 25000, training loss: 0.105955\n",
      "Train Epoch: 0, mini-batch 8500 of 25000, training loss: 0.013117\n",
      "Train Epoch: 0, mini-batch 8510 of 25000, training loss: 0.140137\n",
      "Train Epoch: 0, mini-batch 8520 of 25000, training loss: 1.093678\n",
      "Train Epoch: 0, mini-batch 8530 of 25000, training loss: 0.416582\n",
      "Train Epoch: 0, mini-batch 8540 of 25000, training loss: 0.571890\n",
      "Train Epoch: 0, mini-batch 8550 of 25000, training loss: 0.067124\n",
      "Train Epoch: 0, mini-batch 8560 of 25000, training loss: 0.182604\n",
      "Train Epoch: 0, mini-batch 8570 of 25000, training loss: 0.240939\n",
      "Train Epoch: 0, mini-batch 8580 of 25000, training loss: 0.361168\n",
      "Train Epoch: 0, mini-batch 8590 of 25000, training loss: 0.447067\n",
      "Train Epoch: 0, mini-batch 8600 of 25000, training loss: 0.011886\n",
      "Train Epoch: 0, mini-batch 8610 of 25000, training loss: 0.056727\n",
      "Train Epoch: 0, mini-batch 8620 of 25000, training loss: 0.044688\n",
      "Train Epoch: 0, mini-batch 8630 of 25000, training loss: 0.164523\n",
      "Train Epoch: 0, mini-batch 8640 of 25000, training loss: 0.023684\n",
      "Train Epoch: 0, mini-batch 8650 of 25000, training loss: 0.632921\n",
      "Train Epoch: 0, mini-batch 8660 of 25000, training loss: 0.001854\n",
      "Train Epoch: 0, mini-batch 8670 of 25000, training loss: 1.031329\n",
      "Train Epoch: 0, mini-batch 8680 of 25000, training loss: 0.091082\n",
      "Train Epoch: 0, mini-batch 8690 of 25000, training loss: 0.963939\n",
      "Train Epoch: 0, mini-batch 8700 of 25000, training loss: 0.042561\n",
      "Train Epoch: 0, mini-batch 8710 of 25000, training loss: 0.038829\n",
      "Train Epoch: 0, mini-batch 8720 of 25000, training loss: 0.072503\n",
      "Train Epoch: 0, mini-batch 8730 of 25000, training loss: 0.027386\n",
      "Train Epoch: 0, mini-batch 8740 of 25000, training loss: 0.118776\n",
      "Train Epoch: 0, mini-batch 8750 of 25000, training loss: 1.688110\n",
      "Train Epoch: 0, mini-batch 8760 of 25000, training loss: 0.605282\n",
      "Train Epoch: 0, mini-batch 8770 of 25000, training loss: 0.154449\n",
      "Train Epoch: 0, mini-batch 8780 of 25000, training loss: 0.280426\n",
      "Train Epoch: 0, mini-batch 8790 of 25000, training loss: 0.048996\n",
      "Train Epoch: 0, mini-batch 8800 of 25000, training loss: 0.208403\n",
      "Train Epoch: 0, mini-batch 8810 of 25000, training loss: 0.119460\n",
      "Train Epoch: 0, mini-batch 8820 of 25000, training loss: 0.904039\n",
      "Train Epoch: 0, mini-batch 8830 of 25000, training loss: 1.797579\n",
      "Train Epoch: 0, mini-batch 8840 of 25000, training loss: 0.118109\n",
      "Train Epoch: 0, mini-batch 8850 of 25000, training loss: 0.059094\n",
      "Train Epoch: 0, mini-batch 8860 of 25000, training loss: 1.268468\n",
      "Train Epoch: 0, mini-batch 8870 of 25000, training loss: 0.016353\n",
      "Train Epoch: 0, mini-batch 8880 of 25000, training loss: 0.103724\n",
      "Train Epoch: 0, mini-batch 8890 of 25000, training loss: 1.161945\n",
      "Train Epoch: 0, mini-batch 8900 of 25000, training loss: 0.207147\n",
      "Train Epoch: 0, mini-batch 8910 of 25000, training loss: 0.602743\n",
      "Train Epoch: 0, mini-batch 8920 of 25000, training loss: 0.045747\n",
      "Train Epoch: 0, mini-batch 8930 of 25000, training loss: 0.242135\n",
      "Train Epoch: 0, mini-batch 8940 of 25000, training loss: 0.455789\n",
      "Train Epoch: 0, mini-batch 8950 of 25000, training loss: 0.021869\n",
      "Train Epoch: 0, mini-batch 8960 of 25000, training loss: 0.010217\n",
      "Train Epoch: 0, mini-batch 8970 of 25000, training loss: 0.054628\n",
      "Train Epoch: 0, mini-batch 8980 of 25000, training loss: 0.537310\n",
      "Train Epoch: 0, mini-batch 8990 of 25000, training loss: 0.007834\n",
      "Train Epoch: 0, mini-batch 9000 of 25000, training loss: 0.911153\n",
      "Train Epoch: 0, mini-batch 9010 of 25000, training loss: 0.024850\n",
      "Train Epoch: 0, mini-batch 9020 of 25000, training loss: 0.844210\n",
      "Train Epoch: 0, mini-batch 9030 of 25000, training loss: 0.007505\n",
      "Train Epoch: 0, mini-batch 9040 of 25000, training loss: 0.406275\n",
      "Train Epoch: 0, mini-batch 9050 of 25000, training loss: 0.209697\n",
      "Train Epoch: 0, mini-batch 9060 of 25000, training loss: 0.288593\n",
      "Train Epoch: 0, mini-batch 9070 of 25000, training loss: 0.050028\n",
      "Train Epoch: 0, mini-batch 9080 of 25000, training loss: 0.300621\n",
      "Train Epoch: 0, mini-batch 9090 of 25000, training loss: 1.068041\n",
      "Train Epoch: 0, mini-batch 9100 of 25000, training loss: 0.842695\n",
      "Train Epoch: 0, mini-batch 9110 of 25000, training loss: 0.042757\n",
      "Train Epoch: 0, mini-batch 9120 of 25000, training loss: 0.092583\n",
      "Train Epoch: 0, mini-batch 9130 of 25000, training loss: 0.116227\n",
      "Train Epoch: 0, mini-batch 9140 of 25000, training loss: 0.031895\n",
      "Train Epoch: 0, mini-batch 9150 of 25000, training loss: 0.172951\n",
      "Train Epoch: 0, mini-batch 9160 of 25000, training loss: 0.206919\n",
      "Train Epoch: 0, mini-batch 9170 of 25000, training loss: 0.038421\n",
      "Train Epoch: 0, mini-batch 9180 of 25000, training loss: 3.491547\n",
      "Train Epoch: 0, mini-batch 9190 of 25000, training loss: 0.012665\n",
      "Train Epoch: 0, mini-batch 9200 of 25000, training loss: 0.175989\n",
      "Train Epoch: 0, mini-batch 9210 of 25000, training loss: 0.953436\n",
      "Train Epoch: 0, mini-batch 9220 of 25000, training loss: 0.318288\n",
      "Train Epoch: 0, mini-batch 9230 of 25000, training loss: 0.037834\n",
      "Train Epoch: 0, mini-batch 9240 of 25000, training loss: 0.000002\n",
      "Train Epoch: 0, mini-batch 9250 of 25000, training loss: 2.451470\n",
      "Train Epoch: 0, mini-batch 9260 of 25000, training loss: 0.001480\n",
      "Train Epoch: 0, mini-batch 9270 of 25000, training loss: 0.339488\n",
      "Train Epoch: 0, mini-batch 9280 of 25000, training loss: 0.003083\n",
      "Train Epoch: 0, mini-batch 9290 of 25000, training loss: 0.028961\n",
      "Train Epoch: 0, mini-batch 9300 of 25000, training loss: 0.062582\n",
      "Train Epoch: 0, mini-batch 9310 of 25000, training loss: 0.020772\n",
      "Train Epoch: 0, mini-batch 9320 of 25000, training loss: 0.002079\n",
      "Train Epoch: 0, mini-batch 9330 of 25000, training loss: 0.224382\n",
      "Train Epoch: 0, mini-batch 9340 of 25000, training loss: 0.368406\n",
      "Train Epoch: 0, mini-batch 9350 of 25000, training loss: 0.167171\n",
      "Train Epoch: 0, mini-batch 9360 of 25000, training loss: 0.681895\n",
      "Train Epoch: 0, mini-batch 9370 of 25000, training loss: 0.108415\n",
      "Train Epoch: 0, mini-batch 9380 of 25000, training loss: 0.094984\n",
      "Train Epoch: 0, mini-batch 9390 of 25000, training loss: 0.696513\n",
      "Train Epoch: 0, mini-batch 9400 of 25000, training loss: 0.006768\n",
      "Train Epoch: 0, mini-batch 9410 of 25000, training loss: 1.455273\n",
      "Train Epoch: 0, mini-batch 9420 of 25000, training loss: 0.048080\n",
      "Train Epoch: 0, mini-batch 9430 of 25000, training loss: 0.017776\n",
      "Train Epoch: 0, mini-batch 9440 of 25000, training loss: 0.003525\n",
      "Train Epoch: 0, mini-batch 9450 of 25000, training loss: 0.019093\n",
      "Train Epoch: 0, mini-batch 9460 of 25000, training loss: 0.055887\n",
      "Train Epoch: 0, mini-batch 9470 of 25000, training loss: 0.089427\n",
      "Train Epoch: 0, mini-batch 9480 of 25000, training loss: 0.026698\n",
      "Train Epoch: 0, mini-batch 9490 of 25000, training loss: 0.361301\n",
      "Train Epoch: 0, mini-batch 9500 of 25000, training loss: 0.049404\n",
      "Train Epoch: 0, mini-batch 9510 of 25000, training loss: 0.052961\n",
      "Train Epoch: 0, mini-batch 9520 of 25000, training loss: 0.595347\n",
      "Train Epoch: 0, mini-batch 9530 of 25000, training loss: 0.049127\n",
      "Train Epoch: 0, mini-batch 9540 of 25000, training loss: 0.026448\n",
      "Train Epoch: 0, mini-batch 9550 of 25000, training loss: 0.048033\n",
      "Train Epoch: 0, mini-batch 9560 of 25000, training loss: 0.019017\n",
      "Train Epoch: 0, mini-batch 9570 of 25000, training loss: 0.260494\n",
      "Train Epoch: 0, mini-batch 9580 of 25000, training loss: 0.088820\n",
      "Train Epoch: 0, mini-batch 9590 of 25000, training loss: 0.019677\n",
      "Train Epoch: 0, mini-batch 9600 of 25000, training loss: 0.011657\n",
      "Train Epoch: 0, mini-batch 9610 of 25000, training loss: 0.061066\n",
      "Train Epoch: 0, mini-batch 9620 of 25000, training loss: 0.699371\n",
      "Train Epoch: 0, mini-batch 9630 of 25000, training loss: 0.215907\n",
      "Train Epoch: 0, mini-batch 9640 of 25000, training loss: 0.007412\n",
      "Train Epoch: 0, mini-batch 9650 of 25000, training loss: 0.020799\n",
      "Train Epoch: 0, mini-batch 9660 of 25000, training loss: 0.129713\n",
      "Train Epoch: 0, mini-batch 9670 of 25000, training loss: 0.071698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 9680 of 25000, training loss: 0.891989\n",
      "Train Epoch: 0, mini-batch 9690 of 25000, training loss: 0.937710\n",
      "Train Epoch: 0, mini-batch 9700 of 25000, training loss: 0.249375\n",
      "Train Epoch: 0, mini-batch 9710 of 25000, training loss: 0.082014\n",
      "Train Epoch: 0, mini-batch 9720 of 25000, training loss: 1.655181\n",
      "Train Epoch: 0, mini-batch 9730 of 25000, training loss: 0.014215\n",
      "Train Epoch: 0, mini-batch 9740 of 25000, training loss: 0.328966\n",
      "Train Epoch: 0, mini-batch 9750 of 25000, training loss: 0.009532\n",
      "Train Epoch: 0, mini-batch 9760 of 25000, training loss: 0.016776\n",
      "Train Epoch: 0, mini-batch 9770 of 25000, training loss: 0.315282\n",
      "Train Epoch: 0, mini-batch 9780 of 25000, training loss: 0.003763\n",
      "Train Epoch: 0, mini-batch 9790 of 25000, training loss: 2.079187\n",
      "Train Epoch: 0, mini-batch 9800 of 25000, training loss: 0.010080\n",
      "Train Epoch: 0, mini-batch 9810 of 25000, training loss: 0.017785\n",
      "Train Epoch: 0, mini-batch 9820 of 25000, training loss: 0.007470\n",
      "Train Epoch: 0, mini-batch 9830 of 25000, training loss: 2.206211\n",
      "Train Epoch: 0, mini-batch 9840 of 25000, training loss: 0.208556\n",
      "Train Epoch: 0, mini-batch 9850 of 25000, training loss: 0.008062\n",
      "Train Epoch: 0, mini-batch 9860 of 25000, training loss: 0.016185\n",
      "Train Epoch: 0, mini-batch 9870 of 25000, training loss: 0.550899\n",
      "Train Epoch: 0, mini-batch 9880 of 25000, training loss: 0.126640\n",
      "Train Epoch: 0, mini-batch 9890 of 25000, training loss: 2.711371\n",
      "Train Epoch: 0, mini-batch 9900 of 25000, training loss: 0.152786\n",
      "Train Epoch: 0, mini-batch 9910 of 25000, training loss: 0.129051\n",
      "Train Epoch: 0, mini-batch 9920 of 25000, training loss: 0.100995\n",
      "Train Epoch: 0, mini-batch 9930 of 25000, training loss: 0.036961\n",
      "Train Epoch: 0, mini-batch 9940 of 25000, training loss: 0.007729\n",
      "Train Epoch: 0, mini-batch 9950 of 25000, training loss: 0.000790\n",
      "Train Epoch: 0, mini-batch 9960 of 25000, training loss: 0.028547\n",
      "Train Epoch: 0, mini-batch 9970 of 25000, training loss: 0.075113\n",
      "Train Epoch: 0, mini-batch 9980 of 25000, training loss: 0.015892\n",
      "Train Epoch: 0, mini-batch 9990 of 25000, training loss: 0.593660\n",
      "Train Epoch: 0, mini-batch 10000 of 25000, training loss: 0.635462\n",
      "Train Epoch: 0, mini-batch 10010 of 25000, training loss: 0.016352\n",
      "Train Epoch: 0, mini-batch 10020 of 25000, training loss: 0.019090\n",
      "Train Epoch: 0, mini-batch 10030 of 25000, training loss: 0.019547\n",
      "Train Epoch: 0, mini-batch 10040 of 25000, training loss: 0.109948\n",
      "Train Epoch: 0, mini-batch 10050 of 25000, training loss: 0.001517\n",
      "Train Epoch: 0, mini-batch 10060 of 25000, training loss: 1.160094\n",
      "Train Epoch: 0, mini-batch 10070 of 25000, training loss: 0.185767\n",
      "Train Epoch: 0, mini-batch 10080 of 25000, training loss: 0.017826\n",
      "Train Epoch: 0, mini-batch 10090 of 25000, training loss: 0.015478\n",
      "Train Epoch: 0, mini-batch 10100 of 25000, training loss: 0.058249\n",
      "Train Epoch: 0, mini-batch 10110 of 25000, training loss: 0.088465\n",
      "Train Epoch: 0, mini-batch 10120 of 25000, training loss: 0.050519\n",
      "Train Epoch: 0, mini-batch 10130 of 25000, training loss: 0.010970\n",
      "Train Epoch: 0, mini-batch 10140 of 25000, training loss: 0.027559\n",
      "Train Epoch: 0, mini-batch 10150 of 25000, training loss: 0.458526\n",
      "Train Epoch: 0, mini-batch 10160 of 25000, training loss: 0.031268\n",
      "Train Epoch: 0, mini-batch 10170 of 25000, training loss: 0.014329\n",
      "Train Epoch: 0, mini-batch 10180 of 25000, training loss: 0.054524\n",
      "Train Epoch: 0, mini-batch 10190 of 25000, training loss: 0.138561\n",
      "Train Epoch: 0, mini-batch 10200 of 25000, training loss: 0.043384\n",
      "Train Epoch: 0, mini-batch 10210 of 25000, training loss: 0.240187\n",
      "Train Epoch: 0, mini-batch 10220 of 25000, training loss: 1.036538\n",
      "Train Epoch: 0, mini-batch 10230 of 25000, training loss: 0.110158\n",
      "Train Epoch: 0, mini-batch 10240 of 25000, training loss: 0.059464\n",
      "Train Epoch: 0, mini-batch 10250 of 25000, training loss: 0.012786\n",
      "Train Epoch: 0, mini-batch 10260 of 25000, training loss: 2.766910\n",
      "Train Epoch: 0, mini-batch 10270 of 25000, training loss: 0.082039\n",
      "Train Epoch: 0, mini-batch 10280 of 25000, training loss: 0.150430\n",
      "Train Epoch: 0, mini-batch 10290 of 25000, training loss: 0.057723\n",
      "Train Epoch: 0, mini-batch 10300 of 25000, training loss: 0.028252\n",
      "Train Epoch: 0, mini-batch 10310 of 25000, training loss: 0.023665\n",
      "Train Epoch: 0, mini-batch 10320 of 25000, training loss: 1.446006\n",
      "Train Epoch: 0, mini-batch 10330 of 25000, training loss: 0.055027\n",
      "Train Epoch: 0, mini-batch 10340 of 25000, training loss: 0.433355\n",
      "Train Epoch: 0, mini-batch 10350 of 25000, training loss: 0.139011\n",
      "Train Epoch: 0, mini-batch 10360 of 25000, training loss: 0.040858\n",
      "Train Epoch: 0, mini-batch 10370 of 25000, training loss: 0.000060\n",
      "Train Epoch: 0, mini-batch 10380 of 25000, training loss: 0.305729\n",
      "Train Epoch: 0, mini-batch 10390 of 25000, training loss: 0.031388\n",
      "Train Epoch: 0, mini-batch 10400 of 25000, training loss: 0.111208\n",
      "Train Epoch: 0, mini-batch 10410 of 25000, training loss: 0.015984\n",
      "Train Epoch: 0, mini-batch 10420 of 25000, training loss: 0.023646\n",
      "Train Epoch: 0, mini-batch 10430 of 25000, training loss: 0.009272\n",
      "Train Epoch: 0, mini-batch 10440 of 25000, training loss: 0.013458\n",
      "Train Epoch: 0, mini-batch 10450 of 25000, training loss: 0.921620\n",
      "Train Epoch: 0, mini-batch 10460 of 25000, training loss: 0.097714\n",
      "Train Epoch: 0, mini-batch 10470 of 25000, training loss: 0.343827\n",
      "Train Epoch: 0, mini-batch 10480 of 25000, training loss: 0.065192\n",
      "Train Epoch: 0, mini-batch 10490 of 25000, training loss: 1.541106\n",
      "Train Epoch: 0, mini-batch 10500 of 25000, training loss: 0.026998\n",
      "Train Epoch: 0, mini-batch 10510 of 25000, training loss: 0.649952\n",
      "Train Epoch: 0, mini-batch 10520 of 25000, training loss: 0.032339\n",
      "Train Epoch: 0, mini-batch 10530 of 25000, training loss: 0.015594\n",
      "Train Epoch: 0, mini-batch 10540 of 25000, training loss: 0.013691\n",
      "Train Epoch: 0, mini-batch 10550 of 25000, training loss: 0.105772\n",
      "Train Epoch: 0, mini-batch 10560 of 25000, training loss: 0.431732\n",
      "Train Epoch: 0, mini-batch 10570 of 25000, training loss: 0.113245\n",
      "Train Epoch: 0, mini-batch 10580 of 25000, training loss: 1.486722\n",
      "Train Epoch: 0, mini-batch 10590 of 25000, training loss: 0.084718\n",
      "Train Epoch: 0, mini-batch 10600 of 25000, training loss: 0.007993\n",
      "Train Epoch: 0, mini-batch 10610 of 25000, training loss: 0.421333\n",
      "Train Epoch: 0, mini-batch 10620 of 25000, training loss: 0.176181\n",
      "Train Epoch: 0, mini-batch 10630 of 25000, training loss: 0.007605\n",
      "Train Epoch: 0, mini-batch 10640 of 25000, training loss: 0.541081\n",
      "Train Epoch: 0, mini-batch 10650 of 25000, training loss: 0.044173\n",
      "Train Epoch: 0, mini-batch 10660 of 25000, training loss: 0.648023\n",
      "Train Epoch: 0, mini-batch 10670 of 25000, training loss: 2.434588\n",
      "Train Epoch: 0, mini-batch 10680 of 25000, training loss: 0.038254\n",
      "Train Epoch: 0, mini-batch 10690 of 25000, training loss: 0.683151\n",
      "Train Epoch: 0, mini-batch 10700 of 25000, training loss: 0.023220\n",
      "Train Epoch: 0, mini-batch 10710 of 25000, training loss: 0.016336\n",
      "Train Epoch: 0, mini-batch 10720 of 25000, training loss: 0.077344\n",
      "Train Epoch: 0, mini-batch 10730 of 25000, training loss: 0.005653\n",
      "Train Epoch: 0, mini-batch 10740 of 25000, training loss: 0.030929\n",
      "Train Epoch: 0, mini-batch 10750 of 25000, training loss: 0.006718\n",
      "Train Epoch: 0, mini-batch 10760 of 25000, training loss: 0.071186\n",
      "Train Epoch: 0, mini-batch 10770 of 25000, training loss: 0.518489\n",
      "Train Epoch: 0, mini-batch 10780 of 25000, training loss: 0.032803\n",
      "Train Epoch: 0, mini-batch 10790 of 25000, training loss: 1.605341\n",
      "Train Epoch: 0, mini-batch 10800 of 25000, training loss: 0.095360\n",
      "Train Epoch: 0, mini-batch 10810 of 25000, training loss: 0.936619\n",
      "Train Epoch: 0, mini-batch 10820 of 25000, training loss: 0.500683\n",
      "Train Epoch: 0, mini-batch 10830 of 25000, training loss: 0.030348\n",
      "Train Epoch: 0, mini-batch 10840 of 25000, training loss: 0.036065\n",
      "Train Epoch: 0, mini-batch 10850 of 25000, training loss: 0.152179\n",
      "Train Epoch: 0, mini-batch 10860 of 25000, training loss: 0.026574\n",
      "Train Epoch: 0, mini-batch 10870 of 25000, training loss: 0.263737\n",
      "Train Epoch: 0, mini-batch 10880 of 25000, training loss: 0.010008\n",
      "Train Epoch: 0, mini-batch 10890 of 25000, training loss: 2.224238\n",
      "Train Epoch: 0, mini-batch 10900 of 25000, training loss: 0.015298\n",
      "Train Epoch: 0, mini-batch 10910 of 25000, training loss: 0.804937\n",
      "Train Epoch: 0, mini-batch 10920 of 25000, training loss: 0.105408\n",
      "Train Epoch: 0, mini-batch 10930 of 25000, training loss: 0.023785\n",
      "Train Epoch: 0, mini-batch 10940 of 25000, training loss: 0.117764\n",
      "Train Epoch: 0, mini-batch 10950 of 25000, training loss: 0.052875\n",
      "Train Epoch: 0, mini-batch 10960 of 25000, training loss: 0.058603\n",
      "Train Epoch: 0, mini-batch 10970 of 25000, training loss: 0.290118\n",
      "Train Epoch: 0, mini-batch 10980 of 25000, training loss: 0.102714\n",
      "Train Epoch: 0, mini-batch 10990 of 25000, training loss: 0.039901\n",
      "Train Epoch: 0, mini-batch 11000 of 25000, training loss: 0.054890\n",
      "Train Epoch: 0, mini-batch 11010 of 25000, training loss: 0.031884\n",
      "Train Epoch: 0, mini-batch 11020 of 25000, training loss: 0.059617\n",
      "Train Epoch: 0, mini-batch 11030 of 25000, training loss: 0.087249\n",
      "Train Epoch: 0, mini-batch 11040 of 25000, training loss: 0.002449\n",
      "Train Epoch: 0, mini-batch 11050 of 25000, training loss: 0.580011\n",
      "Train Epoch: 0, mini-batch 11060 of 25000, training loss: 0.141183\n",
      "Train Epoch: 0, mini-batch 11070 of 25000, training loss: 0.129923\n",
      "Train Epoch: 0, mini-batch 11080 of 25000, training loss: 0.419271\n",
      "Train Epoch: 0, mini-batch 11090 of 25000, training loss: 0.010922\n",
      "Train Epoch: 0, mini-batch 11100 of 25000, training loss: 0.052219\n",
      "Train Epoch: 0, mini-batch 11110 of 25000, training loss: 0.101659\n",
      "Train Epoch: 0, mini-batch 11120 of 25000, training loss: 0.025179\n",
      "Train Epoch: 0, mini-batch 11130 of 25000, training loss: 0.003306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 11140 of 25000, training loss: 0.000677\n",
      "Train Epoch: 0, mini-batch 11150 of 25000, training loss: 0.211772\n",
      "Train Epoch: 0, mini-batch 11160 of 25000, training loss: 0.047258\n",
      "Train Epoch: 0, mini-batch 11170 of 25000, training loss: 1.258221\n",
      "Train Epoch: 0, mini-batch 11180 of 25000, training loss: 0.126435\n",
      "Train Epoch: 0, mini-batch 11190 of 25000, training loss: 0.368660\n",
      "Train Epoch: 0, mini-batch 11200 of 25000, training loss: 0.480867\n",
      "Train Epoch: 0, mini-batch 11210 of 25000, training loss: 0.136391\n",
      "Train Epoch: 0, mini-batch 11220 of 25000, training loss: 0.041511\n",
      "Train Epoch: 0, mini-batch 11230 of 25000, training loss: 0.323613\n",
      "Train Epoch: 0, mini-batch 11240 of 25000, training loss: 0.227131\n",
      "Train Epoch: 0, mini-batch 11250 of 25000, training loss: 0.174507\n",
      "Train Epoch: 0, mini-batch 11260 of 25000, training loss: 0.570316\n",
      "Train Epoch: 0, mini-batch 11270 of 25000, training loss: 0.490969\n",
      "Train Epoch: 0, mini-batch 11280 of 25000, training loss: 0.240437\n",
      "Train Epoch: 0, mini-batch 11290 of 25000, training loss: 0.002737\n",
      "Train Epoch: 0, mini-batch 11300 of 25000, training loss: 0.530513\n",
      "Train Epoch: 0, mini-batch 11310 of 25000, training loss: 0.748662\n",
      "Train Epoch: 0, mini-batch 11320 of 25000, training loss: 0.020225\n",
      "Train Epoch: 0, mini-batch 11330 of 25000, training loss: 0.044907\n",
      "Train Epoch: 0, mini-batch 11340 of 25000, training loss: 0.293550\n",
      "Train Epoch: 0, mini-batch 11350 of 25000, training loss: 0.182614\n",
      "Train Epoch: 0, mini-batch 11360 of 25000, training loss: 0.001507\n",
      "Train Epoch: 0, mini-batch 11370 of 25000, training loss: 1.274093\n",
      "Train Epoch: 0, mini-batch 11380 of 25000, training loss: 0.127890\n",
      "Train Epoch: 0, mini-batch 11390 of 25000, training loss: 0.020799\n",
      "Train Epoch: 0, mini-batch 11400 of 25000, training loss: 0.091932\n",
      "Train Epoch: 0, mini-batch 11410 of 25000, training loss: 1.048837\n",
      "Train Epoch: 0, mini-batch 11420 of 25000, training loss: 0.017742\n",
      "Train Epoch: 0, mini-batch 11430 of 25000, training loss: 0.450355\n",
      "Train Epoch: 0, mini-batch 11440 of 25000, training loss: 0.473532\n",
      "Train Epoch: 0, mini-batch 11450 of 25000, training loss: 0.431834\n",
      "Train Epoch: 0, mini-batch 11460 of 25000, training loss: 0.443324\n",
      "Train Epoch: 0, mini-batch 11470 of 25000, training loss: 0.024201\n",
      "Train Epoch: 0, mini-batch 11480 of 25000, training loss: 0.118353\n",
      "Train Epoch: 0, mini-batch 11490 of 25000, training loss: 0.600323\n",
      "Train Epoch: 0, mini-batch 11500 of 25000, training loss: 1.373955\n",
      "Train Epoch: 0, mini-batch 11510 of 25000, training loss: 0.524893\n",
      "Train Epoch: 0, mini-batch 11520 of 25000, training loss: 0.005979\n",
      "Train Epoch: 0, mini-batch 11530 of 25000, training loss: 0.019203\n",
      "Train Epoch: 0, mini-batch 11540 of 25000, training loss: 0.467930\n",
      "Train Epoch: 0, mini-batch 11550 of 25000, training loss: 0.046745\n",
      "Train Epoch: 0, mini-batch 11560 of 25000, training loss: 0.165265\n",
      "Train Epoch: 0, mini-batch 11570 of 25000, training loss: 0.019687\n",
      "Train Epoch: 0, mini-batch 11580 of 25000, training loss: 0.267135\n",
      "Train Epoch: 0, mini-batch 11590 of 25000, training loss: 0.036077\n",
      "Train Epoch: 0, mini-batch 11600 of 25000, training loss: 0.032569\n",
      "Train Epoch: 0, mini-batch 11610 of 25000, training loss: 1.302916\n",
      "Train Epoch: 0, mini-batch 11620 of 25000, training loss: 0.001403\n",
      "Train Epoch: 0, mini-batch 11630 of 25000, training loss: 0.047841\n",
      "Train Epoch: 0, mini-batch 11640 of 25000, training loss: 0.163675\n",
      "Train Epoch: 0, mini-batch 11650 of 25000, training loss: 0.000110\n",
      "Train Epoch: 0, mini-batch 11660 of 25000, training loss: 0.467625\n",
      "Train Epoch: 0, mini-batch 11670 of 25000, training loss: 0.031012\n",
      "Train Epoch: 0, mini-batch 11680 of 25000, training loss: 5.272732\n",
      "Train Epoch: 0, mini-batch 11690 of 25000, training loss: 0.005614\n",
      "Train Epoch: 0, mini-batch 11700 of 25000, training loss: 0.439069\n",
      "Train Epoch: 0, mini-batch 11710 of 25000, training loss: 0.157006\n",
      "Train Epoch: 0, mini-batch 11720 of 25000, training loss: 0.054040\n",
      "Train Epoch: 0, mini-batch 11730 of 25000, training loss: 0.012369\n",
      "Train Epoch: 0, mini-batch 11740 of 25000, training loss: 0.043053\n",
      "Train Epoch: 0, mini-batch 11750 of 25000, training loss: 0.275633\n",
      "Train Epoch: 0, mini-batch 11760 of 25000, training loss: 0.014107\n",
      "Train Epoch: 0, mini-batch 11770 of 25000, training loss: 1.856984\n",
      "Train Epoch: 0, mini-batch 11780 of 25000, training loss: 0.570876\n",
      "Train Epoch: 0, mini-batch 11790 of 25000, training loss: 1.940484\n",
      "Train Epoch: 0, mini-batch 11800 of 25000, training loss: 0.336699\n",
      "Train Epoch: 0, mini-batch 11810 of 25000, training loss: 0.067381\n",
      "Train Epoch: 0, mini-batch 11820 of 25000, training loss: 0.580725\n",
      "Train Epoch: 0, mini-batch 11830 of 25000, training loss: 0.002224\n",
      "Train Epoch: 0, mini-batch 11840 of 25000, training loss: 0.179295\n",
      "Train Epoch: 0, mini-batch 11850 of 25000, training loss: 0.017267\n",
      "Train Epoch: 0, mini-batch 11860 of 25000, training loss: 0.723645\n",
      "Train Epoch: 0, mini-batch 11870 of 25000, training loss: 0.067759\n",
      "Train Epoch: 0, mini-batch 11880 of 25000, training loss: 0.077116\n",
      "Train Epoch: 0, mini-batch 11890 of 25000, training loss: 0.040832\n",
      "Train Epoch: 0, mini-batch 11900 of 25000, training loss: 0.002735\n",
      "Train Epoch: 0, mini-batch 11910 of 25000, training loss: 0.003717\n",
      "Train Epoch: 0, mini-batch 11920 of 25000, training loss: 0.215921\n",
      "Train Epoch: 0, mini-batch 11930 of 25000, training loss: 0.325876\n",
      "Train Epoch: 0, mini-batch 11940 of 25000, training loss: 0.004541\n",
      "Train Epoch: 0, mini-batch 11950 of 25000, training loss: 0.237558\n",
      "Train Epoch: 0, mini-batch 11960 of 25000, training loss: 0.003231\n",
      "Train Epoch: 0, mini-batch 11970 of 25000, training loss: 0.281802\n",
      "Train Epoch: 0, mini-batch 11980 of 25000, training loss: 1.064536\n",
      "Train Epoch: 0, mini-batch 11990 of 25000, training loss: 0.000667\n",
      "Train Epoch: 0, mini-batch 12000 of 25000, training loss: 0.011616\n",
      "Train Epoch: 0, mini-batch 12010 of 25000, training loss: 0.090013\n",
      "Train Epoch: 0, mini-batch 12020 of 25000, training loss: 0.021847\n",
      "Train Epoch: 0, mini-batch 12030 of 25000, training loss: 0.881893\n",
      "Train Epoch: 0, mini-batch 12040 of 25000, training loss: 0.050644\n",
      "Train Epoch: 0, mini-batch 12050 of 25000, training loss: 1.560124\n",
      "Train Epoch: 0, mini-batch 12060 of 25000, training loss: 0.045369\n",
      "Train Epoch: 0, mini-batch 12070 of 25000, training loss: 0.716789\n",
      "Train Epoch: 0, mini-batch 12080 of 25000, training loss: 0.151932\n",
      "Train Epoch: 0, mini-batch 12090 of 25000, training loss: 0.966211\n",
      "Train Epoch: 0, mini-batch 12100 of 25000, training loss: 0.068048\n",
      "Train Epoch: 0, mini-batch 12110 of 25000, training loss: 0.084320\n",
      "Train Epoch: 0, mini-batch 12120 of 25000, training loss: 0.058443\n",
      "Train Epoch: 0, mini-batch 12130 of 25000, training loss: 0.084377\n",
      "Train Epoch: 0, mini-batch 12140 of 25000, training loss: 0.029655\n",
      "Train Epoch: 0, mini-batch 12150 of 25000, training loss: 0.013115\n",
      "Train Epoch: 0, mini-batch 12160 of 25000, training loss: 0.021869\n",
      "Train Epoch: 0, mini-batch 12170 of 25000, training loss: 0.720034\n",
      "Train Epoch: 0, mini-batch 12180 of 25000, training loss: 0.175498\n",
      "Train Epoch: 0, mini-batch 12190 of 25000, training loss: 0.349859\n",
      "Train Epoch: 0, mini-batch 12200 of 25000, training loss: 3.038270\n",
      "Train Epoch: 0, mini-batch 12210 of 25000, training loss: 0.053951\n",
      "Train Epoch: 0, mini-batch 12220 of 25000, training loss: 0.114800\n",
      "Train Epoch: 0, mini-batch 12230 of 25000, training loss: 0.573489\n",
      "Train Epoch: 0, mini-batch 12240 of 25000, training loss: 0.025926\n",
      "Train Epoch: 0, mini-batch 12250 of 25000, training loss: 0.643721\n",
      "Train Epoch: 0, mini-batch 12260 of 25000, training loss: 0.041496\n",
      "Train Epoch: 0, mini-batch 12270 of 25000, training loss: 0.045402\n",
      "Train Epoch: 0, mini-batch 12280 of 25000, training loss: 0.061037\n",
      "Train Epoch: 0, mini-batch 12290 of 25000, training loss: 1.895534\n",
      "Train Epoch: 0, mini-batch 12300 of 25000, training loss: 0.031263\n",
      "Train Epoch: 0, mini-batch 12310 of 25000, training loss: 0.095805\n",
      "Train Epoch: 0, mini-batch 12320 of 25000, training loss: 0.058432\n",
      "Train Epoch: 0, mini-batch 12330 of 25000, training loss: 0.455517\n",
      "Train Epoch: 0, mini-batch 12340 of 25000, training loss: 2.826474\n",
      "Train Epoch: 0, mini-batch 12350 of 25000, training loss: 0.020009\n",
      "Train Epoch: 0, mini-batch 12360 of 25000, training loss: 0.100472\n",
      "Train Epoch: 0, mini-batch 12370 of 25000, training loss: 0.024191\n",
      "Train Epoch: 0, mini-batch 12380 of 25000, training loss: 0.054218\n",
      "Train Epoch: 0, mini-batch 12390 of 25000, training loss: 0.100495\n",
      "Train Epoch: 0, mini-batch 12400 of 25000, training loss: 0.109637\n",
      "Train Epoch: 0, mini-batch 12410 of 25000, training loss: 1.110199\n",
      "Train Epoch: 0, mini-batch 12420 of 25000, training loss: 0.158412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 12430 of 25000, training loss: 0.416376\n",
      "Train Epoch: 0, mini-batch 12440 of 25000, training loss: 2.390151\n",
      "Train Epoch: 0, mini-batch 12450 of 25000, training loss: 0.561809\n",
      "Train Epoch: 0, mini-batch 12460 of 25000, training loss: 0.168254\n",
      "Train Epoch: 0, mini-batch 12470 of 25000, training loss: 0.242876\n",
      "Train Epoch: 0, mini-batch 12480 of 25000, training loss: 0.722814\n",
      "Train Epoch: 0, mini-batch 12490 of 25000, training loss: 0.793184\n",
      "Train Epoch: 0, mini-batch 12500 of 25000, training loss: 0.519394\n",
      "Train Epoch: 0, mini-batch 12510 of 25000, training loss: 0.140334\n",
      "Train Epoch: 0, mini-batch 12520 of 25000, training loss: 0.107285\n",
      "Train Epoch: 0, mini-batch 12530 of 25000, training loss: 0.020514\n",
      "Train Epoch: 0, mini-batch 12540 of 25000, training loss: 0.189991\n",
      "Train Epoch: 0, mini-batch 12550 of 25000, training loss: 0.256083\n",
      "Train Epoch: 0, mini-batch 12560 of 25000, training loss: 0.193469\n",
      "Train Epoch: 0, mini-batch 12570 of 25000, training loss: 0.714727\n",
      "Train Epoch: 0, mini-batch 12580 of 25000, training loss: 0.081142\n",
      "Train Epoch: 0, mini-batch 12590 of 25000, training loss: 0.213560\n",
      "Train Epoch: 0, mini-batch 12600 of 25000, training loss: 3.653857\n",
      "Train Epoch: 0, mini-batch 12610 of 25000, training loss: 0.061126\n",
      "Train Epoch: 0, mini-batch 12620 of 25000, training loss: 0.772160\n",
      "Train Epoch: 0, mini-batch 12630 of 25000, training loss: 0.072577\n",
      "Train Epoch: 0, mini-batch 12640 of 25000, training loss: 0.218394\n",
      "Train Epoch: 0, mini-batch 12650 of 25000, training loss: 1.120248\n",
      "Train Epoch: 0, mini-batch 12660 of 25000, training loss: 0.173898\n",
      "Train Epoch: 0, mini-batch 12670 of 25000, training loss: 0.724622\n",
      "Train Epoch: 0, mini-batch 12680 of 25000, training loss: 0.065324\n",
      "Train Epoch: 0, mini-batch 12690 of 25000, training loss: 0.653561\n",
      "Train Epoch: 0, mini-batch 12700 of 25000, training loss: 0.034095\n",
      "Train Epoch: 0, mini-batch 12710 of 25000, training loss: 0.017388\n",
      "Train Epoch: 0, mini-batch 12720 of 25000, training loss: 0.064668\n",
      "Train Epoch: 0, mini-batch 12730 of 25000, training loss: 0.055080\n",
      "Train Epoch: 0, mini-batch 12740 of 25000, training loss: 0.000383\n",
      "Train Epoch: 0, mini-batch 12750 of 25000, training loss: 2.632448\n",
      "Train Epoch: 0, mini-batch 12760 of 25000, training loss: 0.006776\n",
      "Train Epoch: 0, mini-batch 12770 of 25000, training loss: 0.011964\n",
      "Train Epoch: 0, mini-batch 12780 of 25000, training loss: 0.011983\n",
      "Train Epoch: 0, mini-batch 12790 of 25000, training loss: 0.229736\n",
      "Train Epoch: 0, mini-batch 12800 of 25000, training loss: 0.901788\n",
      "Train Epoch: 0, mini-batch 12810 of 25000, training loss: 0.020042\n",
      "Train Epoch: 0, mini-batch 12820 of 25000, training loss: 0.053679\n",
      "Train Epoch: 0, mini-batch 12830 of 25000, training loss: 1.897440\n",
      "Train Epoch: 0, mini-batch 12840 of 25000, training loss: 0.577705\n",
      "Train Epoch: 0, mini-batch 12850 of 25000, training loss: 0.065964\n",
      "Train Epoch: 0, mini-batch 12860 of 25000, training loss: 0.039280\n",
      "Train Epoch: 0, mini-batch 12870 of 25000, training loss: 0.136137\n",
      "Train Epoch: 0, mini-batch 12880 of 25000, training loss: 0.888322\n",
      "Train Epoch: 0, mini-batch 12890 of 25000, training loss: 0.014232\n",
      "Train Epoch: 0, mini-batch 12900 of 25000, training loss: 0.119689\n",
      "Train Epoch: 0, mini-batch 12910 of 25000, training loss: 0.166273\n",
      "Train Epoch: 0, mini-batch 12920 of 25000, training loss: 1.725566\n",
      "Train Epoch: 0, mini-batch 12930 of 25000, training loss: 0.068328\n",
      "Train Epoch: 0, mini-batch 12940 of 25000, training loss: 0.026489\n",
      "Train Epoch: 0, mini-batch 12950 of 25000, training loss: 0.040142\n",
      "Train Epoch: 0, mini-batch 12960 of 25000, training loss: 0.644133\n",
      "Train Epoch: 0, mini-batch 12970 of 25000, training loss: 0.045995\n",
      "Train Epoch: 0, mini-batch 12980 of 25000, training loss: 0.014760\n",
      "Train Epoch: 0, mini-batch 12990 of 25000, training loss: 0.755421\n",
      "Train Epoch: 0, mini-batch 13000 of 25000, training loss: 0.063738\n",
      "Train Epoch: 0, mini-batch 13010 of 25000, training loss: 0.041999\n",
      "Train Epoch: 0, mini-batch 13020 of 25000, training loss: 0.009719\n",
      "Train Epoch: 0, mini-batch 13030 of 25000, training loss: 0.010276\n",
      "Train Epoch: 0, mini-batch 13040 of 25000, training loss: 0.887029\n",
      "Train Epoch: 0, mini-batch 13050 of 25000, training loss: 0.403451\n",
      "Train Epoch: 0, mini-batch 13060 of 25000, training loss: 0.021819\n",
      "Train Epoch: 0, mini-batch 13070 of 25000, training loss: 0.109635\n",
      "Train Epoch: 0, mini-batch 13080 of 25000, training loss: 0.048674\n",
      "Train Epoch: 0, mini-batch 13090 of 25000, training loss: 0.209074\n",
      "Train Epoch: 0, mini-batch 13100 of 25000, training loss: 0.660747\n",
      "Train Epoch: 0, mini-batch 13110 of 25000, training loss: 0.280939\n",
      "Train Epoch: 0, mini-batch 13120 of 25000, training loss: 0.144846\n",
      "Train Epoch: 0, mini-batch 13130 of 25000, training loss: 0.072012\n",
      "Train Epoch: 0, mini-batch 13140 of 25000, training loss: 0.502764\n",
      "Train Epoch: 0, mini-batch 13150 of 25000, training loss: 0.008172\n",
      "Train Epoch: 0, mini-batch 13160 of 25000, training loss: 0.026292\n",
      "Train Epoch: 0, mini-batch 13170 of 25000, training loss: 0.033972\n",
      "Train Epoch: 0, mini-batch 13180 of 25000, training loss: 1.354410\n",
      "Train Epoch: 0, mini-batch 13190 of 25000, training loss: 0.060821\n",
      "Train Epoch: 0, mini-batch 13200 of 25000, training loss: 0.010888\n",
      "Train Epoch: 0, mini-batch 13210 of 25000, training loss: 0.039617\n",
      "Train Epoch: 0, mini-batch 13220 of 25000, training loss: 0.158763\n",
      "Train Epoch: 0, mini-batch 13230 of 25000, training loss: 0.084411\n",
      "Train Epoch: 0, mini-batch 13240 of 25000, training loss: 0.055933\n",
      "Train Epoch: 0, mini-batch 13250 of 25000, training loss: 0.173730\n",
      "Train Epoch: 0, mini-batch 13260 of 25000, training loss: 1.374958\n",
      "Train Epoch: 0, mini-batch 13270 of 25000, training loss: 0.166885\n",
      "Train Epoch: 0, mini-batch 13280 of 25000, training loss: 0.242009\n",
      "Train Epoch: 0, mini-batch 13290 of 25000, training loss: 0.061903\n",
      "Train Epoch: 0, mini-batch 13300 of 25000, training loss: 0.010308\n",
      "Train Epoch: 0, mini-batch 13310 of 25000, training loss: 0.036916\n",
      "Train Epoch: 0, mini-batch 13320 of 25000, training loss: 0.081455\n",
      "Train Epoch: 0, mini-batch 13330 of 25000, training loss: 0.130135\n",
      "Train Epoch: 0, mini-batch 13340 of 25000, training loss: 0.148238\n",
      "Train Epoch: 0, mini-batch 13350 of 25000, training loss: 0.057781\n",
      "Train Epoch: 0, mini-batch 13360 of 25000, training loss: 4.412893\n",
      "Train Epoch: 0, mini-batch 13370 of 25000, training loss: 0.028197\n",
      "Train Epoch: 0, mini-batch 13380 of 25000, training loss: 0.023235\n",
      "Train Epoch: 0, mini-batch 13390 of 25000, training loss: 1.377137\n",
      "Train Epoch: 0, mini-batch 13400 of 25000, training loss: 0.044587\n",
      "Train Epoch: 0, mini-batch 13410 of 25000, training loss: 0.121494\n",
      "Train Epoch: 0, mini-batch 13420 of 25000, training loss: 0.085278\n",
      "Train Epoch: 0, mini-batch 13430 of 25000, training loss: 0.068735\n",
      "Train Epoch: 0, mini-batch 13440 of 25000, training loss: 0.022938\n",
      "Train Epoch: 0, mini-batch 13450 of 25000, training loss: 0.004959\n",
      "Train Epoch: 0, mini-batch 13460 of 25000, training loss: 0.024629\n",
      "Train Epoch: 0, mini-batch 13470 of 25000, training loss: 0.217185\n",
      "Train Epoch: 0, mini-batch 13480 of 25000, training loss: 0.048745\n",
      "Train Epoch: 0, mini-batch 13490 of 25000, training loss: 0.009817\n",
      "Train Epoch: 0, mini-batch 13500 of 25000, training loss: 0.167959\n",
      "Train Epoch: 0, mini-batch 13510 of 25000, training loss: 0.125445\n",
      "Train Epoch: 0, mini-batch 13520 of 25000, training loss: 1.711500\n",
      "Train Epoch: 0, mini-batch 13530 of 25000, training loss: 1.000287\n",
      "Train Epoch: 0, mini-batch 13540 of 25000, training loss: 0.033378\n",
      "Train Epoch: 0, mini-batch 13550 of 25000, training loss: 0.187437\n",
      "Train Epoch: 0, mini-batch 13560 of 25000, training loss: 0.027187\n",
      "Train Epoch: 0, mini-batch 13570 of 25000, training loss: 0.587427\n",
      "Train Epoch: 0, mini-batch 13580 of 25000, training loss: 0.022030\n",
      "Train Epoch: 0, mini-batch 13590 of 25000, training loss: 0.016614\n",
      "Train Epoch: 0, mini-batch 13600 of 25000, training loss: 0.026292\n",
      "Train Epoch: 0, mini-batch 13610 of 25000, training loss: 0.518859\n",
      "Train Epoch: 0, mini-batch 13620 of 25000, training loss: 0.015173\n",
      "Train Epoch: 0, mini-batch 13630 of 25000, training loss: 0.019405\n",
      "Train Epoch: 0, mini-batch 13640 of 25000, training loss: 0.854415\n",
      "Train Epoch: 0, mini-batch 13650 of 25000, training loss: 0.040680\n",
      "Train Epoch: 0, mini-batch 13660 of 25000, training loss: 0.211465\n",
      "Train Epoch: 0, mini-batch 13670 of 25000, training loss: 0.382293\n",
      "Train Epoch: 0, mini-batch 13680 of 25000, training loss: 0.070800\n",
      "Train Epoch: 0, mini-batch 13690 of 25000, training loss: 0.065583\n",
      "Train Epoch: 0, mini-batch 13700 of 25000, training loss: 0.052783\n",
      "Train Epoch: 0, mini-batch 13710 of 25000, training loss: 0.007295\n",
      "Train Epoch: 0, mini-batch 13720 of 25000, training loss: 0.133428\n",
      "Train Epoch: 0, mini-batch 13730 of 25000, training loss: 0.052335\n",
      "Train Epoch: 0, mini-batch 13740 of 25000, training loss: 0.031127\n",
      "Train Epoch: 0, mini-batch 13750 of 25000, training loss: 0.000972\n",
      "Train Epoch: 0, mini-batch 13760 of 25000, training loss: 0.436146\n",
      "Train Epoch: 0, mini-batch 13770 of 25000, training loss: 0.245243\n",
      "Train Epoch: 0, mini-batch 13780 of 25000, training loss: 1.323081\n",
      "Train Epoch: 0, mini-batch 13790 of 25000, training loss: 0.380998\n",
      "Train Epoch: 0, mini-batch 13800 of 25000, training loss: 0.749222\n",
      "Train Epoch: 0, mini-batch 13810 of 25000, training loss: 0.009194\n",
      "Train Epoch: 0, mini-batch 13820 of 25000, training loss: 0.027506\n",
      "Train Epoch: 0, mini-batch 13830 of 25000, training loss: 0.024148\n",
      "Train Epoch: 0, mini-batch 13840 of 25000, training loss: 0.012993\n",
      "Train Epoch: 0, mini-batch 13850 of 25000, training loss: 1.000912\n",
      "Train Epoch: 0, mini-batch 13860 of 25000, training loss: 0.445487\n",
      "Train Epoch: 0, mini-batch 13870 of 25000, training loss: 0.171214\n",
      "Train Epoch: 0, mini-batch 13880 of 25000, training loss: 0.009233\n",
      "Train Epoch: 0, mini-batch 13890 of 25000, training loss: 0.028573\n",
      "Train Epoch: 0, mini-batch 13900 of 25000, training loss: 0.031648\n",
      "Train Epoch: 0, mini-batch 13910 of 25000, training loss: 0.006469\n",
      "Train Epoch: 0, mini-batch 13920 of 25000, training loss: 0.053766\n",
      "Train Epoch: 0, mini-batch 13930 of 25000, training loss: 0.004567\n",
      "Train Epoch: 0, mini-batch 13940 of 25000, training loss: 1.090679\n",
      "Train Epoch: 0, mini-batch 13950 of 25000, training loss: 0.602220\n",
      "Train Epoch: 0, mini-batch 13960 of 25000, training loss: 0.214563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 13970 of 25000, training loss: 2.581089\n",
      "Train Epoch: 0, mini-batch 13980 of 25000, training loss: 0.272787\n",
      "Train Epoch: 0, mini-batch 13990 of 25000, training loss: 1.861854\n",
      "Train Epoch: 0, mini-batch 14000 of 25000, training loss: 0.189956\n",
      "Train Epoch: 0, mini-batch 14010 of 25000, training loss: 0.202847\n",
      "Train Epoch: 0, mini-batch 14020 of 25000, training loss: 0.050837\n",
      "Train Epoch: 0, mini-batch 14030 of 25000, training loss: 0.022166\n",
      "Train Epoch: 0, mini-batch 14040 of 25000, training loss: 0.509929\n",
      "Train Epoch: 0, mini-batch 14050 of 25000, training loss: 0.575498\n",
      "Train Epoch: 0, mini-batch 14060 of 25000, training loss: 0.049877\n",
      "Train Epoch: 0, mini-batch 14070 of 25000, training loss: 0.714975\n",
      "Train Epoch: 0, mini-batch 14080 of 25000, training loss: 0.635127\n",
      "Train Epoch: 0, mini-batch 14090 of 25000, training loss: 0.335302\n",
      "Train Epoch: 0, mini-batch 14100 of 25000, training loss: 1.168481\n",
      "Train Epoch: 0, mini-batch 14110 of 25000, training loss: 0.346089\n",
      "Train Epoch: 0, mini-batch 14120 of 25000, training loss: 0.071473\n",
      "Train Epoch: 0, mini-batch 14130 of 25000, training loss: 0.024146\n",
      "Train Epoch: 0, mini-batch 14140 of 25000, training loss: 0.038133\n",
      "Train Epoch: 0, mini-batch 14150 of 25000, training loss: 0.018741\n",
      "Train Epoch: 0, mini-batch 14160 of 25000, training loss: 5.043468\n",
      "Train Epoch: 0, mini-batch 14170 of 25000, training loss: 1.645510\n",
      "Train Epoch: 0, mini-batch 14180 of 25000, training loss: 0.016556\n",
      "Train Epoch: 0, mini-batch 14190 of 25000, training loss: 0.800250\n",
      "Train Epoch: 0, mini-batch 14200 of 25000, training loss: 0.145183\n",
      "Train Epoch: 0, mini-batch 14210 of 25000, training loss: 0.135372\n",
      "Train Epoch: 0, mini-batch 14220 of 25000, training loss: 5.532758\n",
      "Train Epoch: 0, mini-batch 14230 of 25000, training loss: 0.268111\n",
      "Train Epoch: 0, mini-batch 14240 of 25000, training loss: 0.197763\n",
      "Train Epoch: 0, mini-batch 14250 of 25000, training loss: 0.029835\n",
      "Train Epoch: 0, mini-batch 14260 of 25000, training loss: 2.131291\n",
      "Train Epoch: 0, mini-batch 14270 of 25000, training loss: 1.091964\n",
      "Train Epoch: 0, mini-batch 14280 of 25000, training loss: 0.209658\n",
      "Train Epoch: 0, mini-batch 14290 of 25000, training loss: 0.000124\n",
      "Train Epoch: 0, mini-batch 14300 of 25000, training loss: 1.021614\n",
      "Train Epoch: 0, mini-batch 14310 of 25000, training loss: 0.002009\n",
      "Train Epoch: 0, mini-batch 14320 of 25000, training loss: 0.697434\n",
      "Train Epoch: 0, mini-batch 14330 of 25000, training loss: 0.121075\n",
      "Train Epoch: 0, mini-batch 14340 of 25000, training loss: 0.000354\n",
      "Train Epoch: 0, mini-batch 14350 of 25000, training loss: 0.042627\n",
      "Train Epoch: 0, mini-batch 14360 of 25000, training loss: 1.541199\n",
      "Train Epoch: 0, mini-batch 14370 of 25000, training loss: 0.084882\n",
      "Train Epoch: 0, mini-batch 14380 of 25000, training loss: 0.025068\n",
      "Train Epoch: 0, mini-batch 14390 of 25000, training loss: 0.010376\n",
      "Train Epoch: 0, mini-batch 14400 of 25000, training loss: 0.743753\n",
      "Train Epoch: 0, mini-batch 14410 of 25000, training loss: 0.050887\n",
      "Train Epoch: 0, mini-batch 14420 of 25000, training loss: 0.479777\n",
      "Train Epoch: 0, mini-batch 14430 of 25000, training loss: 0.007626\n",
      "Train Epoch: 0, mini-batch 14440 of 25000, training loss: 0.011835\n",
      "Train Epoch: 0, mini-batch 14450 of 25000, training loss: 0.092401\n",
      "Train Epoch: 0, mini-batch 14460 of 25000, training loss: 0.061030\n",
      "Train Epoch: 0, mini-batch 14470 of 25000, training loss: 0.268898\n",
      "Train Epoch: 0, mini-batch 14480 of 25000, training loss: 0.002161\n",
      "Train Epoch: 0, mini-batch 14490 of 25000, training loss: 0.264557\n",
      "Train Epoch: 0, mini-batch 14500 of 25000, training loss: 0.561789\n",
      "Train Epoch: 0, mini-batch 14510 of 25000, training loss: 5.141524\n",
      "Train Epoch: 0, mini-batch 14520 of 25000, training loss: 0.436571\n",
      "Train Epoch: 0, mini-batch 14530 of 25000, training loss: 0.042574\n",
      "Train Epoch: 0, mini-batch 14540 of 25000, training loss: 0.317987\n",
      "Train Epoch: 0, mini-batch 14550 of 25000, training loss: 0.022621\n",
      "Train Epoch: 0, mini-batch 14560 of 25000, training loss: 0.129216\n",
      "Train Epoch: 0, mini-batch 14570 of 25000, training loss: 0.033172\n",
      "Train Epoch: 0, mini-batch 14580 of 25000, training loss: 0.195910\n",
      "Train Epoch: 0, mini-batch 14590 of 25000, training loss: 0.025079\n",
      "Train Epoch: 0, mini-batch 14600 of 25000, training loss: 1.719163\n",
      "Train Epoch: 0, mini-batch 14610 of 25000, training loss: 0.235460\n",
      "Train Epoch: 0, mini-batch 14620 of 25000, training loss: 0.713529\n",
      "Train Epoch: 0, mini-batch 14630 of 25000, training loss: 0.057758\n",
      "Train Epoch: 0, mini-batch 14640 of 25000, training loss: 0.026462\n",
      "Train Epoch: 0, mini-batch 14650 of 25000, training loss: 1.185643\n",
      "Train Epoch: 0, mini-batch 14660 of 25000, training loss: 0.061297\n",
      "Train Epoch: 0, mini-batch 14670 of 25000, training loss: 0.391802\n",
      "Train Epoch: 0, mini-batch 14680 of 25000, training loss: 0.924713\n",
      "Train Epoch: 0, mini-batch 14690 of 25000, training loss: 0.016354\n",
      "Train Epoch: 0, mini-batch 14700 of 25000, training loss: 0.111309\n",
      "Train Epoch: 0, mini-batch 14710 of 25000, training loss: 0.041191\n",
      "Train Epoch: 0, mini-batch 14720 of 25000, training loss: 1.353105\n",
      "Train Epoch: 0, mini-batch 14730 of 25000, training loss: 0.187998\n",
      "Train Epoch: 0, mini-batch 14740 of 25000, training loss: 0.090032\n",
      "Train Epoch: 0, mini-batch 14750 of 25000, training loss: 0.479951\n",
      "Train Epoch: 0, mini-batch 14760 of 25000, training loss: 0.055075\n",
      "Train Epoch: 0, mini-batch 14770 of 25000, training loss: 0.003298\n",
      "Train Epoch: 0, mini-batch 14780 of 25000, training loss: 1.025842\n",
      "Train Epoch: 0, mini-batch 14790 of 25000, training loss: 0.022048\n",
      "Train Epoch: 0, mini-batch 14800 of 25000, training loss: 0.009792\n",
      "Train Epoch: 0, mini-batch 14810 of 25000, training loss: 0.023064\n",
      "Train Epoch: 0, mini-batch 14820 of 25000, training loss: 0.321918\n",
      "Train Epoch: 0, mini-batch 14830 of 25000, training loss: 0.249557\n",
      "Train Epoch: 0, mini-batch 14840 of 25000, training loss: 0.170249\n",
      "Train Epoch: 0, mini-batch 14850 of 25000, training loss: 0.280668\n",
      "Train Epoch: 0, mini-batch 14860 of 25000, training loss: 0.024851\n",
      "Train Epoch: 0, mini-batch 14870 of 25000, training loss: 0.021989\n",
      "Train Epoch: 0, mini-batch 14880 of 25000, training loss: 0.097264\n",
      "Train Epoch: 0, mini-batch 14890 of 25000, training loss: 1.087183\n",
      "Train Epoch: 0, mini-batch 14900 of 25000, training loss: 0.119445\n",
      "Train Epoch: 0, mini-batch 14910 of 25000, training loss: 1.433257\n",
      "Train Epoch: 0, mini-batch 14920 of 25000, training loss: 0.430717\n",
      "Train Epoch: 0, mini-batch 14930 of 25000, training loss: 0.178910\n",
      "Train Epoch: 0, mini-batch 14940 of 25000, training loss: 0.100344\n",
      "Train Epoch: 0, mini-batch 14950 of 25000, training loss: 1.343830\n",
      "Train Epoch: 0, mini-batch 14960 of 25000, training loss: 0.000069\n",
      "Train Epoch: 0, mini-batch 14970 of 25000, training loss: 0.039199\n",
      "Train Epoch: 0, mini-batch 14980 of 25000, training loss: 0.035359\n",
      "Train Epoch: 0, mini-batch 14990 of 25000, training loss: 0.007461\n",
      "Train Epoch: 0, mini-batch 15000 of 25000, training loss: 0.458950\n",
      "Train Epoch: 0, mini-batch 15010 of 25000, training loss: 0.936325\n",
      "Train Epoch: 0, mini-batch 15020 of 25000, training loss: 0.015307\n",
      "Train Epoch: 0, mini-batch 15030 of 25000, training loss: 0.006046\n",
      "Train Epoch: 0, mini-batch 15040 of 25000, training loss: 0.046555\n",
      "Train Epoch: 0, mini-batch 15050 of 25000, training loss: 0.149866\n",
      "Train Epoch: 0, mini-batch 15060 of 25000, training loss: 1.036598\n",
      "Train Epoch: 0, mini-batch 15070 of 25000, training loss: 0.027069\n",
      "Train Epoch: 0, mini-batch 15080 of 25000, training loss: 1.421564\n",
      "Train Epoch: 0, mini-batch 15090 of 25000, training loss: 0.049630\n",
      "Train Epoch: 0, mini-batch 15100 of 25000, training loss: 0.781001\n",
      "Train Epoch: 0, mini-batch 15110 of 25000, training loss: 0.011038\n",
      "Train Epoch: 0, mini-batch 15120 of 25000, training loss: 0.180003\n",
      "Train Epoch: 0, mini-batch 15130 of 25000, training loss: 0.223327\n",
      "Train Epoch: 0, mini-batch 15140 of 25000, training loss: 0.007334\n",
      "Train Epoch: 0, mini-batch 15150 of 25000, training loss: 0.107070\n",
      "Train Epoch: 0, mini-batch 15160 of 25000, training loss: 0.217606\n",
      "Train Epoch: 0, mini-batch 15170 of 25000, training loss: 0.527076\n",
      "Train Epoch: 0, mini-batch 15180 of 25000, training loss: 0.990226\n",
      "Train Epoch: 0, mini-batch 15190 of 25000, training loss: 0.947879\n",
      "Train Epoch: 0, mini-batch 15200 of 25000, training loss: 0.198341\n",
      "Train Epoch: 0, mini-batch 15210 of 25000, training loss: 0.015701\n",
      "Train Epoch: 0, mini-batch 15220 of 25000, training loss: 0.055809\n",
      "Train Epoch: 0, mini-batch 15230 of 25000, training loss: 0.029462\n",
      "Train Epoch: 0, mini-batch 15240 of 25000, training loss: 0.212786\n",
      "Train Epoch: 0, mini-batch 15250 of 25000, training loss: 0.198100\n",
      "Train Epoch: 0, mini-batch 15260 of 25000, training loss: 0.440114\n",
      "Train Epoch: 0, mini-batch 15270 of 25000, training loss: 2.276051\n",
      "Train Epoch: 0, mini-batch 15280 of 25000, training loss: 0.016317\n",
      "Train Epoch: 0, mini-batch 15290 of 25000, training loss: 0.013071\n",
      "Train Epoch: 0, mini-batch 15300 of 25000, training loss: 0.013282\n",
      "Train Epoch: 0, mini-batch 15310 of 25000, training loss: 0.265868\n",
      "Train Epoch: 0, mini-batch 15320 of 25000, training loss: 0.231804\n",
      "Train Epoch: 0, mini-batch 15330 of 25000, training loss: 0.000050\n",
      "Train Epoch: 0, mini-batch 15340 of 25000, training loss: 0.030961\n",
      "Train Epoch: 0, mini-batch 15350 of 25000, training loss: 0.410646\n",
      "Train Epoch: 0, mini-batch 15360 of 25000, training loss: 0.019952\n",
      "Train Epoch: 0, mini-batch 15370 of 25000, training loss: 2.359529\n",
      "Train Epoch: 0, mini-batch 15380 of 25000, training loss: 0.035928\n",
      "Train Epoch: 0, mini-batch 15390 of 25000, training loss: 0.633419\n",
      "Train Epoch: 0, mini-batch 15400 of 25000, training loss: 0.289115\n",
      "Train Epoch: 0, mini-batch 15410 of 25000, training loss: 0.244723\n",
      "Train Epoch: 0, mini-batch 15420 of 25000, training loss: 0.064409\n",
      "Train Epoch: 0, mini-batch 15430 of 25000, training loss: 0.004332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 15440 of 25000, training loss: 0.025377\n",
      "Train Epoch: 0, mini-batch 15450 of 25000, training loss: 0.098988\n",
      "Train Epoch: 0, mini-batch 15460 of 25000, training loss: 0.003546\n",
      "Train Epoch: 0, mini-batch 15470 of 25000, training loss: 0.055610\n",
      "Train Epoch: 0, mini-batch 15480 of 25000, training loss: 0.019093\n",
      "Train Epoch: 0, mini-batch 15490 of 25000, training loss: 0.740690\n",
      "Train Epoch: 0, mini-batch 15500 of 25000, training loss: 0.010398\n",
      "Train Epoch: 0, mini-batch 15510 of 25000, training loss: 0.261165\n",
      "Train Epoch: 0, mini-batch 15520 of 25000, training loss: 0.024269\n",
      "Train Epoch: 0, mini-batch 15530 of 25000, training loss: 0.021735\n",
      "Train Epoch: 0, mini-batch 15540 of 25000, training loss: 0.043500\n",
      "Train Epoch: 0, mini-batch 15550 of 25000, training loss: 0.281395\n",
      "Train Epoch: 0, mini-batch 15560 of 25000, training loss: 1.268614\n",
      "Train Epoch: 0, mini-batch 15570 of 25000, training loss: 0.767259\n",
      "Train Epoch: 0, mini-batch 15580 of 25000, training loss: 0.009805\n",
      "Train Epoch: 0, mini-batch 15590 of 25000, training loss: 0.025229\n",
      "Train Epoch: 0, mini-batch 15600 of 25000, training loss: 0.201558\n",
      "Train Epoch: 0, mini-batch 15610 of 25000, training loss: 0.115956\n",
      "Train Epoch: 0, mini-batch 15620 of 25000, training loss: 3.906531\n",
      "Train Epoch: 0, mini-batch 15630 of 25000, training loss: 0.043957\n",
      "Train Epoch: 0, mini-batch 15640 of 25000, training loss: 4.826470\n",
      "Train Epoch: 0, mini-batch 15650 of 25000, training loss: 0.233010\n",
      "Train Epoch: 0, mini-batch 15660 of 25000, training loss: 0.032664\n",
      "Train Epoch: 0, mini-batch 15670 of 25000, training loss: 0.010129\n",
      "Train Epoch: 0, mini-batch 15680 of 25000, training loss: 0.166000\n",
      "Train Epoch: 0, mini-batch 15690 of 25000, training loss: 0.046301\n",
      "Train Epoch: 0, mini-batch 15700 of 25000, training loss: 0.004940\n",
      "Train Epoch: 0, mini-batch 15710 of 25000, training loss: 0.023956\n",
      "Train Epoch: 0, mini-batch 15720 of 25000, training loss: 0.031671\n",
      "Train Epoch: 0, mini-batch 15730 of 25000, training loss: 0.129704\n",
      "Train Epoch: 0, mini-batch 15740 of 25000, training loss: 0.096887\n",
      "Train Epoch: 0, mini-batch 15750 of 25000, training loss: 0.030244\n",
      "Train Epoch: 0, mini-batch 15760 of 25000, training loss: 0.071843\n",
      "Train Epoch: 0, mini-batch 15770 of 25000, training loss: 0.036386\n",
      "Train Epoch: 0, mini-batch 15780 of 25000, training loss: 0.110317\n",
      "Train Epoch: 0, mini-batch 15790 of 25000, training loss: 0.007255\n",
      "Train Epoch: 0, mini-batch 15800 of 25000, training loss: 4.917635\n",
      "Train Epoch: 0, mini-batch 15810 of 25000, training loss: 0.207956\n",
      "Train Epoch: 0, mini-batch 15820 of 25000, training loss: 0.199666\n",
      "Train Epoch: 0, mini-batch 15830 of 25000, training loss: 0.037449\n",
      "Train Epoch: 0, mini-batch 15840 of 25000, training loss: 0.058045\n",
      "Train Epoch: 0, mini-batch 15850 of 25000, training loss: 0.078696\n",
      "Train Epoch: 0, mini-batch 15860 of 25000, training loss: 0.098056\n",
      "Train Epoch: 0, mini-batch 15870 of 25000, training loss: 0.045746\n",
      "Train Epoch: 0, mini-batch 15880 of 25000, training loss: 0.213151\n",
      "Train Epoch: 0, mini-batch 15890 of 25000, training loss: 0.265211\n",
      "Train Epoch: 0, mini-batch 15900 of 25000, training loss: 0.672812\n",
      "Train Epoch: 0, mini-batch 15910 of 25000, training loss: 0.169289\n",
      "Train Epoch: 0, mini-batch 15920 of 25000, training loss: 0.052071\n",
      "Train Epoch: 0, mini-batch 15930 of 25000, training loss: 0.039057\n",
      "Train Epoch: 0, mini-batch 15940 of 25000, training loss: 0.076609\n",
      "Train Epoch: 0, mini-batch 15950 of 25000, training loss: 1.709901\n",
      "Train Epoch: 0, mini-batch 15960 of 25000, training loss: 0.010591\n",
      "Train Epoch: 0, mini-batch 15970 of 25000, training loss: 0.713800\n",
      "Train Epoch: 0, mini-batch 15980 of 25000, training loss: 0.185718\n",
      "Train Epoch: 0, mini-batch 15990 of 25000, training loss: 0.006068\n",
      "Train Epoch: 0, mini-batch 16000 of 25000, training loss: 0.424633\n",
      "Train Epoch: 0, mini-batch 16010 of 25000, training loss: 0.159597\n",
      "Train Epoch: 0, mini-batch 16020 of 25000, training loss: 0.323965\n",
      "Train Epoch: 0, mini-batch 16030 of 25000, training loss: 0.242210\n",
      "Train Epoch: 0, mini-batch 16040 of 25000, training loss: 0.025086\n",
      "Train Epoch: 0, mini-batch 16050 of 25000, training loss: 0.062991\n",
      "Train Epoch: 0, mini-batch 16060 of 25000, training loss: 0.074271\n",
      "Train Epoch: 0, mini-batch 16070 of 25000, training loss: 0.016658\n",
      "Train Epoch: 0, mini-batch 16080 of 25000, training loss: 0.016254\n",
      "Train Epoch: 0, mini-batch 16090 of 25000, training loss: 0.172558\n",
      "Train Epoch: 0, mini-batch 16100 of 25000, training loss: 0.052148\n",
      "Train Epoch: 0, mini-batch 16110 of 25000, training loss: 0.030197\n",
      "Train Epoch: 0, mini-batch 16120 of 25000, training loss: 1.082158\n",
      "Train Epoch: 0, mini-batch 16130 of 25000, training loss: 0.010396\n",
      "Train Epoch: 0, mini-batch 16140 of 25000, training loss: 0.164298\n",
      "Train Epoch: 0, mini-batch 16150 of 25000, training loss: 0.016132\n",
      "Train Epoch: 0, mini-batch 16160 of 25000, training loss: 0.046559\n",
      "Train Epoch: 0, mini-batch 16170 of 25000, training loss: 0.178958\n",
      "Train Epoch: 0, mini-batch 16180 of 25000, training loss: 0.114812\n",
      "Train Epoch: 0, mini-batch 16190 of 25000, training loss: 0.074752\n",
      "Train Epoch: 0, mini-batch 16200 of 25000, training loss: 0.054794\n",
      "Train Epoch: 0, mini-batch 16210 of 25000, training loss: 0.025578\n",
      "Train Epoch: 0, mini-batch 16220 of 25000, training loss: 0.436202\n",
      "Train Epoch: 0, mini-batch 16230 of 25000, training loss: 0.087572\n",
      "Train Epoch: 0, mini-batch 16240 of 25000, training loss: 0.138040\n",
      "Train Epoch: 0, mini-batch 16250 of 25000, training loss: 0.117858\n",
      "Train Epoch: 0, mini-batch 16260 of 25000, training loss: 0.011037\n",
      "Train Epoch: 0, mini-batch 16270 of 25000, training loss: 0.072175\n",
      "Train Epoch: 0, mini-batch 16280 of 25000, training loss: 0.029266\n",
      "Train Epoch: 0, mini-batch 16290 of 25000, training loss: 0.073607\n",
      "Train Epoch: 0, mini-batch 16300 of 25000, training loss: 0.014628\n",
      "Train Epoch: 0, mini-batch 16310 of 25000, training loss: 0.095071\n",
      "Train Epoch: 0, mini-batch 16320 of 25000, training loss: 0.137925\n",
      "Train Epoch: 0, mini-batch 16330 of 25000, training loss: 0.032601\n",
      "Train Epoch: 0, mini-batch 16340 of 25000, training loss: 0.234519\n",
      "Train Epoch: 0, mini-batch 16350 of 25000, training loss: 0.101546\n",
      "Train Epoch: 0, mini-batch 16360 of 25000, training loss: 0.479614\n",
      "Train Epoch: 0, mini-batch 16370 of 25000, training loss: 0.165550\n",
      "Train Epoch: 0, mini-batch 16380 of 25000, training loss: 0.082284\n",
      "Train Epoch: 0, mini-batch 16390 of 25000, training loss: 0.737180\n",
      "Train Epoch: 0, mini-batch 16400 of 25000, training loss: 0.005212\n",
      "Train Epoch: 0, mini-batch 16410 of 25000, training loss: 0.075693\n",
      "Train Epoch: 0, mini-batch 16420 of 25000, training loss: 0.073060\n",
      "Train Epoch: 0, mini-batch 16430 of 25000, training loss: 0.130085\n",
      "Train Epoch: 0, mini-batch 16440 of 25000, training loss: 0.065568\n",
      "Train Epoch: 0, mini-batch 16450 of 25000, training loss: 0.093502\n",
      "Train Epoch: 0, mini-batch 16460 of 25000, training loss: 0.272146\n",
      "Train Epoch: 0, mini-batch 16470 of 25000, training loss: 0.003482\n",
      "Train Epoch: 0, mini-batch 16480 of 25000, training loss: 0.748610\n",
      "Train Epoch: 0, mini-batch 16490 of 25000, training loss: 0.005481\n",
      "Train Epoch: 0, mini-batch 16500 of 25000, training loss: 1.597480\n",
      "Train Epoch: 0, mini-batch 16510 of 25000, training loss: 0.064035\n",
      "Train Epoch: 0, mini-batch 16520 of 25000, training loss: 2.148109\n",
      "Train Epoch: 0, mini-batch 16530 of 25000, training loss: 0.494599\n",
      "Train Epoch: 0, mini-batch 16540 of 25000, training loss: 0.013812\n",
      "Train Epoch: 0, mini-batch 16550 of 25000, training loss: 0.191173\n",
      "Train Epoch: 0, mini-batch 16560 of 25000, training loss: 0.023778\n",
      "Train Epoch: 0, mini-batch 16570 of 25000, training loss: 1.358401\n",
      "Train Epoch: 0, mini-batch 16580 of 25000, training loss: 0.127288\n",
      "Train Epoch: 0, mini-batch 16590 of 25000, training loss: 0.229752\n",
      "Train Epoch: 0, mini-batch 16600 of 25000, training loss: 0.089336\n",
      "Train Epoch: 0, mini-batch 16610 of 25000, training loss: 0.205779\n",
      "Train Epoch: 0, mini-batch 16620 of 25000, training loss: 0.077674\n",
      "Train Epoch: 0, mini-batch 16630 of 25000, training loss: 0.021930\n",
      "Train Epoch: 0, mini-batch 16640 of 25000, training loss: 0.133230\n",
      "Train Epoch: 0, mini-batch 16650 of 25000, training loss: 0.097872\n",
      "Train Epoch: 0, mini-batch 16660 of 25000, training loss: 0.341990\n",
      "Train Epoch: 0, mini-batch 16670 of 25000, training loss: 0.031967\n",
      "Train Epoch: 0, mini-batch 16680 of 25000, training loss: 0.118572\n",
      "Train Epoch: 0, mini-batch 16690 of 25000, training loss: 0.128778\n",
      "Train Epoch: 0, mini-batch 16700 of 25000, training loss: 0.238730\n",
      "Train Epoch: 0, mini-batch 16710 of 25000, training loss: 0.007262\n",
      "Train Epoch: 0, mini-batch 16720 of 25000, training loss: 0.397008\n",
      "Train Epoch: 0, mini-batch 16730 of 25000, training loss: 0.055059\n",
      "Train Epoch: 0, mini-batch 16740 of 25000, training loss: 0.054683\n",
      "Train Epoch: 0, mini-batch 16750 of 25000, training loss: 0.157183\n",
      "Train Epoch: 0, mini-batch 16760 of 25000, training loss: 0.068413\n",
      "Train Epoch: 0, mini-batch 16770 of 25000, training loss: 0.890102\n",
      "Train Epoch: 0, mini-batch 16780 of 25000, training loss: 2.121064\n",
      "Train Epoch: 0, mini-batch 16790 of 25000, training loss: 0.144537\n",
      "Train Epoch: 0, mini-batch 16800 of 25000, training loss: 1.829869\n",
      "Train Epoch: 0, mini-batch 16810 of 25000, training loss: 0.587785\n",
      "Train Epoch: 0, mini-batch 16820 of 25000, training loss: 0.050401\n",
      "Train Epoch: 0, mini-batch 16830 of 25000, training loss: 0.000053\n",
      "Train Epoch: 0, mini-batch 16840 of 25000, training loss: 0.004885\n",
      "Train Epoch: 0, mini-batch 16850 of 25000, training loss: 0.111214\n",
      "Train Epoch: 0, mini-batch 16860 of 25000, training loss: 0.103257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 16870 of 25000, training loss: 0.003095\n",
      "Train Epoch: 0, mini-batch 16880 of 25000, training loss: 0.000108\n",
      "Train Epoch: 0, mini-batch 16890 of 25000, training loss: 0.065827\n",
      "Train Epoch: 0, mini-batch 16900 of 25000, training loss: 0.004856\n",
      "Train Epoch: 0, mini-batch 16910 of 25000, training loss: 0.078855\n",
      "Train Epoch: 0, mini-batch 16920 of 25000, training loss: 0.016270\n",
      "Train Epoch: 0, mini-batch 16930 of 25000, training loss: 1.082990\n",
      "Train Epoch: 0, mini-batch 16940 of 25000, training loss: 0.085360\n",
      "Train Epoch: 0, mini-batch 16950 of 25000, training loss: 0.039076\n",
      "Train Epoch: 0, mini-batch 16960 of 25000, training loss: 0.115687\n",
      "Train Epoch: 0, mini-batch 16970 of 25000, training loss: 0.576850\n",
      "Train Epoch: 0, mini-batch 16980 of 25000, training loss: 0.117479\n",
      "Train Epoch: 0, mini-batch 16990 of 25000, training loss: 0.082589\n",
      "Train Epoch: 0, mini-batch 17000 of 25000, training loss: 0.148266\n",
      "Train Epoch: 0, mini-batch 17010 of 25000, training loss: 0.065890\n",
      "Train Epoch: 0, mini-batch 17020 of 25000, training loss: 0.011348\n",
      "Train Epoch: 0, mini-batch 17030 of 25000, training loss: 0.041558\n",
      "Train Epoch: 0, mini-batch 17040 of 25000, training loss: 0.016293\n",
      "Train Epoch: 0, mini-batch 17050 of 25000, training loss: 0.004487\n",
      "Train Epoch: 0, mini-batch 17060 of 25000, training loss: 0.125478\n",
      "Train Epoch: 0, mini-batch 17070 of 25000, training loss: 0.686832\n",
      "Train Epoch: 0, mini-batch 17080 of 25000, training loss: 0.051642\n",
      "Train Epoch: 0, mini-batch 17090 of 25000, training loss: 0.029900\n",
      "Train Epoch: 0, mini-batch 17100 of 25000, training loss: 0.062982\n",
      "Train Epoch: 0, mini-batch 17110 of 25000, training loss: 0.347422\n",
      "Train Epoch: 0, mini-batch 17120 of 25000, training loss: 3.643062\n",
      "Train Epoch: 0, mini-batch 17130 of 25000, training loss: 0.015770\n",
      "Train Epoch: 0, mini-batch 17140 of 25000, training loss: 0.028351\n",
      "Train Epoch: 0, mini-batch 17150 of 25000, training loss: 0.067133\n",
      "Train Epoch: 0, mini-batch 17160 of 25000, training loss: 0.016879\n",
      "Train Epoch: 0, mini-batch 17170 of 25000, training loss: 1.601376\n",
      "Train Epoch: 0, mini-batch 17180 of 25000, training loss: 2.195717\n",
      "Train Epoch: 0, mini-batch 17190 of 25000, training loss: 1.919740\n",
      "Train Epoch: 0, mini-batch 17200 of 25000, training loss: 0.076585\n",
      "Train Epoch: 0, mini-batch 17210 of 25000, training loss: 0.654905\n",
      "Train Epoch: 0, mini-batch 17220 of 25000, training loss: 0.043114\n",
      "Train Epoch: 0, mini-batch 17230 of 25000, training loss: 0.087576\n",
      "Train Epoch: 0, mini-batch 17240 of 25000, training loss: 0.086061\n",
      "Train Epoch: 0, mini-batch 17250 of 25000, training loss: 0.005904\n",
      "Train Epoch: 0, mini-batch 17260 of 25000, training loss: 0.202914\n",
      "Train Epoch: 0, mini-batch 17270 of 25000, training loss: 0.069482\n",
      "Train Epoch: 0, mini-batch 17280 of 25000, training loss: 1.267937\n",
      "Train Epoch: 0, mini-batch 17290 of 25000, training loss: 0.026743\n",
      "Train Epoch: 0, mini-batch 17300 of 25000, training loss: 0.276337\n",
      "Train Epoch: 0, mini-batch 17310 of 25000, training loss: 1.022381\n",
      "Train Epoch: 0, mini-batch 17320 of 25000, training loss: 0.016500\n",
      "Train Epoch: 0, mini-batch 17330 of 25000, training loss: 1.993849\n",
      "Train Epoch: 0, mini-batch 17340 of 25000, training loss: 0.071619\n",
      "Train Epoch: 0, mini-batch 17350 of 25000, training loss: 2.860234\n",
      "Train Epoch: 0, mini-batch 17360 of 25000, training loss: 0.126821\n",
      "Train Epoch: 0, mini-batch 17370 of 25000, training loss: 1.083840\n",
      "Train Epoch: 0, mini-batch 17380 of 25000, training loss: 0.086525\n",
      "Train Epoch: 0, mini-batch 17390 of 25000, training loss: 0.822118\n",
      "Train Epoch: 0, mini-batch 17400 of 25000, training loss: 0.000985\n",
      "Train Epoch: 0, mini-batch 17410 of 25000, training loss: 0.003673\n",
      "Train Epoch: 0, mini-batch 17420 of 25000, training loss: 0.891251\n",
      "Train Epoch: 0, mini-batch 17430 of 25000, training loss: 0.379277\n",
      "Train Epoch: 0, mini-batch 17440 of 25000, training loss: 0.613652\n",
      "Train Epoch: 0, mini-batch 17450 of 25000, training loss: 0.203813\n",
      "Train Epoch: 0, mini-batch 17460 of 25000, training loss: 0.039347\n",
      "Train Epoch: 0, mini-batch 17470 of 25000, training loss: 0.047505\n",
      "Train Epoch: 0, mini-batch 17480 of 25000, training loss: 0.041138\n",
      "Train Epoch: 0, mini-batch 17490 of 25000, training loss: 0.080421\n",
      "Train Epoch: 0, mini-batch 17500 of 25000, training loss: 0.066559\n",
      "Train Epoch: 0, mini-batch 17510 of 25000, training loss: 0.014744\n",
      "Train Epoch: 0, mini-batch 17520 of 25000, training loss: 1.101572\n",
      "Train Epoch: 0, mini-batch 17530 of 25000, training loss: 0.242366\n",
      "Train Epoch: 0, mini-batch 17540 of 25000, training loss: 0.015600\n",
      "Train Epoch: 0, mini-batch 17550 of 25000, training loss: 0.161215\n",
      "Train Epoch: 0, mini-batch 17560 of 25000, training loss: 0.028286\n",
      "Train Epoch: 0, mini-batch 17570 of 25000, training loss: 0.106608\n",
      "Train Epoch: 0, mini-batch 17580 of 25000, training loss: 0.051245\n",
      "Train Epoch: 0, mini-batch 17590 of 25000, training loss: 0.394336\n",
      "Train Epoch: 0, mini-batch 17600 of 25000, training loss: 0.026970\n",
      "Train Epoch: 0, mini-batch 17610 of 25000, training loss: 0.378568\n",
      "Train Epoch: 0, mini-batch 17620 of 25000, training loss: 0.157300\n",
      "Train Epoch: 0, mini-batch 17630 of 25000, training loss: 0.298624\n",
      "Train Epoch: 0, mini-batch 17640 of 25000, training loss: 0.934237\n",
      "Train Epoch: 0, mini-batch 17650 of 25000, training loss: 0.176857\n",
      "Train Epoch: 0, mini-batch 17660 of 25000, training loss: 0.043312\n",
      "Train Epoch: 0, mini-batch 17670 of 25000, training loss: 0.365653\n",
      "Train Epoch: 0, mini-batch 17680 of 25000, training loss: 0.003653\n",
      "Train Epoch: 0, mini-batch 17690 of 25000, training loss: 0.023296\n",
      "Train Epoch: 0, mini-batch 17700 of 25000, training loss: 0.325109\n",
      "Train Epoch: 0, mini-batch 17710 of 25000, training loss: 0.556047\n",
      "Train Epoch: 0, mini-batch 17720 of 25000, training loss: 0.037263\n",
      "Train Epoch: 0, mini-batch 17730 of 25000, training loss: 0.007080\n",
      "Train Epoch: 0, mini-batch 17740 of 25000, training loss: 0.226455\n",
      "Train Epoch: 0, mini-batch 17750 of 25000, training loss: 0.132635\n",
      "Train Epoch: 0, mini-batch 17760 of 25000, training loss: 0.228316\n",
      "Train Epoch: 0, mini-batch 17770 of 25000, training loss: 0.002626\n",
      "Train Epoch: 0, mini-batch 17780 of 25000, training loss: 0.010276\n",
      "Train Epoch: 0, mini-batch 17790 of 25000, training loss: 0.129834\n",
      "Train Epoch: 0, mini-batch 17800 of 25000, training loss: 0.072843\n",
      "Train Epoch: 0, mini-batch 17810 of 25000, training loss: 1.123273\n",
      "Train Epoch: 0, mini-batch 17820 of 25000, training loss: 0.037840\n",
      "Train Epoch: 0, mini-batch 17830 of 25000, training loss: 0.038541\n",
      "Train Epoch: 0, mini-batch 17840 of 25000, training loss: 0.208913\n",
      "Train Epoch: 0, mini-batch 17850 of 25000, training loss: 0.082498\n",
      "Train Epoch: 0, mini-batch 17860 of 25000, training loss: 0.348626\n",
      "Train Epoch: 0, mini-batch 17870 of 25000, training loss: 0.323056\n",
      "Train Epoch: 0, mini-batch 17880 of 25000, training loss: 0.004950\n",
      "Train Epoch: 0, mini-batch 17890 of 25000, training loss: 0.166488\n",
      "Train Epoch: 0, mini-batch 17900 of 25000, training loss: 0.000282\n",
      "Train Epoch: 0, mini-batch 17910 of 25000, training loss: 0.973509\n",
      "Train Epoch: 0, mini-batch 17920 of 25000, training loss: 0.331321\n",
      "Train Epoch: 0, mini-batch 17930 of 25000, training loss: 1.986357\n",
      "Train Epoch: 0, mini-batch 17940 of 25000, training loss: 0.034848\n",
      "Train Epoch: 0, mini-batch 17950 of 25000, training loss: 0.007664\n",
      "Train Epoch: 0, mini-batch 17960 of 25000, training loss: 0.080113\n",
      "Train Epoch: 0, mini-batch 17970 of 25000, training loss: 0.832551\n",
      "Train Epoch: 0, mini-batch 17980 of 25000, training loss: 0.050325\n",
      "Train Epoch: 0, mini-batch 17990 of 25000, training loss: 0.000816\n",
      "Train Epoch: 0, mini-batch 18000 of 25000, training loss: 0.020616\n",
      "Train Epoch: 0, mini-batch 18010 of 25000, training loss: 0.120238\n",
      "Train Epoch: 0, mini-batch 18020 of 25000, training loss: 0.026817\n",
      "Train Epoch: 0, mini-batch 18030 of 25000, training loss: 3.454917\n",
      "Train Epoch: 0, mini-batch 18040 of 25000, training loss: 0.076984\n",
      "Train Epoch: 0, mini-batch 18050 of 25000, training loss: 0.005555\n",
      "Train Epoch: 0, mini-batch 18060 of 25000, training loss: 0.019586\n",
      "Train Epoch: 0, mini-batch 18070 of 25000, training loss: 0.010213\n",
      "Train Epoch: 0, mini-batch 18080 of 25000, training loss: 0.225770\n",
      "Train Epoch: 0, mini-batch 18090 of 25000, training loss: 0.049603\n",
      "Train Epoch: 0, mini-batch 18100 of 25000, training loss: 0.430417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 18110 of 25000, training loss: 0.305988\n",
      "Train Epoch: 0, mini-batch 18120 of 25000, training loss: 0.144220\n",
      "Train Epoch: 0, mini-batch 18130 of 25000, training loss: 0.060948\n",
      "Train Epoch: 0, mini-batch 18140 of 25000, training loss: 0.151573\n",
      "Train Epoch: 0, mini-batch 18150 of 25000, training loss: 0.056079\n",
      "Train Epoch: 0, mini-batch 18160 of 25000, training loss: 0.005527\n",
      "Train Epoch: 0, mini-batch 18170 of 25000, training loss: 0.980717\n",
      "Train Epoch: 0, mini-batch 18180 of 25000, training loss: 0.021968\n",
      "Train Epoch: 0, mini-batch 18190 of 25000, training loss: 1.337979\n",
      "Train Epoch: 0, mini-batch 18200 of 25000, training loss: 0.005598\n",
      "Train Epoch: 0, mini-batch 18210 of 25000, training loss: 0.009470\n",
      "Train Epoch: 0, mini-batch 18220 of 25000, training loss: 0.055478\n",
      "Train Epoch: 0, mini-batch 18230 of 25000, training loss: 1.284391\n",
      "Train Epoch: 0, mini-batch 18240 of 25000, training loss: 0.003926\n",
      "Train Epoch: 0, mini-batch 18250 of 25000, training loss: 0.013226\n",
      "Train Epoch: 0, mini-batch 18260 of 25000, training loss: 0.052916\n",
      "Train Epoch: 0, mini-batch 18270 of 25000, training loss: 0.395027\n",
      "Train Epoch: 0, mini-batch 18280 of 25000, training loss: 0.392698\n",
      "Train Epoch: 0, mini-batch 18290 of 25000, training loss: 0.001396\n",
      "Train Epoch: 0, mini-batch 18300 of 25000, training loss: 0.005493\n",
      "Train Epoch: 0, mini-batch 18310 of 25000, training loss: 0.297219\n",
      "Train Epoch: 0, mini-batch 18320 of 25000, training loss: 0.574671\n",
      "Train Epoch: 0, mini-batch 18330 of 25000, training loss: 0.224087\n",
      "Train Epoch: 0, mini-batch 18340 of 25000, training loss: 0.053600\n",
      "Train Epoch: 0, mini-batch 18350 of 25000, training loss: 0.401142\n",
      "Train Epoch: 0, mini-batch 18360 of 25000, training loss: 0.018309\n",
      "Train Epoch: 0, mini-batch 18370 of 25000, training loss: 1.221492\n",
      "Train Epoch: 0, mini-batch 18380 of 25000, training loss: 0.021222\n",
      "Train Epoch: 0, mini-batch 18390 of 25000, training loss: 0.212114\n",
      "Train Epoch: 0, mini-batch 18400 of 25000, training loss: 0.113572\n",
      "Train Epoch: 0, mini-batch 18410 of 25000, training loss: 0.579555\n",
      "Train Epoch: 0, mini-batch 18420 of 25000, training loss: 0.784173\n",
      "Train Epoch: 0, mini-batch 18430 of 25000, training loss: 0.486690\n",
      "Train Epoch: 0, mini-batch 18440 of 25000, training loss: 0.129190\n",
      "Train Epoch: 0, mini-batch 18450 of 25000, training loss: 0.943183\n",
      "Train Epoch: 0, mini-batch 18460 of 25000, training loss: 1.445628\n",
      "Train Epoch: 0, mini-batch 18470 of 25000, training loss: 0.439227\n",
      "Train Epoch: 0, mini-batch 18480 of 25000, training loss: 0.915592\n",
      "Train Epoch: 0, mini-batch 18490 of 25000, training loss: 0.119469\n",
      "Train Epoch: 0, mini-batch 18500 of 25000, training loss: 1.164299\n",
      "Train Epoch: 0, mini-batch 18510 of 25000, training loss: 0.226984\n",
      "Train Epoch: 0, mini-batch 18520 of 25000, training loss: 0.033944\n",
      "Train Epoch: 0, mini-batch 18530 of 25000, training loss: 0.099238\n",
      "Train Epoch: 0, mini-batch 18540 of 25000, training loss: 0.076198\n",
      "Train Epoch: 0, mini-batch 18550 of 25000, training loss: 0.042663\n",
      "Train Epoch: 0, mini-batch 18560 of 25000, training loss: 0.129196\n",
      "Train Epoch: 0, mini-batch 18570 of 25000, training loss: 0.020764\n",
      "Train Epoch: 0, mini-batch 18580 of 25000, training loss: 0.067884\n",
      "Train Epoch: 0, mini-batch 18590 of 25000, training loss: 0.012960\n",
      "Train Epoch: 0, mini-batch 18600 of 25000, training loss: 1.688708\n",
      "Train Epoch: 0, mini-batch 18610 of 25000, training loss: 0.047104\n",
      "Train Epoch: 0, mini-batch 18620 of 25000, training loss: 0.042761\n",
      "Train Epoch: 0, mini-batch 18630 of 25000, training loss: 0.010012\n",
      "Train Epoch: 0, mini-batch 18640 of 25000, training loss: 0.136220\n",
      "Train Epoch: 0, mini-batch 18650 of 25000, training loss: 0.245173\n",
      "Train Epoch: 0, mini-batch 18660 of 25000, training loss: 0.002929\n",
      "Train Epoch: 0, mini-batch 18670 of 25000, training loss: 0.004890\n",
      "Train Epoch: 0, mini-batch 18680 of 25000, training loss: 0.341820\n",
      "Train Epoch: 0, mini-batch 18690 of 25000, training loss: 0.170697\n",
      "Train Epoch: 0, mini-batch 18700 of 25000, training loss: 0.565509\n",
      "Train Epoch: 0, mini-batch 18710 of 25000, training loss: 0.036695\n",
      "Train Epoch: 0, mini-batch 18720 of 25000, training loss: 1.152636\n",
      "Train Epoch: 0, mini-batch 18730 of 25000, training loss: 1.084966\n",
      "Train Epoch: 0, mini-batch 18740 of 25000, training loss: 0.057938\n",
      "Train Epoch: 0, mini-batch 18750 of 25000, training loss: 0.587906\n",
      "Train Epoch: 0, mini-batch 18760 of 25000, training loss: 1.402089\n",
      "Train Epoch: 0, mini-batch 18770 of 25000, training loss: 0.038832\n",
      "Train Epoch: 0, mini-batch 18780 of 25000, training loss: 0.007667\n",
      "Train Epoch: 0, mini-batch 18790 of 25000, training loss: 0.017890\n",
      "Train Epoch: 0, mini-batch 18800 of 25000, training loss: 0.404787\n",
      "Train Epoch: 0, mini-batch 18810 of 25000, training loss: 0.016130\n",
      "Train Epoch: 0, mini-batch 18820 of 25000, training loss: 0.134931\n",
      "Train Epoch: 0, mini-batch 18830 of 25000, training loss: 0.164541\n",
      "Train Epoch: 0, mini-batch 18840 of 25000, training loss: 0.393022\n",
      "Train Epoch: 0, mini-batch 18850 of 25000, training loss: 0.188646\n",
      "Train Epoch: 0, mini-batch 18860 of 25000, training loss: 0.030504\n",
      "Train Epoch: 0, mini-batch 18870 of 25000, training loss: 0.596888\n",
      "Train Epoch: 0, mini-batch 18880 of 25000, training loss: 0.016369\n",
      "Train Epoch: 0, mini-batch 18890 of 25000, training loss: 0.009735\n",
      "Train Epoch: 0, mini-batch 18900 of 25000, training loss: 0.191706\n",
      "Train Epoch: 0, mini-batch 18910 of 25000, training loss: 0.105625\n",
      "Train Epoch: 0, mini-batch 18920 of 25000, training loss: 0.073547\n",
      "Train Epoch: 0, mini-batch 18930 of 25000, training loss: 0.004012\n",
      "Train Epoch: 0, mini-batch 18940 of 25000, training loss: 0.040526\n",
      "Train Epoch: 0, mini-batch 18950 of 25000, training loss: 0.005553\n",
      "Train Epoch: 0, mini-batch 18960 of 25000, training loss: 1.166939\n",
      "Train Epoch: 0, mini-batch 18970 of 25000, training loss: 0.040674\n",
      "Train Epoch: 0, mini-batch 18980 of 25000, training loss: 0.003603\n",
      "Train Epoch: 0, mini-batch 18990 of 25000, training loss: 0.107523\n",
      "Train Epoch: 0, mini-batch 19000 of 25000, training loss: 0.288518\n",
      "Train Epoch: 0, mini-batch 19010 of 25000, training loss: 1.149313\n",
      "Train Epoch: 0, mini-batch 19020 of 25000, training loss: 0.148518\n",
      "Train Epoch: 0, mini-batch 19030 of 25000, training loss: 0.047748\n",
      "Train Epoch: 0, mini-batch 19040 of 25000, training loss: 0.066790\n",
      "Train Epoch: 0, mini-batch 19050 of 25000, training loss: 0.598712\n",
      "Train Epoch: 0, mini-batch 19060 of 25000, training loss: 0.012911\n",
      "Train Epoch: 0, mini-batch 19070 of 25000, training loss: 0.407954\n",
      "Train Epoch: 0, mini-batch 19080 of 25000, training loss: 0.024682\n",
      "Train Epoch: 0, mini-batch 19090 of 25000, training loss: 0.163353\n",
      "Train Epoch: 0, mini-batch 19100 of 25000, training loss: 0.151523\n",
      "Train Epoch: 0, mini-batch 19110 of 25000, training loss: 0.564271\n",
      "Train Epoch: 0, mini-batch 19120 of 25000, training loss: 0.016664\n",
      "Train Epoch: 0, mini-batch 19130 of 25000, training loss: 0.151001\n",
      "Train Epoch: 0, mini-batch 19140 of 25000, training loss: 0.006419\n",
      "Train Epoch: 0, mini-batch 19150 of 25000, training loss: 0.045396\n",
      "Train Epoch: 0, mini-batch 19160 of 25000, training loss: 0.024798\n",
      "Train Epoch: 0, mini-batch 19170 of 25000, training loss: 0.045932\n",
      "Train Epoch: 0, mini-batch 19180 of 25000, training loss: 1.530524\n",
      "Train Epoch: 0, mini-batch 19190 of 25000, training loss: 1.867851\n",
      "Train Epoch: 0, mini-batch 19200 of 25000, training loss: 0.018244\n",
      "Train Epoch: 0, mini-batch 19210 of 25000, training loss: 0.415488\n",
      "Train Epoch: 0, mini-batch 19220 of 25000, training loss: 0.448643\n",
      "Train Epoch: 0, mini-batch 19230 of 25000, training loss: 0.052624\n",
      "Train Epoch: 0, mini-batch 19240 of 25000, training loss: 0.011863\n",
      "Train Epoch: 0, mini-batch 19250 of 25000, training loss: 0.008088\n",
      "Train Epoch: 0, mini-batch 19260 of 25000, training loss: 0.028409\n",
      "Train Epoch: 0, mini-batch 19270 of 25000, training loss: 0.042204\n",
      "Train Epoch: 0, mini-batch 19280 of 25000, training loss: 0.551707\n",
      "Train Epoch: 0, mini-batch 19290 of 25000, training loss: 0.037511\n",
      "Train Epoch: 0, mini-batch 19300 of 25000, training loss: 0.008189\n",
      "Train Epoch: 0, mini-batch 19310 of 25000, training loss: 0.201271\n",
      "Train Epoch: 0, mini-batch 19320 of 25000, training loss: 0.017227\n",
      "Train Epoch: 0, mini-batch 19330 of 25000, training loss: 0.002094\n",
      "Train Epoch: 0, mini-batch 19340 of 25000, training loss: 0.307476\n",
      "Train Epoch: 0, mini-batch 19350 of 25000, training loss: 0.132591\n",
      "Train Epoch: 0, mini-batch 19360 of 25000, training loss: 0.236873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 19370 of 25000, training loss: 0.007493\n",
      "Train Epoch: 0, mini-batch 19380 of 25000, training loss: 0.414980\n",
      "Train Epoch: 0, mini-batch 19390 of 25000, training loss: 0.032032\n",
      "Train Epoch: 0, mini-batch 19400 of 25000, training loss: 1.750396\n",
      "Train Epoch: 0, mini-batch 19410 of 25000, training loss: 0.166618\n",
      "Train Epoch: 0, mini-batch 19420 of 25000, training loss: 0.035464\n",
      "Train Epoch: 0, mini-batch 19430 of 25000, training loss: 0.125427\n",
      "Train Epoch: 0, mini-batch 19440 of 25000, training loss: 0.009154\n",
      "Train Epoch: 0, mini-batch 19450 of 25000, training loss: 0.001513\n",
      "Train Epoch: 0, mini-batch 19460 of 25000, training loss: 0.029878\n",
      "Train Epoch: 0, mini-batch 19470 of 25000, training loss: 0.257645\n",
      "Train Epoch: 0, mini-batch 19480 of 25000, training loss: 0.014918\n",
      "Train Epoch: 0, mini-batch 19490 of 25000, training loss: 0.032626\n",
      "Train Epoch: 0, mini-batch 19500 of 25000, training loss: 0.033073\n",
      "Train Epoch: 0, mini-batch 19510 of 25000, training loss: 0.003590\n",
      "Train Epoch: 0, mini-batch 19520 of 25000, training loss: 0.254549\n",
      "Train Epoch: 0, mini-batch 19530 of 25000, training loss: 0.212927\n",
      "Train Epoch: 0, mini-batch 19540 of 25000, training loss: 0.052019\n",
      "Train Epoch: 0, mini-batch 19550 of 25000, training loss: 0.451336\n",
      "Train Epoch: 0, mini-batch 19560 of 25000, training loss: 0.060529\n",
      "Train Epoch: 0, mini-batch 19570 of 25000, training loss: 0.089490\n",
      "Train Epoch: 0, mini-batch 19580 of 25000, training loss: 0.002557\n",
      "Train Epoch: 0, mini-batch 19590 of 25000, training loss: 0.029603\n",
      "Train Epoch: 0, mini-batch 19600 of 25000, training loss: 0.010847\n",
      "Train Epoch: 0, mini-batch 19610 of 25000, training loss: 0.072902\n",
      "Train Epoch: 0, mini-batch 19620 of 25000, training loss: 0.168688\n",
      "Train Epoch: 0, mini-batch 19630 of 25000, training loss: 0.000549\n",
      "Train Epoch: 0, mini-batch 19640 of 25000, training loss: 0.030878\n",
      "Train Epoch: 0, mini-batch 19650 of 25000, training loss: 0.041401\n",
      "Train Epoch: 0, mini-batch 19660 of 25000, training loss: 0.049454\n",
      "Train Epoch: 0, mini-batch 19670 of 25000, training loss: 0.094749\n",
      "Train Epoch: 0, mini-batch 19680 of 25000, training loss: 1.366118\n",
      "Train Epoch: 0, mini-batch 19690 of 25000, training loss: 1.205667\n",
      "Train Epoch: 0, mini-batch 19700 of 25000, training loss: 0.336183\n",
      "Train Epoch: 0, mini-batch 19710 of 25000, training loss: 0.014128\n",
      "Train Epoch: 0, mini-batch 19720 of 25000, training loss: 0.631446\n",
      "Train Epoch: 0, mini-batch 19730 of 25000, training loss: 0.702371\n",
      "Train Epoch: 0, mini-batch 19740 of 25000, training loss: 0.136494\n",
      "Train Epoch: 0, mini-batch 19750 of 25000, training loss: 0.009480\n",
      "Train Epoch: 0, mini-batch 19760 of 25000, training loss: 0.053706\n",
      "Train Epoch: 0, mini-batch 19770 of 25000, training loss: 0.016385\n",
      "Train Epoch: 0, mini-batch 19780 of 25000, training loss: 0.107477\n",
      "Train Epoch: 0, mini-batch 19790 of 25000, training loss: 1.517258\n",
      "Train Epoch: 0, mini-batch 19800 of 25000, training loss: 0.480911\n",
      "Train Epoch: 0, mini-batch 19810 of 25000, training loss: 0.003130\n",
      "Train Epoch: 0, mini-batch 19820 of 25000, training loss: 0.000013\n",
      "Train Epoch: 0, mini-batch 19830 of 25000, training loss: 0.058319\n",
      "Train Epoch: 0, mini-batch 19840 of 25000, training loss: 0.663522\n",
      "Train Epoch: 0, mini-batch 19850 of 25000, training loss: 0.029783\n",
      "Train Epoch: 0, mini-batch 19860 of 25000, training loss: 0.049633\n",
      "Train Epoch: 0, mini-batch 19870 of 25000, training loss: 0.000858\n",
      "Train Epoch: 0, mini-batch 19880 of 25000, training loss: 0.295042\n",
      "Train Epoch: 0, mini-batch 19890 of 25000, training loss: 0.101277\n",
      "Train Epoch: 0, mini-batch 19900 of 25000, training loss: 3.405985\n",
      "Train Epoch: 0, mini-batch 19910 of 25000, training loss: 0.359563\n",
      "Train Epoch: 0, mini-batch 19920 of 25000, training loss: 2.186889\n",
      "Train Epoch: 0, mini-batch 19930 of 25000, training loss: 0.085082\n",
      "Train Epoch: 0, mini-batch 19940 of 25000, training loss: 0.999742\n",
      "Train Epoch: 0, mini-batch 19950 of 25000, training loss: 0.007677\n",
      "Train Epoch: 0, mini-batch 19960 of 25000, training loss: 0.031127\n",
      "Train Epoch: 0, mini-batch 19970 of 25000, training loss: 0.007049\n",
      "Train Epoch: 0, mini-batch 19980 of 25000, training loss: 1.471820\n",
      "Train Epoch: 0, mini-batch 19990 of 25000, training loss: 0.125958\n",
      "Train Epoch: 0, mini-batch 20000 of 25000, training loss: 1.159350\n",
      "Train Epoch: 0, mini-batch 20010 of 25000, training loss: 0.028081\n",
      "Train Epoch: 0, mini-batch 20020 of 25000, training loss: 0.013706\n",
      "Train Epoch: 0, mini-batch 20030 of 25000, training loss: 0.063040\n",
      "Train Epoch: 0, mini-batch 20040 of 25000, training loss: 0.025042\n",
      "Train Epoch: 0, mini-batch 20050 of 25000, training loss: 0.056940\n",
      "Train Epoch: 0, mini-batch 20060 of 25000, training loss: 0.032332\n",
      "Train Epoch: 0, mini-batch 20070 of 25000, training loss: 0.030447\n",
      "Train Epoch: 0, mini-batch 20080 of 25000, training loss: 0.357230\n",
      "Train Epoch: 0, mini-batch 20090 of 25000, training loss: 0.040570\n",
      "Train Epoch: 0, mini-batch 20100 of 25000, training loss: 0.038052\n",
      "Train Epoch: 0, mini-batch 20110 of 25000, training loss: 0.202815\n",
      "Train Epoch: 0, mini-batch 20120 of 25000, training loss: 0.133954\n",
      "Train Epoch: 0, mini-batch 20130 of 25000, training loss: 2.278666\n",
      "Train Epoch: 0, mini-batch 20140 of 25000, training loss: 1.018121\n",
      "Train Epoch: 0, mini-batch 20150 of 25000, training loss: 0.048097\n",
      "Train Epoch: 0, mini-batch 20160 of 25000, training loss: 0.468713\n",
      "Train Epoch: 0, mini-batch 20170 of 25000, training loss: 1.400089\n",
      "Train Epoch: 0, mini-batch 20180 of 25000, training loss: 0.031673\n",
      "Train Epoch: 0, mini-batch 20190 of 25000, training loss: 0.947739\n",
      "Train Epoch: 0, mini-batch 20200 of 25000, training loss: 0.097717\n",
      "Train Epoch: 0, mini-batch 20210 of 25000, training loss: 0.034796\n",
      "Train Epoch: 0, mini-batch 20220 of 25000, training loss: 0.009070\n",
      "Train Epoch: 0, mini-batch 20230 of 25000, training loss: 0.020607\n",
      "Train Epoch: 0, mini-batch 20240 of 25000, training loss: 0.739358\n",
      "Train Epoch: 0, mini-batch 20250 of 25000, training loss: 1.112144\n",
      "Train Epoch: 0, mini-batch 20260 of 25000, training loss: 0.071649\n",
      "Train Epoch: 0, mini-batch 20270 of 25000, training loss: 0.055688\n",
      "Train Epoch: 0, mini-batch 20280 of 25000, training loss: 0.000237\n",
      "Train Epoch: 0, mini-batch 20290 of 25000, training loss: 0.011356\n",
      "Train Epoch: 0, mini-batch 20300 of 25000, training loss: 0.009193\n",
      "Train Epoch: 0, mini-batch 20310 of 25000, training loss: 0.015933\n",
      "Train Epoch: 0, mini-batch 20320 of 25000, training loss: 0.826331\n",
      "Train Epoch: 0, mini-batch 20330 of 25000, training loss: 0.069571\n",
      "Train Epoch: 0, mini-batch 20340 of 25000, training loss: 0.103896\n",
      "Train Epoch: 0, mini-batch 20350 of 25000, training loss: 0.003303\n",
      "Train Epoch: 0, mini-batch 20360 of 25000, training loss: 0.302061\n",
      "Train Epoch: 0, mini-batch 20370 of 25000, training loss: 0.001753\n",
      "Train Epoch: 0, mini-batch 20380 of 25000, training loss: 0.544664\n",
      "Train Epoch: 0, mini-batch 20390 of 25000, training loss: 0.053982\n",
      "Train Epoch: 0, mini-batch 20400 of 25000, training loss: 1.091213\n",
      "Train Epoch: 0, mini-batch 20410 of 25000, training loss: 0.000791\n",
      "Train Epoch: 0, mini-batch 20420 of 25000, training loss: 0.015250\n",
      "Train Epoch: 0, mini-batch 20430 of 25000, training loss: 0.001496\n",
      "Train Epoch: 0, mini-batch 20440 of 25000, training loss: 0.060145\n",
      "Train Epoch: 0, mini-batch 20450 of 25000, training loss: 0.003106\n",
      "Train Epoch: 0, mini-batch 20460 of 25000, training loss: 0.095998\n",
      "Train Epoch: 0, mini-batch 20470 of 25000, training loss: 0.146887\n",
      "Train Epoch: 0, mini-batch 20480 of 25000, training loss: 0.263017\n",
      "Train Epoch: 0, mini-batch 20490 of 25000, training loss: 2.397994\n",
      "Train Epoch: 0, mini-batch 20500 of 25000, training loss: 0.584376\n",
      "Train Epoch: 0, mini-batch 20510 of 25000, training loss: 0.433882\n",
      "Train Epoch: 0, mini-batch 20520 of 25000, training loss: 0.004846\n",
      "Train Epoch: 0, mini-batch 20530 of 25000, training loss: 0.048976\n",
      "Train Epoch: 0, mini-batch 20540 of 25000, training loss: 0.014747\n",
      "Train Epoch: 0, mini-batch 20550 of 25000, training loss: 0.509401\n",
      "Train Epoch: 0, mini-batch 20560 of 25000, training loss: 0.000870\n",
      "Train Epoch: 0, mini-batch 20570 of 25000, training loss: 0.002931\n",
      "Train Epoch: 0, mini-batch 20580 of 25000, training loss: 0.390184\n",
      "Train Epoch: 0, mini-batch 20590 of 25000, training loss: 0.230427\n",
      "Train Epoch: 0, mini-batch 20600 of 25000, training loss: 0.160626\n",
      "Train Epoch: 0, mini-batch 20610 of 25000, training loss: 0.009125\n",
      "Train Epoch: 0, mini-batch 20620 of 25000, training loss: 0.857793\n",
      "Train Epoch: 0, mini-batch 20630 of 25000, training loss: 0.128714\n",
      "Train Epoch: 0, mini-batch 20640 of 25000, training loss: 0.294581\n",
      "Train Epoch: 0, mini-batch 20650 of 25000, training loss: 0.094953\n",
      "Train Epoch: 0, mini-batch 20660 of 25000, training loss: 0.042951\n",
      "Train Epoch: 0, mini-batch 20670 of 25000, training loss: 1.026193\n",
      "Train Epoch: 0, mini-batch 20680 of 25000, training loss: 0.023317\n",
      "Train Epoch: 0, mini-batch 20690 of 25000, training loss: 0.044721\n",
      "Train Epoch: 0, mini-batch 20700 of 25000, training loss: 0.005344\n",
      "Train Epoch: 0, mini-batch 20710 of 25000, training loss: 0.036344\n",
      "Train Epoch: 0, mini-batch 20720 of 25000, training loss: 0.014899\n",
      "Train Epoch: 0, mini-batch 20730 of 25000, training loss: 0.030201\n",
      "Train Epoch: 0, mini-batch 20740 of 25000, training loss: 0.070057\n",
      "Train Epoch: 0, mini-batch 20750 of 25000, training loss: 1.202016\n",
      "Train Epoch: 0, mini-batch 20760 of 25000, training loss: 1.312409\n",
      "Train Epoch: 0, mini-batch 20770 of 25000, training loss: 0.126336\n",
      "Train Epoch: 0, mini-batch 20780 of 25000, training loss: 0.197707\n",
      "Train Epoch: 0, mini-batch 20790 of 25000, training loss: 0.925957\n",
      "Train Epoch: 0, mini-batch 20800 of 25000, training loss: 0.483509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 20810 of 25000, training loss: 0.123088\n",
      "Train Epoch: 0, mini-batch 20820 of 25000, training loss: 0.217426\n",
      "Train Epoch: 0, mini-batch 20830 of 25000, training loss: 0.301322\n",
      "Train Epoch: 0, mini-batch 20840 of 25000, training loss: 0.003360\n",
      "Train Epoch: 0, mini-batch 20850 of 25000, training loss: 0.011562\n",
      "Train Epoch: 0, mini-batch 20860 of 25000, training loss: 0.101807\n",
      "Train Epoch: 0, mini-batch 20870 of 25000, training loss: 0.112275\n",
      "Train Epoch: 0, mini-batch 20880 of 25000, training loss: 1.341494\n",
      "Train Epoch: 0, mini-batch 20890 of 25000, training loss: 0.018845\n",
      "Train Epoch: 0, mini-batch 20900 of 25000, training loss: 1.957750\n",
      "Train Epoch: 0, mini-batch 20910 of 25000, training loss: 0.020309\n",
      "Train Epoch: 0, mini-batch 20920 of 25000, training loss: 0.005219\n",
      "Train Epoch: 0, mini-batch 20930 of 25000, training loss: 0.256992\n",
      "Train Epoch: 0, mini-batch 20940 of 25000, training loss: 0.129655\n",
      "Train Epoch: 0, mini-batch 20950 of 25000, training loss: 0.242600\n",
      "Train Epoch: 0, mini-batch 20960 of 25000, training loss: 0.160724\n",
      "Train Epoch: 0, mini-batch 20970 of 25000, training loss: 0.178359\n",
      "Train Epoch: 0, mini-batch 20980 of 25000, training loss: 0.002200\n",
      "Train Epoch: 0, mini-batch 20990 of 25000, training loss: 0.017275\n",
      "Train Epoch: 0, mini-batch 21000 of 25000, training loss: 0.142755\n",
      "Train Epoch: 0, mini-batch 21010 of 25000, training loss: 1.826313\n",
      "Train Epoch: 0, mini-batch 21020 of 25000, training loss: 0.008057\n",
      "Train Epoch: 0, mini-batch 21030 of 25000, training loss: 0.079824\n",
      "Train Epoch: 0, mini-batch 21040 of 25000, training loss: 1.026417\n",
      "Train Epoch: 0, mini-batch 21050 of 25000, training loss: 0.437435\n",
      "Train Epoch: 0, mini-batch 21060 of 25000, training loss: 0.606360\n",
      "Train Epoch: 0, mini-batch 21070 of 25000, training loss: 0.003241\n",
      "Train Epoch: 0, mini-batch 21080 of 25000, training loss: 0.565253\n",
      "Train Epoch: 0, mini-batch 21090 of 25000, training loss: 0.096364\n",
      "Train Epoch: 0, mini-batch 21100 of 25000, training loss: 0.010405\n",
      "Train Epoch: 0, mini-batch 21110 of 25000, training loss: 0.044070\n",
      "Train Epoch: 0, mini-batch 21120 of 25000, training loss: 0.071153\n",
      "Train Epoch: 0, mini-batch 21130 of 25000, training loss: 0.345892\n",
      "Train Epoch: 0, mini-batch 21140 of 25000, training loss: 0.000028\n",
      "Train Epoch: 0, mini-batch 21150 of 25000, training loss: 0.185069\n",
      "Train Epoch: 0, mini-batch 21160 of 25000, training loss: 0.101582\n",
      "Train Epoch: 0, mini-batch 21170 of 25000, training loss: 0.095125\n",
      "Train Epoch: 0, mini-batch 21180 of 25000, training loss: 0.007846\n",
      "Train Epoch: 0, mini-batch 21190 of 25000, training loss: 0.055556\n",
      "Train Epoch: 0, mini-batch 21200 of 25000, training loss: 0.119486\n",
      "Train Epoch: 0, mini-batch 21210 of 25000, training loss: 0.024336\n",
      "Train Epoch: 0, mini-batch 21220 of 25000, training loss: 0.534713\n",
      "Train Epoch: 0, mini-batch 21230 of 25000, training loss: 0.525289\n",
      "Train Epoch: 0, mini-batch 21240 of 25000, training loss: 0.050128\n",
      "Train Epoch: 0, mini-batch 21250 of 25000, training loss: 0.105928\n",
      "Train Epoch: 0, mini-batch 21260 of 25000, training loss: 0.020803\n",
      "Train Epoch: 0, mini-batch 21270 of 25000, training loss: 0.978103\n",
      "Train Epoch: 0, mini-batch 21280 of 25000, training loss: 1.368703\n",
      "Train Epoch: 0, mini-batch 21290 of 25000, training loss: 0.044530\n",
      "Train Epoch: 0, mini-batch 21300 of 25000, training loss: 0.027157\n",
      "Train Epoch: 0, mini-batch 21310 of 25000, training loss: 0.186650\n",
      "Train Epoch: 0, mini-batch 21320 of 25000, training loss: 0.002354\n",
      "Train Epoch: 0, mini-batch 21330 of 25000, training loss: 0.095677\n",
      "Train Epoch: 0, mini-batch 21340 of 25000, training loss: 0.027281\n",
      "Train Epoch: 0, mini-batch 21350 of 25000, training loss: 1.246189\n",
      "Train Epoch: 0, mini-batch 21360 of 25000, training loss: 0.156984\n",
      "Train Epoch: 0, mini-batch 21370 of 25000, training loss: 3.697265\n",
      "Train Epoch: 0, mini-batch 21380 of 25000, training loss: 0.066340\n",
      "Train Epoch: 0, mini-batch 21390 of 25000, training loss: 0.021175\n",
      "Train Epoch: 0, mini-batch 21400 of 25000, training loss: 0.000180\n",
      "Train Epoch: 0, mini-batch 21410 of 25000, training loss: 2.166481\n",
      "Train Epoch: 0, mini-batch 21420 of 25000, training loss: 0.092672\n",
      "Train Epoch: 0, mini-batch 21430 of 25000, training loss: 0.071010\n",
      "Train Epoch: 0, mini-batch 21440 of 25000, training loss: 0.176500\n",
      "Train Epoch: 0, mini-batch 21450 of 25000, training loss: 0.056209\n",
      "Train Epoch: 0, mini-batch 21460 of 25000, training loss: 0.157696\n",
      "Train Epoch: 0, mini-batch 21470 of 25000, training loss: 0.007243\n",
      "Train Epoch: 0, mini-batch 21480 of 25000, training loss: 0.048778\n",
      "Train Epoch: 0, mini-batch 21490 of 25000, training loss: 0.000445\n",
      "Train Epoch: 0, mini-batch 21500 of 25000, training loss: 0.815976\n",
      "Train Epoch: 0, mini-batch 21510 of 25000, training loss: 0.552655\n",
      "Train Epoch: 0, mini-batch 21520 of 25000, training loss: 0.032998\n",
      "Train Epoch: 0, mini-batch 21530 of 25000, training loss: 0.108264\n",
      "Train Epoch: 0, mini-batch 21540 of 25000, training loss: 0.133081\n",
      "Train Epoch: 0, mini-batch 21550 of 25000, training loss: 0.874318\n",
      "Train Epoch: 0, mini-batch 21560 of 25000, training loss: 0.225477\n",
      "Train Epoch: 0, mini-batch 21570 of 25000, training loss: 0.834141\n",
      "Train Epoch: 0, mini-batch 21580 of 25000, training loss: 0.054514\n",
      "Train Epoch: 0, mini-batch 21590 of 25000, training loss: 0.069718\n",
      "Train Epoch: 0, mini-batch 21600 of 25000, training loss: 0.002355\n",
      "Train Epoch: 0, mini-batch 21610 of 25000, training loss: 0.021073\n",
      "Train Epoch: 0, mini-batch 21620 of 25000, training loss: 0.053763\n",
      "Train Epoch: 0, mini-batch 21630 of 25000, training loss: 0.504236\n",
      "Train Epoch: 0, mini-batch 21640 of 25000, training loss: 0.090313\n",
      "Train Epoch: 0, mini-batch 21650 of 25000, training loss: 0.227179\n",
      "Train Epoch: 0, mini-batch 21660 of 25000, training loss: 0.002940\n",
      "Train Epoch: 0, mini-batch 21670 of 25000, training loss: 1.017136\n",
      "Train Epoch: 0, mini-batch 21680 of 25000, training loss: 1.800453\n",
      "Train Epoch: 0, mini-batch 21690 of 25000, training loss: 0.000332\n",
      "Train Epoch: 0, mini-batch 21700 of 25000, training loss: 0.008614\n",
      "Train Epoch: 0, mini-batch 21710 of 25000, training loss: 0.094536\n",
      "Train Epoch: 0, mini-batch 21720 of 25000, training loss: 0.244577\n",
      "Train Epoch: 0, mini-batch 21730 of 25000, training loss: 0.015923\n",
      "Train Epoch: 0, mini-batch 21740 of 25000, training loss: 0.011699\n",
      "Train Epoch: 0, mini-batch 21750 of 25000, training loss: 0.104188\n",
      "Train Epoch: 0, mini-batch 21760 of 25000, training loss: 0.009699\n",
      "Train Epoch: 0, mini-batch 21770 of 25000, training loss: 0.041245\n",
      "Train Epoch: 0, mini-batch 21780 of 25000, training loss: 0.045951\n",
      "Train Epoch: 0, mini-batch 21790 of 25000, training loss: 0.000408\n",
      "Train Epoch: 0, mini-batch 21800 of 25000, training loss: 0.007153\n",
      "Train Epoch: 0, mini-batch 21810 of 25000, training loss: 0.167742\n",
      "Train Epoch: 0, mini-batch 21820 of 25000, training loss: 0.224321\n",
      "Train Epoch: 0, mini-batch 21830 of 25000, training loss: 0.053235\n",
      "Train Epoch: 0, mini-batch 21840 of 25000, training loss: 0.122902\n",
      "Train Epoch: 0, mini-batch 21850 of 25000, training loss: 3.234094\n",
      "Train Epoch: 0, mini-batch 21860 of 25000, training loss: 0.001383\n",
      "Train Epoch: 0, mini-batch 21870 of 25000, training loss: 0.000008\n",
      "Train Epoch: 0, mini-batch 21880 of 25000, training loss: 0.546031\n",
      "Train Epoch: 0, mini-batch 21890 of 25000, training loss: 0.018737\n",
      "Train Epoch: 0, mini-batch 21900 of 25000, training loss: 0.022560\n",
      "Train Epoch: 0, mini-batch 21910 of 25000, training loss: 0.560147\n",
      "Train Epoch: 0, mini-batch 21920 of 25000, training loss: 0.081909\n",
      "Train Epoch: 0, mini-batch 21930 of 25000, training loss: 0.017289\n",
      "Train Epoch: 0, mini-batch 21940 of 25000, training loss: 0.090715\n",
      "Train Epoch: 0, mini-batch 21950 of 25000, training loss: 0.192946\n",
      "Train Epoch: 0, mini-batch 21960 of 25000, training loss: 5.404890\n",
      "Train Epoch: 0, mini-batch 21970 of 25000, training loss: 0.074474\n",
      "Train Epoch: 0, mini-batch 21980 of 25000, training loss: 0.403990\n",
      "Train Epoch: 0, mini-batch 21990 of 25000, training loss: 0.248364\n",
      "Train Epoch: 0, mini-batch 22000 of 25000, training loss: 0.031640\n",
      "Train Epoch: 0, mini-batch 22010 of 25000, training loss: 0.746303\n",
      "Train Epoch: 0, mini-batch 22020 of 25000, training loss: 0.054005\n",
      "Train Epoch: 0, mini-batch 22030 of 25000, training loss: 1.013238\n",
      "Train Epoch: 0, mini-batch 22040 of 25000, training loss: 0.362806\n",
      "Train Epoch: 0, mini-batch 22050 of 25000, training loss: 0.052783\n",
      "Train Epoch: 0, mini-batch 22060 of 25000, training loss: 0.113459\n",
      "Train Epoch: 0, mini-batch 22070 of 25000, training loss: 0.336167\n",
      "Train Epoch: 0, mini-batch 22080 of 25000, training loss: 0.038915\n",
      "Train Epoch: 0, mini-batch 22090 of 25000, training loss: 0.456304\n",
      "Train Epoch: 0, mini-batch 22100 of 25000, training loss: 0.025326\n",
      "Train Epoch: 0, mini-batch 22110 of 25000, training loss: 0.096405\n",
      "Train Epoch: 0, mini-batch 22120 of 25000, training loss: 0.086472\n",
      "Train Epoch: 0, mini-batch 22130 of 25000, training loss: 0.104805\n",
      "Train Epoch: 0, mini-batch 22140 of 25000, training loss: 0.064438\n",
      "Train Epoch: 0, mini-batch 22150 of 25000, training loss: 0.878690\n",
      "Train Epoch: 0, mini-batch 22160 of 25000, training loss: 0.106069\n",
      "Train Epoch: 0, mini-batch 22170 of 25000, training loss: 0.008275\n",
      "Train Epoch: 0, mini-batch 22180 of 25000, training loss: 0.074870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 22190 of 25000, training loss: 0.023039\n",
      "Train Epoch: 0, mini-batch 22200 of 25000, training loss: 0.013306\n",
      "Train Epoch: 0, mini-batch 22210 of 25000, training loss: 0.363100\n",
      "Train Epoch: 0, mini-batch 22220 of 25000, training loss: 0.009641\n",
      "Train Epoch: 0, mini-batch 22230 of 25000, training loss: 0.540001\n",
      "Train Epoch: 0, mini-batch 22240 of 25000, training loss: 0.028538\n",
      "Train Epoch: 0, mini-batch 22250 of 25000, training loss: 0.026374\n",
      "Train Epoch: 0, mini-batch 22260 of 25000, training loss: 1.303832\n",
      "Train Epoch: 0, mini-batch 22270 of 25000, training loss: 0.061830\n",
      "Train Epoch: 0, mini-batch 22280 of 25000, training loss: 2.132433\n",
      "Train Epoch: 0, mini-batch 22290 of 25000, training loss: 0.016168\n",
      "Train Epoch: 0, mini-batch 22300 of 25000, training loss: 0.008035\n",
      "Train Epoch: 0, mini-batch 22310 of 25000, training loss: 0.007714\n",
      "Train Epoch: 0, mini-batch 22320 of 25000, training loss: 0.008672\n",
      "Train Epoch: 0, mini-batch 22330 of 25000, training loss: 0.073222\n",
      "Train Epoch: 0, mini-batch 22340 of 25000, training loss: 0.120066\n",
      "Train Epoch: 0, mini-batch 22350 of 25000, training loss: 0.017355\n",
      "Train Epoch: 0, mini-batch 22360 of 25000, training loss: 0.040881\n",
      "Train Epoch: 0, mini-batch 22370 of 25000, training loss: 0.037345\n",
      "Train Epoch: 0, mini-batch 22380 of 25000, training loss: 0.003982\n",
      "Train Epoch: 0, mini-batch 22390 of 25000, training loss: 0.948666\n",
      "Train Epoch: 0, mini-batch 22400 of 25000, training loss: 0.003168\n",
      "Train Epoch: 0, mini-batch 22410 of 25000, training loss: 0.012557\n",
      "Train Epoch: 0, mini-batch 22420 of 25000, training loss: 0.240297\n",
      "Train Epoch: 0, mini-batch 22430 of 25000, training loss: 0.029994\n",
      "Train Epoch: 0, mini-batch 22440 of 25000, training loss: 0.043721\n",
      "Train Epoch: 0, mini-batch 22450 of 25000, training loss: 0.086538\n",
      "Train Epoch: 0, mini-batch 22460 of 25000, training loss: 0.003463\n",
      "Train Epoch: 0, mini-batch 22470 of 25000, training loss: 0.030487\n",
      "Train Epoch: 0, mini-batch 22480 of 25000, training loss: 0.000855\n",
      "Train Epoch: 0, mini-batch 22490 of 25000, training loss: 0.151071\n",
      "Train Epoch: 0, mini-batch 22500 of 25000, training loss: 0.007775\n",
      "Train Epoch: 0, mini-batch 22510 of 25000, training loss: 0.031615\n",
      "Train Epoch: 0, mini-batch 22520 of 25000, training loss: 0.160885\n",
      "Train Epoch: 0, mini-batch 22530 of 25000, training loss: 0.575601\n",
      "Train Epoch: 0, mini-batch 22540 of 25000, training loss: 0.117395\n",
      "Train Epoch: 0, mini-batch 22550 of 25000, training loss: 0.306648\n",
      "Train Epoch: 0, mini-batch 22560 of 25000, training loss: 0.653890\n",
      "Train Epoch: 0, mini-batch 22570 of 25000, training loss: 0.015102\n",
      "Train Epoch: 0, mini-batch 22580 of 25000, training loss: 0.124269\n",
      "Train Epoch: 0, mini-batch 22590 of 25000, training loss: 0.956598\n",
      "Train Epoch: 0, mini-batch 22600 of 25000, training loss: 0.625517\n",
      "Train Epoch: 0, mini-batch 22610 of 25000, training loss: 0.586476\n",
      "Train Epoch: 0, mini-batch 22620 of 25000, training loss: 0.261230\n",
      "Train Epoch: 0, mini-batch 22630 of 25000, training loss: 0.003515\n",
      "Train Epoch: 0, mini-batch 22640 of 25000, training loss: 0.012447\n",
      "Train Epoch: 0, mini-batch 22650 of 25000, training loss: 0.054571\n",
      "Train Epoch: 0, mini-batch 22660 of 25000, training loss: 0.000066\n",
      "Train Epoch: 0, mini-batch 22670 of 25000, training loss: 0.093199\n",
      "Train Epoch: 0, mini-batch 22680 of 25000, training loss: 0.668110\n",
      "Train Epoch: 0, mini-batch 22690 of 25000, training loss: 0.008823\n",
      "Train Epoch: 0, mini-batch 22700 of 25000, training loss: 0.010450\n",
      "Train Epoch: 0, mini-batch 22710 of 25000, training loss: 0.002094\n",
      "Train Epoch: 0, mini-batch 22720 of 25000, training loss: 0.326040\n",
      "Train Epoch: 0, mini-batch 22730 of 25000, training loss: 0.878900\n",
      "Train Epoch: 0, mini-batch 22740 of 25000, training loss: 0.011134\n",
      "Train Epoch: 0, mini-batch 22750 of 25000, training loss: 0.018503\n",
      "Train Epoch: 0, mini-batch 22760 of 25000, training loss: 0.122837\n",
      "Train Epoch: 0, mini-batch 22770 of 25000, training loss: 0.689553\n",
      "Train Epoch: 0, mini-batch 22780 of 25000, training loss: 0.147889\n",
      "Train Epoch: 0, mini-batch 22790 of 25000, training loss: 0.607538\n",
      "Train Epoch: 0, mini-batch 22800 of 25000, training loss: 0.349833\n",
      "Train Epoch: 0, mini-batch 22810 of 25000, training loss: 0.866578\n",
      "Train Epoch: 0, mini-batch 22820 of 25000, training loss: 0.270355\n",
      "Train Epoch: 0, mini-batch 22830 of 25000, training loss: 0.322838\n",
      "Train Epoch: 0, mini-batch 22840 of 25000, training loss: 0.036671\n",
      "Train Epoch: 0, mini-batch 22850 of 25000, training loss: 0.797962\n",
      "Train Epoch: 0, mini-batch 22860 of 25000, training loss: 1.211784\n",
      "Train Epoch: 0, mini-batch 22870 of 25000, training loss: 0.434060\n",
      "Train Epoch: 0, mini-batch 22880 of 25000, training loss: 0.132031\n",
      "Train Epoch: 0, mini-batch 22890 of 25000, training loss: 1.504146\n",
      "Train Epoch: 0, mini-batch 22900 of 25000, training loss: 1.227344\n",
      "Train Epoch: 0, mini-batch 22910 of 25000, training loss: 0.007175\n",
      "Train Epoch: 0, mini-batch 22920 of 25000, training loss: 0.722615\n",
      "Train Epoch: 0, mini-batch 22930 of 25000, training loss: 0.002534\n",
      "Train Epoch: 0, mini-batch 22940 of 25000, training loss: 0.749793\n",
      "Train Epoch: 0, mini-batch 22950 of 25000, training loss: 0.807721\n",
      "Train Epoch: 0, mini-batch 22960 of 25000, training loss: 0.117266\n",
      "Train Epoch: 0, mini-batch 22970 of 25000, training loss: 0.016904\n",
      "Train Epoch: 0, mini-batch 22980 of 25000, training loss: 0.390418\n",
      "Train Epoch: 0, mini-batch 22990 of 25000, training loss: 0.434919\n",
      "Train Epoch: 0, mini-batch 23000 of 25000, training loss: 0.300986\n",
      "Train Epoch: 0, mini-batch 23010 of 25000, training loss: 0.018348\n",
      "Train Epoch: 0, mini-batch 23020 of 25000, training loss: 1.813459\n",
      "Train Epoch: 0, mini-batch 23030 of 25000, training loss: 0.147551\n",
      "Train Epoch: 0, mini-batch 23040 of 25000, training loss: 0.011536\n",
      "Train Epoch: 0, mini-batch 23050 of 25000, training loss: 0.018470\n",
      "Train Epoch: 0, mini-batch 23060 of 25000, training loss: 0.077636\n",
      "Train Epoch: 0, mini-batch 23070 of 25000, training loss: 0.034239\n",
      "Train Epoch: 0, mini-batch 23080 of 25000, training loss: 0.121448\n",
      "Train Epoch: 0, mini-batch 23090 of 25000, training loss: 0.043679\n",
      "Train Epoch: 0, mini-batch 23100 of 25000, training loss: 0.056888\n",
      "Train Epoch: 0, mini-batch 23110 of 25000, training loss: 0.032109\n",
      "Train Epoch: 0, mini-batch 23120 of 25000, training loss: 0.011988\n",
      "Train Epoch: 0, mini-batch 23130 of 25000, training loss: 0.011070\n",
      "Train Epoch: 0, mini-batch 23140 of 25000, training loss: 0.035054\n",
      "Train Epoch: 0, mini-batch 23150 of 25000, training loss: 0.088062\n",
      "Train Epoch: 0, mini-batch 23160 of 25000, training loss: 0.117763\n",
      "Train Epoch: 0, mini-batch 23170 of 25000, training loss: 0.110158\n",
      "Train Epoch: 0, mini-batch 23180 of 25000, training loss: 0.192614\n",
      "Train Epoch: 0, mini-batch 23190 of 25000, training loss: 0.079760\n",
      "Train Epoch: 0, mini-batch 23200 of 25000, training loss: 0.001448\n",
      "Train Epoch: 0, mini-batch 23210 of 25000, training loss: 0.021943\n",
      "Train Epoch: 0, mini-batch 23220 of 25000, training loss: 0.234499\n",
      "Train Epoch: 0, mini-batch 23230 of 25000, training loss: 0.015913\n",
      "Train Epoch: 0, mini-batch 23240 of 25000, training loss: 0.788846\n",
      "Train Epoch: 0, mini-batch 23250 of 25000, training loss: 0.860711\n",
      "Train Epoch: 0, mini-batch 23260 of 25000, training loss: 0.000368\n",
      "Train Epoch: 0, mini-batch 23270 of 25000, training loss: 0.000855\n",
      "Train Epoch: 0, mini-batch 23280 of 25000, training loss: 0.107073\n",
      "Train Epoch: 0, mini-batch 23290 of 25000, training loss: 0.287795\n",
      "Train Epoch: 0, mini-batch 23300 of 25000, training loss: 0.014612\n",
      "Train Epoch: 0, mini-batch 23310 of 25000, training loss: 0.001667\n",
      "Train Epoch: 0, mini-batch 23320 of 25000, training loss: 0.120982\n",
      "Train Epoch: 0, mini-batch 23330 of 25000, training loss: 0.050407\n",
      "Train Epoch: 0, mini-batch 23340 of 25000, training loss: 0.349473\n",
      "Train Epoch: 0, mini-batch 23350 of 25000, training loss: 0.144337\n",
      "Train Epoch: 0, mini-batch 23360 of 25000, training loss: 0.008604\n",
      "Train Epoch: 0, mini-batch 23370 of 25000, training loss: 0.232081\n",
      "Train Epoch: 0, mini-batch 23380 of 25000, training loss: 0.023360\n",
      "Train Epoch: 0, mini-batch 23390 of 25000, training loss: 0.005409\n",
      "Train Epoch: 0, mini-batch 23400 of 25000, training loss: 0.138346\n",
      "Train Epoch: 0, mini-batch 23410 of 25000, training loss: 0.145819\n",
      "Train Epoch: 0, mini-batch 23420 of 25000, training loss: 0.103481\n",
      "Train Epoch: 0, mini-batch 23430 of 25000, training loss: 0.132026\n",
      "Train Epoch: 0, mini-batch 23440 of 25000, training loss: 0.049765\n",
      "Train Epoch: 0, mini-batch 23450 of 25000, training loss: 0.029243\n",
      "Train Epoch: 0, mini-batch 23460 of 25000, training loss: 0.182050\n",
      "Train Epoch: 0, mini-batch 23470 of 25000, training loss: 0.053303\n",
      "Train Epoch: 0, mini-batch 23480 of 25000, training loss: 1.358339\n",
      "Train Epoch: 0, mini-batch 23490 of 25000, training loss: 0.432448\n",
      "Train Epoch: 0, mini-batch 23500 of 25000, training loss: 0.006769\n",
      "Train Epoch: 0, mini-batch 23510 of 25000, training loss: 0.164324\n",
      "Train Epoch: 0, mini-batch 23520 of 25000, training loss: 0.542742\n",
      "Train Epoch: 0, mini-batch 23530 of 25000, training loss: 0.031712\n",
      "Train Epoch: 0, mini-batch 23540 of 25000, training loss: 0.316308\n",
      "Train Epoch: 0, mini-batch 23550 of 25000, training loss: 0.097209\n",
      "Train Epoch: 0, mini-batch 23560 of 25000, training loss: 0.032299\n",
      "Train Epoch: 0, mini-batch 23570 of 25000, training loss: 7.270780\n",
      "Train Epoch: 0, mini-batch 23580 of 25000, training loss: 0.466758\n",
      "Train Epoch: 0, mini-batch 23590 of 25000, training loss: 0.042214\n",
      "Train Epoch: 0, mini-batch 23600 of 25000, training loss: 1.806789\n",
      "Train Epoch: 0, mini-batch 23610 of 25000, training loss: 0.328108\n",
      "Train Epoch: 0, mini-batch 23620 of 25000, training loss: 0.062374\n",
      "Train Epoch: 0, mini-batch 23630 of 25000, training loss: 0.002260\n",
      "Train Epoch: 0, mini-batch 23640 of 25000, training loss: 0.070067\n",
      "Train Epoch: 0, mini-batch 23650 of 25000, training loss: 0.085260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 23660 of 25000, training loss: 0.060520\n",
      "Train Epoch: 0, mini-batch 23670 of 25000, training loss: 0.145529\n",
      "Train Epoch: 0, mini-batch 23680 of 25000, training loss: 0.247305\n",
      "Train Epoch: 0, mini-batch 23690 of 25000, training loss: 0.039215\n",
      "Train Epoch: 0, mini-batch 23700 of 25000, training loss: 0.254025\n",
      "Train Epoch: 0, mini-batch 23710 of 25000, training loss: 0.114241\n",
      "Train Epoch: 0, mini-batch 23720 of 25000, training loss: 1.582356\n",
      "Train Epoch: 0, mini-batch 23730 of 25000, training loss: 0.003452\n",
      "Train Epoch: 0, mini-batch 23740 of 25000, training loss: 0.003625\n",
      "Train Epoch: 0, mini-batch 23750 of 25000, training loss: 0.009783\n",
      "Train Epoch: 0, mini-batch 23760 of 25000, training loss: 0.092677\n",
      "Train Epoch: 0, mini-batch 23770 of 25000, training loss: 0.550467\n",
      "Train Epoch: 0, mini-batch 23780 of 25000, training loss: 0.002972\n",
      "Train Epoch: 0, mini-batch 23790 of 25000, training loss: 0.235835\n",
      "Train Epoch: 0, mini-batch 23800 of 25000, training loss: 0.011481\n",
      "Train Epoch: 0, mini-batch 23810 of 25000, training loss: 0.195346\n",
      "Train Epoch: 0, mini-batch 23820 of 25000, training loss: 0.050413\n",
      "Train Epoch: 0, mini-batch 23830 of 25000, training loss: 0.527744\n",
      "Train Epoch: 0, mini-batch 23840 of 25000, training loss: 0.254652\n",
      "Train Epoch: 0, mini-batch 23850 of 25000, training loss: 0.109702\n",
      "Train Epoch: 0, mini-batch 23860 of 25000, training loss: 0.371395\n",
      "Train Epoch: 0, mini-batch 23870 of 25000, training loss: 0.016083\n",
      "Train Epoch: 0, mini-batch 23880 of 25000, training loss: 0.167775\n",
      "Train Epoch: 0, mini-batch 23890 of 25000, training loss: 0.058673\n",
      "Train Epoch: 0, mini-batch 23900 of 25000, training loss: 0.026863\n",
      "Train Epoch: 0, mini-batch 23910 of 25000, training loss: 0.045131\n",
      "Train Epoch: 0, mini-batch 23920 of 25000, training loss: 0.069422\n",
      "Train Epoch: 0, mini-batch 23930 of 25000, training loss: 0.779367\n",
      "Train Epoch: 0, mini-batch 23940 of 25000, training loss: 0.030306\n",
      "Train Epoch: 0, mini-batch 23950 of 25000, training loss: 0.140638\n",
      "Train Epoch: 0, mini-batch 23960 of 25000, training loss: 0.050691\n",
      "Train Epoch: 0, mini-batch 23970 of 25000, training loss: 0.038117\n",
      "Train Epoch: 0, mini-batch 23980 of 25000, training loss: 0.315682\n",
      "Train Epoch: 0, mini-batch 23990 of 25000, training loss: 0.144198\n",
      "Train Epoch: 0, mini-batch 24000 of 25000, training loss: 0.004427\n",
      "Train Epoch: 0, mini-batch 24010 of 25000, training loss: 0.597287\n",
      "Train Epoch: 0, mini-batch 24020 of 25000, training loss: 3.176445\n",
      "Train Epoch: 0, mini-batch 24030 of 25000, training loss: 0.530553\n",
      "Train Epoch: 0, mini-batch 24040 of 25000, training loss: 0.222760\n",
      "Train Epoch: 0, mini-batch 24050 of 25000, training loss: 0.026006\n",
      "Train Epoch: 0, mini-batch 24060 of 25000, training loss: 0.091285\n",
      "Train Epoch: 0, mini-batch 24070 of 25000, training loss: 0.054434\n",
      "Train Epoch: 0, mini-batch 24080 of 25000, training loss: 0.135915\n",
      "Train Epoch: 0, mini-batch 24090 of 25000, training loss: 0.014548\n",
      "Train Epoch: 0, mini-batch 24100 of 25000, training loss: 0.058214\n",
      "Train Epoch: 0, mini-batch 24110 of 25000, training loss: 0.062827\n",
      "Train Epoch: 0, mini-batch 24120 of 25000, training loss: 0.294153\n",
      "Train Epoch: 0, mini-batch 24130 of 25000, training loss: 0.544865\n",
      "Train Epoch: 0, mini-batch 24140 of 25000, training loss: 0.022327\n",
      "Train Epoch: 0, mini-batch 24150 of 25000, training loss: 0.006926\n",
      "Train Epoch: 0, mini-batch 24160 of 25000, training loss: 0.048073\n",
      "Train Epoch: 0, mini-batch 24170 of 25000, training loss: 0.749163\n",
      "Train Epoch: 0, mini-batch 24180 of 25000, training loss: 0.036670\n",
      "Train Epoch: 0, mini-batch 24190 of 25000, training loss: 0.108177\n",
      "Train Epoch: 0, mini-batch 24200 of 25000, training loss: 0.060616\n",
      "Train Epoch: 0, mini-batch 24210 of 25000, training loss: 0.085361\n",
      "Train Epoch: 0, mini-batch 24220 of 25000, training loss: 1.912175\n",
      "Train Epoch: 0, mini-batch 24230 of 25000, training loss: 0.028771\n",
      "Train Epoch: 0, mini-batch 24240 of 25000, training loss: 0.008621\n",
      "Train Epoch: 0, mini-batch 24250 of 25000, training loss: 0.008425\n",
      "Train Epoch: 0, mini-batch 24260 of 25000, training loss: 0.522242\n",
      "Train Epoch: 0, mini-batch 24270 of 25000, training loss: 0.024031\n",
      "Train Epoch: 0, mini-batch 24280 of 25000, training loss: 0.276196\n",
      "Train Epoch: 0, mini-batch 24290 of 25000, training loss: 0.002559\n",
      "Train Epoch: 0, mini-batch 24300 of 25000, training loss: 0.035460\n",
      "Train Epoch: 0, mini-batch 24310 of 25000, training loss: 0.049717\n",
      "Train Epoch: 0, mini-batch 24320 of 25000, training loss: 1.814084\n",
      "Train Epoch: 0, mini-batch 24330 of 25000, training loss: 0.186296\n",
      "Train Epoch: 0, mini-batch 24340 of 25000, training loss: 0.001075\n",
      "Train Epoch: 0, mini-batch 24350 of 25000, training loss: 0.006711\n",
      "Train Epoch: 0, mini-batch 24360 of 25000, training loss: 0.205271\n",
      "Train Epoch: 0, mini-batch 24370 of 25000, training loss: 1.003781\n",
      "Train Epoch: 0, mini-batch 24380 of 25000, training loss: 0.315388\n",
      "Train Epoch: 0, mini-batch 24390 of 25000, training loss: 0.019774\n",
      "Train Epoch: 0, mini-batch 24400 of 25000, training loss: 0.465871\n",
      "Train Epoch: 0, mini-batch 24410 of 25000, training loss: 1.432076\n",
      "Train Epoch: 0, mini-batch 24420 of 25000, training loss: 0.006873\n",
      "Train Epoch: 0, mini-batch 24430 of 25000, training loss: 0.040141\n",
      "Train Epoch: 0, mini-batch 24440 of 25000, training loss: 0.310183\n",
      "Train Epoch: 0, mini-batch 24450 of 25000, training loss: 0.351757\n",
      "Train Epoch: 0, mini-batch 24460 of 25000, training loss: 0.846094\n",
      "Train Epoch: 0, mini-batch 24470 of 25000, training loss: 1.420634\n",
      "Train Epoch: 0, mini-batch 24480 of 25000, training loss: 0.041130\n",
      "Train Epoch: 0, mini-batch 24490 of 25000, training loss: 0.055744\n",
      "Train Epoch: 0, mini-batch 24500 of 25000, training loss: 0.056403\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "train_data_gen = zip(train_features,train_target)\n",
    "train_size = len(train_target)\n",
    "while epoch < epochs:\n",
    "    predictions = []\n",
    "    truth_values = []\n",
    "\n",
    "    for batch_idx, (xs, y) in enumerate(train_data_gen):\n",
    "        xs, y = torch.from_numpy(xs).float(), torch.FloatTensor([y])\n",
    "\n",
    "        y_pred = model(xs)\n",
    "        loss = criterion(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        #nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions.append(y_pred.cpu().data.numpy().ravel())\n",
    "        truth_values.append(y)\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {}, mini-batch {} of {}, training loss: {:.6f}'.format(\n",
    "                epoch, batch_idx, train_size, loss.item()))\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls  # toggle 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test accuracy histories\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch, train_loss)\n",
    "plt.plot(epoch, test_loss)\n",
    "# plt.plot(no_reg['epoch'], no_reg['train_loss'])  # toggle 0\n",
    "# plt.plot(no_reg['epoch'], no_reg['test_loss'])  # toggle 0\n",
    "\n",
    "plt.legend(['Train loss', 'Test loss', 'Train no-reg', 'Test no-reg'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss score')\n",
    "\n",
    "# Get training and test accuracy histories\n",
    "train_accuracy = history.history['acc']\n",
    "test_accuracy = history.history['val_acc']\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch, train_accuracy)\n",
    "plt.plot(epoch, test_accuracy)\n",
    "# plt.plot(no_reg['epoch'], no_reg['train_accuracy'])  # toggle 0\n",
    "# plt.plot(no_reg['epoch'], no_reg['test_accuracy'])  # toggle 0\n",
    "\n",
    "plt.legend(['Train accuracy', 'Test accuracy', 'Train no-reg', 'Test no-reg'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "\n",
    "no_reg = {                             # toggle 0\n",
    "    'epoch': epoch,                    # toggle 0\n",
    "    'train_loss': train_loss,          # toggle 0\n",
    "    'test_loss': test_loss,            # toggle 0\n",
    "    'train_accuracy': train_accuracy,  # toggle 0\n",
    "    'test_accuracy': test_accuracy,    # toggle 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup weights\n",
    "weights = network.layers[0].get_weights()[0]  # toggle 0\n",
    "# weights_L1 = network.layers[0].get_weights()[0]  # toggle 1\n",
    "# weights_L2 = network.layers[0].get_weights()[0]  # toggle 2\n",
    "# weights_max = network.layers[0].get_weights()[0]  # toggle 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you got to toggle `# toggle 3`, execute the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show weight distribution\n",
    "plt.hist((\n",
    "    weights.reshape(-1),\n",
    "    weights_L1.reshape(-1),\n",
    "    weights_L2.reshape(-1),\n",
    "    weights_max.reshape(-1),\n",
    "), 49, range=(-.5, .5), label=(\n",
    "    'No-reg',\n",
    "    'L1',\n",
    "    'L2',\n",
    "    'Max',\n",
    "))\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codas ML",
   "language": "python",
   "name": "codasml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
