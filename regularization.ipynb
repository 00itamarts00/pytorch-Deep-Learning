{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation in NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "from tensorflow import keras as kr \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my plotting style\n",
    "plt.style.use(('dark_background', 'bmh'))\n",
    "plt.rc('axes', facecolor='none')\n",
    "plt.rc('figure', figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113bd0df0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortcuts\n",
    "imdb = kr.datasets.imdb\n",
    "Tokeniser = kr.preprocessing.text.Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of features we want\n",
    "features_nb = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=features_nb)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokeniser = Tokeniser(num_words=features_nb)\n",
    "train_features = tokeniser.sequences_to_matrix(train_data, mode='binary')\n",
    "test_features = tokeniser.sequences_to_matrix(test_data, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploring the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (25000,)\n",
      "train_target.shape: (25000,)\n",
      "test_data.shape: (25000,)\n",
      "test_target.shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Check data set sizes\n",
    "print('train_data.shape:', train_data.shape)\n",
    "print('train_target.shape:', train_target.shape)\n",
    "print('test_data.shape:', test_data.shape)\n",
    "print('test_target.shape:', test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_data[0]): <class 'list'>\n",
      "type(train_target[0]): <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# Check format of first training sample\n",
    "print('type(train_data[0]):', type(train_data[0]))\n",
    "print('type(train_target[0]):', type(train_target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews length: [218, 189, 141, 550, 147, 43, 123, 562, 233, 130]\n",
      "Review sentiment (bad/good): [1 0 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Check size of first 10 training samples and corresponding target\n",
    "print('Reviews length:', [len(sample) for sample in train_data[:10]])\n",
    "print('Review sentiment (bad/good):', train_target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - machine format\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set text visualisation helper function\n",
    "def show_text(sample):\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "    word_to_id[\"<PAD>\"] = 0\n",
    "    word_to_id[\"<START>\"] = 1\n",
    "    word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "    id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "    print(' '.join(id_to_word[id_] for id_ in sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this film was just brilliant casting <UNK> <UNK> story direction <UNK> really <UNK> the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> <UNK> as myself so i loved the fact there was a real <UNK> with this film the <UNK> <UNK> throughout the film were great it was just brilliant so much that i <UNK> the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the <UNK> <UNK> was amazing really <UNK> at the end it was so sad and you know what they say if you <UNK> at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of <UNK> and paul they were just brilliant children are often left out of the <UNK> <UNK> i think because the stars that play them all <UNK> up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so <UNK> because it was true and was <UNK> life after all that was <UNK> with us all\n"
     ]
    }
   ],
   "source": [
    "# Show first review - human format\n",
    "show_text(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - neural net format\n",
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   2.   0.   4.   5.   6.   7.   8.   9.   0.   0.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.   0.  21.  22.   0.   0.  25.  26.   0.\n",
      "  28.   0.  30.   0.  32.  33.   0.  35.  36.   0.  38.  39.   0.   0.\n",
      "   0.  43.   0.   0.  46.   0.  48.   0.  50.  51.  52.   0.   0.   0.\n",
      "  56.   0.   0.   0.   0.   0.  62.   0.   0.  65.  66.   0.   0.   0.\n",
      "   0.  71.   0.   0.   0.   0.  76.  77.   0.   0.   0.   0.  82.   0.\n",
      "   0.   0.   0.  87.  88.   0.   0.   0.  92.   0.   0.   0.   0.   0.\n",
      "  98.   0. 100.   0.   0. 103. 104.   0. 106. 107.   0.   0.   0.   0.\n",
      " 112. 113.   0.   0.   0. 117.   0.   0.   0.   0.   0.   0. 124.   0.\n",
      "   0.   0.   0.   0. 130.   0.   0.   0. 134. 135.   0.   0.   0.   0.\n",
      "   0. 141.   0.   0. 144.   0.   0. 147.   0.   0. 150.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 167.\n",
      "   0.   0.   0.   0. 172. 173.   0.   0.   0.   0. 178.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 192.   0. 194.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 215.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 224.   0. 226.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 256.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 283. 284.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 297.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 316. 317.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 336.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 381.   0.   0.   0. 385. 386.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 400.   0.   0.   0.   0.   0.\n",
      "   0. 407.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 447.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 458.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 469.   0.   0.   0.   0.   0.   0.\n",
      " 476.   0.   0.   0. 480.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 515.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 530.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 546.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 619.   0.   0.   0.   0.   0.   0. 626.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 670.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 723.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 838.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 973.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - neural net format - explanation\n",
    "print(train_features[0] * np.arange(len(train_features[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring regularisation of NN\n",
    "\n",
    "Play with the code, especially the one marked `# toggle`.  \n",
    "Start from `# toggle 0`, and then, one at the time, `# toggle 1` to `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerDense(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, units_size):\n",
    "\n",
    "        super(ThreeLayerDense, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_size, units_size) #features_nb, 16\n",
    "        self.linear2 = torch.nn.Linear(units_size, units_size)\n",
    "        #self.dropout\n",
    "        self.linear3 = torch.nn.Linear(units_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.linear2(x) \n",
    "        x = F.relu(x)\n",
    "        #Add dropout regularization\n",
    "        #x = F.dropout(x, training=self.training)   \n",
    "        return nn.Sigmoid()(self.linear3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2 #25\n",
    "log_interval = 10\n",
    "batch_size = 100\n",
    "\n",
    "model = ThreeLayerDense(features_nb, 16)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "#L1 regularization. Apply only to the first layer\n",
    "l1_regularization_factor = 0.0001\n",
    "#The model.params() would return a generator over all layers and activations. We would only need to retain 1st\n",
    "params = next(model.parameters())\n",
    "\n",
    "#l2 regularization can be added in the same fasjion as L1, but it can also be added via a weighT_decay parameter \n",
    "#directly in the optimizer (for all the layers)\n",
    "#l2_regularization_factor = 0.0005\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay = l2_regularization_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 0 of 25000, training loss: 0.458598\n",
      "Train Epoch: 0, mini-batch 10 of 25000, training loss: 0.474120\n",
      "Train Epoch: 0, mini-batch 20 of 25000, training loss: 0.973176\n",
      "Train Epoch: 0, mini-batch 30 of 25000, training loss: 0.946634\n",
      "Train Epoch: 0, mini-batch 40 of 25000, training loss: 0.513123\n",
      "Train Epoch: 0, mini-batch 50 of 25000, training loss: 0.922678\n",
      "Train Epoch: 0, mini-batch 60 of 25000, training loss: 0.871077\n",
      "Train Epoch: 0, mini-batch 70 of 25000, training loss: 0.538530\n",
      "Train Epoch: 0, mini-batch 80 of 25000, training loss: 0.526957\n",
      "Train Epoch: 0, mini-batch 90 of 25000, training loss: 0.870298\n",
      "Train Epoch: 0, mini-batch 100 of 25000, training loss: 0.784882\n",
      "Train Epoch: 0, mini-batch 110 of 25000, training loss: 0.758884\n",
      "Train Epoch: 0, mini-batch 120 of 25000, training loss: 0.569724\n",
      "Train Epoch: 0, mini-batch 130 of 25000, training loss: 0.732693\n",
      "Train Epoch: 0, mini-batch 140 of 25000, training loss: 0.606772\n",
      "Train Epoch: 0, mini-batch 150 of 25000, training loss: 0.605605\n",
      "Train Epoch: 0, mini-batch 160 of 25000, training loss: 0.768301\n",
      "Train Epoch: 0, mini-batch 170 of 25000, training loss: 0.591979\n",
      "Train Epoch: 0, mini-batch 180 of 25000, training loss: 0.617392\n",
      "Train Epoch: 0, mini-batch 190 of 25000, training loss: 0.741410\n",
      "Train Epoch: 0, mini-batch 200 of 25000, training loss: 0.656477\n",
      "Train Epoch: 0, mini-batch 210 of 25000, training loss: 0.619216\n",
      "Train Epoch: 0, mini-batch 220 of 25000, training loss: 0.760698\n",
      "Train Epoch: 0, mini-batch 230 of 25000, training loss: 0.745712\n",
      "Train Epoch: 0, mini-batch 240 of 25000, training loss: 0.723651\n",
      "Train Epoch: 0, mini-batch 250 of 25000, training loss: 0.780832\n",
      "Train Epoch: 0, mini-batch 260 of 25000, training loss: 0.784707\n",
      "Train Epoch: 0, mini-batch 270 of 25000, training loss: 0.565080\n",
      "Train Epoch: 0, mini-batch 280 of 25000, training loss: 0.534021\n",
      "Train Epoch: 0, mini-batch 290 of 25000, training loss: 0.798133\n",
      "Train Epoch: 0, mini-batch 300 of 25000, training loss: 0.609005\n",
      "Train Epoch: 0, mini-batch 310 of 25000, training loss: 0.771839\n",
      "Train Epoch: 0, mini-batch 320 of 25000, training loss: 0.608048\n",
      "Train Epoch: 0, mini-batch 330 of 25000, training loss: 0.559680\n",
      "Train Epoch: 0, mini-batch 340 of 25000, training loss: 0.836801\n",
      "Train Epoch: 0, mini-batch 350 of 25000, training loss: 0.838335\n",
      "Train Epoch: 0, mini-batch 360 of 25000, training loss: 0.820469\n",
      "Train Epoch: 0, mini-batch 370 of 25000, training loss: 0.739221\n",
      "Train Epoch: 0, mini-batch 380 of 25000, training loss: 0.794654\n",
      "Train Epoch: 0, mini-batch 390 of 25000, training loss: 0.638329\n",
      "Train Epoch: 0, mini-batch 400 of 25000, training loss: 0.594600\n",
      "Train Epoch: 0, mini-batch 410 of 25000, training loss: 0.790013\n",
      "Train Epoch: 0, mini-batch 420 of 25000, training loss: 0.791378\n",
      "Train Epoch: 0, mini-batch 430 of 25000, training loss: 0.880596\n",
      "Train Epoch: 0, mini-batch 440 of 25000, training loss: 0.584425\n",
      "Train Epoch: 0, mini-batch 450 of 25000, training loss: 0.756055\n",
      "Train Epoch: 0, mini-batch 460 of 25000, training loss: 0.575769\n",
      "Train Epoch: 0, mini-batch 470 of 25000, training loss: 0.444727\n",
      "Train Epoch: 0, mini-batch 480 of 25000, training loss: 0.434270\n",
      "Train Epoch: 0, mini-batch 490 of 25000, training loss: 0.799355\n",
      "Train Epoch: 0, mini-batch 500 of 25000, training loss: 0.850705\n",
      "Train Epoch: 0, mini-batch 510 of 25000, training loss: 0.730758\n",
      "Train Epoch: 0, mini-batch 520 of 25000, training loss: 0.468036\n",
      "Train Epoch: 0, mini-batch 530 of 25000, training loss: 0.619091\n",
      "Train Epoch: 0, mini-batch 540 of 25000, training loss: 0.575336\n",
      "Train Epoch: 0, mini-batch 550 of 25000, training loss: 0.460128\n",
      "Train Epoch: 0, mini-batch 560 of 25000, training loss: 0.565226\n",
      "Train Epoch: 0, mini-batch 570 of 25000, training loss: 0.477904\n",
      "Train Epoch: 0, mini-batch 580 of 25000, training loss: 0.712923\n",
      "Train Epoch: 0, mini-batch 590 of 25000, training loss: 0.398499\n",
      "Train Epoch: 0, mini-batch 600 of 25000, training loss: 0.760474\n",
      "Train Epoch: 0, mini-batch 610 of 25000, training loss: 0.721759\n",
      "Train Epoch: 0, mini-batch 620 of 25000, training loss: 0.408650\n",
      "Train Epoch: 0, mini-batch 630 of 25000, training loss: 0.804461\n",
      "Train Epoch: 0, mini-batch 640 of 25000, training loss: 0.506981\n",
      "Train Epoch: 0, mini-batch 650 of 25000, training loss: 0.527491\n",
      "Train Epoch: 0, mini-batch 660 of 25000, training loss: 0.775706\n",
      "Train Epoch: 0, mini-batch 670 of 25000, training loss: 1.013202\n",
      "Train Epoch: 0, mini-batch 680 of 25000, training loss: 0.475595\n",
      "Train Epoch: 0, mini-batch 690 of 25000, training loss: 0.782204\n",
      "Train Epoch: 0, mini-batch 700 of 25000, training loss: 0.558395\n",
      "Train Epoch: 0, mini-batch 710 of 25000, training loss: 0.363678\n",
      "Train Epoch: 0, mini-batch 720 of 25000, training loss: 0.380325\n",
      "Train Epoch: 0, mini-batch 730 of 25000, training loss: 1.012182\n",
      "Train Epoch: 0, mini-batch 740 of 25000, training loss: 0.376758\n",
      "Train Epoch: 0, mini-batch 750 of 25000, training loss: 0.818526\n",
      "Train Epoch: 0, mini-batch 760 of 25000, training loss: 0.756923\n",
      "Train Epoch: 0, mini-batch 770 of 25000, training loss: 0.351636\n",
      "Train Epoch: 0, mini-batch 780 of 25000, training loss: 0.658407\n",
      "Train Epoch: 0, mini-batch 790 of 25000, training loss: 0.579503\n",
      "Train Epoch: 0, mini-batch 800 of 25000, training loss: 0.763227\n",
      "Train Epoch: 0, mini-batch 810 of 25000, training loss: 0.906178\n",
      "Train Epoch: 0, mini-batch 820 of 25000, training loss: 0.382697\n",
      "Train Epoch: 0, mini-batch 830 of 25000, training loss: 0.522572\n",
      "Train Epoch: 0, mini-batch 840 of 25000, training loss: 0.676202\n",
      "Train Epoch: 0, mini-batch 850 of 25000, training loss: 0.450245\n",
      "Train Epoch: 0, mini-batch 860 of 25000, training loss: 0.711993\n",
      "Train Epoch: 0, mini-batch 870 of 25000, training loss: 0.696868\n",
      "Train Epoch: 0, mini-batch 880 of 25000, training loss: 0.851025\n",
      "Train Epoch: 0, mini-batch 890 of 25000, training loss: 0.556208\n",
      "Train Epoch: 0, mini-batch 900 of 25000, training loss: 0.495959\n",
      "Train Epoch: 0, mini-batch 910 of 25000, training loss: 0.698295\n",
      "Train Epoch: 0, mini-batch 920 of 25000, training loss: 0.712066\n",
      "Train Epoch: 0, mini-batch 930 of 25000, training loss: 0.475902\n",
      "Train Epoch: 0, mini-batch 940 of 25000, training loss: 0.351403\n",
      "Train Epoch: 0, mini-batch 950 of 25000, training loss: 0.736177\n",
      "Train Epoch: 0, mini-batch 960 of 25000, training loss: 0.612156\n",
      "Train Epoch: 0, mini-batch 970 of 25000, training loss: 0.708143\n",
      "Train Epoch: 0, mini-batch 980 of 25000, training loss: 0.618111\n",
      "Train Epoch: 0, mini-batch 990 of 25000, training loss: 0.722403\n",
      "Train Epoch: 0, mini-batch 1000 of 25000, training loss: 0.723623\n",
      "Train Epoch: 0, mini-batch 1010 of 25000, training loss: 0.654530\n",
      "Train Epoch: 0, mini-batch 1020 of 25000, training loss: 0.694505\n",
      "Train Epoch: 0, mini-batch 1030 of 25000, training loss: 0.362155\n",
      "Train Epoch: 0, mini-batch 1040 of 25000, training loss: 0.870181\n",
      "Train Epoch: 0, mini-batch 1050 of 25000, training loss: 0.624902\n",
      "Train Epoch: 0, mini-batch 1060 of 25000, training loss: 0.349571\n",
      "Train Epoch: 0, mini-batch 1070 of 25000, training loss: 0.812947\n",
      "Train Epoch: 0, mini-batch 1080 of 25000, training loss: 0.518306\n",
      "Train Epoch: 0, mini-batch 1090 of 25000, training loss: 0.695818\n",
      "Train Epoch: 0, mini-batch 1100 of 25000, training loss: 0.350801\n",
      "Train Epoch: 0, mini-batch 1110 of 25000, training loss: 0.693428\n",
      "Train Epoch: 0, mini-batch 1120 of 25000, training loss: 0.725221\n",
      "Train Epoch: 0, mini-batch 1130 of 25000, training loss: 0.700165\n",
      "Train Epoch: 0, mini-batch 1140 of 25000, training loss: 0.709071\n",
      "Train Epoch: 0, mini-batch 1150 of 25000, training loss: 0.697998\n",
      "Train Epoch: 0, mini-batch 1160 of 25000, training loss: 0.688453\n",
      "Train Epoch: 0, mini-batch 1170 of 25000, training loss: 0.722940\n",
      "Train Epoch: 0, mini-batch 1180 of 25000, training loss: 0.363868\n",
      "Train Epoch: 0, mini-batch 1190 of 25000, training loss: 0.343635\n",
      "Train Epoch: 0, mini-batch 1200 of 25000, training loss: 0.698304\n",
      "Train Epoch: 0, mini-batch 1210 of 25000, training loss: 0.643053\n",
      "Train Epoch: 0, mini-batch 1220 of 25000, training loss: 1.137764\n",
      "Train Epoch: 0, mini-batch 1230 of 25000, training loss: 0.695695\n",
      "Train Epoch: 0, mini-batch 1240 of 25000, training loss: 0.703263\n",
      "Train Epoch: 0, mini-batch 1250 of 25000, training loss: 0.718164\n",
      "Train Epoch: 0, mini-batch 1260 of 25000, training loss: 0.697774\n",
      "Train Epoch: 0, mini-batch 1270 of 25000, training loss: 0.693309\n",
      "Train Epoch: 0, mini-batch 1280 of 25000, training loss: 0.555199\n",
      "Train Epoch: 0, mini-batch 1290 of 25000, training loss: 0.694332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 1300 of 25000, training loss: 0.725728\n",
      "Train Epoch: 0, mini-batch 1310 of 25000, training loss: 0.749498\n",
      "Train Epoch: 0, mini-batch 1320 of 25000, training loss: 0.707980\n",
      "Train Epoch: 0, mini-batch 1330 of 25000, training loss: 0.954869\n",
      "Train Epoch: 0, mini-batch 1340 of 25000, training loss: 0.768683\n",
      "Train Epoch: 0, mini-batch 1350 of 25000, training loss: 0.720416\n",
      "Train Epoch: 0, mini-batch 1360 of 25000, training loss: 0.783634\n",
      "Train Epoch: 0, mini-batch 1370 of 25000, training loss: 0.783574\n",
      "Train Epoch: 0, mini-batch 1380 of 25000, training loss: 0.709728\n",
      "Train Epoch: 0, mini-batch 1390 of 25000, training loss: 0.699666\n",
      "Train Epoch: 0, mini-batch 1400 of 25000, training loss: 0.781675\n",
      "Train Epoch: 0, mini-batch 1410 of 25000, training loss: 0.370301\n",
      "Train Epoch: 0, mini-batch 1420 of 25000, training loss: 0.756619\n",
      "Train Epoch: 0, mini-batch 1430 of 25000, training loss: 0.334019\n",
      "Train Epoch: 0, mini-batch 1440 of 25000, training loss: 0.479502\n",
      "Train Epoch: 0, mini-batch 1450 of 25000, training loss: 0.339468\n",
      "Train Epoch: 0, mini-batch 1460 of 25000, training loss: 0.449590\n",
      "Train Epoch: 0, mini-batch 1470 of 25000, training loss: 0.329318\n",
      "Train Epoch: 0, mini-batch 1480 of 25000, training loss: 0.316450\n",
      "Train Epoch: 0, mini-batch 1490 of 25000, training loss: 0.332821\n",
      "Train Epoch: 0, mini-batch 1500 of 25000, training loss: 0.325100\n",
      "Train Epoch: 0, mini-batch 1510 of 25000, training loss: 0.694072\n",
      "Train Epoch: 0, mini-batch 1520 of 25000, training loss: 0.356852\n",
      "Train Epoch: 0, mini-batch 1530 of 25000, training loss: 0.717089\n",
      "Train Epoch: 0, mini-batch 1540 of 25000, training loss: 0.418420\n",
      "Train Epoch: 0, mini-batch 1550 of 25000, training loss: 0.728523\n",
      "Train Epoch: 0, mini-batch 1560 of 25000, training loss: 0.537472\n",
      "Train Epoch: 0, mini-batch 1570 of 25000, training loss: 0.583780\n",
      "Train Epoch: 0, mini-batch 1580 of 25000, training loss: 0.399412\n",
      "Train Epoch: 0, mini-batch 1590 of 25000, training loss: 0.380370\n",
      "Train Epoch: 0, mini-batch 1600 of 25000, training loss: 0.315706\n",
      "Train Epoch: 0, mini-batch 1610 of 25000, training loss: 0.696195\n",
      "Train Epoch: 0, mini-batch 1620 of 25000, training loss: 0.831545\n",
      "Train Epoch: 0, mini-batch 1630 of 25000, training loss: 0.693166\n",
      "Train Epoch: 0, mini-batch 1640 of 25000, training loss: 0.332989\n",
      "Train Epoch: 0, mini-batch 1650 of 25000, training loss: 0.454550\n",
      "Train Epoch: 0, mini-batch 1660 of 25000, training loss: 0.360901\n",
      "Train Epoch: 0, mini-batch 1670 of 25000, training loss: 0.334190\n",
      "Train Epoch: 0, mini-batch 1680 of 25000, training loss: 0.700402\n",
      "Train Epoch: 0, mini-batch 1690 of 25000, training loss: 0.321054\n",
      "Train Epoch: 0, mini-batch 1700 of 25000, training loss: 0.334193\n",
      "Train Epoch: 0, mini-batch 1710 of 25000, training loss: 0.850097\n",
      "Train Epoch: 0, mini-batch 1720 of 25000, training loss: 0.342775\n",
      "Train Epoch: 0, mini-batch 1730 of 25000, training loss: 0.482004\n",
      "Train Epoch: 0, mini-batch 1740 of 25000, training loss: 0.700467\n",
      "Train Epoch: 0, mini-batch 1750 of 25000, training loss: 0.693309\n",
      "Train Epoch: 0, mini-batch 1760 of 25000, training loss: 0.323013\n",
      "Train Epoch: 0, mini-batch 1770 of 25000, training loss: 0.749295\n",
      "Train Epoch: 0, mini-batch 1780 of 25000, training loss: 0.734444\n",
      "Train Epoch: 0, mini-batch 1790 of 25000, training loss: 0.321329\n",
      "Train Epoch: 0, mini-batch 1800 of 25000, training loss: 0.361400\n",
      "Train Epoch: 0, mini-batch 1810 of 25000, training loss: 0.502748\n",
      "Train Epoch: 0, mini-batch 1820 of 25000, training loss: 0.655548\n",
      "Train Epoch: 0, mini-batch 1830 of 25000, training loss: 0.693234\n",
      "Train Epoch: 0, mini-batch 1840 of 25000, training loss: 0.729331\n",
      "Train Epoch: 0, mini-batch 1850 of 25000, training loss: 0.674768\n",
      "Train Epoch: 0, mini-batch 1860 of 25000, training loss: 0.693674\n",
      "Train Epoch: 0, mini-batch 1870 of 25000, training loss: 0.628134\n",
      "Train Epoch: 0, mini-batch 1880 of 25000, training loss: 1.268011\n",
      "Train Epoch: 0, mini-batch 1890 of 25000, training loss: 0.452090\n",
      "Train Epoch: 0, mini-batch 1900 of 25000, training loss: 0.776693\n",
      "Train Epoch: 0, mini-batch 1910 of 25000, training loss: 0.375037\n",
      "Train Epoch: 0, mini-batch 1920 of 25000, training loss: 0.694101\n",
      "Train Epoch: 0, mini-batch 1930 of 25000, training loss: 0.693285\n",
      "Train Epoch: 0, mini-batch 1940 of 25000, training loss: 0.318578\n",
      "Train Epoch: 0, mini-batch 1950 of 25000, training loss: 0.499144\n",
      "Train Epoch: 0, mini-batch 1960 of 25000, training loss: 0.694682\n",
      "Train Epoch: 0, mini-batch 1970 of 25000, training loss: 0.694061\n",
      "Train Epoch: 0, mini-batch 1980 of 25000, training loss: 1.158470\n",
      "Train Epoch: 0, mini-batch 1990 of 25000, training loss: 0.313696\n",
      "Train Epoch: 0, mini-batch 2000 of 25000, training loss: 0.716521\n",
      "Train Epoch: 0, mini-batch 2010 of 25000, training loss: 0.318567\n",
      "Train Epoch: 0, mini-batch 2020 of 25000, training loss: 1.123022\n",
      "Train Epoch: 0, mini-batch 2030 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 2040 of 25000, training loss: 0.317072\n",
      "Train Epoch: 0, mini-batch 2050 of 25000, training loss: 0.606603\n",
      "Train Epoch: 0, mini-batch 2060 of 25000, training loss: 0.693470\n",
      "Train Epoch: 0, mini-batch 2070 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 2080 of 25000, training loss: 0.694677\n",
      "Train Epoch: 0, mini-batch 2090 of 25000, training loss: 0.694456\n",
      "Train Epoch: 0, mini-batch 2100 of 25000, training loss: 0.361834\n",
      "Train Epoch: 0, mini-batch 2110 of 25000, training loss: 0.317874\n",
      "Train Epoch: 0, mini-batch 2120 of 25000, training loss: 0.321897\n",
      "Train Epoch: 0, mini-batch 2130 of 25000, training loss: 0.771803\n",
      "Train Epoch: 0, mini-batch 2140 of 25000, training loss: 0.319141\n",
      "Train Epoch: 0, mini-batch 2150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 2160 of 25000, training loss: 0.693264\n",
      "Train Epoch: 0, mini-batch 2170 of 25000, training loss: 0.340115\n",
      "Train Epoch: 0, mini-batch 2180 of 25000, training loss: 0.315680\n",
      "Train Epoch: 0, mini-batch 2190 of 25000, training loss: 1.298537\n",
      "Train Epoch: 0, mini-batch 2200 of 25000, training loss: 1.156621\n",
      "Train Epoch: 0, mini-batch 2210 of 25000, training loss: 0.319395\n",
      "Train Epoch: 0, mini-batch 2220 of 25000, training loss: 0.603109\n",
      "Train Epoch: 0, mini-batch 2230 of 25000, training loss: 0.634430\n",
      "Train Epoch: 0, mini-batch 2240 of 25000, training loss: 0.441188\n",
      "Train Epoch: 0, mini-batch 2250 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 2260 of 25000, training loss: 0.316551\n",
      "Train Epoch: 0, mini-batch 2270 of 25000, training loss: 0.636563\n",
      "Train Epoch: 0, mini-batch 2280 of 25000, training loss: 0.317459\n",
      "Train Epoch: 0, mini-batch 2290 of 25000, training loss: 0.653441\n",
      "Train Epoch: 0, mini-batch 2300 of 25000, training loss: 0.839138\n",
      "Train Epoch: 0, mini-batch 2310 of 25000, training loss: 0.618595\n",
      "Train Epoch: 0, mini-batch 2320 of 25000, training loss: 0.324073\n",
      "Train Epoch: 0, mini-batch 2330 of 25000, training loss: 0.695516\n",
      "Train Epoch: 0, mini-batch 2340 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 2350 of 25000, training loss: 1.293193\n",
      "Train Epoch: 0, mini-batch 2360 of 25000, training loss: 0.650070\n",
      "Train Epoch: 0, mini-batch 2370 of 25000, training loss: 0.658978\n",
      "Train Epoch: 0, mini-batch 2380 of 25000, training loss: 0.697882\n",
      "Train Epoch: 0, mini-batch 2390 of 25000, training loss: 0.778284\n",
      "Train Epoch: 0, mini-batch 2400 of 25000, training loss: 0.692181\n",
      "Train Epoch: 0, mini-batch 2410 of 25000, training loss: 1.072417\n",
      "Train Epoch: 0, mini-batch 2420 of 25000, training loss: 0.693163\n",
      "Train Epoch: 0, mini-batch 2430 of 25000, training loss: 1.023525\n",
      "Train Epoch: 0, mini-batch 2440 of 25000, training loss: 0.314499\n",
      "Train Epoch: 0, mini-batch 2450 of 25000, training loss: 0.694757\n",
      "Train Epoch: 0, mini-batch 2460 of 25000, training loss: 0.648962\n",
      "Train Epoch: 0, mini-batch 2470 of 25000, training loss: 0.686953\n",
      "Train Epoch: 0, mini-batch 2480 of 25000, training loss: 0.325564\n",
      "Train Epoch: 0, mini-batch 2490 of 25000, training loss: 0.709769\n",
      "Train Epoch: 0, mini-batch 2500 of 25000, training loss: 0.676568\n",
      "Train Epoch: 0, mini-batch 2510 of 25000, training loss: 1.310460\n",
      "Train Epoch: 0, mini-batch 2520 of 25000, training loss: 0.696302\n",
      "Train Epoch: 0, mini-batch 2530 of 25000, training loss: 0.352282\n",
      "Train Epoch: 0, mini-batch 2540 of 25000, training loss: 0.692720\n",
      "Train Epoch: 0, mini-batch 2550 of 25000, training loss: 0.707595\n",
      "Train Epoch: 0, mini-batch 2560 of 25000, training loss: 0.693264\n",
      "Train Epoch: 0, mini-batch 2570 of 25000, training loss: 0.749945\n",
      "Train Epoch: 0, mini-batch 2580 of 25000, training loss: 0.700177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 2590 of 25000, training loss: 1.264931\n",
      "Train Epoch: 0, mini-batch 2600 of 25000, training loss: 0.548043\n",
      "Train Epoch: 0, mini-batch 2610 of 25000, training loss: 0.796529\n",
      "Train Epoch: 0, mini-batch 2620 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 2630 of 25000, training loss: 0.336446\n",
      "Train Epoch: 0, mini-batch 2640 of 25000, training loss: 0.313294\n",
      "Train Epoch: 0, mini-batch 2650 of 25000, training loss: 1.041120\n",
      "Train Epoch: 0, mini-batch 2660 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 2670 of 25000, training loss: 0.694972\n",
      "Train Epoch: 0, mini-batch 2680 of 25000, training loss: 0.693221\n",
      "Train Epoch: 0, mini-batch 2690 of 25000, training loss: 0.995658\n",
      "Train Epoch: 0, mini-batch 2700 of 25000, training loss: 0.693162\n",
      "Train Epoch: 0, mini-batch 2710 of 25000, training loss: 0.717583\n",
      "Train Epoch: 0, mini-batch 2720 of 25000, training loss: 0.314227\n",
      "Train Epoch: 0, mini-batch 2730 of 25000, training loss: 0.466932\n",
      "Train Epoch: 0, mini-batch 2740 of 25000, training loss: 0.353860\n",
      "Train Epoch: 0, mini-batch 2750 of 25000, training loss: 0.318286\n",
      "Train Epoch: 0, mini-batch 2760 of 25000, training loss: 0.751374\n",
      "Train Epoch: 0, mini-batch 2770 of 25000, training loss: 0.519400\n",
      "Train Epoch: 0, mini-batch 2780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 2790 of 25000, training loss: 0.810880\n",
      "Train Epoch: 0, mini-batch 2800 of 25000, training loss: 0.693312\n",
      "Train Epoch: 0, mini-batch 2810 of 25000, training loss: 0.418833\n",
      "Train Epoch: 0, mini-batch 2820 of 25000, training loss: 1.269981\n",
      "Train Epoch: 0, mini-batch 2830 of 25000, training loss: 0.320205\n",
      "Train Epoch: 0, mini-batch 2840 of 25000, training loss: 0.313568\n",
      "Train Epoch: 0, mini-batch 2850 of 25000, training loss: 0.700828\n",
      "Train Epoch: 0, mini-batch 2860 of 25000, training loss: 0.321341\n",
      "Train Epoch: 0, mini-batch 2870 of 25000, training loss: 0.319668\n",
      "Train Epoch: 0, mini-batch 2880 of 25000, training loss: 0.700584\n",
      "Train Epoch: 0, mini-batch 2890 of 25000, training loss: 0.313466\n",
      "Train Epoch: 0, mini-batch 2900 of 25000, training loss: 0.693211\n",
      "Train Epoch: 0, mini-batch 2910 of 25000, training loss: 0.693155\n",
      "Train Epoch: 0, mini-batch 2920 of 25000, training loss: 0.316182\n",
      "Train Epoch: 0, mini-batch 2930 of 25000, training loss: 0.692903\n",
      "Train Epoch: 0, mini-batch 2940 of 25000, training loss: 0.693709\n",
      "Train Epoch: 0, mini-batch 2950 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 2960 of 25000, training loss: 0.313896\n",
      "Train Epoch: 0, mini-batch 2970 of 25000, training loss: 0.693204\n",
      "Train Epoch: 0, mini-batch 2980 of 25000, training loss: 0.691904\n",
      "Train Epoch: 0, mini-batch 2990 of 25000, training loss: 0.888750\n",
      "Train Epoch: 0, mini-batch 3000 of 25000, training loss: 0.706633\n",
      "Train Epoch: 0, mini-batch 3010 of 25000, training loss: 0.694181\n",
      "Train Epoch: 0, mini-batch 3020 of 25000, training loss: 0.317390\n",
      "Train Epoch: 0, mini-batch 3030 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3040 of 25000, training loss: 0.334463\n",
      "Train Epoch: 0, mini-batch 3050 of 25000, training loss: 0.555972\n",
      "Train Epoch: 0, mini-batch 3060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3070 of 25000, training loss: 0.695626\n",
      "Train Epoch: 0, mini-batch 3080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3090 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3110 of 25000, training loss: 0.696622\n",
      "Train Epoch: 0, mini-batch 3120 of 25000, training loss: 0.315110\n",
      "Train Epoch: 0, mini-batch 3130 of 25000, training loss: 0.693384\n",
      "Train Epoch: 0, mini-batch 3140 of 25000, training loss: 0.693305\n",
      "Train Epoch: 0, mini-batch 3150 of 25000, training loss: 0.313996\n",
      "Train Epoch: 0, mini-batch 3160 of 25000, training loss: 0.757204\n",
      "Train Epoch: 0, mini-batch 3170 of 25000, training loss: 0.745994\n",
      "Train Epoch: 0, mini-batch 3180 of 25000, training loss: 0.318345\n",
      "Train Epoch: 0, mini-batch 3190 of 25000, training loss: 0.694792\n",
      "Train Epoch: 0, mini-batch 3200 of 25000, training loss: 0.704393\n",
      "Train Epoch: 0, mini-batch 3210 of 25000, training loss: 0.315063\n",
      "Train Epoch: 0, mini-batch 3220 of 25000, training loss: 0.693201\n",
      "Train Epoch: 0, mini-batch 3230 of 25000, training loss: 0.713033\n",
      "Train Epoch: 0, mini-batch 3240 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 3250 of 25000, training loss: 0.325058\n",
      "Train Epoch: 0, mini-batch 3260 of 25000, training loss: 0.701784\n",
      "Train Epoch: 0, mini-batch 3270 of 25000, training loss: 0.313774\n",
      "Train Epoch: 0, mini-batch 3280 of 25000, training loss: 0.337089\n",
      "Train Epoch: 0, mini-batch 3290 of 25000, training loss: 0.693585\n",
      "Train Epoch: 0, mini-batch 3300 of 25000, training loss: 0.445343\n",
      "Train Epoch: 0, mini-batch 3310 of 25000, training loss: 0.323242\n",
      "Train Epoch: 0, mini-batch 3320 of 25000, training loss: 0.314270\n",
      "Train Epoch: 0, mini-batch 3330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3340 of 25000, training loss: 0.313671\n",
      "Train Epoch: 0, mini-batch 3350 of 25000, training loss: 0.313999\n",
      "Train Epoch: 0, mini-batch 3360 of 25000, training loss: 0.313284\n",
      "Train Epoch: 0, mini-batch 3370 of 25000, training loss: 0.693639\n",
      "Train Epoch: 0, mini-batch 3380 of 25000, training loss: 0.693520\n",
      "Train Epoch: 0, mini-batch 3390 of 25000, training loss: 0.693713\n",
      "Train Epoch: 0, mini-batch 3400 of 25000, training loss: 0.318815\n",
      "Train Epoch: 0, mini-batch 3410 of 25000, training loss: 0.314620\n",
      "Train Epoch: 0, mini-batch 3420 of 25000, training loss: 0.324849\n",
      "Train Epoch: 0, mini-batch 3430 of 25000, training loss: 0.314618\n",
      "Train Epoch: 0, mini-batch 3440 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 3450 of 25000, training loss: 0.693158\n",
      "Train Epoch: 0, mini-batch 3460 of 25000, training loss: 0.693111\n",
      "Train Epoch: 0, mini-batch 3470 of 25000, training loss: 0.693156\n",
      "Train Epoch: 0, mini-batch 3480 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3490 of 25000, training loss: 0.315675\n",
      "Train Epoch: 0, mini-batch 3500 of 25000, training loss: 0.471191\n",
      "Train Epoch: 0, mini-batch 3510 of 25000, training loss: 0.549118\n",
      "Train Epoch: 0, mini-batch 3520 of 25000, training loss: 0.692939\n",
      "Train Epoch: 0, mini-batch 3530 of 25000, training loss: 0.705928\n",
      "Train Epoch: 0, mini-batch 3540 of 25000, training loss: 0.693217\n",
      "Train Epoch: 0, mini-batch 3550 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3560 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3570 of 25000, training loss: 1.162910\n",
      "Train Epoch: 0, mini-batch 3580 of 25000, training loss: 0.530195\n",
      "Train Epoch: 0, mini-batch 3590 of 25000, training loss: 0.695568\n",
      "Train Epoch: 0, mini-batch 3600 of 25000, training loss: 0.693181\n",
      "Train Epoch: 0, mini-batch 3610 of 25000, training loss: 0.584103\n",
      "Train Epoch: 0, mini-batch 3620 of 25000, training loss: 0.315651\n",
      "Train Epoch: 0, mini-batch 3630 of 25000, training loss: 0.313567\n",
      "Train Epoch: 0, mini-batch 3640 of 25000, training loss: 1.182554\n",
      "Train Epoch: 0, mini-batch 3650 of 25000, training loss: 0.349087\n",
      "Train Epoch: 0, mini-batch 3660 of 25000, training loss: 0.314629\n",
      "Train Epoch: 0, mini-batch 3670 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 3680 of 25000, training loss: 0.323538\n",
      "Train Epoch: 0, mini-batch 3690 of 25000, training loss: 0.502146\n",
      "Train Epoch: 0, mini-batch 3700 of 25000, training loss: 0.693106\n",
      "Train Epoch: 0, mini-batch 3710 of 25000, training loss: 0.350362\n",
      "Train Epoch: 0, mini-batch 3720 of 25000, training loss: 0.314067\n",
      "Train Epoch: 0, mini-batch 3730 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 3740 of 25000, training loss: 0.327824\n",
      "Train Epoch: 0, mini-batch 3750 of 25000, training loss: 1.288602\n",
      "Train Epoch: 0, mini-batch 3760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3770 of 25000, training loss: 0.695367\n",
      "Train Epoch: 0, mini-batch 3780 of 25000, training loss: 0.318457\n",
      "Train Epoch: 0, mini-batch 3790 of 25000, training loss: 1.271919\n",
      "Train Epoch: 0, mini-batch 3800 of 25000, training loss: 0.672071\n",
      "Train Epoch: 0, mini-batch 3810 of 25000, training loss: 0.333362\n",
      "Train Epoch: 0, mini-batch 3820 of 25000, training loss: 0.316837\n",
      "Train Epoch: 0, mini-batch 3830 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 3840 of 25000, training loss: 0.714339\n",
      "Train Epoch: 0, mini-batch 3850 of 25000, training loss: 0.320466\n",
      "Train Epoch: 0, mini-batch 3860 of 25000, training loss: 0.459859\n",
      "Train Epoch: 0, mini-batch 3870 of 25000, training loss: 1.242433\n",
      "Train Epoch: 0, mini-batch 3880 of 25000, training loss: 0.313279\n",
      "Train Epoch: 0, mini-batch 3890 of 25000, training loss: 0.693914\n",
      "Train Epoch: 0, mini-batch 3900 of 25000, training loss: 0.313286\n",
      "Train Epoch: 0, mini-batch 3910 of 25000, training loss: 0.684895\n",
      "Train Epoch: 0, mini-batch 3920 of 25000, training loss: 0.315907\n",
      "Train Epoch: 0, mini-batch 3930 of 25000, training loss: 1.001811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 3940 of 25000, training loss: 0.314655\n",
      "Train Epoch: 0, mini-batch 3950 of 25000, training loss: 0.645391\n",
      "Train Epoch: 0, mini-batch 3960 of 25000, training loss: 0.314891\n",
      "Train Epoch: 0, mini-batch 3970 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 3980 of 25000, training loss: 0.314775\n",
      "Train Epoch: 0, mini-batch 3990 of 25000, training loss: 1.294976\n",
      "Train Epoch: 0, mini-batch 4000 of 25000, training loss: 1.269227\n",
      "Train Epoch: 0, mini-batch 4010 of 25000, training loss: 0.831059\n",
      "Train Epoch: 0, mini-batch 4020 of 25000, training loss: 0.317323\n",
      "Train Epoch: 0, mini-batch 4030 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4040 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 4050 of 25000, training loss: 0.313780\n",
      "Train Epoch: 0, mini-batch 4060 of 25000, training loss: 0.615510\n",
      "Train Epoch: 0, mini-batch 4070 of 25000, training loss: 0.690235\n",
      "Train Epoch: 0, mini-batch 4080 of 25000, training loss: 0.315242\n",
      "Train Epoch: 0, mini-batch 4090 of 25000, training loss: 1.298867\n",
      "Train Epoch: 0, mini-batch 4100 of 25000, training loss: 0.313851\n",
      "Train Epoch: 0, mini-batch 4110 of 25000, training loss: 0.912571\n",
      "Train Epoch: 0, mini-batch 4120 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 4130 of 25000, training loss: 0.318172\n",
      "Train Epoch: 0, mini-batch 4140 of 25000, training loss: 0.313383\n",
      "Train Epoch: 0, mini-batch 4150 of 25000, training loss: 0.314032\n",
      "Train Epoch: 0, mini-batch 4160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4170 of 25000, training loss: 0.744739\n",
      "Train Epoch: 0, mini-batch 4180 of 25000, training loss: 0.313586\n",
      "Train Epoch: 0, mini-batch 4190 of 25000, training loss: 0.428241\n",
      "Train Epoch: 0, mini-batch 4200 of 25000, training loss: 0.527537\n",
      "Train Epoch: 0, mini-batch 4210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4220 of 25000, training loss: 0.693223\n",
      "Train Epoch: 0, mini-batch 4230 of 25000, training loss: 0.722712\n",
      "Train Epoch: 0, mini-batch 4240 of 25000, training loss: 1.109366\n",
      "Train Epoch: 0, mini-batch 4250 of 25000, training loss: 0.320954\n",
      "Train Epoch: 0, mini-batch 4260 of 25000, training loss: 0.693300\n",
      "Train Epoch: 0, mini-batch 4270 of 25000, training loss: 0.439369\n",
      "Train Epoch: 0, mini-batch 4280 of 25000, training loss: 0.315087\n",
      "Train Epoch: 0, mini-batch 4290 of 25000, training loss: 0.314625\n",
      "Train Epoch: 0, mini-batch 4300 of 25000, training loss: 0.693368\n",
      "Train Epoch: 0, mini-batch 4310 of 25000, training loss: 0.693264\n",
      "Train Epoch: 0, mini-batch 4320 of 25000, training loss: 0.313435\n",
      "Train Epoch: 0, mini-batch 4330 of 25000, training loss: 0.966125\n",
      "Train Epoch: 0, mini-batch 4340 of 25000, training loss: 1.283638\n",
      "Train Epoch: 0, mini-batch 4350 of 25000, training loss: 0.315038\n",
      "Train Epoch: 0, mini-batch 4360 of 25000, training loss: 0.315807\n",
      "Train Epoch: 0, mini-batch 4370 of 25000, training loss: 0.644017\n",
      "Train Epoch: 0, mini-batch 4380 of 25000, training loss: 0.515616\n",
      "Train Epoch: 0, mini-batch 4390 of 25000, training loss: 0.694067\n",
      "Train Epoch: 0, mini-batch 4400 of 25000, training loss: 0.789782\n",
      "Train Epoch: 0, mini-batch 4410 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 4420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4430 of 25000, training loss: 0.313267\n",
      "Train Epoch: 0, mini-batch 4440 of 25000, training loss: 0.693277\n",
      "Train Epoch: 0, mini-batch 4450 of 25000, training loss: 0.313288\n",
      "Train Epoch: 0, mini-batch 4460 of 25000, training loss: 0.353324\n",
      "Train Epoch: 0, mini-batch 4470 of 25000, training loss: 0.693152\n",
      "Train Epoch: 0, mini-batch 4480 of 25000, training loss: 0.718650\n",
      "Train Epoch: 0, mini-batch 4490 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4500 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4510 of 25000, training loss: 0.704665\n",
      "Train Epoch: 0, mini-batch 4520 of 25000, training loss: 0.693223\n",
      "Train Epoch: 0, mini-batch 4530 of 25000, training loss: 0.709720\n",
      "Train Epoch: 0, mini-batch 4540 of 25000, training loss: 0.693145\n",
      "Train Epoch: 0, mini-batch 4550 of 25000, training loss: 0.687312\n",
      "Train Epoch: 0, mini-batch 4560 of 25000, training loss: 0.314087\n",
      "Train Epoch: 0, mini-batch 4570 of 25000, training loss: 0.316737\n",
      "Train Epoch: 0, mini-batch 4580 of 25000, training loss: 0.728020\n",
      "Train Epoch: 0, mini-batch 4590 of 25000, training loss: 1.310897\n",
      "Train Epoch: 0, mini-batch 4600 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4610 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4620 of 25000, training loss: 0.313896\n",
      "Train Epoch: 0, mini-batch 4630 of 25000, training loss: 0.505259\n",
      "Train Epoch: 0, mini-batch 4640 of 25000, training loss: 0.735069\n",
      "Train Epoch: 0, mini-batch 4650 of 25000, training loss: 0.328421\n",
      "Train Epoch: 0, mini-batch 4660 of 25000, training loss: 0.313639\n",
      "Train Epoch: 0, mini-batch 4670 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 4680 of 25000, training loss: 0.319839\n",
      "Train Epoch: 0, mini-batch 4690 of 25000, training loss: 0.317476\n",
      "Train Epoch: 0, mini-batch 4700 of 25000, training loss: 0.314829\n",
      "Train Epoch: 0, mini-batch 4710 of 25000, training loss: 0.707367\n",
      "Train Epoch: 0, mini-batch 4720 of 25000, training loss: 0.714507\n",
      "Train Epoch: 0, mini-batch 4730 of 25000, training loss: 1.245993\n",
      "Train Epoch: 0, mini-batch 4740 of 25000, training loss: 0.316934\n",
      "Train Epoch: 0, mini-batch 4750 of 25000, training loss: 0.319281\n",
      "Train Epoch: 0, mini-batch 4760 of 25000, training loss: 0.313346\n",
      "Train Epoch: 0, mini-batch 4770 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 4780 of 25000, training loss: 0.693899\n",
      "Train Epoch: 0, mini-batch 4790 of 25000, training loss: 1.310714\n",
      "Train Epoch: 0, mini-batch 4800 of 25000, training loss: 0.694498\n",
      "Train Epoch: 0, mini-batch 4810 of 25000, training loss: 0.317418\n",
      "Train Epoch: 0, mini-batch 4820 of 25000, training loss: 0.317184\n",
      "Train Epoch: 0, mini-batch 4830 of 25000, training loss: 0.711739\n",
      "Train Epoch: 0, mini-batch 4840 of 25000, training loss: 0.693234\n",
      "Train Epoch: 0, mini-batch 4850 of 25000, training loss: 0.313402\n",
      "Train Epoch: 0, mini-batch 4860 of 25000, training loss: 0.704783\n",
      "Train Epoch: 0, mini-batch 4870 of 25000, training loss: 0.695272\n",
      "Train Epoch: 0, mini-batch 4880 of 25000, training loss: 0.987721\n",
      "Train Epoch: 0, mini-batch 4890 of 25000, training loss: 0.420109\n",
      "Train Epoch: 0, mini-batch 4900 of 25000, training loss: 0.367777\n",
      "Train Epoch: 0, mini-batch 4910 of 25000, training loss: 0.675998\n",
      "Train Epoch: 0, mini-batch 4920 of 25000, training loss: 0.313459\n",
      "Train Epoch: 0, mini-batch 4930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 4940 of 25000, training loss: 0.712985\n",
      "Train Epoch: 0, mini-batch 4950 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 4960 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 4970 of 25000, training loss: 0.659669\n",
      "Train Epoch: 0, mini-batch 4980 of 25000, training loss: 0.315767\n",
      "Train Epoch: 0, mini-batch 4990 of 25000, training loss: 0.693665\n",
      "Train Epoch: 0, mini-batch 5000 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5010 of 25000, training loss: 0.678501\n",
      "Train Epoch: 0, mini-batch 5020 of 25000, training loss: 0.314760\n",
      "Train Epoch: 0, mini-batch 5030 of 25000, training loss: 0.693403\n",
      "Train Epoch: 0, mini-batch 5040 of 25000, training loss: 0.313315\n",
      "Train Epoch: 0, mini-batch 5050 of 25000, training loss: 0.317521\n",
      "Train Epoch: 0, mini-batch 5060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5070 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 5080 of 25000, training loss: 0.340339\n",
      "Train Epoch: 0, mini-batch 5090 of 25000, training loss: 0.313569\n",
      "Train Epoch: 0, mini-batch 5100 of 25000, training loss: 0.753497\n",
      "Train Epoch: 0, mini-batch 5110 of 25000, training loss: 0.693143\n",
      "Train Epoch: 0, mini-batch 5120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5130 of 25000, training loss: 0.319038\n",
      "Train Epoch: 0, mini-batch 5140 of 25000, training loss: 0.343095\n",
      "Train Epoch: 0, mini-batch 5150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5160 of 25000, training loss: 0.313532\n",
      "Train Epoch: 0, mini-batch 5170 of 25000, training loss: 0.693502\n",
      "Train Epoch: 0, mini-batch 5180 of 25000, training loss: 0.313924\n",
      "Train Epoch: 0, mini-batch 5190 of 25000, training loss: 0.693147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 5200 of 25000, training loss: 0.768198\n",
      "Train Epoch: 0, mini-batch 5210 of 25000, training loss: 0.725890\n",
      "Train Epoch: 0, mini-batch 5220 of 25000, training loss: 0.477106\n",
      "Train Epoch: 0, mini-batch 5230 of 25000, training loss: 0.313272\n",
      "Train Epoch: 0, mini-batch 5240 of 25000, training loss: 0.320443\n",
      "Train Epoch: 0, mini-batch 5250 of 25000, training loss: 0.601229\n",
      "Train Epoch: 0, mini-batch 5260 of 25000, training loss: 0.315955\n",
      "Train Epoch: 0, mini-batch 5270 of 25000, training loss: 0.696177\n",
      "Train Epoch: 0, mini-batch 5280 of 25000, training loss: 0.314741\n",
      "Train Epoch: 0, mini-batch 5290 of 25000, training loss: 0.694664\n",
      "Train Epoch: 0, mini-batch 5300 of 25000, training loss: 0.316883\n",
      "Train Epoch: 0, mini-batch 5310 of 25000, training loss: 0.313267\n",
      "Train Epoch: 0, mini-batch 5320 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 5330 of 25000, training loss: 0.314618\n",
      "Train Epoch: 0, mini-batch 5340 of 25000, training loss: 0.562337\n",
      "Train Epoch: 0, mini-batch 5350 of 25000, training loss: 0.313575\n",
      "Train Epoch: 0, mini-batch 5360 of 25000, training loss: 1.304514\n",
      "Train Epoch: 0, mini-batch 5370 of 25000, training loss: 0.314831\n",
      "Train Epoch: 0, mini-batch 5380 of 25000, training loss: 0.313437\n",
      "Train Epoch: 0, mini-batch 5390 of 25000, training loss: 0.314370\n",
      "Train Epoch: 0, mini-batch 5400 of 25000, training loss: 0.693154\n",
      "Train Epoch: 0, mini-batch 5410 of 25000, training loss: 0.314601\n",
      "Train Epoch: 0, mini-batch 5420 of 25000, training loss: 1.236195\n",
      "Train Epoch: 0, mini-batch 5430 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 5440 of 25000, training loss: 0.693222\n",
      "Train Epoch: 0, mini-batch 5450 of 25000, training loss: 0.337009\n",
      "Train Epoch: 0, mini-batch 5460 of 25000, training loss: 1.286086\n",
      "Train Epoch: 0, mini-batch 5470 of 25000, training loss: 0.688628\n",
      "Train Epoch: 0, mini-batch 5480 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5490 of 25000, training loss: 0.313719\n",
      "Train Epoch: 0, mini-batch 5500 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5510 of 25000, training loss: 0.313926\n",
      "Train Epoch: 0, mini-batch 5520 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 5530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5540 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5550 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 5560 of 25000, training loss: 0.693162\n",
      "Train Epoch: 0, mini-batch 5570 of 25000, training loss: 0.517150\n",
      "Train Epoch: 0, mini-batch 5580 of 25000, training loss: 0.698078\n",
      "Train Epoch: 0, mini-batch 5590 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5600 of 25000, training loss: 0.315358\n",
      "Train Epoch: 0, mini-batch 5610 of 25000, training loss: 0.688807\n",
      "Train Epoch: 0, mini-batch 5620 of 25000, training loss: 0.693151\n",
      "Train Epoch: 0, mini-batch 5630 of 25000, training loss: 0.316037\n",
      "Train Epoch: 0, mini-batch 5640 of 25000, training loss: 0.313696\n",
      "Train Epoch: 0, mini-batch 5650 of 25000, training loss: 0.313858\n",
      "Train Epoch: 0, mini-batch 5660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5670 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5680 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5690 of 25000, training loss: 0.693343\n",
      "Train Epoch: 0, mini-batch 5700 of 25000, training loss: 0.313468\n",
      "Train Epoch: 0, mini-batch 5710 of 25000, training loss: 0.726126\n",
      "Train Epoch: 0, mini-batch 5720 of 25000, training loss: 0.693182\n",
      "Train Epoch: 0, mini-batch 5730 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5740 of 25000, training loss: 0.693163\n",
      "Train Epoch: 0, mini-batch 5750 of 25000, training loss: 0.313407\n",
      "Train Epoch: 0, mini-batch 5760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5770 of 25000, training loss: 0.693153\n",
      "Train Epoch: 0, mini-batch 5780 of 25000, training loss: 0.693223\n",
      "Train Epoch: 0, mini-batch 5790 of 25000, training loss: 0.706568\n",
      "Train Epoch: 0, mini-batch 5800 of 25000, training loss: 0.313477\n",
      "Train Epoch: 0, mini-batch 5810 of 25000, training loss: 0.314910\n",
      "Train Epoch: 0, mini-batch 5820 of 25000, training loss: 1.013041\n",
      "Train Epoch: 0, mini-batch 5830 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 5840 of 25000, training loss: 0.693717\n",
      "Train Epoch: 0, mini-batch 5850 of 25000, training loss: 0.319689\n",
      "Train Epoch: 0, mini-batch 5860 of 25000, training loss: 0.315425\n",
      "Train Epoch: 0, mini-batch 5870 of 25000, training loss: 0.327451\n",
      "Train Epoch: 0, mini-batch 5880 of 25000, training loss: 0.727733\n",
      "Train Epoch: 0, mini-batch 5890 of 25000, training loss: 0.313350\n",
      "Train Epoch: 0, mini-batch 5900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5940 of 25000, training loss: 1.313248\n",
      "Train Epoch: 0, mini-batch 5950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5960 of 25000, training loss: 0.692925\n",
      "Train Epoch: 0, mini-batch 5970 of 25000, training loss: 0.314874\n",
      "Train Epoch: 0, mini-batch 5980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 5990 of 25000, training loss: 0.693152\n",
      "Train Epoch: 0, mini-batch 6000 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6010 of 25000, training loss: 0.394898\n",
      "Train Epoch: 0, mini-batch 6020 of 25000, training loss: 0.683358\n",
      "Train Epoch: 0, mini-batch 6030 of 25000, training loss: 0.693054\n",
      "Train Epoch: 0, mini-batch 6040 of 25000, training loss: 0.680727\n",
      "Train Epoch: 0, mini-batch 6050 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 6060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6070 of 25000, training loss: 0.448545\n",
      "Train Epoch: 0, mini-batch 6080 of 25000, training loss: 0.719923\n",
      "Train Epoch: 0, mini-batch 6090 of 25000, training loss: 0.657187\n",
      "Train Epoch: 0, mini-batch 6100 of 25000, training loss: 0.478403\n",
      "Train Epoch: 0, mini-batch 6110 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6120 of 25000, training loss: 0.314066\n",
      "Train Epoch: 0, mini-batch 6130 of 25000, training loss: 0.313651\n",
      "Train Epoch: 0, mini-batch 6140 of 25000, training loss: 0.313609\n",
      "Train Epoch: 0, mini-batch 6150 of 25000, training loss: 1.295924\n",
      "Train Epoch: 0, mini-batch 6160 of 25000, training loss: 0.611470\n",
      "Train Epoch: 0, mini-batch 6170 of 25000, training loss: 0.314234\n",
      "Train Epoch: 0, mini-batch 6180 of 25000, training loss: 0.313506\n",
      "Train Epoch: 0, mini-batch 6190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6200 of 25000, training loss: 0.313875\n",
      "Train Epoch: 0, mini-batch 6210 of 25000, training loss: 0.315409\n",
      "Train Epoch: 0, mini-batch 6220 of 25000, training loss: 0.315903\n",
      "Train Epoch: 0, mini-batch 6230 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6240 of 25000, training loss: 0.314943\n",
      "Train Epoch: 0, mini-batch 6250 of 25000, training loss: 0.693092\n",
      "Train Epoch: 0, mini-batch 6260 of 25000, training loss: 0.314289\n",
      "Train Epoch: 0, mini-batch 6270 of 25000, training loss: 0.320981\n",
      "Train Epoch: 0, mini-batch 6280 of 25000, training loss: 0.315890\n",
      "Train Epoch: 0, mini-batch 6290 of 25000, training loss: 0.386040\n",
      "Train Epoch: 0, mini-batch 6300 of 25000, training loss: 0.538453\n",
      "Train Epoch: 0, mini-batch 6310 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6320 of 25000, training loss: 0.317246\n",
      "Train Epoch: 0, mini-batch 6330 of 25000, training loss: 1.033349\n",
      "Train Epoch: 0, mini-batch 6340 of 25000, training loss: 0.314703\n",
      "Train Epoch: 0, mini-batch 6350 of 25000, training loss: 0.693524\n",
      "Train Epoch: 0, mini-batch 6360 of 25000, training loss: 0.314228\n",
      "Train Epoch: 0, mini-batch 6370 of 25000, training loss: 0.399679\n",
      "Train Epoch: 0, mini-batch 6380 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 6390 of 25000, training loss: 0.995343\n",
      "Train Epoch: 0, mini-batch 6400 of 25000, training loss: 0.313353\n",
      "Train Epoch: 0, mini-batch 6410 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 6420 of 25000, training loss: 0.317583\n",
      "Train Epoch: 0, mini-batch 6430 of 25000, training loss: 0.313323\n",
      "Train Epoch: 0, mini-batch 6440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6460 of 25000, training loss: 0.720659\n",
      "Train Epoch: 0, mini-batch 6470 of 25000, training loss: 0.321379\n",
      "Train Epoch: 0, mini-batch 6480 of 25000, training loss: 0.686585\n",
      "Train Epoch: 0, mini-batch 6490 of 25000, training loss: 0.313771\n",
      "Train Epoch: 0, mini-batch 6500 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6510 of 25000, training loss: 0.701063\n",
      "Train Epoch: 0, mini-batch 6520 of 25000, training loss: 0.833205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 6530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6540 of 25000, training loss: 1.310228\n",
      "Train Epoch: 0, mini-batch 6550 of 25000, training loss: 0.672894\n",
      "Train Epoch: 0, mini-batch 6560 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6570 of 25000, training loss: 0.699295\n",
      "Train Epoch: 0, mini-batch 6580 of 25000, training loss: 0.693574\n",
      "Train Epoch: 0, mini-batch 6590 of 25000, training loss: 0.315006\n",
      "Train Epoch: 0, mini-batch 6600 of 25000, training loss: 0.695169\n",
      "Train Epoch: 0, mini-batch 6610 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6620 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6630 of 25000, training loss: 0.798449\n",
      "Train Epoch: 0, mini-batch 6640 of 25000, training loss: 0.314794\n",
      "Train Epoch: 0, mini-batch 6650 of 25000, training loss: 0.698241\n",
      "Train Epoch: 0, mini-batch 6660 of 25000, training loss: 0.698362\n",
      "Train Epoch: 0, mini-batch 6670 of 25000, training loss: 0.691758\n",
      "Train Epoch: 0, mini-batch 6680 of 25000, training loss: 0.549619\n",
      "Train Epoch: 0, mini-batch 6690 of 25000, training loss: 0.671615\n",
      "Train Epoch: 0, mini-batch 6700 of 25000, training loss: 0.314743\n",
      "Train Epoch: 0, mini-batch 6710 of 25000, training loss: 0.317279\n",
      "Train Epoch: 0, mini-batch 6720 of 25000, training loss: 0.314090\n",
      "Train Epoch: 0, mini-batch 6730 of 25000, training loss: 0.313552\n",
      "Train Epoch: 0, mini-batch 6740 of 25000, training loss: 0.624035\n",
      "Train Epoch: 0, mini-batch 6750 of 25000, training loss: 0.313735\n",
      "Train Epoch: 0, mini-batch 6760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6770 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6780 of 25000, training loss: 0.313339\n",
      "Train Epoch: 0, mini-batch 6790 of 25000, training loss: 0.313402\n",
      "Train Epoch: 0, mini-batch 6800 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6810 of 25000, training loss: 0.693842\n",
      "Train Epoch: 0, mini-batch 6820 of 25000, training loss: 0.313361\n",
      "Train Epoch: 0, mini-batch 6830 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6840 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6850 of 25000, training loss: 0.313907\n",
      "Train Epoch: 0, mini-batch 6860 of 25000, training loss: 0.324143\n",
      "Train Epoch: 0, mini-batch 6870 of 25000, training loss: 0.804394\n",
      "Train Epoch: 0, mini-batch 6880 of 25000, training loss: 0.313507\n",
      "Train Epoch: 0, mini-batch 6890 of 25000, training loss: 0.315149\n",
      "Train Epoch: 0, mini-batch 6900 of 25000, training loss: 0.313295\n",
      "Train Epoch: 0, mini-batch 6910 of 25000, training loss: 0.693290\n",
      "Train Epoch: 0, mini-batch 6920 of 25000, training loss: 0.313291\n",
      "Train Epoch: 0, mini-batch 6930 of 25000, training loss: 0.693001\n",
      "Train Epoch: 0, mini-batch 6940 of 25000, training loss: 0.885186\n",
      "Train Epoch: 0, mini-batch 6950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 6980 of 25000, training loss: 0.693151\n",
      "Train Epoch: 0, mini-batch 6990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7000 of 25000, training loss: 0.592448\n",
      "Train Epoch: 0, mini-batch 7010 of 25000, training loss: 0.379686\n",
      "Train Epoch: 0, mini-batch 7020 of 25000, training loss: 0.686638\n",
      "Train Epoch: 0, mini-batch 7030 of 25000, training loss: 0.692406\n",
      "Train Epoch: 0, mini-batch 7040 of 25000, training loss: 0.694866\n",
      "Train Epoch: 0, mini-batch 7050 of 25000, training loss: 0.313355\n",
      "Train Epoch: 0, mini-batch 7060 of 25000, training loss: 0.665810\n",
      "Train Epoch: 0, mini-batch 7070 of 25000, training loss: 0.315914\n",
      "Train Epoch: 0, mini-batch 7080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7090 of 25000, training loss: 1.198933\n",
      "Train Epoch: 0, mini-batch 7100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7110 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7130 of 25000, training loss: 0.690477\n",
      "Train Epoch: 0, mini-batch 7140 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 7150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7160 of 25000, training loss: 0.695601\n",
      "Train Epoch: 0, mini-batch 7170 of 25000, training loss: 0.555420\n",
      "Train Epoch: 0, mini-batch 7180 of 25000, training loss: 0.695096\n",
      "Train Epoch: 0, mini-batch 7190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7200 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7210 of 25000, training loss: 0.694910\n",
      "Train Epoch: 0, mini-batch 7220 of 25000, training loss: 0.364576\n",
      "Train Epoch: 0, mini-batch 7230 of 25000, training loss: 0.313384\n",
      "Train Epoch: 0, mini-batch 7240 of 25000, training loss: 0.693151\n",
      "Train Epoch: 0, mini-batch 7250 of 25000, training loss: 0.314456\n",
      "Train Epoch: 0, mini-batch 7260 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 7270 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7280 of 25000, training loss: 0.692994\n",
      "Train Epoch: 0, mini-batch 7290 of 25000, training loss: 0.313350\n",
      "Train Epoch: 0, mini-batch 7300 of 25000, training loss: 0.313354\n",
      "Train Epoch: 0, mini-batch 7310 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7320 of 25000, training loss: 0.693432\n",
      "Train Epoch: 0, mini-batch 7330 of 25000, training loss: 0.692783\n",
      "Train Epoch: 0, mini-batch 7340 of 25000, training loss: 0.693139\n",
      "Train Epoch: 0, mini-batch 7350 of 25000, training loss: 0.693125\n",
      "Train Epoch: 0, mini-batch 7360 of 25000, training loss: 0.580536\n",
      "Train Epoch: 0, mini-batch 7370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7380 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 7390 of 25000, training loss: 0.313590\n",
      "Train Epoch: 0, mini-batch 7400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7410 of 25000, training loss: 0.693154\n",
      "Train Epoch: 0, mini-batch 7420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7430 of 25000, training loss: 0.319277\n",
      "Train Epoch: 0, mini-batch 7440 of 25000, training loss: 0.313583\n",
      "Train Epoch: 0, mini-batch 7450 of 25000, training loss: 0.711581\n",
      "Train Epoch: 0, mini-batch 7460 of 25000, training loss: 1.287840\n",
      "Train Epoch: 0, mini-batch 7470 of 25000, training loss: 1.306493\n",
      "Train Epoch: 0, mini-batch 7480 of 25000, training loss: 0.784145\n",
      "Train Epoch: 0, mini-batch 7490 of 25000, training loss: 0.490916\n",
      "Train Epoch: 0, mini-batch 7500 of 25000, training loss: 0.609683\n",
      "Train Epoch: 0, mini-batch 7510 of 25000, training loss: 0.344015\n",
      "Train Epoch: 0, mini-batch 7520 of 25000, training loss: 0.314167\n",
      "Train Epoch: 0, mini-batch 7530 of 25000, training loss: 0.446985\n",
      "Train Epoch: 0, mini-batch 7540 of 25000, training loss: 0.693542\n",
      "Train Epoch: 0, mini-batch 7550 of 25000, training loss: 0.314443\n",
      "Train Epoch: 0, mini-batch 7560 of 25000, training loss: 0.693000\n",
      "Train Epoch: 0, mini-batch 7570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7580 of 25000, training loss: 0.313337\n",
      "Train Epoch: 0, mini-batch 7590 of 25000, training loss: 0.693186\n",
      "Train Epoch: 0, mini-batch 7600 of 25000, training loss: 0.313972\n",
      "Train Epoch: 0, mini-batch 7610 of 25000, training loss: 0.693349\n",
      "Train Epoch: 0, mini-batch 7620 of 25000, training loss: 0.315044\n",
      "Train Epoch: 0, mini-batch 7630 of 25000, training loss: 1.280758\n",
      "Train Epoch: 0, mini-batch 7640 of 25000, training loss: 1.305815\n",
      "Train Epoch: 0, mini-batch 7650 of 25000, training loss: 1.308808\n",
      "Train Epoch: 0, mini-batch 7660 of 25000, training loss: 0.693160\n",
      "Train Epoch: 0, mini-batch 7670 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7680 of 25000, training loss: 0.335651\n",
      "Train Epoch: 0, mini-batch 7690 of 25000, training loss: 0.498412\n",
      "Train Epoch: 0, mini-batch 7700 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7710 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7720 of 25000, training loss: 1.311021\n",
      "Train Epoch: 0, mini-batch 7730 of 25000, training loss: 0.390981\n",
      "Train Epoch: 0, mini-batch 7740 of 25000, training loss: 1.311344\n",
      "Train Epoch: 0, mini-batch 7750 of 25000, training loss: 0.313963\n",
      "Train Epoch: 0, mini-batch 7760 of 25000, training loss: 0.694857\n",
      "Train Epoch: 0, mini-batch 7770 of 25000, training loss: 0.317120\n",
      "Train Epoch: 0, mini-batch 7780 of 25000, training loss: 0.736485\n",
      "Train Epoch: 0, mini-batch 7790 of 25000, training loss: 0.560598\n",
      "Train Epoch: 0, mini-batch 7800 of 25000, training loss: 0.321236\n",
      "Train Epoch: 0, mini-batch 7810 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 7820 of 25000, training loss: 0.322305\n",
      "Train Epoch: 0, mini-batch 7830 of 25000, training loss: 0.313948\n",
      "Train Epoch: 0, mini-batch 7840 of 25000, training loss: 0.313286\n",
      "Train Epoch: 0, mini-batch 7850 of 25000, training loss: 0.693856\n",
      "Train Epoch: 0, mini-batch 7860 of 25000, training loss: 0.314870\n",
      "Train Epoch: 0, mini-batch 7870 of 25000, training loss: 0.324408\n",
      "Train Epoch: 0, mini-batch 7880 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7900 of 25000, training loss: 0.570451\n",
      "Train Epoch: 0, mini-batch 7910 of 25000, training loss: 0.693147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 7920 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 7930 of 25000, training loss: 0.694253\n",
      "Train Epoch: 0, mini-batch 7940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7950 of 25000, training loss: 0.314351\n",
      "Train Epoch: 0, mini-batch 7960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7970 of 25000, training loss: 0.316683\n",
      "Train Epoch: 0, mini-batch 7980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 7990 of 25000, training loss: 0.313374\n",
      "Train Epoch: 0, mini-batch 8000 of 25000, training loss: 0.700687\n",
      "Train Epoch: 0, mini-batch 8010 of 25000, training loss: 0.426761\n",
      "Train Epoch: 0, mini-batch 8020 of 25000, training loss: 0.313269\n",
      "Train Epoch: 0, mini-batch 8030 of 25000, training loss: 0.693191\n",
      "Train Epoch: 0, mini-batch 8040 of 25000, training loss: 0.313910\n",
      "Train Epoch: 0, mini-batch 8050 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8060 of 25000, training loss: 1.309915\n",
      "Train Epoch: 0, mini-batch 8070 of 25000, training loss: 0.313343\n",
      "Train Epoch: 0, mini-batch 8080 of 25000, training loss: 0.711397\n",
      "Train Epoch: 0, mini-batch 8090 of 25000, training loss: 0.313923\n",
      "Train Epoch: 0, mini-batch 8100 of 25000, training loss: 0.683024\n",
      "Train Epoch: 0, mini-batch 8110 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8120 of 25000, training loss: 1.308269\n",
      "Train Epoch: 0, mini-batch 8130 of 25000, training loss: 1.311320\n",
      "Train Epoch: 0, mini-batch 8140 of 25000, training loss: 0.314206\n",
      "Train Epoch: 0, mini-batch 8150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8170 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8180 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8200 of 25000, training loss: 0.720424\n",
      "Train Epoch: 0, mini-batch 8210 of 25000, training loss: 0.354396\n",
      "Train Epoch: 0, mini-batch 8220 of 25000, training loss: 0.344572\n",
      "Train Epoch: 0, mini-batch 8230 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8240 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 8250 of 25000, training loss: 0.314179\n",
      "Train Epoch: 0, mini-batch 8260 of 25000, training loss: 0.950284\n",
      "Train Epoch: 0, mini-batch 8270 of 25000, training loss: 0.314980\n",
      "Train Epoch: 0, mini-batch 8280 of 25000, training loss: 0.313316\n",
      "Train Epoch: 0, mini-batch 8290 of 25000, training loss: 0.665853\n",
      "Train Epoch: 0, mini-batch 8300 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8310 of 25000, training loss: 0.313319\n",
      "Train Epoch: 0, mini-batch 8320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8340 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8350 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 8360 of 25000, training loss: 0.314227\n",
      "Train Epoch: 0, mini-batch 8370 of 25000, training loss: 1.313130\n",
      "Train Epoch: 0, mini-batch 8380 of 25000, training loss: 0.728168\n",
      "Train Epoch: 0, mini-batch 8390 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 8400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8410 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 8420 of 25000, training loss: 0.693307\n",
      "Train Epoch: 0, mini-batch 8430 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 8440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8460 of 25000, training loss: 0.313280\n",
      "Train Epoch: 0, mini-batch 8470 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8480 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8490 of 25000, training loss: 0.319335\n",
      "Train Epoch: 0, mini-batch 8500 of 25000, training loss: 0.313573\n",
      "Train Epoch: 0, mini-batch 8510 of 25000, training loss: 0.674520\n",
      "Train Epoch: 0, mini-batch 8520 of 25000, training loss: 0.917985\n",
      "Train Epoch: 0, mini-batch 8530 of 25000, training loss: 0.679989\n",
      "Train Epoch: 0, mini-batch 8540 of 25000, training loss: 0.693099\n",
      "Train Epoch: 0, mini-batch 8550 of 25000, training loss: 0.313653\n",
      "Train Epoch: 0, mini-batch 8560 of 25000, training loss: 0.693202\n",
      "Train Epoch: 0, mini-batch 8570 of 25000, training loss: 0.315540\n",
      "Train Epoch: 0, mini-batch 8580 of 25000, training loss: 0.316307\n",
      "Train Epoch: 0, mini-batch 8590 of 25000, training loss: 0.693378\n",
      "Train Epoch: 0, mini-batch 8600 of 25000, training loss: 0.313349\n",
      "Train Epoch: 0, mini-batch 8610 of 25000, training loss: 0.315427\n",
      "Train Epoch: 0, mini-batch 8620 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8630 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 8640 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8650 of 25000, training loss: 0.716130\n",
      "Train Epoch: 0, mini-batch 8660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8670 of 25000, training loss: 0.693128\n",
      "Train Epoch: 0, mini-batch 8680 of 25000, training loss: 0.313572\n",
      "Train Epoch: 0, mini-batch 8690 of 25000, training loss: 0.692375\n",
      "Train Epoch: 0, mini-batch 8700 of 25000, training loss: 0.417540\n",
      "Train Epoch: 0, mini-batch 8710 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8720 of 25000, training loss: 0.336788\n",
      "Train Epoch: 0, mini-batch 8730 of 25000, training loss: 0.315469\n",
      "Train Epoch: 0, mini-batch 8740 of 25000, training loss: 0.693152\n",
      "Train Epoch: 0, mini-batch 8750 of 25000, training loss: 1.133344\n",
      "Train Epoch: 0, mini-batch 8760 of 25000, training loss: 0.693151\n",
      "Train Epoch: 0, mini-batch 8770 of 25000, training loss: 0.638290\n",
      "Train Epoch: 0, mini-batch 8780 of 25000, training loss: 0.672615\n",
      "Train Epoch: 0, mini-batch 8790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8800 of 25000, training loss: 0.686888\n",
      "Train Epoch: 0, mini-batch 8810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8820 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8830 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8840 of 25000, training loss: 0.670739\n",
      "Train Epoch: 0, mini-batch 8850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8860 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8870 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8880 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8900 of 25000, training loss: 0.316970\n",
      "Train Epoch: 0, mini-batch 8910 of 25000, training loss: 0.692643\n",
      "Train Epoch: 0, mini-batch 8920 of 25000, training loss: 0.313942\n",
      "Train Epoch: 0, mini-batch 8930 of 25000, training loss: 0.692442\n",
      "Train Epoch: 0, mini-batch 8940 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 8950 of 25000, training loss: 0.313504\n",
      "Train Epoch: 0, mini-batch 8960 of 25000, training loss: 0.313482\n",
      "Train Epoch: 0, mini-batch 8970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 8980 of 25000, training loss: 0.693193\n",
      "Train Epoch: 0, mini-batch 8990 of 25000, training loss: 0.313621\n",
      "Train Epoch: 0, mini-batch 9000 of 25000, training loss: 1.258837\n",
      "Train Epoch: 0, mini-batch 9010 of 25000, training loss: 0.313632\n",
      "Train Epoch: 0, mini-batch 9020 of 25000, training loss: 0.639257\n",
      "Train Epoch: 0, mini-batch 9030 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9040 of 25000, training loss: 0.317940\n",
      "Train Epoch: 0, mini-batch 9050 of 25000, training loss: 0.315064\n",
      "Train Epoch: 0, mini-batch 9060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9070 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9080 of 25000, training loss: 0.368991\n",
      "Train Epoch: 0, mini-batch 9090 of 25000, training loss: 0.634881\n",
      "Train Epoch: 0, mini-batch 9100 of 25000, training loss: 0.729470\n",
      "Train Epoch: 0, mini-batch 9110 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9120 of 25000, training loss: 0.313852\n",
      "Train Epoch: 0, mini-batch 9130 of 25000, training loss: 0.314918\n",
      "Train Epoch: 0, mini-batch 9140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9150 of 25000, training loss: 0.313580\n",
      "Train Epoch: 0, mini-batch 9160 of 25000, training loss: 0.693184\n",
      "Train Epoch: 0, mini-batch 9170 of 25000, training loss: 0.314229\n",
      "Train Epoch: 0, mini-batch 9180 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9200 of 25000, training loss: 0.323444\n",
      "Train Epoch: 0, mini-batch 9210 of 25000, training loss: 0.693126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 9220 of 25000, training loss: 0.747015\n",
      "Train Epoch: 0, mini-batch 9230 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9240 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 9250 of 25000, training loss: 1.310220\n",
      "Train Epoch: 0, mini-batch 9260 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 9270 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9280 of 25000, training loss: 0.313371\n",
      "Train Epoch: 0, mini-batch 9290 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9300 of 25000, training loss: 0.313776\n",
      "Train Epoch: 0, mini-batch 9310 of 25000, training loss: 0.315462\n",
      "Train Epoch: 0, mini-batch 9320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9330 of 25000, training loss: 0.346407\n",
      "Train Epoch: 0, mini-batch 9340 of 25000, training loss: 0.693174\n",
      "Train Epoch: 0, mini-batch 9350 of 25000, training loss: 0.695245\n",
      "Train Epoch: 0, mini-batch 9360 of 25000, training loss: 0.621040\n",
      "Train Epoch: 0, mini-batch 9370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9380 of 25000, training loss: 0.317119\n",
      "Train Epoch: 0, mini-batch 9390 of 25000, training loss: 0.317843\n",
      "Train Epoch: 0, mini-batch 9400 of 25000, training loss: 0.313380\n",
      "Train Epoch: 0, mini-batch 9410 of 25000, training loss: 1.115971\n",
      "Train Epoch: 0, mini-batch 9420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9430 of 25000, training loss: 0.313556\n",
      "Train Epoch: 0, mini-batch 9440 of 25000, training loss: 0.313313\n",
      "Train Epoch: 0, mini-batch 9450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9460 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9470 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 9480 of 25000, training loss: 0.313414\n",
      "Train Epoch: 0, mini-batch 9490 of 25000, training loss: 0.719457\n",
      "Train Epoch: 0, mini-batch 9500 of 25000, training loss: 0.313778\n",
      "Train Epoch: 0, mini-batch 9510 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9520 of 25000, training loss: 1.278492\n",
      "Train Epoch: 0, mini-batch 9530 of 25000, training loss: 0.693155\n",
      "Train Epoch: 0, mini-batch 9540 of 25000, training loss: 0.313273\n",
      "Train Epoch: 0, mini-batch 9550 of 25000, training loss: 0.313267\n",
      "Train Epoch: 0, mini-batch 9560 of 25000, training loss: 0.313853\n",
      "Train Epoch: 0, mini-batch 9570 of 25000, training loss: 0.315660\n",
      "Train Epoch: 0, mini-batch 9580 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9590 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9600 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9610 of 25000, training loss: 0.313906\n",
      "Train Epoch: 0, mini-batch 9620 of 25000, training loss: 1.056267\n",
      "Train Epoch: 0, mini-batch 9630 of 25000, training loss: 0.323284\n",
      "Train Epoch: 0, mini-batch 9640 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9650 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9660 of 25000, training loss: 0.698053\n",
      "Train Epoch: 0, mini-batch 9670 of 25000, training loss: 0.313503\n",
      "Train Epoch: 0, mini-batch 9680 of 25000, training loss: 0.684210\n",
      "Train Epoch: 0, mini-batch 9690 of 25000, training loss: 0.467880\n",
      "Train Epoch: 0, mini-batch 9700 of 25000, training loss: 0.313291\n",
      "Train Epoch: 0, mini-batch 9710 of 25000, training loss: 0.693159\n",
      "Train Epoch: 0, mini-batch 9720 of 25000, training loss: 1.312059\n",
      "Train Epoch: 0, mini-batch 9730 of 25000, training loss: 0.313325\n",
      "Train Epoch: 0, mini-batch 9740 of 25000, training loss: 0.329809\n",
      "Train Epoch: 0, mini-batch 9750 of 25000, training loss: 0.313334\n",
      "Train Epoch: 0, mini-batch 9760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9770 of 25000, training loss: 1.264152\n",
      "Train Epoch: 0, mini-batch 9780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9790 of 25000, training loss: 1.308690\n",
      "Train Epoch: 0, mini-batch 9800 of 25000, training loss: 0.313431\n",
      "Train Epoch: 0, mini-batch 9810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9820 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9830 of 25000, training loss: 1.312183\n",
      "Train Epoch: 0, mini-batch 9840 of 25000, training loss: 0.313589\n",
      "Train Epoch: 0, mini-batch 9850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9860 of 25000, training loss: 0.313330\n",
      "Train Epoch: 0, mini-batch 9870 of 25000, training loss: 1.313126\n",
      "Train Epoch: 0, mini-batch 9880 of 25000, training loss: 0.771885\n",
      "Train Epoch: 0, mini-batch 9890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9900 of 25000, training loss: 0.317024\n",
      "Train Epoch: 0, mini-batch 9910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9920 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 9930 of 25000, training loss: 0.541959\n",
      "Train Epoch: 0, mini-batch 9940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9950 of 25000, training loss: 0.313278\n",
      "Train Epoch: 0, mini-batch 9960 of 25000, training loss: 0.313310\n",
      "Train Epoch: 0, mini-batch 9970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 9990 of 25000, training loss: 0.691703\n",
      "Train Epoch: 0, mini-batch 10000 of 25000, training loss: 0.694497\n",
      "Train Epoch: 0, mini-batch 10010 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10020 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 10030 of 25000, training loss: 0.313326\n",
      "Train Epoch: 0, mini-batch 10040 of 25000, training loss: 0.957503\n",
      "Train Epoch: 0, mini-batch 10050 of 25000, training loss: 0.313287\n",
      "Train Epoch: 0, mini-batch 10060 of 25000, training loss: 0.733599\n",
      "Train Epoch: 0, mini-batch 10070 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10090 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10110 of 25000, training loss: 0.313471\n",
      "Train Epoch: 0, mini-batch 10120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10130 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10170 of 25000, training loss: 0.314049\n",
      "Train Epoch: 0, mini-batch 10180 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10190 of 25000, training loss: 0.318753\n",
      "Train Epoch: 0, mini-batch 10200 of 25000, training loss: 0.317482\n",
      "Train Epoch: 0, mini-batch 10210 of 25000, training loss: 0.690649\n",
      "Train Epoch: 0, mini-batch 10220 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10230 of 25000, training loss: 0.314448\n",
      "Train Epoch: 0, mini-batch 10240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10250 of 25000, training loss: 0.313298\n",
      "Train Epoch: 0, mini-batch 10260 of 25000, training loss: 1.311609\n",
      "Train Epoch: 0, mini-batch 10270 of 25000, training loss: 0.315329\n",
      "Train Epoch: 0, mini-batch 10280 of 25000, training loss: 0.405604\n",
      "Train Epoch: 0, mini-batch 10290 of 25000, training loss: 0.314294\n",
      "Train Epoch: 0, mini-batch 10300 of 25000, training loss: 0.314371\n",
      "Train Epoch: 0, mini-batch 10310 of 25000, training loss: 0.313513\n",
      "Train Epoch: 0, mini-batch 10320 of 25000, training loss: 0.693480\n",
      "Train Epoch: 0, mini-batch 10330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10340 of 25000, training loss: 0.391215\n",
      "Train Epoch: 0, mini-batch 10350 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10360 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10380 of 25000, training loss: 0.693160\n",
      "Train Epoch: 0, mini-batch 10390 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10400 of 25000, training loss: 0.693609\n",
      "Train Epoch: 0, mini-batch 10410 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10420 of 25000, training loss: 0.313723\n",
      "Train Epoch: 0, mini-batch 10430 of 25000, training loss: 0.313293\n",
      "Train Epoch: 0, mini-batch 10440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10450 of 25000, training loss: 0.693175\n",
      "Train Epoch: 0, mini-batch 10460 of 25000, training loss: 0.317548\n",
      "Train Epoch: 0, mini-batch 10470 of 25000, training loss: 0.323653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 10480 of 25000, training loss: 0.400885\n",
      "Train Epoch: 0, mini-batch 10490 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10500 of 25000, training loss: 0.313322\n",
      "Train Epoch: 0, mini-batch 10510 of 25000, training loss: 0.643779\n",
      "Train Epoch: 0, mini-batch 10520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10540 of 25000, training loss: 0.313354\n",
      "Train Epoch: 0, mini-batch 10550 of 25000, training loss: 0.313657\n",
      "Train Epoch: 0, mini-batch 10560 of 25000, training loss: 0.692804\n",
      "Train Epoch: 0, mini-batch 10570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10580 of 25000, training loss: 1.255968\n",
      "Train Epoch: 0, mini-batch 10590 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10600 of 25000, training loss: 0.313513\n",
      "Train Epoch: 0, mini-batch 10610 of 25000, training loss: 0.691176\n",
      "Train Epoch: 0, mini-batch 10620 of 25000, training loss: 0.325582\n",
      "Train Epoch: 0, mini-batch 10630 of 25000, training loss: 0.313417\n",
      "Train Epoch: 0, mini-batch 10640 of 25000, training loss: 0.692199\n",
      "Train Epoch: 0, mini-batch 10650 of 25000, training loss: 0.314999\n",
      "Train Epoch: 0, mini-batch 10660 of 25000, training loss: 0.693135\n",
      "Train Epoch: 0, mini-batch 10670 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10680 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10690 of 25000, training loss: 0.689466\n",
      "Train Epoch: 0, mini-batch 10700 of 25000, training loss: 0.313642\n",
      "Train Epoch: 0, mini-batch 10710 of 25000, training loss: 0.313389\n",
      "Train Epoch: 0, mini-batch 10720 of 25000, training loss: 0.313477\n",
      "Train Epoch: 0, mini-batch 10730 of 25000, training loss: 0.313269\n",
      "Train Epoch: 0, mini-batch 10740 of 25000, training loss: 0.315335\n",
      "Train Epoch: 0, mini-batch 10750 of 25000, training loss: 0.313356\n",
      "Train Epoch: 0, mini-batch 10760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10770 of 25000, training loss: 0.335095\n",
      "Train Epoch: 0, mini-batch 10780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10790 of 25000, training loss: 1.306825\n",
      "Train Epoch: 0, mini-batch 10800 of 25000, training loss: 0.313280\n",
      "Train Epoch: 0, mini-batch 10810 of 25000, training loss: 0.695766\n",
      "Train Epoch: 0, mini-batch 10820 of 25000, training loss: 0.319402\n",
      "Train Epoch: 0, mini-batch 10830 of 25000, training loss: 0.313410\n",
      "Train Epoch: 0, mini-batch 10840 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10850 of 25000, training loss: 0.313294\n",
      "Train Epoch: 0, mini-batch 10860 of 25000, training loss: 0.313333\n",
      "Train Epoch: 0, mini-batch 10870 of 25000, training loss: 0.693312\n",
      "Train Epoch: 0, mini-batch 10880 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10890 of 25000, training loss: 1.303012\n",
      "Train Epoch: 0, mini-batch 10900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 10910 of 25000, training loss: 1.311545\n",
      "Train Epoch: 0, mini-batch 10920 of 25000, training loss: 0.314031\n",
      "Train Epoch: 0, mini-batch 10930 of 25000, training loss: 0.313361\n",
      "Train Epoch: 0, mini-batch 10940 of 25000, training loss: 0.693242\n",
      "Train Epoch: 0, mini-batch 10950 of 25000, training loss: 0.313306\n",
      "Train Epoch: 0, mini-batch 10960 of 25000, training loss: 0.704096\n",
      "Train Epoch: 0, mini-batch 10970 of 25000, training loss: 1.205600\n",
      "Train Epoch: 0, mini-batch 10980 of 25000, training loss: 0.313312\n",
      "Train Epoch: 0, mini-batch 10990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11000 of 25000, training loss: 0.313756\n",
      "Train Epoch: 0, mini-batch 11010 of 25000, training loss: 0.313397\n",
      "Train Epoch: 0, mini-batch 11020 of 25000, training loss: 0.372709\n",
      "Train Epoch: 0, mini-batch 11030 of 25000, training loss: 0.314788\n",
      "Train Epoch: 0, mini-batch 11040 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11050 of 25000, training loss: 0.693080\n",
      "Train Epoch: 0, mini-batch 11060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11070 of 25000, training loss: 0.318998\n",
      "Train Epoch: 0, mini-batch 11080 of 25000, training loss: 0.633156\n",
      "Train Epoch: 0, mini-batch 11090 of 25000, training loss: 0.313327\n",
      "Train Epoch: 0, mini-batch 11100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11110 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 11120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11130 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 11140 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 11150 of 25000, training loss: 0.317308\n",
      "Train Epoch: 0, mini-batch 11160 of 25000, training loss: 0.314872\n",
      "Train Epoch: 0, mini-batch 11170 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 11180 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11190 of 25000, training loss: 0.314963\n",
      "Train Epoch: 0, mini-batch 11200 of 25000, training loss: 0.344645\n",
      "Train Epoch: 0, mini-batch 11210 of 25000, training loss: 0.693167\n",
      "Train Epoch: 0, mini-batch 11220 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11230 of 25000, training loss: 0.488483\n",
      "Train Epoch: 0, mini-batch 11240 of 25000, training loss: 0.313813\n",
      "Train Epoch: 0, mini-batch 11250 of 25000, training loss: 0.313655\n",
      "Train Epoch: 0, mini-batch 11260 of 25000, training loss: 0.694180\n",
      "Train Epoch: 0, mini-batch 11270 of 25000, training loss: 0.315359\n",
      "Train Epoch: 0, mini-batch 11280 of 25000, training loss: 0.693227\n",
      "Train Epoch: 0, mini-batch 11290 of 25000, training loss: 0.313280\n",
      "Train Epoch: 0, mini-batch 11300 of 25000, training loss: 0.693989\n",
      "Train Epoch: 0, mini-batch 11310 of 25000, training loss: 0.542311\n",
      "Train Epoch: 0, mini-batch 11320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11330 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 11340 of 25000, training loss: 0.313454\n",
      "Train Epoch: 0, mini-batch 11350 of 25000, training loss: 0.315491\n",
      "Train Epoch: 0, mini-batch 11360 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 11370 of 25000, training loss: 1.313262\n",
      "Train Epoch: 0, mini-batch 11380 of 25000, training loss: 0.693173\n",
      "Train Epoch: 0, mini-batch 11390 of 25000, training loss: 0.313371\n",
      "Train Epoch: 0, mini-batch 11400 of 25000, training loss: 0.693399\n",
      "Train Epoch: 0, mini-batch 11410 of 25000, training loss: 0.691678\n",
      "Train Epoch: 0, mini-batch 11420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11430 of 25000, training loss: 0.693290\n",
      "Train Epoch: 0, mini-batch 11440 of 25000, training loss: 1.276945\n",
      "Train Epoch: 0, mini-batch 11450 of 25000, training loss: 0.694135\n",
      "Train Epoch: 0, mini-batch 11460 of 25000, training loss: 0.693161\n",
      "Train Epoch: 0, mini-batch 11470 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11480 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 11490 of 25000, training loss: 0.691227\n",
      "Train Epoch: 0, mini-batch 11500 of 25000, training loss: 1.095798\n",
      "Train Epoch: 0, mini-batch 11510 of 25000, training loss: 0.662057\n",
      "Train Epoch: 0, mini-batch 11520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11540 of 25000, training loss: 0.668585\n",
      "Train Epoch: 0, mini-batch 11550 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11560 of 25000, training loss: 0.684427\n",
      "Train Epoch: 0, mini-batch 11570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11580 of 25000, training loss: 0.694178\n",
      "Train Epoch: 0, mini-batch 11590 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11600 of 25000, training loss: 0.313846\n",
      "Train Epoch: 0, mini-batch 11610 of 25000, training loss: 0.679041\n",
      "Train Epoch: 0, mini-batch 11620 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11630 of 25000, training loss: 0.315581\n",
      "Train Epoch: 0, mini-batch 11640 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11650 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11660 of 25000, training loss: 0.345813\n",
      "Train Epoch: 0, mini-batch 11670 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 11680 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11700 of 25000, training loss: 0.662424\n",
      "Train Epoch: 0, mini-batch 11710 of 25000, training loss: 0.313269\n",
      "Train Epoch: 0, mini-batch 11720 of 25000, training loss: 0.693147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 11730 of 25000, training loss: 0.313266\n",
      "Train Epoch: 0, mini-batch 11740 of 25000, training loss: 0.313335\n",
      "Train Epoch: 0, mini-batch 11750 of 25000, training loss: 0.934611\n",
      "Train Epoch: 0, mini-batch 11760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11770 of 25000, training loss: 1.311633\n",
      "Train Epoch: 0, mini-batch 11780 of 25000, training loss: 0.817650\n",
      "Train Epoch: 0, mini-batch 11790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11800 of 25000, training loss: 0.693162\n",
      "Train Epoch: 0, mini-batch 11810 of 25000, training loss: 0.314426\n",
      "Train Epoch: 0, mini-batch 11820 of 25000, training loss: 0.321722\n",
      "Train Epoch: 0, mini-batch 11830 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 11840 of 25000, training loss: 0.321037\n",
      "Train Epoch: 0, mini-batch 11850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11860 of 25000, training loss: 0.315384\n",
      "Train Epoch: 0, mini-batch 11870 of 25000, training loss: 0.695015\n",
      "Train Epoch: 0, mini-batch 11880 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 11890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11920 of 25000, training loss: 0.318032\n",
      "Train Epoch: 0, mini-batch 11930 of 25000, training loss: 0.725109\n",
      "Train Epoch: 0, mini-batch 11940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11950 of 25000, training loss: 1.195832\n",
      "Train Epoch: 0, mini-batch 11960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 11970 of 25000, training loss: 0.316623\n",
      "Train Epoch: 0, mini-batch 11980 of 25000, training loss: 0.693140\n",
      "Train Epoch: 0, mini-batch 11990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12000 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12010 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12020 of 25000, training loss: 0.313412\n",
      "Train Epoch: 0, mini-batch 12030 of 25000, training loss: 0.536473\n",
      "Train Epoch: 0, mini-batch 12040 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12050 of 25000, training loss: 0.800695\n",
      "Train Epoch: 0, mini-batch 12060 of 25000, training loss: 0.313414\n",
      "Train Epoch: 0, mini-batch 12070 of 25000, training loss: 0.552680\n",
      "Train Epoch: 0, mini-batch 12080 of 25000, training loss: 0.320410\n",
      "Train Epoch: 0, mini-batch 12090 of 25000, training loss: 0.764924\n",
      "Train Epoch: 0, mini-batch 12100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12110 of 25000, training loss: 0.313884\n",
      "Train Epoch: 0, mini-batch 12120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12130 of 25000, training loss: 0.314027\n",
      "Train Epoch: 0, mini-batch 12140 of 25000, training loss: 0.693445\n",
      "Train Epoch: 0, mini-batch 12150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12160 of 25000, training loss: 0.313447\n",
      "Train Epoch: 0, mini-batch 12170 of 25000, training loss: 0.313279\n",
      "Train Epoch: 0, mini-batch 12180 of 25000, training loss: 0.316277\n",
      "Train Epoch: 0, mini-batch 12190 of 25000, training loss: 0.683741\n",
      "Train Epoch: 0, mini-batch 12200 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12220 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12230 of 25000, training loss: 0.318062\n",
      "Train Epoch: 0, mini-batch 12240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12250 of 25000, training loss: 0.693153\n",
      "Train Epoch: 0, mini-batch 12260 of 25000, training loss: 0.313502\n",
      "Train Epoch: 0, mini-batch 12270 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12280 of 25000, training loss: 0.313977\n",
      "Train Epoch: 0, mini-batch 12290 of 25000, training loss: 1.295519\n",
      "Train Epoch: 0, mini-batch 12300 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12310 of 25000, training loss: 0.313333\n",
      "Train Epoch: 0, mini-batch 12320 of 25000, training loss: 0.314278\n",
      "Train Epoch: 0, mini-batch 12330 of 25000, training loss: 0.315051\n",
      "Train Epoch: 0, mini-batch 12340 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12350 of 25000, training loss: 0.313498\n",
      "Train Epoch: 0, mini-batch 12360 of 25000, training loss: 0.469694\n",
      "Train Epoch: 0, mini-batch 12370 of 25000, training loss: 0.315478\n",
      "Train Epoch: 0, mini-batch 12380 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12390 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12400 of 25000, training loss: 0.343199\n",
      "Train Epoch: 0, mini-batch 12410 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 12420 of 25000, training loss: 0.313695\n",
      "Train Epoch: 0, mini-batch 12430 of 25000, training loss: 0.698941\n",
      "Train Epoch: 0, mini-batch 12440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12450 of 25000, training loss: 0.345089\n",
      "Train Epoch: 0, mini-batch 12460 of 25000, training loss: 0.313338\n",
      "Train Epoch: 0, mini-batch 12470 of 25000, training loss: 1.304177\n",
      "Train Epoch: 0, mini-batch 12480 of 25000, training loss: 0.693323\n",
      "Train Epoch: 0, mini-batch 12490 of 25000, training loss: 0.617768\n",
      "Train Epoch: 0, mini-batch 12500 of 25000, training loss: 0.631650\n",
      "Train Epoch: 0, mini-batch 12510 of 25000, training loss: 0.712325\n",
      "Train Epoch: 0, mini-batch 12520 of 25000, training loss: 0.697497\n",
      "Train Epoch: 0, mini-batch 12530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12540 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12550 of 25000, training loss: 0.324969\n",
      "Train Epoch: 0, mini-batch 12560 of 25000, training loss: 0.327573\n",
      "Train Epoch: 0, mini-batch 12570 of 25000, training loss: 0.313881\n",
      "Train Epoch: 0, mini-batch 12580 of 25000, training loss: 0.313386\n",
      "Train Epoch: 0, mini-batch 12590 of 25000, training loss: 0.313308\n",
      "Train Epoch: 0, mini-batch 12600 of 25000, training loss: 1.311879\n",
      "Train Epoch: 0, mini-batch 12610 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12620 of 25000, training loss: 0.693177\n",
      "Train Epoch: 0, mini-batch 12630 of 25000, training loss: 0.313941\n",
      "Train Epoch: 0, mini-batch 12640 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12650 of 25000, training loss: 1.307823\n",
      "Train Epoch: 0, mini-batch 12660 of 25000, training loss: 0.314354\n",
      "Train Epoch: 0, mini-batch 12670 of 25000, training loss: 1.241776\n",
      "Train Epoch: 0, mini-batch 12680 of 25000, training loss: 0.313309\n",
      "Train Epoch: 0, mini-batch 12690 of 25000, training loss: 0.697839\n",
      "Train Epoch: 0, mini-batch 12700 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12710 of 25000, training loss: 0.313419\n",
      "Train Epoch: 0, mini-batch 12720 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12730 of 25000, training loss: 0.313430\n",
      "Train Epoch: 0, mini-batch 12740 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 12750 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12760 of 25000, training loss: 0.313273\n",
      "Train Epoch: 0, mini-batch 12770 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12790 of 25000, training loss: 0.461620\n",
      "Train Epoch: 0, mini-batch 12800 of 25000, training loss: 0.693054\n",
      "Train Epoch: 0, mini-batch 12810 of 25000, training loss: 0.313686\n",
      "Train Epoch: 0, mini-batch 12820 of 25000, training loss: 0.315174\n",
      "Train Epoch: 0, mini-batch 12830 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12840 of 25000, training loss: 0.689221\n",
      "Train Epoch: 0, mini-batch 12850 of 25000, training loss: 0.314884\n",
      "Train Epoch: 0, mini-batch 12860 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12870 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12880 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 12890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12910 of 25000, training loss: 0.316768\n",
      "Train Epoch: 0, mini-batch 12920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12930 of 25000, training loss: 0.313694\n",
      "Train Epoch: 0, mini-batch 12940 of 25000, training loss: 0.313478\n",
      "Train Epoch: 0, mini-batch 12950 of 25000, training loss: 0.313581\n",
      "Train Epoch: 0, mini-batch 12960 of 25000, training loss: 1.303615\n",
      "Train Epoch: 0, mini-batch 12970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 12980 of 25000, training loss: 0.313275\n",
      "Train Epoch: 0, mini-batch 12990 of 25000, training loss: 1.261782\n",
      "Train Epoch: 0, mini-batch 13000 of 25000, training loss: 0.313644\n",
      "Train Epoch: 0, mini-batch 13010 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13020 of 25000, training loss: 0.313270\n",
      "Train Epoch: 0, mini-batch 13030 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13040 of 25000, training loss: 0.694423\n",
      "Train Epoch: 0, mini-batch 13050 of 25000, training loss: 0.693674\n",
      "Train Epoch: 0, mini-batch 13060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13070 of 25000, training loss: 0.315609\n",
      "Train Epoch: 0, mini-batch 13080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13090 of 25000, training loss: 0.315491\n",
      "Train Epoch: 0, mini-batch 13100 of 25000, training loss: 0.693289\n",
      "Train Epoch: 0, mini-batch 13110 of 25000, training loss: 0.314549\n",
      "Train Epoch: 0, mini-batch 13120 of 25000, training loss: 0.318525\n",
      "Train Epoch: 0, mini-batch 13130 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13140 of 25000, training loss: 0.317363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 13150 of 25000, training loss: 0.313266\n",
      "Train Epoch: 0, mini-batch 13160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13170 of 25000, training loss: 0.313876\n",
      "Train Epoch: 0, mini-batch 13180 of 25000, training loss: 1.303073\n",
      "Train Epoch: 0, mini-batch 13190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13200 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13210 of 25000, training loss: 0.313385\n",
      "Train Epoch: 0, mini-batch 13220 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 13230 of 25000, training loss: 0.693310\n",
      "Train Epoch: 0, mini-batch 13240 of 25000, training loss: 0.313840\n",
      "Train Epoch: 0, mini-batch 13250 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13260 of 25000, training loss: 0.693128\n",
      "Train Epoch: 0, mini-batch 13270 of 25000, training loss: 0.320654\n",
      "Train Epoch: 0, mini-batch 13280 of 25000, training loss: 0.693763\n",
      "Train Epoch: 0, mini-batch 13290 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13300 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13310 of 25000, training loss: 0.313599\n",
      "Train Epoch: 0, mini-batch 13320 of 25000, training loss: 0.313301\n",
      "Train Epoch: 0, mini-batch 13330 of 25000, training loss: 0.693297\n",
      "Train Epoch: 0, mini-batch 13340 of 25000, training loss: 0.314277\n",
      "Train Epoch: 0, mini-batch 13350 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13360 of 25000, training loss: 1.313130\n",
      "Train Epoch: 0, mini-batch 13370 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 13380 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13390 of 25000, training loss: 0.692889\n",
      "Train Epoch: 0, mini-batch 13400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13410 of 25000, training loss: 1.309524\n",
      "Train Epoch: 0, mini-batch 13420 of 25000, training loss: 0.313852\n",
      "Train Epoch: 0, mini-batch 13430 of 25000, training loss: 0.313485\n",
      "Train Epoch: 0, mini-batch 13440 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 13450 of 25000, training loss: 0.313387\n",
      "Train Epoch: 0, mini-batch 13460 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13470 of 25000, training loss: 0.341113\n",
      "Train Epoch: 0, mini-batch 13480 of 25000, training loss: 0.313715\n",
      "Train Epoch: 0, mini-batch 13490 of 25000, training loss: 0.313338\n",
      "Train Epoch: 0, mini-batch 13500 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13510 of 25000, training loss: 0.317179\n",
      "Train Epoch: 0, mini-batch 13520 of 25000, training loss: 1.310836\n",
      "Train Epoch: 0, mini-batch 13530 of 25000, training loss: 0.734404\n",
      "Train Epoch: 0, mini-batch 13540 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13550 of 25000, training loss: 0.621050\n",
      "Train Epoch: 0, mini-batch 13560 of 25000, training loss: 0.314164\n",
      "Train Epoch: 0, mini-batch 13570 of 25000, training loss: 0.693131\n",
      "Train Epoch: 0, mini-batch 13580 of 25000, training loss: 0.314555\n",
      "Train Epoch: 0, mini-batch 13590 of 25000, training loss: 0.313357\n",
      "Train Epoch: 0, mini-batch 13600 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13610 of 25000, training loss: 0.693155\n",
      "Train Epoch: 0, mini-batch 13620 of 25000, training loss: 0.313293\n",
      "Train Epoch: 0, mini-batch 13630 of 25000, training loss: 0.313270\n",
      "Train Epoch: 0, mini-batch 13640 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13650 of 25000, training loss: 0.313768\n",
      "Train Epoch: 0, mini-batch 13660 of 25000, training loss: 0.314612\n",
      "Train Epoch: 0, mini-batch 13670 of 25000, training loss: 0.693128\n",
      "Train Epoch: 0, mini-batch 13680 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13700 of 25000, training loss: 0.313298\n",
      "Train Epoch: 0, mini-batch 13710 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13720 of 25000, training loss: 0.368447\n",
      "Train Epoch: 0, mini-batch 13730 of 25000, training loss: 0.314141\n",
      "Train Epoch: 0, mini-batch 13740 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13750 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13760 of 25000, training loss: 0.698899\n",
      "Train Epoch: 0, mini-batch 13770 of 25000, training loss: 0.320260\n",
      "Train Epoch: 0, mini-batch 13780 of 25000, training loss: 1.103001\n",
      "Train Epoch: 0, mini-batch 13790 of 25000, training loss: 0.692899\n",
      "Train Epoch: 0, mini-batch 13800 of 25000, training loss: 0.763686\n",
      "Train Epoch: 0, mini-batch 13810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13820 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13830 of 25000, training loss: 0.313385\n",
      "Train Epoch: 0, mini-batch 13840 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13850 of 25000, training loss: 0.696346\n",
      "Train Epoch: 0, mini-batch 13860 of 25000, training loss: 0.328194\n",
      "Train Epoch: 0, mini-batch 13870 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13880 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13890 of 25000, training loss: 0.313386\n",
      "Train Epoch: 0, mini-batch 13900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13940 of 25000, training loss: 0.316144\n",
      "Train Epoch: 0, mini-batch 13950 of 25000, training loss: 0.319583\n",
      "Train Epoch: 0, mini-batch 13960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 13990 of 25000, training loss: 0.692436\n",
      "Train Epoch: 0, mini-batch 14000 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14010 of 25000, training loss: 0.460649\n",
      "Train Epoch: 0, mini-batch 14020 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14030 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 14040 of 25000, training loss: 1.258288\n",
      "Train Epoch: 0, mini-batch 14050 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 14060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14070 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14080 of 25000, training loss: 0.693100\n",
      "Train Epoch: 0, mini-batch 14090 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 14100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14110 of 25000, training loss: 0.693412\n",
      "Train Epoch: 0, mini-batch 14120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14130 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14170 of 25000, training loss: 0.693108\n",
      "Train Epoch: 0, mini-batch 14180 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14190 of 25000, training loss: 0.695153\n",
      "Train Epoch: 0, mini-batch 14200 of 25000, training loss: 0.323549\n",
      "Train Epoch: 0, mini-batch 14210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14220 of 25000, training loss: 1.312373\n",
      "Train Epoch: 0, mini-batch 14230 of 25000, training loss: 0.699303\n",
      "Train Epoch: 0, mini-batch 14240 of 25000, training loss: 0.334848\n",
      "Train Epoch: 0, mini-batch 14250 of 25000, training loss: 0.313703\n",
      "Train Epoch: 0, mini-batch 14260 of 25000, training loss: 1.300592\n",
      "Train Epoch: 0, mini-batch 14270 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14280 of 25000, training loss: 0.338781\n",
      "Train Epoch: 0, mini-batch 14290 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 14300 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14310 of 25000, training loss: 0.313268\n",
      "Train Epoch: 0, mini-batch 14320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14340 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 14350 of 25000, training loss: 0.315352\n",
      "Train Epoch: 0, mini-batch 14360 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 14370 of 25000, training loss: 0.313277\n",
      "Train Epoch: 0, mini-batch 14380 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14390 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14400 of 25000, training loss: 0.502320\n",
      "Train Epoch: 0, mini-batch 14410 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 14420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14430 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14440 of 25000, training loss: 0.313421\n",
      "Train Epoch: 0, mini-batch 14450 of 25000, training loss: 0.316134\n",
      "Train Epoch: 0, mini-batch 14460 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14470 of 25000, training loss: 0.469633\n",
      "Train Epoch: 0, mini-batch 14480 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14490 of 25000, training loss: 0.319828\n",
      "Train Epoch: 0, mini-batch 14500 of 25000, training loss: 0.716435\n",
      "Train Epoch: 0, mini-batch 14510 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14530 of 25000, training loss: 0.314689\n",
      "Train Epoch: 0, mini-batch 14540 of 25000, training loss: 0.693147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 14550 of 25000, training loss: 0.313547\n",
      "Train Epoch: 0, mini-batch 14560 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14570 of 25000, training loss: 0.313712\n",
      "Train Epoch: 0, mini-batch 14580 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14590 of 25000, training loss: 0.313636\n",
      "Train Epoch: 0, mini-batch 14600 of 25000, training loss: 0.693095\n",
      "Train Epoch: 0, mini-batch 14610 of 25000, training loss: 0.322233\n",
      "Train Epoch: 0, mini-batch 14620 of 25000, training loss: 0.729401\n",
      "Train Epoch: 0, mini-batch 14630 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 14640 of 25000, training loss: 0.313550\n",
      "Train Epoch: 0, mini-batch 14650 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14670 of 25000, training loss: 0.317588\n",
      "Train Epoch: 0, mini-batch 14680 of 25000, training loss: 0.693329\n",
      "Train Epoch: 0, mini-batch 14690 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 14700 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14710 of 25000, training loss: 0.313927\n",
      "Train Epoch: 0, mini-batch 14720 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 14730 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 14740 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14750 of 25000, training loss: 0.698957\n",
      "Train Epoch: 0, mini-batch 14760 of 25000, training loss: 0.316401\n",
      "Train Epoch: 0, mini-batch 14770 of 25000, training loss: 0.313464\n",
      "Train Epoch: 0, mini-batch 14780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14800 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14810 of 25000, training loss: 0.314271\n",
      "Train Epoch: 0, mini-batch 14820 of 25000, training loss: 0.692910\n",
      "Train Epoch: 0, mini-batch 14830 of 25000, training loss: 0.314909\n",
      "Train Epoch: 0, mini-batch 14840 of 25000, training loss: 0.692538\n",
      "Train Epoch: 0, mini-batch 14850 of 25000, training loss: 0.690363\n",
      "Train Epoch: 0, mini-batch 14860 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14870 of 25000, training loss: 0.313266\n",
      "Train Epoch: 0, mini-batch 14880 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14890 of 25000, training loss: 1.303685\n",
      "Train Epoch: 0, mini-batch 14900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14920 of 25000, training loss: 0.314720\n",
      "Train Epoch: 0, mini-batch 14930 of 25000, training loss: 0.693151\n",
      "Train Epoch: 0, mini-batch 14940 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 14950 of 25000, training loss: 1.091447\n",
      "Train Epoch: 0, mini-batch 14960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14970 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 14980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 14990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15000 of 25000, training loss: 0.693570\n",
      "Train Epoch: 0, mini-batch 15010 of 25000, training loss: 0.692768\n",
      "Train Epoch: 0, mini-batch 15020 of 25000, training loss: 0.313462\n",
      "Train Epoch: 0, mini-batch 15030 of 25000, training loss: 0.313284\n",
      "Train Epoch: 0, mini-batch 15040 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15050 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15060 of 25000, training loss: 0.314778\n",
      "Train Epoch: 0, mini-batch 15070 of 25000, training loss: 0.313419\n",
      "Train Epoch: 0, mini-batch 15080 of 25000, training loss: 0.313409\n",
      "Train Epoch: 0, mini-batch 15090 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15100 of 25000, training loss: 0.553980\n",
      "Train Epoch: 0, mini-batch 15110 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 15120 of 25000, training loss: 0.693166\n",
      "Train Epoch: 0, mini-batch 15130 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15170 of 25000, training loss: 0.329459\n",
      "Train Epoch: 0, mini-batch 15180 of 25000, training loss: 0.694742\n",
      "Train Epoch: 0, mini-batch 15190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15200 of 25000, training loss: 0.693152\n",
      "Train Epoch: 0, mini-batch 15210 of 25000, training loss: 0.313338\n",
      "Train Epoch: 0, mini-batch 15220 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15230 of 25000, training loss: 0.313658\n",
      "Train Epoch: 0, mini-batch 15240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15250 of 25000, training loss: 0.315113\n",
      "Train Epoch: 0, mini-batch 15260 of 25000, training loss: 0.701496\n",
      "Train Epoch: 0, mini-batch 15270 of 25000, training loss: 1.310549\n",
      "Train Epoch: 0, mini-batch 15280 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15290 of 25000, training loss: 0.313482\n",
      "Train Epoch: 0, mini-batch 15300 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15310 of 25000, training loss: 0.315810\n",
      "Train Epoch: 0, mini-batch 15320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15330 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 15340 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15350 of 25000, training loss: 0.728121\n",
      "Train Epoch: 0, mini-batch 15360 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15370 of 25000, training loss: 1.308766\n",
      "Train Epoch: 0, mini-batch 15380 of 25000, training loss: 0.313472\n",
      "Train Epoch: 0, mini-batch 15390 of 25000, training loss: 0.816103\n",
      "Train Epoch: 0, mini-batch 15400 of 25000, training loss: 0.693397\n",
      "Train Epoch: 0, mini-batch 15410 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15430 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15460 of 25000, training loss: 0.313270\n",
      "Train Epoch: 0, mini-batch 15470 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15480 of 25000, training loss: 0.313317\n",
      "Train Epoch: 0, mini-batch 15490 of 25000, training loss: 0.413376\n",
      "Train Epoch: 0, mini-batch 15500 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15510 of 25000, training loss: 0.313400\n",
      "Train Epoch: 0, mini-batch 15520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15540 of 25000, training loss: 0.693496\n",
      "Train Epoch: 0, mini-batch 15550 of 25000, training loss: 0.316556\n",
      "Train Epoch: 0, mini-batch 15560 of 25000, training loss: 0.363911\n",
      "Train Epoch: 0, mini-batch 15570 of 25000, training loss: 0.492230\n",
      "Train Epoch: 0, mini-batch 15580 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 15590 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15600 of 25000, training loss: 0.709930\n",
      "Train Epoch: 0, mini-batch 15610 of 25000, training loss: 0.314606\n",
      "Train Epoch: 0, mini-batch 15620 of 25000, training loss: 0.693109\n",
      "Train Epoch: 0, mini-batch 15630 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15640 of 25000, training loss: 0.692870\n",
      "Train Epoch: 0, mini-batch 15650 of 25000, training loss: 0.334629\n",
      "Train Epoch: 0, mini-batch 15660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15670 of 25000, training loss: 0.313267\n",
      "Train Epoch: 0, mini-batch 15680 of 25000, training loss: 0.314448\n",
      "Train Epoch: 0, mini-batch 15690 of 25000, training loss: 0.313712\n",
      "Train Epoch: 0, mini-batch 15700 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15710 of 25000, training loss: 0.313296\n",
      "Train Epoch: 0, mini-batch 15720 of 25000, training loss: 0.313299\n",
      "Train Epoch: 0, mini-batch 15730 of 25000, training loss: 0.813433\n",
      "Train Epoch: 0, mini-batch 15740 of 25000, training loss: 1.308609\n",
      "Train Epoch: 0, mini-batch 15750 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15760 of 25000, training loss: 0.313670\n",
      "Train Epoch: 0, mini-batch 15770 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15780 of 25000, training loss: 0.694847\n",
      "Train Epoch: 0, mini-batch 15790 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 15800 of 25000, training loss: 1.313257\n",
      "Train Epoch: 0, mini-batch 15810 of 25000, training loss: 1.217781\n",
      "Train Epoch: 0, mini-batch 15820 of 25000, training loss: 0.346128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 15830 of 25000, training loss: 0.313459\n",
      "Train Epoch: 0, mini-batch 15840 of 25000, training loss: 0.313935\n",
      "Train Epoch: 0, mini-batch 15850 of 25000, training loss: 0.315693\n",
      "Train Epoch: 0, mini-batch 15860 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15870 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15880 of 25000, training loss: 0.313365\n",
      "Train Epoch: 0, mini-batch 15890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15900 of 25000, training loss: 0.336603\n",
      "Train Epoch: 0, mini-batch 15910 of 25000, training loss: 0.315877\n",
      "Train Epoch: 0, mini-batch 15920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15930 of 25000, training loss: 0.313286\n",
      "Train Epoch: 0, mini-batch 15940 of 25000, training loss: 0.313311\n",
      "Train Epoch: 0, mini-batch 15950 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 15960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 15970 of 25000, training loss: 1.050185\n",
      "Train Epoch: 0, mini-batch 15980 of 25000, training loss: 0.313509\n",
      "Train Epoch: 0, mini-batch 15990 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 16000 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16010 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16020 of 25000, training loss: 0.680004\n",
      "Train Epoch: 0, mini-batch 16030 of 25000, training loss: 0.693109\n",
      "Train Epoch: 0, mini-batch 16040 of 25000, training loss: 0.313379\n",
      "Train Epoch: 0, mini-batch 16050 of 25000, training loss: 0.314102\n",
      "Train Epoch: 0, mini-batch 16060 of 25000, training loss: 0.313944\n",
      "Train Epoch: 0, mini-batch 16070 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16090 of 25000, training loss: 0.326189\n",
      "Train Epoch: 0, mini-batch 16100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16110 of 25000, training loss: 0.313525\n",
      "Train Epoch: 0, mini-batch 16120 of 25000, training loss: 0.691843\n",
      "Train Epoch: 0, mini-batch 16130 of 25000, training loss: 0.313530\n",
      "Train Epoch: 0, mini-batch 16140 of 25000, training loss: 0.315527\n",
      "Train Epoch: 0, mini-batch 16150 of 25000, training loss: 0.313273\n",
      "Train Epoch: 0, mini-batch 16160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16170 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16180 of 25000, training loss: 0.316060\n",
      "Train Epoch: 0, mini-batch 16190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16200 of 25000, training loss: 0.693169\n",
      "Train Epoch: 0, mini-batch 16210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16220 of 25000, training loss: 0.693230\n",
      "Train Epoch: 0, mini-batch 16230 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16250 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16260 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16270 of 25000, training loss: 0.313634\n",
      "Train Epoch: 0, mini-batch 16280 of 25000, training loss: 0.313376\n",
      "Train Epoch: 0, mini-batch 16290 of 25000, training loss: 0.313652\n",
      "Train Epoch: 0, mini-batch 16300 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 16310 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16320 of 25000, training loss: 0.313390\n",
      "Train Epoch: 0, mini-batch 16330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16340 of 25000, training loss: 0.693411\n",
      "Train Epoch: 0, mini-batch 16350 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16360 of 25000, training loss: 0.769868\n",
      "Train Epoch: 0, mini-batch 16370 of 25000, training loss: 0.313532\n",
      "Train Epoch: 0, mini-batch 16380 of 25000, training loss: 0.693770\n",
      "Train Epoch: 0, mini-batch 16390 of 25000, training loss: 0.347446\n",
      "Train Epoch: 0, mini-batch 16400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16410 of 25000, training loss: 0.313494\n",
      "Train Epoch: 0, mini-batch 16420 of 25000, training loss: 0.313408\n",
      "Train Epoch: 0, mini-batch 16430 of 25000, training loss: 0.313318\n",
      "Train Epoch: 0, mini-batch 16440 of 25000, training loss: 0.313703\n",
      "Train Epoch: 0, mini-batch 16450 of 25000, training loss: 0.313306\n",
      "Train Epoch: 0, mini-batch 16460 of 25000, training loss: 0.315941\n",
      "Train Epoch: 0, mini-batch 16470 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16480 of 25000, training loss: 0.313666\n",
      "Train Epoch: 0, mini-batch 16490 of 25000, training loss: 0.313267\n",
      "Train Epoch: 0, mini-batch 16500 of 25000, training loss: 0.693137\n",
      "Train Epoch: 0, mini-batch 16510 of 25000, training loss: 0.313829\n",
      "Train Epoch: 0, mini-batch 16520 of 25000, training loss: 1.309224\n",
      "Train Epoch: 0, mini-batch 16530 of 25000, training loss: 0.676095\n",
      "Train Epoch: 0, mini-batch 16540 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16550 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 16560 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 16570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16580 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16590 of 25000, training loss: 0.958902\n",
      "Train Epoch: 0, mini-batch 16600 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16610 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16620 of 25000, training loss: 0.672926\n",
      "Train Epoch: 0, mini-batch 16630 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16640 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16650 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16660 of 25000, training loss: 0.692935\n",
      "Train Epoch: 0, mini-batch 16670 of 25000, training loss: 0.313635\n",
      "Train Epoch: 0, mini-batch 16680 of 25000, training loss: 0.323146\n",
      "Train Epoch: 0, mini-batch 16690 of 25000, training loss: 0.315751\n",
      "Train Epoch: 0, mini-batch 16700 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16710 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 16720 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16730 of 25000, training loss: 0.684946\n",
      "Train Epoch: 0, mini-batch 16740 of 25000, training loss: 0.314040\n",
      "Train Epoch: 0, mini-batch 16750 of 25000, training loss: 0.330681\n",
      "Train Epoch: 0, mini-batch 16760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16770 of 25000, training loss: 0.693183\n",
      "Train Epoch: 0, mini-batch 16780 of 25000, training loss: 0.693179\n",
      "Train Epoch: 0, mini-batch 16790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16800 of 25000, training loss: 1.313261\n",
      "Train Epoch: 0, mini-batch 16810 of 25000, training loss: 0.402085\n",
      "Train Epoch: 0, mini-batch 16820 of 25000, training loss: 0.313438\n",
      "Train Epoch: 0, mini-batch 16830 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 16840 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 16850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16860 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16870 of 25000, training loss: 0.313280\n",
      "Train Epoch: 0, mini-batch 16880 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 16890 of 25000, training loss: 0.315601\n",
      "Train Epoch: 0, mini-batch 16900 of 25000, training loss: 0.313272\n",
      "Train Epoch: 0, mini-batch 16910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16940 of 25000, training loss: 0.313462\n",
      "Train Epoch: 0, mini-batch 16950 of 25000, training loss: 0.313322\n",
      "Train Epoch: 0, mini-batch 16960 of 25000, training loss: 0.314219\n",
      "Train Epoch: 0, mini-batch 16970 of 25000, training loss: 0.693156\n",
      "Train Epoch: 0, mini-batch 16980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 16990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17000 of 25000, training loss: 0.314431\n",
      "Train Epoch: 0, mini-batch 17010 of 25000, training loss: 0.693209\n",
      "Train Epoch: 0, mini-batch 17020 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 17030 of 25000, training loss: 0.313964\n",
      "Train Epoch: 0, mini-batch 17040 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17050 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17060 of 25000, training loss: 0.313610\n",
      "Train Epoch: 0, mini-batch 17070 of 25000, training loss: 1.107274\n",
      "Train Epoch: 0, mini-batch 17080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17090 of 25000, training loss: 0.313269\n",
      "Train Epoch: 0, mini-batch 17100 of 25000, training loss: 0.313753\n",
      "Train Epoch: 0, mini-batch 17110 of 25000, training loss: 0.320232\n",
      "Train Epoch: 0, mini-batch 17120 of 25000, training loss: 0.693140\n",
      "Train Epoch: 0, mini-batch 17130 of 25000, training loss: 0.313373\n",
      "Train Epoch: 0, mini-batch 17140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17170 of 25000, training loss: 0.693369\n",
      "Train Epoch: 0, mini-batch 17180 of 25000, training loss: 1.248681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 17190 of 25000, training loss: 1.002028\n",
      "Train Epoch: 0, mini-batch 17200 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17220 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17230 of 25000, training loss: 0.314420\n",
      "Train Epoch: 0, mini-batch 17240 of 25000, training loss: 0.313677\n",
      "Train Epoch: 0, mini-batch 17250 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17260 of 25000, training loss: 0.693154\n",
      "Train Epoch: 0, mini-batch 17270 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17280 of 25000, training loss: 0.690536\n",
      "Train Epoch: 0, mini-batch 17290 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17300 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17310 of 25000, training loss: 1.232199\n",
      "Train Epoch: 0, mini-batch 17320 of 25000, training loss: 0.313895\n",
      "Train Epoch: 0, mini-batch 17330 of 25000, training loss: 1.308851\n",
      "Train Epoch: 0, mini-batch 17340 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17350 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17360 of 25000, training loss: 0.317934\n",
      "Train Epoch: 0, mini-batch 17370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17380 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17390 of 25000, training loss: 0.696208\n",
      "Train Epoch: 0, mini-batch 17400 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 17410 of 25000, training loss: 0.313296\n",
      "Train Epoch: 0, mini-batch 17420 of 25000, training loss: 1.310409\n",
      "Train Epoch: 0, mini-batch 17430 of 25000, training loss: 0.693155\n",
      "Train Epoch: 0, mini-batch 17440 of 25000, training loss: 0.695167\n",
      "Train Epoch: 0, mini-batch 17450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17460 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17470 of 25000, training loss: 0.609293\n",
      "Train Epoch: 0, mini-batch 17480 of 25000, training loss: 0.313362\n",
      "Train Epoch: 0, mini-batch 17490 of 25000, training loss: 0.313353\n",
      "Train Epoch: 0, mini-batch 17500 of 25000, training loss: 0.316348\n",
      "Train Epoch: 0, mini-batch 17510 of 25000, training loss: 0.313359\n",
      "Train Epoch: 0, mini-batch 17520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17530 of 25000, training loss: 0.323261\n",
      "Train Epoch: 0, mini-batch 17540 of 25000, training loss: 0.313533\n",
      "Train Epoch: 0, mini-batch 17550 of 25000, training loss: 0.361596\n",
      "Train Epoch: 0, mini-batch 17560 of 25000, training loss: 0.313606\n",
      "Train Epoch: 0, mini-batch 17570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17580 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 17590 of 25000, training loss: 0.313611\n",
      "Train Epoch: 0, mini-batch 17600 of 25000, training loss: 0.322784\n",
      "Train Epoch: 0, mini-batch 17610 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17620 of 25000, training loss: 0.317258\n",
      "Train Epoch: 0, mini-batch 17630 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17640 of 25000, training loss: 0.693142\n",
      "Train Epoch: 0, mini-batch 17650 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 17660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17670 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 17680 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 17690 of 25000, training loss: 0.313770\n",
      "Train Epoch: 0, mini-batch 17700 of 25000, training loss: 0.315081\n",
      "Train Epoch: 0, mini-batch 17710 of 25000, training loss: 0.724316\n",
      "Train Epoch: 0, mini-batch 17720 of 25000, training loss: 0.313306\n",
      "Train Epoch: 0, mini-batch 17730 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17740 of 25000, training loss: 0.693137\n",
      "Train Epoch: 0, mini-batch 17750 of 25000, training loss: 0.313409\n",
      "Train Epoch: 0, mini-batch 17760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17770 of 25000, training loss: 0.313300\n",
      "Train Epoch: 0, mini-batch 17780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17790 of 25000, training loss: 0.689552\n",
      "Train Epoch: 0, mini-batch 17800 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 17810 of 25000, training loss: 0.689211\n",
      "Train Epoch: 0, mini-batch 17820 of 25000, training loss: 0.313281\n",
      "Train Epoch: 0, mini-batch 17830 of 25000, training loss: 0.313705\n",
      "Train Epoch: 0, mini-batch 17840 of 25000, training loss: 0.315157\n",
      "Train Epoch: 0, mini-batch 17850 of 25000, training loss: 0.356468\n",
      "Train Epoch: 0, mini-batch 17860 of 25000, training loss: 0.764367\n",
      "Train Epoch: 0, mini-batch 17870 of 25000, training loss: 0.693126\n",
      "Train Epoch: 0, mini-batch 17880 of 25000, training loss: 0.313361\n",
      "Train Epoch: 0, mini-batch 17890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17910 of 25000, training loss: 0.692823\n",
      "Train Epoch: 0, mini-batch 17920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 17970 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 17980 of 25000, training loss: 0.314302\n",
      "Train Epoch: 0, mini-batch 17990 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 18000 of 25000, training loss: 0.313310\n",
      "Train Epoch: 0, mini-batch 18010 of 25000, training loss: 0.319934\n",
      "Train Epoch: 0, mini-batch 18020 of 25000, training loss: 0.313416\n",
      "Train Epoch: 0, mini-batch 18030 of 25000, training loss: 1.309630\n",
      "Train Epoch: 0, mini-batch 18040 of 25000, training loss: 0.313673\n",
      "Train Epoch: 0, mini-batch 18050 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18070 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 18080 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 18090 of 25000, training loss: 0.313452\n",
      "Train Epoch: 0, mini-batch 18100 of 25000, training loss: 0.588870\n",
      "Train Epoch: 0, mini-batch 18110 of 25000, training loss: 0.320389\n",
      "Train Epoch: 0, mini-batch 18120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18130 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18140 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 18150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18160 of 25000, training loss: 0.313312\n",
      "Train Epoch: 0, mini-batch 18170 of 25000, training loss: 1.221619\n",
      "Train Epoch: 0, mini-batch 18180 of 25000, training loss: 0.313509\n",
      "Train Epoch: 0, mini-batch 18190 of 25000, training loss: 0.313375\n",
      "Train Epoch: 0, mini-batch 18200 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18210 of 25000, training loss: 0.313342\n",
      "Train Epoch: 0, mini-batch 18220 of 25000, training loss: 0.313806\n",
      "Train Epoch: 0, mini-batch 18230 of 25000, training loss: 0.717653\n",
      "Train Epoch: 0, mini-batch 18240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18250 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18260 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18270 of 25000, training loss: 0.693186\n",
      "Train Epoch: 0, mini-batch 18280 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18290 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 18300 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18310 of 25000, training loss: 0.327368\n",
      "Train Epoch: 0, mini-batch 18320 of 25000, training loss: 0.364641\n",
      "Train Epoch: 0, mini-batch 18330 of 25000, training loss: 0.693079\n",
      "Train Epoch: 0, mini-batch 18340 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18350 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18360 of 25000, training loss: 0.313264\n",
      "Train Epoch: 0, mini-batch 18370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18380 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18390 of 25000, training loss: 0.315364\n",
      "Train Epoch: 0, mini-batch 18400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18410 of 25000, training loss: 1.289551\n",
      "Train Epoch: 0, mini-batch 18420 of 25000, training loss: 1.313261\n",
      "Train Epoch: 0, mini-batch 18430 of 25000, training loss: 0.688376\n",
      "Train Epoch: 0, mini-batch 18440 of 25000, training loss: 0.313946\n",
      "Train Epoch: 0, mini-batch 18450 of 25000, training loss: 0.927875\n",
      "Train Epoch: 0, mini-batch 18460 of 25000, training loss: 1.237270\n",
      "Train Epoch: 0, mini-batch 18470 of 25000, training loss: 0.315105\n",
      "Train Epoch: 0, mini-batch 18480 of 25000, training loss: 0.693176\n",
      "Train Epoch: 0, mini-batch 18490 of 25000, training loss: 0.313521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 18500 of 25000, training loss: 0.693063\n",
      "Train Epoch: 0, mini-batch 18510 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18530 of 25000, training loss: 0.314565\n",
      "Train Epoch: 0, mini-batch 18540 of 25000, training loss: 0.313494\n",
      "Train Epoch: 0, mini-batch 18550 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18560 of 25000, training loss: 0.314774\n",
      "Train Epoch: 0, mini-batch 18570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18580 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18590 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18600 of 25000, training loss: 1.310143\n",
      "Train Epoch: 0, mini-batch 18610 of 25000, training loss: 0.313276\n",
      "Train Epoch: 0, mini-batch 18620 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18630 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18640 of 25000, training loss: 0.314401\n",
      "Train Epoch: 0, mini-batch 18650 of 25000, training loss: 0.897723\n",
      "Train Epoch: 0, mini-batch 18660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18670 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18680 of 25000, training loss: 0.468059\n",
      "Train Epoch: 0, mini-batch 18690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18700 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18710 of 25000, training loss: 0.313274\n",
      "Train Epoch: 0, mini-batch 18720 of 25000, training loss: 1.281724\n",
      "Train Epoch: 0, mini-batch 18730 of 25000, training loss: 1.295914\n",
      "Train Epoch: 0, mini-batch 18740 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18750 of 25000, training loss: 0.313319\n",
      "Train Epoch: 0, mini-batch 18760 of 25000, training loss: 0.693546\n",
      "Train Epoch: 0, mini-batch 18770 of 25000, training loss: 0.313504\n",
      "Train Epoch: 0, mini-batch 18780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18790 of 25000, training loss: 0.313274\n",
      "Train Epoch: 0, mini-batch 18800 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18820 of 25000, training loss: 0.313486\n",
      "Train Epoch: 0, mini-batch 18830 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18840 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18850 of 25000, training loss: 0.595086\n",
      "Train Epoch: 0, mini-batch 18860 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 18870 of 25000, training loss: 0.682181\n",
      "Train Epoch: 0, mini-batch 18880 of 25000, training loss: 0.313302\n",
      "Train Epoch: 0, mini-batch 18890 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 18900 of 25000, training loss: 0.691248\n",
      "Train Epoch: 0, mini-batch 18910 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 18920 of 25000, training loss: 0.313310\n",
      "Train Epoch: 0, mini-batch 18930 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 18940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18960 of 25000, training loss: 0.697451\n",
      "Train Epoch: 0, mini-batch 18970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 18990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19000 of 25000, training loss: 0.699076\n",
      "Train Epoch: 0, mini-batch 19010 of 25000, training loss: 0.693503\n",
      "Train Epoch: 0, mini-batch 19020 of 25000, training loss: 0.313426\n",
      "Train Epoch: 0, mini-batch 19030 of 25000, training loss: 0.313349\n",
      "Train Epoch: 0, mini-batch 19040 of 25000, training loss: 0.313405\n",
      "Train Epoch: 0, mini-batch 19050 of 25000, training loss: 0.703425\n",
      "Train Epoch: 0, mini-batch 19060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19070 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 19080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19090 of 25000, training loss: 0.313834\n",
      "Train Epoch: 0, mini-batch 19100 of 25000, training loss: 0.313463\n",
      "Train Epoch: 0, mini-batch 19110 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19120 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19130 of 25000, training loss: 0.313753\n",
      "Train Epoch: 0, mini-batch 19140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19160 of 25000, training loss: 0.694003\n",
      "Train Epoch: 0, mini-batch 19170 of 25000, training loss: 0.313736\n",
      "Train Epoch: 0, mini-batch 19180 of 25000, training loss: 1.312868\n",
      "Train Epoch: 0, mini-batch 19190 of 25000, training loss: 1.017632\n",
      "Train Epoch: 0, mini-batch 19200 of 25000, training loss: 0.313322\n",
      "Train Epoch: 0, mini-batch 19210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19220 of 25000, training loss: 0.366055\n",
      "Train Epoch: 0, mini-batch 19230 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19250 of 25000, training loss: 0.313266\n",
      "Train Epoch: 0, mini-batch 19260 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19270 of 25000, training loss: 0.313393\n",
      "Train Epoch: 0, mini-batch 19280 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19290 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19300 of 25000, training loss: 0.313269\n",
      "Train Epoch: 0, mini-batch 19310 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19340 of 25000, training loss: 0.313856\n",
      "Train Epoch: 0, mini-batch 19350 of 25000, training loss: 0.314978\n",
      "Train Epoch: 0, mini-batch 19360 of 25000, training loss: 0.315831\n",
      "Train Epoch: 0, mini-batch 19370 of 25000, training loss: 0.693394\n",
      "Train Epoch: 0, mini-batch 19380 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 19390 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19400 of 25000, training loss: 1.312508\n",
      "Train Epoch: 0, mini-batch 19410 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19420 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 19430 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 19440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19460 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19470 of 25000, training loss: 0.313467\n",
      "Train Epoch: 0, mini-batch 19480 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19490 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19500 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 19510 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 19520 of 25000, training loss: 0.313267\n",
      "Train Epoch: 0, mini-batch 19530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19540 of 25000, training loss: 0.313323\n",
      "Train Epoch: 0, mini-batch 19550 of 25000, training loss: 1.019081\n",
      "Train Epoch: 0, mini-batch 19560 of 25000, training loss: 0.313953\n",
      "Train Epoch: 0, mini-batch 19570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19580 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19590 of 25000, training loss: 0.723858\n",
      "Train Epoch: 0, mini-batch 19600 of 25000, training loss: 0.313465\n",
      "Train Epoch: 0, mini-batch 19610 of 25000, training loss: 0.313390\n",
      "Train Epoch: 0, mini-batch 19620 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19630 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 19640 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19650 of 25000, training loss: 0.314211\n",
      "Train Epoch: 0, mini-batch 19660 of 25000, training loss: 0.314581\n",
      "Train Epoch: 0, mini-batch 19670 of 25000, training loss: 0.313660\n",
      "Train Epoch: 0, mini-batch 19680 of 25000, training loss: 1.145989\n",
      "Train Epoch: 0, mini-batch 19690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19700 of 25000, training loss: 0.656998\n",
      "Train Epoch: 0, mini-batch 19710 of 25000, training loss: 0.313281\n",
      "Train Epoch: 0, mini-batch 19720 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19730 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19740 of 25000, training loss: 0.314521\n",
      "Train Epoch: 0, mini-batch 19750 of 25000, training loss: 0.313641\n",
      "Train Epoch: 0, mini-batch 19760 of 25000, training loss: 0.313809\n",
      "Train Epoch: 0, mini-batch 19770 of 25000, training loss: 0.313460\n",
      "Train Epoch: 0, mini-batch 19780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19800 of 25000, training loss: 0.693052\n",
      "Train Epoch: 0, mini-batch 19810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19820 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19830 of 25000, training loss: 0.587898\n",
      "Train Epoch: 0, mini-batch 19840 of 25000, training loss: 0.694498\n",
      "Train Epoch: 0, mini-batch 19850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19860 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19870 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 19880 of 25000, training loss: 0.693434\n",
      "Train Epoch: 0, mini-batch 19890 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 19900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19910 of 25000, training loss: 0.837899\n",
      "Train Epoch: 0, mini-batch 19920 of 25000, training loss: 0.682736\n",
      "Train Epoch: 0, mini-batch 19930 of 25000, training loss: 0.316176\n",
      "Train Epoch: 0, mini-batch 19940 of 25000, training loss: 1.306102\n",
      "Train Epoch: 0, mini-batch 19950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19960 of 25000, training loss: 0.313336\n",
      "Train Epoch: 0, mini-batch 19970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 19980 of 25000, training loss: 1.296742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 19990 of 25000, training loss: 0.343864\n",
      "Train Epoch: 0, mini-batch 20000 of 25000, training loss: 0.756494\n",
      "Train Epoch: 0, mini-batch 20010 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20020 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20030 of 25000, training loss: 0.316977\n",
      "Train Epoch: 0, mini-batch 20040 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20050 of 25000, training loss: 0.313589\n",
      "Train Epoch: 0, mini-batch 20060 of 25000, training loss: 0.313613\n",
      "Train Epoch: 0, mini-batch 20070 of 25000, training loss: 0.313505\n",
      "Train Epoch: 0, mini-batch 20080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20090 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20100 of 25000, training loss: 0.315158\n",
      "Train Epoch: 0, mini-batch 20110 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20120 of 25000, training loss: 0.347269\n",
      "Train Epoch: 0, mini-batch 20130 of 25000, training loss: 1.070241\n",
      "Train Epoch: 0, mini-batch 20140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20150 of 25000, training loss: 0.314446\n",
      "Train Epoch: 0, mini-batch 20160 of 25000, training loss: 0.946627\n",
      "Train Epoch: 0, mini-batch 20170 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20180 of 25000, training loss: 0.313587\n",
      "Train Epoch: 0, mini-batch 20190 of 25000, training loss: 0.693126\n",
      "Train Epoch: 0, mini-batch 20200 of 25000, training loss: 0.693169\n",
      "Train Epoch: 0, mini-batch 20210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20220 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20230 of 25000, training loss: 0.313753\n",
      "Train Epoch: 0, mini-batch 20240 of 25000, training loss: 1.313198\n",
      "Train Epoch: 0, mini-batch 20250 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20260 of 25000, training loss: 0.668380\n",
      "Train Epoch: 0, mini-batch 20270 of 25000, training loss: 0.320324\n",
      "Train Epoch: 0, mini-batch 20280 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20290 of 25000, training loss: 0.315053\n",
      "Train Epoch: 0, mini-batch 20300 of 25000, training loss: 0.313420\n",
      "Train Epoch: 0, mini-batch 20310 of 25000, training loss: 0.313674\n",
      "Train Epoch: 0, mini-batch 20320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20340 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 20350 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20360 of 25000, training loss: 0.313595\n",
      "Train Epoch: 0, mini-batch 20370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20380 of 25000, training loss: 0.693145\n",
      "Train Epoch: 0, mini-batch 20390 of 25000, training loss: 1.313209\n",
      "Train Epoch: 0, mini-batch 20400 of 25000, training loss: 0.693095\n",
      "Train Epoch: 0, mini-batch 20410 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 20420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20430 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20460 of 25000, training loss: 0.693163\n",
      "Train Epoch: 0, mini-batch 20470 of 25000, training loss: 0.313315\n",
      "Train Epoch: 0, mini-batch 20480 of 25000, training loss: 0.693684\n",
      "Train Epoch: 0, mini-batch 20490 of 25000, training loss: 1.310915\n",
      "Train Epoch: 0, mini-batch 20500 of 25000, training loss: 0.547302\n",
      "Train Epoch: 0, mini-batch 20510 of 25000, training loss: 1.075303\n",
      "Train Epoch: 0, mini-batch 20520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20540 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20550 of 25000, training loss: 0.896797\n",
      "Train Epoch: 0, mini-batch 20560 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 20570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20580 of 25000, training loss: 0.837604\n",
      "Train Epoch: 0, mini-batch 20590 of 25000, training loss: 0.316071\n",
      "Train Epoch: 0, mini-batch 20600 of 25000, training loss: 0.319599\n",
      "Train Epoch: 0, mini-batch 20610 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20620 of 25000, training loss: 0.693152\n",
      "Train Epoch: 0, mini-batch 20630 of 25000, training loss: 0.314022\n",
      "Train Epoch: 0, mini-batch 20640 of 25000, training loss: 0.316565\n",
      "Train Epoch: 0, mini-batch 20650 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20660 of 25000, training loss: 0.313877\n",
      "Train Epoch: 0, mini-batch 20670 of 25000, training loss: 0.693861\n",
      "Train Epoch: 0, mini-batch 20680 of 25000, training loss: 0.313756\n",
      "Train Epoch: 0, mini-batch 20690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20700 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 20710 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20720 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20730 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20740 of 25000, training loss: 0.313813\n",
      "Train Epoch: 0, mini-batch 20750 of 25000, training loss: 1.259921\n",
      "Train Epoch: 0, mini-batch 20760 of 25000, training loss: 0.692715\n",
      "Train Epoch: 0, mini-batch 20770 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20790 of 25000, training loss: 0.695379\n",
      "Train Epoch: 0, mini-batch 20800 of 25000, training loss: 0.689971\n",
      "Train Epoch: 0, mini-batch 20810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20820 of 25000, training loss: 0.330012\n",
      "Train Epoch: 0, mini-batch 20830 of 25000, training loss: 0.373621\n",
      "Train Epoch: 0, mini-batch 20840 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20860 of 25000, training loss: 0.313686\n",
      "Train Epoch: 0, mini-batch 20870 of 25000, training loss: 0.314286\n",
      "Train Epoch: 0, mini-batch 20880 of 25000, training loss: 1.289718\n",
      "Train Epoch: 0, mini-batch 20890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20920 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 20930 of 25000, training loss: 0.708482\n",
      "Train Epoch: 0, mini-batch 20940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20950 of 25000, training loss: 0.693014\n",
      "Train Epoch: 0, mini-batch 20960 of 25000, training loss: 0.315050\n",
      "Train Epoch: 0, mini-batch 20970 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 20980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 20990 of 25000, training loss: 0.313303\n",
      "Train Epoch: 0, mini-batch 21000 of 25000, training loss: 0.317449\n",
      "Train Epoch: 0, mini-batch 21010 of 25000, training loss: 1.298002\n",
      "Train Epoch: 0, mini-batch 21020 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21030 of 25000, training loss: 0.313546\n",
      "Train Epoch: 0, mini-batch 21040 of 25000, training loss: 1.158947\n",
      "Train Epoch: 0, mini-batch 21050 of 25000, training loss: 0.315728\n",
      "Train Epoch: 0, mini-batch 21060 of 25000, training loss: 0.757095\n",
      "Train Epoch: 0, mini-batch 21070 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21080 of 25000, training loss: 0.314887\n",
      "Train Epoch: 0, mini-batch 21090 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21110 of 25000, training loss: 0.693177\n",
      "Train Epoch: 0, mini-batch 21120 of 25000, training loss: 0.313326\n",
      "Train Epoch: 0, mini-batch 21130 of 25000, training loss: 0.366056\n",
      "Train Epoch: 0, mini-batch 21140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21150 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 21160 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21170 of 25000, training loss: 0.313494\n",
      "Train Epoch: 0, mini-batch 21180 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21190 of 25000, training loss: 0.693150\n",
      "Train Epoch: 0, mini-batch 21200 of 25000, training loss: 0.317822\n",
      "Train Epoch: 0, mini-batch 21210 of 25000, training loss: 0.313367\n",
      "Train Epoch: 0, mini-batch 21220 of 25000, training loss: 0.569178\n",
      "Train Epoch: 0, mini-batch 21230 of 25000, training loss: 0.329897\n",
      "Train Epoch: 0, mini-batch 21240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21250 of 25000, training loss: 0.313832\n",
      "Train Epoch: 0, mini-batch 21260 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21270 of 25000, training loss: 0.692681\n",
      "Train Epoch: 0, mini-batch 21280 of 25000, training loss: 0.315038\n",
      "Train Epoch: 0, mini-batch 21290 of 25000, training loss: 0.693169\n",
      "Train Epoch: 0, mini-batch 21300 of 25000, training loss: 0.313275\n",
      "Train Epoch: 0, mini-batch 21310 of 25000, training loss: 0.698596\n",
      "Train Epoch: 0, mini-batch 21320 of 25000, training loss: 0.693147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 21330 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 21340 of 25000, training loss: 0.313508\n",
      "Train Epoch: 0, mini-batch 21350 of 25000, training loss: 0.632001\n",
      "Train Epoch: 0, mini-batch 21360 of 25000, training loss: 0.332183\n",
      "Train Epoch: 0, mini-batch 21370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21380 of 25000, training loss: 0.313404\n",
      "Train Epoch: 0, mini-batch 21390 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21400 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 21410 of 25000, training loss: 1.296899\n",
      "Train Epoch: 0, mini-batch 21420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21430 of 25000, training loss: 0.314083\n",
      "Train Epoch: 0, mini-batch 21440 of 25000, training loss: 0.317991\n",
      "Train Epoch: 0, mini-batch 21450 of 25000, training loss: 0.313715\n",
      "Train Epoch: 0, mini-batch 21460 of 25000, training loss: 0.693417\n",
      "Train Epoch: 0, mini-batch 21470 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21480 of 25000, training loss: 0.314559\n",
      "Train Epoch: 0, mini-batch 21490 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21500 of 25000, training loss: 0.313369\n",
      "Train Epoch: 0, mini-batch 21510 of 25000, training loss: 0.554256\n",
      "Train Epoch: 0, mini-batch 21520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21540 of 25000, training loss: 1.239674\n",
      "Train Epoch: 0, mini-batch 21550 of 25000, training loss: 0.560556\n",
      "Train Epoch: 0, mini-batch 21560 of 25000, training loss: 0.314636\n",
      "Train Epoch: 0, mini-batch 21570 of 25000, training loss: 0.693144\n",
      "Train Epoch: 0, mini-batch 21580 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 21590 of 25000, training loss: 0.323883\n",
      "Train Epoch: 0, mini-batch 21600 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21610 of 25000, training loss: 0.314515\n",
      "Train Epoch: 0, mini-batch 21620 of 25000, training loss: 0.315882\n",
      "Train Epoch: 0, mini-batch 21630 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21640 of 25000, training loss: 0.316587\n",
      "Train Epoch: 0, mini-batch 21650 of 25000, training loss: 0.337864\n",
      "Train Epoch: 0, mini-batch 21660 of 25000, training loss: 1.301513\n",
      "Train Epoch: 0, mini-batch 21670 of 25000, training loss: 0.691882\n",
      "Train Epoch: 0, mini-batch 21680 of 25000, training loss: 0.741892\n",
      "Train Epoch: 0, mini-batch 21690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21700 of 25000, training loss: 0.314869\n",
      "Train Epoch: 0, mini-batch 21710 of 25000, training loss: 0.322741\n",
      "Train Epoch: 0, mini-batch 21720 of 25000, training loss: 0.699848\n",
      "Train Epoch: 0, mini-batch 21730 of 25000, training loss: 0.314245\n",
      "Train Epoch: 0, mini-batch 21740 of 25000, training loss: 0.313333\n",
      "Train Epoch: 0, mini-batch 21750 of 25000, training loss: 0.316228\n",
      "Train Epoch: 0, mini-batch 21760 of 25000, training loss: 0.313711\n",
      "Train Epoch: 0, mini-batch 21770 of 25000, training loss: 0.314854\n",
      "Train Epoch: 0, mini-batch 21780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21800 of 25000, training loss: 0.313433\n",
      "Train Epoch: 0, mini-batch 21810 of 25000, training loss: 0.519940\n",
      "Train Epoch: 0, mini-batch 21820 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 21830 of 25000, training loss: 0.693320\n",
      "Train Epoch: 0, mini-batch 21840 of 25000, training loss: 0.324846\n",
      "Train Epoch: 0, mini-batch 21850 of 25000, training loss: 1.307552\n",
      "Train Epoch: 0, mini-batch 21860 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 21870 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21880 of 25000, training loss: 0.922179\n",
      "Train Epoch: 0, mini-batch 21890 of 25000, training loss: 0.313435\n",
      "Train Epoch: 0, mini-batch 21900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21950 of 25000, training loss: 0.693079\n",
      "Train Epoch: 0, mini-batch 21960 of 25000, training loss: 1.311584\n",
      "Train Epoch: 0, mini-batch 21970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21980 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 21990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22000 of 25000, training loss: 0.327442\n",
      "Train Epoch: 0, mini-batch 22010 of 25000, training loss: 0.693155\n",
      "Train Epoch: 0, mini-batch 22020 of 25000, training loss: 0.320091\n",
      "Train Epoch: 0, mini-batch 22030 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22040 of 25000, training loss: 0.693151\n",
      "Train Epoch: 0, mini-batch 22050 of 25000, training loss: 0.313501\n",
      "Train Epoch: 0, mini-batch 22060 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 22070 of 25000, training loss: 0.693151\n",
      "Train Epoch: 0, mini-batch 22080 of 25000, training loss: 0.484470\n",
      "Train Epoch: 0, mini-batch 22090 of 25000, training loss: 0.703578\n",
      "Train Epoch: 0, mini-batch 22100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22110 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22120 of 25000, training loss: 0.313332\n",
      "Train Epoch: 0, mini-batch 22130 of 25000, training loss: 0.313635\n",
      "Train Epoch: 0, mini-batch 22140 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22150 of 25000, training loss: 1.312644\n",
      "Train Epoch: 0, mini-batch 22160 of 25000, training loss: 0.314053\n",
      "Train Epoch: 0, mini-batch 22170 of 25000, training loss: 0.313285\n",
      "Train Epoch: 0, mini-batch 22180 of 25000, training loss: 0.313689\n",
      "Train Epoch: 0, mini-batch 22190 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22200 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 22210 of 25000, training loss: 0.346678\n",
      "Train Epoch: 0, mini-batch 22220 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22230 of 25000, training loss: 1.312565\n",
      "Train Epoch: 0, mini-batch 22240 of 25000, training loss: 1.178239\n",
      "Train Epoch: 0, mini-batch 22250 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22260 of 25000, training loss: 1.298292\n",
      "Train Epoch: 0, mini-batch 22270 of 25000, training loss: 0.315615\n",
      "Train Epoch: 0, mini-batch 22280 of 25000, training loss: 1.313206\n",
      "Train Epoch: 0, mini-batch 22290 of 25000, training loss: 0.313322\n",
      "Train Epoch: 0, mini-batch 22300 of 25000, training loss: 0.313270\n",
      "Train Epoch: 0, mini-batch 22310 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22320 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22330 of 25000, training loss: 0.313863\n",
      "Train Epoch: 0, mini-batch 22340 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 22350 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22360 of 25000, training loss: 0.313276\n",
      "Train Epoch: 0, mini-batch 22370 of 25000, training loss: 0.313526\n",
      "Train Epoch: 0, mini-batch 22380 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22390 of 25000, training loss: 1.312238\n",
      "Train Epoch: 0, mini-batch 22400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22410 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22420 of 25000, training loss: 0.412726\n",
      "Train Epoch: 0, mini-batch 22430 of 25000, training loss: 0.313324\n",
      "Train Epoch: 0, mini-batch 22440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22450 of 25000, training loss: 0.313384\n",
      "Train Epoch: 0, mini-batch 22460 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 22470 of 25000, training loss: 0.313274\n",
      "Train Epoch: 0, mini-batch 22480 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22490 of 25000, training loss: 0.700131\n",
      "Train Epoch: 0, mini-batch 22500 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 22510 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22520 of 25000, training loss: 0.313671\n",
      "Train Epoch: 0, mini-batch 22530 of 25000, training loss: 1.311063\n",
      "Train Epoch: 0, mini-batch 22540 of 25000, training loss: 0.313605\n",
      "Train Epoch: 0, mini-batch 22550 of 25000, training loss: 0.313278\n",
      "Train Epoch: 0, mini-batch 22560 of 25000, training loss: 0.313268\n",
      "Train Epoch: 0, mini-batch 22570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22580 of 25000, training loss: 0.693155\n",
      "Train Epoch: 0, mini-batch 22590 of 25000, training loss: 1.313257\n",
      "Train Epoch: 0, mini-batch 22600 of 25000, training loss: 0.313265\n",
      "Train Epoch: 0, mini-batch 22610 of 25000, training loss: 0.696476\n",
      "Train Epoch: 0, mini-batch 22620 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22630 of 25000, training loss: 0.313274\n",
      "Train Epoch: 0, mini-batch 22640 of 25000, training loss: 0.313290\n",
      "Train Epoch: 0, mini-batch 22650 of 25000, training loss: 0.693147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 22660 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 22670 of 25000, training loss: 0.313765\n",
      "Train Epoch: 0, mini-batch 22680 of 25000, training loss: 0.633067\n",
      "Train Epoch: 0, mini-batch 22690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22700 of 25000, training loss: 0.313337\n",
      "Train Epoch: 0, mini-batch 22710 of 25000, training loss: 0.313306\n",
      "Train Epoch: 0, mini-batch 22720 of 25000, training loss: 0.313278\n",
      "Train Epoch: 0, mini-batch 22730 of 25000, training loss: 0.695371\n",
      "Train Epoch: 0, mini-batch 22740 of 25000, training loss: 0.313324\n",
      "Train Epoch: 0, mini-batch 22750 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22770 of 25000, training loss: 0.313355\n",
      "Train Epoch: 0, mini-batch 22780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22800 of 25000, training loss: 0.692128\n",
      "Train Epoch: 0, mini-batch 22810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22820 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22830 of 25000, training loss: 0.354449\n",
      "Train Epoch: 0, mini-batch 22840 of 25000, training loss: 0.317395\n",
      "Train Epoch: 0, mini-batch 22850 of 25000, training loss: 0.693159\n",
      "Train Epoch: 0, mini-batch 22860 of 25000, training loss: 0.729384\n",
      "Train Epoch: 0, mini-batch 22870 of 25000, training loss: 0.693289\n",
      "Train Epoch: 0, mini-batch 22880 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 22890 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22900 of 25000, training loss: 0.699454\n",
      "Train Epoch: 0, mini-batch 22910 of 25000, training loss: 0.313271\n",
      "Train Epoch: 0, mini-batch 22920 of 25000, training loss: 0.766743\n",
      "Train Epoch: 0, mini-batch 22930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22940 of 25000, training loss: 0.693283\n",
      "Train Epoch: 0, mini-batch 22950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 22970 of 25000, training loss: 0.313568\n",
      "Train Epoch: 0, mini-batch 22980 of 25000, training loss: 0.692831\n",
      "Train Epoch: 0, mini-batch 22990 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23000 of 25000, training loss: 0.318916\n",
      "Train Epoch: 0, mini-batch 23010 of 25000, training loss: 0.313282\n",
      "Train Epoch: 0, mini-batch 23020 of 25000, training loss: 1.306275\n",
      "Train Epoch: 0, mini-batch 23030 of 25000, training loss: 0.693204\n",
      "Train Epoch: 0, mini-batch 23040 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23050 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23070 of 25000, training loss: 0.313426\n",
      "Train Epoch: 0, mini-batch 23080 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23090 of 25000, training loss: 0.313451\n",
      "Train Epoch: 0, mini-batch 23100 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23110 of 25000, training loss: 0.313305\n",
      "Train Epoch: 0, mini-batch 23120 of 25000, training loss: 0.313273\n",
      "Train Epoch: 0, mini-batch 23130 of 25000, training loss: 0.313321\n",
      "Train Epoch: 0, mini-batch 23140 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 23150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23160 of 25000, training loss: 0.313479\n",
      "Train Epoch: 0, mini-batch 23170 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23180 of 25000, training loss: 0.314451\n",
      "Train Epoch: 0, mini-batch 23190 of 25000, training loss: 0.693149\n",
      "Train Epoch: 0, mini-batch 23200 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 23210 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23220 of 25000, training loss: 0.314281\n",
      "Train Epoch: 0, mini-batch 23230 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23240 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23250 of 25000, training loss: 0.639531\n",
      "Train Epoch: 0, mini-batch 23260 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 23270 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23280 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23290 of 25000, training loss: 0.317060\n",
      "Train Epoch: 0, mini-batch 23300 of 25000, training loss: 0.313372\n",
      "Train Epoch: 0, mini-batch 23310 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23320 of 25000, training loss: 0.693165\n",
      "Train Epoch: 0, mini-batch 23330 of 25000, training loss: 0.313581\n",
      "Train Epoch: 0, mini-batch 23340 of 25000, training loss: 0.692873\n",
      "Train Epoch: 0, mini-batch 23350 of 25000, training loss: 0.573654\n",
      "Train Epoch: 0, mini-batch 23360 of 25000, training loss: 0.313276\n",
      "Train Epoch: 0, mini-batch 23370 of 25000, training loss: 0.693205\n",
      "Train Epoch: 0, mini-batch 23380 of 25000, training loss: 0.313270\n",
      "Train Epoch: 0, mini-batch 23390 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23410 of 25000, training loss: 0.316331\n",
      "Train Epoch: 0, mini-batch 23420 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23430 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 23440 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23450 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23460 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23470 of 25000, training loss: 0.315254\n",
      "Train Epoch: 0, mini-batch 23480 of 25000, training loss: 0.683623\n",
      "Train Epoch: 0, mini-batch 23490 of 25000, training loss: 0.694296\n",
      "Train Epoch: 0, mini-batch 23500 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23510 of 25000, training loss: 0.313786\n",
      "Train Epoch: 0, mini-batch 23520 of 25000, training loss: 0.718405\n",
      "Train Epoch: 0, mini-batch 23530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23540 of 25000, training loss: 0.313765\n",
      "Train Epoch: 0, mini-batch 23550 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23560 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23570 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23580 of 25000, training loss: 1.275743\n",
      "Train Epoch: 0, mini-batch 23590 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23600 of 25000, training loss: 0.340813\n",
      "Train Epoch: 0, mini-batch 23610 of 25000, training loss: 0.313787\n",
      "Train Epoch: 0, mini-batch 23620 of 25000, training loss: 0.313970\n",
      "Train Epoch: 0, mini-batch 23630 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 23640 of 25000, training loss: 0.313643\n",
      "Train Epoch: 0, mini-batch 23650 of 25000, training loss: 0.313274\n",
      "Train Epoch: 0, mini-batch 23660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23670 of 25000, training loss: 0.700810\n",
      "Train Epoch: 0, mini-batch 23680 of 25000, training loss: 0.693170\n",
      "Train Epoch: 0, mini-batch 23690 of 25000, training loss: 0.313279\n",
      "Train Epoch: 0, mini-batch 23700 of 25000, training loss: 1.313261\n",
      "Train Epoch: 0, mini-batch 23710 of 25000, training loss: 0.313263\n",
      "Train Epoch: 0, mini-batch 23720 of 25000, training loss: 0.693144\n",
      "Train Epoch: 0, mini-batch 23730 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23740 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23750 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23770 of 25000, training loss: 0.476142\n",
      "Train Epoch: 0, mini-batch 23780 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 23790 of 25000, training loss: 0.314854\n",
      "Train Epoch: 0, mini-batch 23800 of 25000, training loss: 0.314426\n",
      "Train Epoch: 0, mini-batch 23810 of 25000, training loss: 0.598606\n",
      "Train Epoch: 0, mini-batch 23820 of 25000, training loss: 0.313978\n",
      "Train Epoch: 0, mini-batch 23830 of 25000, training loss: 0.693111\n",
      "Train Epoch: 0, mini-batch 23840 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23860 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23870 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23880 of 25000, training loss: 0.314308\n",
      "Train Epoch: 0, mini-batch 23890 of 25000, training loss: 0.314033\n",
      "Train Epoch: 0, mini-batch 23900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23910 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23930 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23940 of 25000, training loss: 0.313714\n",
      "Train Epoch: 0, mini-batch 23950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23960 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23970 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 23980 of 25000, training loss: 0.469495\n",
      "Train Epoch: 0, mini-batch 23990 of 25000, training loss: 0.313407\n",
      "Train Epoch: 0, mini-batch 24000 of 25000, training loss: 0.313266\n",
      "Train Epoch: 0, mini-batch 24010 of 25000, training loss: 0.693146\n",
      "Train Epoch: 0, mini-batch 24020 of 25000, training loss: 1.313262\n",
      "Train Epoch: 0, mini-batch 24030 of 25000, training loss: 0.691822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 24040 of 25000, training loss: 0.316286\n",
      "Train Epoch: 0, mini-batch 24050 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24060 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24070 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24080 of 25000, training loss: 0.313277\n",
      "Train Epoch: 0, mini-batch 24090 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24100 of 25000, training loss: 0.313269\n",
      "Train Epoch: 0, mini-batch 24110 of 25000, training loss: 0.313508\n",
      "Train Epoch: 0, mini-batch 24120 of 25000, training loss: 0.742773\n",
      "Train Epoch: 0, mini-batch 24130 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24140 of 25000, training loss: 0.313281\n",
      "Train Epoch: 0, mini-batch 24150 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24160 of 25000, training loss: 0.313357\n",
      "Train Epoch: 0, mini-batch 24170 of 25000, training loss: 0.750347\n",
      "Train Epoch: 0, mini-batch 24180 of 25000, training loss: 0.313400\n",
      "Train Epoch: 0, mini-batch 24190 of 25000, training loss: 0.320275\n",
      "Train Epoch: 0, mini-batch 24200 of 25000, training loss: 0.313837\n",
      "Train Epoch: 0, mini-batch 24210 of 25000, training loss: 0.313455\n",
      "Train Epoch: 0, mini-batch 24220 of 25000, training loss: 1.311282\n",
      "Train Epoch: 0, mini-batch 24230 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24240 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 24250 of 25000, training loss: 0.313335\n",
      "Train Epoch: 0, mini-batch 24260 of 25000, training loss: 0.699735\n",
      "Train Epoch: 0, mini-batch 24270 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24280 of 25000, training loss: 0.358191\n",
      "Train Epoch: 0, mini-batch 24290 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24300 of 25000, training loss: 0.313329\n",
      "Train Epoch: 0, mini-batch 24310 of 25000, training loss: 0.314247\n",
      "Train Epoch: 0, mini-batch 24320 of 25000, training loss: 1.274076\n",
      "Train Epoch: 0, mini-batch 24330 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24340 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24350 of 25000, training loss: 0.313266\n",
      "Train Epoch: 0, mini-batch 24360 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24370 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24380 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24390 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24400 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24410 of 25000, training loss: 0.693157\n",
      "Train Epoch: 0, mini-batch 24420 of 25000, training loss: 0.313319\n",
      "Train Epoch: 0, mini-batch 24430 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24440 of 25000, training loss: 0.661807\n",
      "Train Epoch: 0, mini-batch 24450 of 25000, training loss: 0.316044\n",
      "Train Epoch: 0, mini-batch 24460 of 25000, training loss: 0.705991\n",
      "Train Epoch: 0, mini-batch 24470 of 25000, training loss: 1.312649\n",
      "Train Epoch: 0, mini-batch 24480 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24490 of 25000, training loss: 0.314012\n",
      "Train Epoch: 0, mini-batch 24500 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24510 of 25000, training loss: 0.313520\n",
      "Train Epoch: 0, mini-batch 24520 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24530 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24540 of 25000, training loss: 0.313332\n",
      "Train Epoch: 0, mini-batch 24550 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24560 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24570 of 25000, training loss: 0.313491\n",
      "Train Epoch: 0, mini-batch 24580 of 25000, training loss: 0.693036\n",
      "Train Epoch: 0, mini-batch 24590 of 25000, training loss: 0.313577\n",
      "Train Epoch: 0, mini-batch 24600 of 25000, training loss: 0.692693\n",
      "Train Epoch: 0, mini-batch 24610 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24620 of 25000, training loss: 0.313401\n",
      "Train Epoch: 0, mini-batch 24630 of 25000, training loss: 0.696007\n",
      "Train Epoch: 0, mini-batch 24640 of 25000, training loss: 0.313294\n",
      "Train Epoch: 0, mini-batch 24650 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24660 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24670 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24680 of 25000, training loss: 0.314613\n",
      "Train Epoch: 0, mini-batch 24690 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24700 of 25000, training loss: 1.312477\n",
      "Train Epoch: 0, mini-batch 24710 of 25000, training loss: 0.313262\n",
      "Train Epoch: 0, mini-batch 24720 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24730 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24740 of 25000, training loss: 0.313266\n",
      "Train Epoch: 0, mini-batch 24750 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24760 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24770 of 25000, training loss: 0.313330\n",
      "Train Epoch: 0, mini-batch 24780 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24790 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24800 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24810 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24820 of 25000, training loss: 0.680996\n",
      "Train Epoch: 0, mini-batch 24830 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24840 of 25000, training loss: 0.313296\n",
      "Train Epoch: 0, mini-batch 24850 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24860 of 25000, training loss: 0.313790\n",
      "Train Epoch: 0, mini-batch 24870 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24880 of 25000, training loss: 0.693142\n",
      "Train Epoch: 0, mini-batch 24890 of 25000, training loss: 0.314159\n",
      "Train Epoch: 0, mini-batch 24900 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24910 of 25000, training loss: 0.412767\n",
      "Train Epoch: 0, mini-batch 24920 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24930 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 24940 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24950 of 25000, training loss: 0.693147\n",
      "Train Epoch: 0, mini-batch 24960 of 25000, training loss: 0.313303\n",
      "Train Epoch: 0, mini-batch 24970 of 25000, training loss: 0.313277\n",
      "Train Epoch: 0, mini-batch 24980 of 25000, training loss: 0.693148\n",
      "Train Epoch: 0, mini-batch 24990 of 25000, training loss: 0.317954\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "train_data_gen = zip(train_features, train_target)\n",
    "train_size = len(train_target)\n",
    "\n",
    "while epoch < epochs:\n",
    "    predictions = []\n",
    "    truth_values = []\n",
    "\n",
    "    for batch_idx, (xs, y) in enumerate(train_data_gen):\n",
    "        xs, y = torch.from_numpy(xs).float(), torch.FloatTensor([y])\n",
    "\n",
    "        y_pred = model(xs)\n",
    "        loss = criterion(y_pred, y)\n",
    "        #uncomment to enable L1 regularisation\n",
    "        #loss += l1_regularization_factor * torch.abs(params).sum()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions.append(y_pred.cpu().data.numpy().ravel())\n",
    "        truth_values.append(y)\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {}, mini-batch {} of {}, training loss: {:.6f}'.format(\n",
    "                epoch, batch_idx, train_size, loss.item()))\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test accuracy histories\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch, train_loss)\n",
    "plt.plot(epoch, test_loss)\n",
    "# plt.plot(no_reg['epoch'], no_reg['train_loss'])  # toggle 0\n",
    "# plt.plot(no_reg['epoch'], no_reg['test_loss'])  # toggle 0\n",
    "\n",
    "plt.legend(['Train loss', 'Test loss', 'Train no-reg', 'Test no-reg'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss score')\n",
    "\n",
    "# Get training and test accuracy histories\n",
    "train_accuracy = history.history['acc']\n",
    "test_accuracy = history.history['val_acc']\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch, train_accuracy)\n",
    "plt.plot(epoch, test_accuracy)\n",
    "# plt.plot(no_reg['epoch'], no_reg['train_accuracy'])  # toggle 0\n",
    "# plt.plot(no_reg['epoch'], no_reg['test_accuracy'])  # toggle 0\n",
    "\n",
    "plt.legend(['Train accuracy', 'Test accuracy', 'Train no-reg', 'Test no-reg'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "\n",
    "no_reg = {                             # toggle 0\n",
    "    'epoch': epoch,                    # toggle 0\n",
    "    'train_loss': train_loss,          # toggle 0\n",
    "    'test_loss': test_loss,            # toggle 0\n",
    "    'train_accuracy': train_accuracy,  # toggle 0\n",
    "    'test_accuracy': test_accuracy,    # toggle 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup weights\n",
    "weights = network.layers[0].get_weights()[0]  # toggle 0\n",
    "# weights_L1 = network.layers[0].get_weights()[0]  # toggle 1\n",
    "# weights_L2 = network.layers[0].get_weights()[0]  # toggle 2\n",
    "# weights_max = network.layers[0].get_weights()[0]  # toggle 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you got to toggle `# toggle 3`, execute the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show weight distribution\n",
    "plt.hist((\n",
    "    weights.reshape(-1),\n",
    "    weights_L1.reshape(-1),\n",
    "    weights_L2.reshape(-1),\n",
    "    weights_max.reshape(-1),\n",
    "), 49, range=(-.5, .5), label=(\n",
    "    'No-reg',\n",
    "    'L1',\n",
    "    'L2',\n",
    "    'Max',\n",
    "))\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codas ML",
   "language": "python",
   "name": "codasml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
