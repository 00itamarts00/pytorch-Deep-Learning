{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation in NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "from tensorflow import keras as kr \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my plotting style\n",
    "plt.style.use(('dark_background', 'bmh'))\n",
    "plt.rc('axes', facecolor='none')\n",
    "plt.rc('figure', figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112be9e90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortcuts\n",
    "imdb = kr.datasets.imdb\n",
    "Tokeniser = kr.preprocessing.text.Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of features we want\n",
    "features_nb = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=features_nb)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokeniser = Tokeniser(num_words=features_nb)\n",
    "train_features = tokeniser.sequences_to_matrix(train_data, mode='binary')\n",
    "test_features = tokeniser.sequences_to_matrix(test_data, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploring the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (25000,)\n",
      "train_target.shape: (25000,)\n",
      "test_data.shape: (25000,)\n",
      "test_target.shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Check data set sizes\n",
    "print('train_data.shape:', train_data.shape)\n",
    "print('train_target.shape:', train_target.shape)\n",
    "print('test_data.shape:', test_data.shape)\n",
    "print('test_target.shape:', test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_data[0]): <class 'list'>\n",
      "type(train_target[0]): <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# Check format of first training sample\n",
    "print('type(train_data[0]):', type(train_data[0]))\n",
    "print('type(train_target[0]):', type(train_target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews length: [218, 189, 141, 550, 147, 43, 123, 562, 233, 130]\n",
      "Review sentiment (bad/good): [1 0 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Check size of first 10 training samples and corresponding target\n",
    "print('Reviews length:', [len(sample) for sample in train_data[:10]])\n",
    "print('Review sentiment (bad/good):', train_target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - machine format\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set text visualisation helper function\n",
    "def show_text(sample):\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "    word_to_id[\"<PAD>\"] = 0\n",
    "    word_to_id[\"<START>\"] = 1\n",
    "    word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "    id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "    print(' '.join(id_to_word[id_] for id_ in sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this film was just brilliant casting <UNK> <UNK> story direction <UNK> really <UNK> the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> <UNK> as myself so i loved the fact there was a real <UNK> with this film the <UNK> <UNK> throughout the film were great it was just brilliant so much that i <UNK> the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the <UNK> <UNK> was amazing really <UNK> at the end it was so sad and you know what they say if you <UNK> at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of <UNK> and paul they were just brilliant children are often left out of the <UNK> <UNK> i think because the stars that play them all <UNK> up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so <UNK> because it was true and was <UNK> life after all that was <UNK> with us all\n"
     ]
    }
   ],
   "source": [
    "# Show first review - human format\n",
    "show_text(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - neural net format\n",
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   2.   0.   4.   5.   6.   7.   8.   9.   0.   0.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.   0.  21.  22.   0.   0.  25.  26.   0.\n",
      "  28.   0.  30.   0.  32.  33.   0.  35.  36.   0.  38.  39.   0.   0.\n",
      "   0.  43.   0.   0.  46.   0.  48.   0.  50.  51.  52.   0.   0.   0.\n",
      "  56.   0.   0.   0.   0.   0.  62.   0.   0.  65.  66.   0.   0.   0.\n",
      "   0.  71.   0.   0.   0.   0.  76.  77.   0.   0.   0.   0.  82.   0.\n",
      "   0.   0.   0.  87.  88.   0.   0.   0.  92.   0.   0.   0.   0.   0.\n",
      "  98.   0. 100.   0.   0. 103. 104.   0. 106. 107.   0.   0.   0.   0.\n",
      " 112. 113.   0.   0.   0. 117.   0.   0.   0.   0.   0.   0. 124.   0.\n",
      "   0.   0.   0.   0. 130.   0.   0.   0. 134. 135.   0.   0.   0.   0.\n",
      "   0. 141.   0.   0. 144.   0.   0. 147.   0.   0. 150.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 167.\n",
      "   0.   0.   0.   0. 172. 173.   0.   0.   0.   0. 178.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 192.   0. 194.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 215.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 224.   0. 226.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 256.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 283. 284.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 297.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 316. 317.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 336.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 381.   0.   0.   0. 385. 386.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 400.   0.   0.   0.   0.   0.\n",
      "   0. 407.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 447.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 458.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 469.   0.   0.   0.   0.   0.   0.\n",
      " 476.   0.   0.   0. 480.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 515.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 530.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 546.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 619.   0.   0.   0.   0.   0.   0. 626.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 670.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 723.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 838.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 973.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "# Show first review - neural net format - explanation\n",
    "print(train_features[0] * np.arange(len(train_features[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring regularisation of NN\n",
    "\n",
    "Play with the code, especially the one marked `# toggle`.  \n",
    "Start from `# toggle 0`, and then, one at the time, `# toggle 1` to `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerDense(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, units_size):\n",
    "\n",
    "        super(ThreeLayerDense, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_size, units_size) #features_nb, 16\n",
    "        self.linear2 = torch.nn.Linear(units_size, units_size)\n",
    "        #self.dropout\n",
    "        self.linear3 = torch.nn.Linear(units_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.linear2(x) \n",
    "        x = F.relu(x)\n",
    "        #Add dropout regularization\n",
    "        #x = F.dropout(x, training=self.training)   \n",
    "        return nn.Sigmoid()(self.linear3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "log_interval = 10\n",
    "batch_size = 100\n",
    "\n",
    "model = ThreeLayerDense(features_nb, 16)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "log_interval = 10\n",
    "batch_size = 100\n",
    "\n",
    "model = ThreeLayerDense(features_nb, 16)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "#l2 regularization\n",
    "#l2_regularization_factor = 0.0005\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay = l2_regularization_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 0 of 25000, training loss: 0.663057\n",
      "Train Epoch: 0, mini-batch 10 of 25000, training loss: 0.672497\n",
      "Train Epoch: 0, mini-batch 20 of 25000, training loss: 0.683663\n",
      "Train Epoch: 0, mini-batch 30 of 25000, training loss: 0.657638\n",
      "Train Epoch: 0, mini-batch 40 of 25000, training loss: 0.678395\n",
      "Train Epoch: 0, mini-batch 50 of 25000, training loss: 0.675862\n",
      "Train Epoch: 0, mini-batch 60 of 25000, training loss: 0.629715\n",
      "Train Epoch: 0, mini-batch 70 of 25000, training loss: 0.678230\n",
      "Train Epoch: 0, mini-batch 80 of 25000, training loss: 0.712157\n",
      "Train Epoch: 0, mini-batch 90 of 25000, training loss: 0.608832\n",
      "Train Epoch: 0, mini-batch 100 of 25000, training loss: 0.509348\n",
      "Train Epoch: 0, mini-batch 110 of 25000, training loss: 0.481726\n",
      "Train Epoch: 0, mini-batch 120 of 25000, training loss: 0.809702\n",
      "Train Epoch: 0, mini-batch 130 of 25000, training loss: 0.432869\n",
      "Train Epoch: 0, mini-batch 140 of 25000, training loss: 0.912524\n",
      "Train Epoch: 0, mini-batch 150 of 25000, training loss: 0.753959\n",
      "Train Epoch: 0, mini-batch 160 of 25000, training loss: 0.539631\n",
      "Train Epoch: 0, mini-batch 170 of 25000, training loss: 0.820063\n",
      "Train Epoch: 0, mini-batch 180 of 25000, training loss: 0.593880\n",
      "Train Epoch: 0, mini-batch 190 of 25000, training loss: 0.658383\n",
      "Train Epoch: 0, mini-batch 200 of 25000, training loss: 0.984920\n",
      "Train Epoch: 0, mini-batch 210 of 25000, training loss: 0.763284\n",
      "Train Epoch: 0, mini-batch 220 of 25000, training loss: 0.885074\n",
      "Train Epoch: 0, mini-batch 230 of 25000, training loss: 0.763760\n",
      "Train Epoch: 0, mini-batch 240 of 25000, training loss: 0.740401\n",
      "Train Epoch: 0, mini-batch 250 of 25000, training loss: 1.004960\n",
      "Train Epoch: 0, mini-batch 260 of 25000, training loss: 0.896189\n",
      "Train Epoch: 0, mini-batch 270 of 25000, training loss: 0.453135\n",
      "Train Epoch: 0, mini-batch 280 of 25000, training loss: 0.289646\n",
      "Train Epoch: 0, mini-batch 290 of 25000, training loss: 0.720930\n",
      "Train Epoch: 0, mini-batch 300 of 25000, training loss: 0.939988\n",
      "Train Epoch: 0, mini-batch 310 of 25000, training loss: 0.561440\n",
      "Train Epoch: 0, mini-batch 320 of 25000, training loss: 0.526581\n",
      "Train Epoch: 0, mini-batch 330 of 25000, training loss: 0.456844\n",
      "Train Epoch: 0, mini-batch 340 of 25000, training loss: 1.161179\n",
      "Train Epoch: 0, mini-batch 350 of 25000, training loss: 0.939137\n",
      "Train Epoch: 0, mini-batch 360 of 25000, training loss: 0.510371\n",
      "Train Epoch: 0, mini-batch 370 of 25000, training loss: 0.751815\n",
      "Train Epoch: 0, mini-batch 380 of 25000, training loss: 0.594929\n",
      "Train Epoch: 0, mini-batch 390 of 25000, training loss: 1.148179\n",
      "Train Epoch: 0, mini-batch 400 of 25000, training loss: 0.336896\n",
      "Train Epoch: 0, mini-batch 410 of 25000, training loss: 0.390836\n",
      "Train Epoch: 0, mini-batch 420 of 25000, training loss: 0.583437\n",
      "Train Epoch: 0, mini-batch 430 of 25000, training loss: 0.817723\n",
      "Train Epoch: 0, mini-batch 440 of 25000, training loss: 0.263711\n",
      "Train Epoch: 0, mini-batch 450 of 25000, training loss: 0.446019\n",
      "Train Epoch: 0, mini-batch 460 of 25000, training loss: 0.624832\n",
      "Train Epoch: 0, mini-batch 470 of 25000, training loss: 0.296840\n",
      "Train Epoch: 0, mini-batch 480 of 25000, training loss: 0.163037\n",
      "Train Epoch: 0, mini-batch 490 of 25000, training loss: 0.314862\n",
      "Train Epoch: 0, mini-batch 500 of 25000, training loss: 0.499825\n",
      "Train Epoch: 0, mini-batch 510 of 25000, training loss: 0.286656\n",
      "Train Epoch: 0, mini-batch 520 of 25000, training loss: 0.394420\n",
      "Train Epoch: 0, mini-batch 530 of 25000, training loss: 1.400131\n",
      "Train Epoch: 0, mini-batch 540 of 25000, training loss: 0.795296\n",
      "Train Epoch: 0, mini-batch 550 of 25000, training loss: 0.329738\n",
      "Train Epoch: 0, mini-batch 560 of 25000, training loss: 0.589007\n",
      "Train Epoch: 0, mini-batch 570 of 25000, training loss: 0.284512\n",
      "Train Epoch: 0, mini-batch 580 of 25000, training loss: 0.115304\n",
      "Train Epoch: 0, mini-batch 590 of 25000, training loss: 0.109760\n",
      "Train Epoch: 0, mini-batch 600 of 25000, training loss: 0.205413\n",
      "Train Epoch: 0, mini-batch 610 of 25000, training loss: 0.119924\n",
      "Train Epoch: 0, mini-batch 620 of 25000, training loss: 0.182580\n",
      "Train Epoch: 0, mini-batch 630 of 25000, training loss: 0.520945\n",
      "Train Epoch: 0, mini-batch 640 of 25000, training loss: 0.475269\n",
      "Train Epoch: 0, mini-batch 650 of 25000, training loss: 0.595255\n",
      "Train Epoch: 0, mini-batch 660 of 25000, training loss: 0.556459\n",
      "Train Epoch: 0, mini-batch 670 of 25000, training loss: 1.695138\n",
      "Train Epoch: 0, mini-batch 680 of 25000, training loss: 0.426376\n",
      "Train Epoch: 0, mini-batch 690 of 25000, training loss: 0.770700\n",
      "Train Epoch: 0, mini-batch 700 of 25000, training loss: 0.802453\n",
      "Train Epoch: 0, mini-batch 710 of 25000, training loss: 0.046766\n",
      "Train Epoch: 0, mini-batch 720 of 25000, training loss: 0.086700\n",
      "Train Epoch: 0, mini-batch 730 of 25000, training loss: 1.335175\n",
      "Train Epoch: 0, mini-batch 740 of 25000, training loss: 0.065472\n",
      "Train Epoch: 0, mini-batch 750 of 25000, training loss: 0.383389\n",
      "Train Epoch: 0, mini-batch 760 of 25000, training loss: 0.302972\n",
      "Train Epoch: 0, mini-batch 770 of 25000, training loss: 0.017644\n",
      "Train Epoch: 0, mini-batch 780 of 25000, training loss: 1.069725\n",
      "Train Epoch: 0, mini-batch 790 of 25000, training loss: 0.352398\n",
      "Train Epoch: 0, mini-batch 800 of 25000, training loss: 0.241182\n",
      "Train Epoch: 0, mini-batch 810 of 25000, training loss: 1.211280\n",
      "Train Epoch: 0, mini-batch 820 of 25000, training loss: 0.109212\n",
      "Train Epoch: 0, mini-batch 830 of 25000, training loss: 0.848950\n",
      "Train Epoch: 0, mini-batch 840 of 25000, training loss: 2.157599\n",
      "Train Epoch: 0, mini-batch 850 of 25000, training loss: 0.379685\n",
      "Train Epoch: 0, mini-batch 860 of 25000, training loss: 0.119058\n",
      "Train Epoch: 0, mini-batch 870 of 25000, training loss: 0.084202\n",
      "Train Epoch: 0, mini-batch 880 of 25000, training loss: 0.659412\n",
      "Train Epoch: 0, mini-batch 890 of 25000, training loss: 0.296641\n",
      "Train Epoch: 0, mini-batch 900 of 25000, training loss: 0.366175\n",
      "Train Epoch: 0, mini-batch 910 of 25000, training loss: 0.080276\n",
      "Train Epoch: 0, mini-batch 920 of 25000, training loss: 0.232866\n",
      "Train Epoch: 0, mini-batch 930 of 25000, training loss: 0.318629\n",
      "Train Epoch: 0, mini-batch 940 of 25000, training loss: 0.107804\n",
      "Train Epoch: 0, mini-batch 950 of 25000, training loss: 0.187516\n",
      "Train Epoch: 0, mini-batch 960 of 25000, training loss: 1.495825\n",
      "Train Epoch: 0, mini-batch 970 of 25000, training loss: 0.258930\n",
      "Train Epoch: 0, mini-batch 980 of 25000, training loss: 0.690241\n",
      "Train Epoch: 0, mini-batch 990 of 25000, training loss: 0.259564\n",
      "Train Epoch: 0, mini-batch 1000 of 25000, training loss: 0.491034\n",
      "Train Epoch: 0, mini-batch 1010 of 25000, training loss: 1.344972\n",
      "Train Epoch: 0, mini-batch 1020 of 25000, training loss: 0.056569\n",
      "Train Epoch: 0, mini-batch 1030 of 25000, training loss: 0.171576\n",
      "Train Epoch: 0, mini-batch 1040 of 25000, training loss: 1.774862\n",
      "Train Epoch: 0, mini-batch 1050 of 25000, training loss: 1.219940\n",
      "Train Epoch: 0, mini-batch 1060 of 25000, training loss: 0.087877\n",
      "Train Epoch: 0, mini-batch 1070 of 25000, training loss: 0.780250\n",
      "Train Epoch: 0, mini-batch 1080 of 25000, training loss: 0.324158\n",
      "Train Epoch: 0, mini-batch 1090 of 25000, training loss: 0.065386\n",
      "Train Epoch: 0, mini-batch 1100 of 25000, training loss: 0.089931\n",
      "Train Epoch: 0, mini-batch 1110 of 25000, training loss: 0.037008\n",
      "Train Epoch: 0, mini-batch 1120 of 25000, training loss: 0.237214\n",
      "Train Epoch: 0, mini-batch 1130 of 25000, training loss: 0.232084\n",
      "Train Epoch: 0, mini-batch 1140 of 25000, training loss: 0.230642\n",
      "Train Epoch: 0, mini-batch 1150 of 25000, training loss: 0.118339\n",
      "Train Epoch: 0, mini-batch 1160 of 25000, training loss: 1.234322\n",
      "Train Epoch: 0, mini-batch 1170 of 25000, training loss: 0.471045\n",
      "Train Epoch: 0, mini-batch 1180 of 25000, training loss: 0.125652\n",
      "Train Epoch: 0, mini-batch 1190 of 25000, training loss: 0.062966\n",
      "Train Epoch: 0, mini-batch 1200 of 25000, training loss: 0.105575\n",
      "Train Epoch: 0, mini-batch 1210 of 25000, training loss: 0.658447\n",
      "Train Epoch: 0, mini-batch 1220 of 25000, training loss: 1.031681\n",
      "Train Epoch: 0, mini-batch 1230 of 25000, training loss: 0.108964\n",
      "Train Epoch: 0, mini-batch 1240 of 25000, training loss: 0.133814\n",
      "Train Epoch: 0, mini-batch 1250 of 25000, training loss: 0.211756\n",
      "Train Epoch: 0, mini-batch 1260 of 25000, training loss: 0.118803\n",
      "Train Epoch: 0, mini-batch 1270 of 25000, training loss: 0.031506\n",
      "Train Epoch: 0, mini-batch 1280 of 25000, training loss: 0.518305\n",
      "Train Epoch: 0, mini-batch 1290 of 25000, training loss: 0.082105\n",
      "Train Epoch: 0, mini-batch 1300 of 25000, training loss: 0.354748\n",
      "Train Epoch: 0, mini-batch 1310 of 25000, training loss: 0.406083\n",
      "Train Epoch: 0, mini-batch 1320 of 25000, training loss: 0.115361\n",
      "Train Epoch: 0, mini-batch 1330 of 25000, training loss: 0.541890\n",
      "Train Epoch: 0, mini-batch 1340 of 25000, training loss: 0.314678\n",
      "Train Epoch: 0, mini-batch 1350 of 25000, training loss: 0.317839\n",
      "Train Epoch: 0, mini-batch 1360 of 25000, training loss: 0.427830\n",
      "Train Epoch: 0, mini-batch 1370 of 25000, training loss: 0.747307\n",
      "Train Epoch: 0, mini-batch 1380 of 25000, training loss: 0.101525\n",
      "Train Epoch: 0, mini-batch 1390 of 25000, training loss: 0.139058\n",
      "Train Epoch: 0, mini-batch 1400 of 25000, training loss: 0.675882\n",
      "Train Epoch: 0, mini-batch 1410 of 25000, training loss: 0.353339\n",
      "Train Epoch: 0, mini-batch 1420 of 25000, training loss: 0.316376\n",
      "Train Epoch: 0, mini-batch 1430 of 25000, training loss: 0.079262\n",
      "Train Epoch: 0, mini-batch 1440 of 25000, training loss: 0.536520\n",
      "Train Epoch: 0, mini-batch 1450 of 25000, training loss: 0.108497\n",
      "Train Epoch: 0, mini-batch 1460 of 25000, training loss: 0.230377\n",
      "Train Epoch: 0, mini-batch 1470 of 25000, training loss: 0.040320\n",
      "Train Epoch: 0, mini-batch 1480 of 25000, training loss: 0.020326\n",
      "Train Epoch: 0, mini-batch 1490 of 25000, training loss: 0.133848\n",
      "Train Epoch: 0, mini-batch 1500 of 25000, training loss: 0.046253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 1510 of 25000, training loss: 0.072857\n",
      "Train Epoch: 0, mini-batch 1520 of 25000, training loss: 0.108400\n",
      "Train Epoch: 0, mini-batch 1530 of 25000, training loss: 0.207838\n",
      "Train Epoch: 0, mini-batch 1540 of 25000, training loss: 0.362455\n",
      "Train Epoch: 0, mini-batch 1550 of 25000, training loss: 0.268761\n",
      "Train Epoch: 0, mini-batch 1560 of 25000, training loss: 0.715087\n",
      "Train Epoch: 0, mini-batch 1570 of 25000, training loss: 1.614928\n",
      "Train Epoch: 0, mini-batch 1580 of 25000, training loss: 1.338564\n",
      "Train Epoch: 0, mini-batch 1590 of 25000, training loss: 0.396873\n",
      "Train Epoch: 0, mini-batch 1600 of 25000, training loss: 0.024909\n",
      "Train Epoch: 0, mini-batch 1610 of 25000, training loss: 0.099906\n",
      "Train Epoch: 0, mini-batch 1620 of 25000, training loss: 0.372154\n",
      "Train Epoch: 0, mini-batch 1630 of 25000, training loss: 0.033038\n",
      "Train Epoch: 0, mini-batch 1640 of 25000, training loss: 0.078775\n",
      "Train Epoch: 0, mini-batch 1650 of 25000, training loss: 0.682308\n",
      "Train Epoch: 0, mini-batch 1660 of 25000, training loss: 0.169311\n",
      "Train Epoch: 0, mini-batch 1670 of 25000, training loss: 0.065327\n",
      "Train Epoch: 0, mini-batch 1680 of 25000, training loss: 0.108054\n",
      "Train Epoch: 0, mini-batch 1690 of 25000, training loss: 0.080697\n",
      "Train Epoch: 0, mini-batch 1700 of 25000, training loss: 0.077117\n",
      "Train Epoch: 0, mini-batch 1710 of 25000, training loss: 0.648145\n",
      "Train Epoch: 0, mini-batch 1720 of 25000, training loss: 0.129812\n",
      "Train Epoch: 0, mini-batch 1730 of 25000, training loss: 0.562059\n",
      "Train Epoch: 0, mini-batch 1740 of 25000, training loss: 0.257722\n",
      "Train Epoch: 0, mini-batch 1750 of 25000, training loss: 0.067654\n",
      "Train Epoch: 0, mini-batch 1760 of 25000, training loss: 0.028142\n",
      "Train Epoch: 0, mini-batch 1770 of 25000, training loss: 0.603540\n",
      "Train Epoch: 0, mini-batch 1780 of 25000, training loss: 0.323011\n",
      "Train Epoch: 0, mini-batch 1790 of 25000, training loss: 0.063055\n",
      "Train Epoch: 0, mini-batch 1800 of 25000, training loss: 0.072875\n",
      "Train Epoch: 0, mini-batch 1810 of 25000, training loss: 0.172445\n",
      "Train Epoch: 0, mini-batch 1820 of 25000, training loss: 0.995925\n",
      "Train Epoch: 0, mini-batch 1830 of 25000, training loss: 0.057555\n",
      "Train Epoch: 0, mini-batch 1840 of 25000, training loss: 0.720096\n",
      "Train Epoch: 0, mini-batch 1850 of 25000, training loss: 1.342664\n",
      "Train Epoch: 0, mini-batch 1860 of 25000, training loss: 0.119154\n",
      "Train Epoch: 0, mini-batch 1870 of 25000, training loss: 0.596914\n",
      "Train Epoch: 0, mini-batch 1880 of 25000, training loss: 2.350554\n",
      "Train Epoch: 0, mini-batch 1890 of 25000, training loss: 0.389748\n",
      "Train Epoch: 0, mini-batch 1900 of 25000, training loss: 0.429812\n",
      "Train Epoch: 0, mini-batch 1910 of 25000, training loss: 0.195141\n",
      "Train Epoch: 0, mini-batch 1920 of 25000, training loss: 0.088091\n",
      "Train Epoch: 0, mini-batch 1930 of 25000, training loss: 0.063659\n",
      "Train Epoch: 0, mini-batch 1940 of 25000, training loss: 0.024484\n",
      "Train Epoch: 0, mini-batch 1950 of 25000, training loss: 0.466114\n",
      "Train Epoch: 0, mini-batch 1960 of 25000, training loss: 0.115403\n",
      "Train Epoch: 0, mini-batch 1970 of 25000, training loss: 0.074640\n",
      "Train Epoch: 0, mini-batch 1980 of 25000, training loss: 1.870918\n",
      "Train Epoch: 0, mini-batch 1990 of 25000, training loss: 0.142759\n",
      "Train Epoch: 0, mini-batch 2000 of 25000, training loss: 0.120185\n",
      "Train Epoch: 0, mini-batch 2010 of 25000, training loss: 0.050446\n",
      "Train Epoch: 0, mini-batch 2020 of 25000, training loss: 1.109695\n",
      "Train Epoch: 0, mini-batch 2030 of 25000, training loss: 0.024843\n",
      "Train Epoch: 0, mini-batch 2040 of 25000, training loss: 0.013143\n",
      "Train Epoch: 0, mini-batch 2050 of 25000, training loss: 0.336709\n",
      "Train Epoch: 0, mini-batch 2060 of 25000, training loss: 0.209501\n",
      "Train Epoch: 0, mini-batch 2070 of 25000, training loss: 0.006053\n",
      "Train Epoch: 0, mini-batch 2080 of 25000, training loss: 0.243529\n",
      "Train Epoch: 0, mini-batch 2090 of 25000, training loss: 0.130367\n",
      "Train Epoch: 0, mini-batch 2100 of 25000, training loss: 0.189277\n",
      "Train Epoch: 0, mini-batch 2110 of 25000, training loss: 0.059570\n",
      "Train Epoch: 0, mini-batch 2120 of 25000, training loss: 0.064146\n",
      "Train Epoch: 0, mini-batch 2130 of 25000, training loss: 0.929942\n",
      "Train Epoch: 0, mini-batch 2140 of 25000, training loss: 0.090562\n",
      "Train Epoch: 0, mini-batch 2150 of 25000, training loss: 0.019633\n",
      "Train Epoch: 0, mini-batch 2160 of 25000, training loss: 0.148032\n",
      "Train Epoch: 0, mini-batch 2170 of 25000, training loss: 0.157675\n",
      "Train Epoch: 0, mini-batch 2180 of 25000, training loss: 0.619928\n",
      "Train Epoch: 0, mini-batch 2190 of 25000, training loss: 2.836935\n",
      "Train Epoch: 0, mini-batch 2200 of 25000, training loss: 0.893410\n",
      "Train Epoch: 0, mini-batch 2210 of 25000, training loss: 0.070990\n",
      "Train Epoch: 0, mini-batch 2220 of 25000, training loss: 0.199094\n",
      "Train Epoch: 0, mini-batch 2230 of 25000, training loss: 0.504227\n",
      "Train Epoch: 0, mini-batch 2240 of 25000, training loss: 0.635023\n",
      "Train Epoch: 0, mini-batch 2250 of 25000, training loss: 0.027539\n",
      "Train Epoch: 0, mini-batch 2260 of 25000, training loss: 0.313714\n",
      "Train Epoch: 0, mini-batch 2270 of 25000, training loss: 1.019797\n",
      "Train Epoch: 0, mini-batch 2280 of 25000, training loss: 0.112223\n",
      "Train Epoch: 0, mini-batch 2290 of 25000, training loss: 1.419758\n",
      "Train Epoch: 0, mini-batch 2300 of 25000, training loss: 0.648272\n",
      "Train Epoch: 0, mini-batch 2310 of 25000, training loss: 0.714347\n",
      "Train Epoch: 0, mini-batch 2320 of 25000, training loss: 0.163021\n",
      "Train Epoch: 0, mini-batch 2330 of 25000, training loss: 0.263200\n",
      "Train Epoch: 0, mini-batch 2340 of 25000, training loss: 0.059098\n",
      "Train Epoch: 0, mini-batch 2350 of 25000, training loss: 2.026391\n",
      "Train Epoch: 0, mini-batch 2360 of 25000, training loss: 0.994500\n",
      "Train Epoch: 0, mini-batch 2370 of 25000, training loss: 1.401645\n",
      "Train Epoch: 0, mini-batch 2380 of 25000, training loss: 0.120610\n",
      "Train Epoch: 0, mini-batch 2390 of 25000, training loss: 0.482795\n",
      "Train Epoch: 0, mini-batch 2400 of 25000, training loss: 2.313738\n",
      "Train Epoch: 0, mini-batch 2410 of 25000, training loss: 1.141449\n",
      "Train Epoch: 0, mini-batch 2420 of 25000, training loss: 0.047923\n",
      "Train Epoch: 0, mini-batch 2430 of 25000, training loss: 1.042141\n",
      "Train Epoch: 0, mini-batch 2440 of 25000, training loss: 0.050186\n",
      "Train Epoch: 0, mini-batch 2450 of 25000, training loss: 0.173613\n",
      "Train Epoch: 0, mini-batch 2460 of 25000, training loss: 0.960021\n",
      "Train Epoch: 0, mini-batch 2470 of 25000, training loss: 1.099667\n",
      "Train Epoch: 0, mini-batch 2480 of 25000, training loss: 0.037671\n",
      "Train Epoch: 0, mini-batch 2490 of 25000, training loss: 0.293233\n",
      "Train Epoch: 0, mini-batch 2500 of 25000, training loss: 1.196378\n",
      "Train Epoch: 0, mini-batch 2510 of 25000, training loss: 2.299263\n",
      "Train Epoch: 0, mini-batch 2520 of 25000, training loss: 0.112843\n",
      "Train Epoch: 0, mini-batch 2530 of 25000, training loss: 0.376836\n",
      "Train Epoch: 0, mini-batch 2540 of 25000, training loss: 3.528849\n",
      "Train Epoch: 0, mini-batch 2550 of 25000, training loss: 0.318136\n",
      "Train Epoch: 0, mini-batch 2560 of 25000, training loss: 0.070673\n",
      "Train Epoch: 0, mini-batch 2570 of 25000, training loss: 0.639364\n",
      "Train Epoch: 0, mini-batch 2580 of 25000, training loss: 0.322046\n",
      "Train Epoch: 0, mini-batch 2590 of 25000, training loss: 1.351882\n",
      "Train Epoch: 0, mini-batch 2600 of 25000, training loss: 0.815424\n",
      "Train Epoch: 0, mini-batch 2610 of 25000, training loss: 0.589333\n",
      "Train Epoch: 0, mini-batch 2620 of 25000, training loss: 0.021477\n",
      "Train Epoch: 0, mini-batch 2630 of 25000, training loss: 0.215860\n",
      "Train Epoch: 0, mini-batch 2640 of 25000, training loss: 0.001698\n",
      "Train Epoch: 0, mini-batch 2650 of 25000, training loss: 1.392438\n",
      "Train Epoch: 0, mini-batch 2660 of 25000, training loss: 0.112757\n",
      "Train Epoch: 0, mini-batch 2670 of 25000, training loss: 0.225068\n",
      "Train Epoch: 0, mini-batch 2680 of 25000, training loss: 0.110020\n",
      "Train Epoch: 0, mini-batch 2690 of 25000, training loss: 1.286582\n",
      "Train Epoch: 0, mini-batch 2700 of 25000, training loss: 0.127058\n",
      "Train Epoch: 0, mini-batch 2710 of 25000, training loss: 0.428781\n",
      "Train Epoch: 0, mini-batch 2720 of 25000, training loss: 0.027992\n",
      "Train Epoch: 0, mini-batch 2730 of 25000, training loss: 0.481538\n",
      "Train Epoch: 0, mini-batch 2740 of 25000, training loss: 0.474072\n",
      "Train Epoch: 0, mini-batch 2750 of 25000, training loss: 0.095307\n",
      "Train Epoch: 0, mini-batch 2760 of 25000, training loss: 0.305082\n",
      "Train Epoch: 0, mini-batch 2770 of 25000, training loss: 0.501482\n",
      "Train Epoch: 0, mini-batch 2780 of 25000, training loss: 0.012331\n",
      "Train Epoch: 0, mini-batch 2790 of 25000, training loss: 0.227251\n",
      "Train Epoch: 0, mini-batch 2800 of 25000, training loss: 0.161090\n",
      "Train Epoch: 0, mini-batch 2810 of 25000, training loss: 0.266455\n",
      "Train Epoch: 0, mini-batch 2820 of 25000, training loss: 1.214456\n",
      "Train Epoch: 0, mini-batch 2830 of 25000, training loss: 0.085027\n",
      "Train Epoch: 0, mini-batch 2840 of 25000, training loss: 0.047932\n",
      "Train Epoch: 0, mini-batch 2850 of 25000, training loss: 0.155219\n",
      "Train Epoch: 0, mini-batch 2860 of 25000, training loss: 0.135900\n",
      "Train Epoch: 0, mini-batch 2870 of 25000, training loss: 0.122332\n",
      "Train Epoch: 0, mini-batch 2880 of 25000, training loss: 0.189603\n",
      "Train Epoch: 0, mini-batch 2890 of 25000, training loss: 0.016460\n",
      "Train Epoch: 0, mini-batch 2900 of 25000, training loss: 0.293812\n",
      "Train Epoch: 0, mini-batch 2910 of 25000, training loss: 0.065176\n",
      "Train Epoch: 0, mini-batch 2920 of 25000, training loss: 0.042253\n",
      "Train Epoch: 0, mini-batch 2930 of 25000, training loss: 1.618183\n",
      "Train Epoch: 0, mini-batch 2940 of 25000, training loss: 0.335122\n",
      "Train Epoch: 0, mini-batch 2950 of 25000, training loss: 0.043433\n",
      "Train Epoch: 0, mini-batch 2960 of 25000, training loss: 0.080943\n",
      "Train Epoch: 0, mini-batch 2970 of 25000, training loss: 0.044244\n",
      "Train Epoch: 0, mini-batch 2980 of 25000, training loss: 1.414860\n",
      "Train Epoch: 0, mini-batch 2990 of 25000, training loss: 0.879271\n",
      "Train Epoch: 0, mini-batch 3000 of 25000, training loss: 0.824246\n",
      "Train Epoch: 0, mini-batch 3010 of 25000, training loss: 0.151091\n",
      "Train Epoch: 0, mini-batch 3020 of 25000, training loss: 0.068375\n",
      "Train Epoch: 0, mini-batch 3030 of 25000, training loss: 0.038103\n",
      "Train Epoch: 0, mini-batch 3040 of 25000, training loss: 0.165636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 3050 of 25000, training loss: 0.356812\n",
      "Train Epoch: 0, mini-batch 3060 of 25000, training loss: 0.044164\n",
      "Train Epoch: 0, mini-batch 3070 of 25000, training loss: 0.388022\n",
      "Train Epoch: 0, mini-batch 3080 of 25000, training loss: 0.037784\n",
      "Train Epoch: 0, mini-batch 3090 of 25000, training loss: 0.050311\n",
      "Train Epoch: 0, mini-batch 3100 of 25000, training loss: 1.693717\n",
      "Train Epoch: 0, mini-batch 3110 of 25000, training loss: 0.216080\n",
      "Train Epoch: 0, mini-batch 3120 of 25000, training loss: 0.026501\n",
      "Train Epoch: 0, mini-batch 3130 of 25000, training loss: 0.306336\n",
      "Train Epoch: 0, mini-batch 3140 of 25000, training loss: 0.096358\n",
      "Train Epoch: 0, mini-batch 3150 of 25000, training loss: 0.018375\n",
      "Train Epoch: 0, mini-batch 3160 of 25000, training loss: 1.069773\n",
      "Train Epoch: 0, mini-batch 3170 of 25000, training loss: 0.424782\n",
      "Train Epoch: 0, mini-batch 3180 of 25000, training loss: 0.084638\n",
      "Train Epoch: 0, mini-batch 3190 of 25000, training loss: 0.513798\n",
      "Train Epoch: 0, mini-batch 3200 of 25000, training loss: 0.131450\n",
      "Train Epoch: 0, mini-batch 3210 of 25000, training loss: 0.034627\n",
      "Train Epoch: 0, mini-batch 3220 of 25000, training loss: 0.127357\n",
      "Train Epoch: 0, mini-batch 3230 of 25000, training loss: 1.280641\n",
      "Train Epoch: 0, mini-batch 3240 of 25000, training loss: 0.031167\n",
      "Train Epoch: 0, mini-batch 3250 of 25000, training loss: 0.070408\n",
      "Train Epoch: 0, mini-batch 3260 of 25000, training loss: 0.425971\n",
      "Train Epoch: 0, mini-batch 3270 of 25000, training loss: 0.011156\n",
      "Train Epoch: 0, mini-batch 3280 of 25000, training loss: 0.165736\n",
      "Train Epoch: 0, mini-batch 3290 of 25000, training loss: 0.113120\n",
      "Train Epoch: 0, mini-batch 3300 of 25000, training loss: 1.088591\n",
      "Train Epoch: 0, mini-batch 3310 of 25000, training loss: 0.093199\n",
      "Train Epoch: 0, mini-batch 3320 of 25000, training loss: 0.008985\n",
      "Train Epoch: 0, mini-batch 3330 of 25000, training loss: 0.043715\n",
      "Train Epoch: 0, mini-batch 3340 of 25000, training loss: 0.083095\n",
      "Train Epoch: 0, mini-batch 3350 of 25000, training loss: 0.015516\n",
      "Train Epoch: 0, mini-batch 3360 of 25000, training loss: 0.002276\n",
      "Train Epoch: 0, mini-batch 3370 of 25000, training loss: 0.081543\n",
      "Train Epoch: 0, mini-batch 3380 of 25000, training loss: 0.177845\n",
      "Train Epoch: 0, mini-batch 3390 of 25000, training loss: 0.186973\n",
      "Train Epoch: 0, mini-batch 3400 of 25000, training loss: 0.247138\n",
      "Train Epoch: 0, mini-batch 3410 of 25000, training loss: 0.166930\n",
      "Train Epoch: 0, mini-batch 3420 of 25000, training loss: 0.157625\n",
      "Train Epoch: 0, mini-batch 3430 of 25000, training loss: 0.019932\n",
      "Train Epoch: 0, mini-batch 3440 of 25000, training loss: 0.079578\n",
      "Train Epoch: 0, mini-batch 3450 of 25000, training loss: 0.056061\n",
      "Train Epoch: 0, mini-batch 3460 of 25000, training loss: 2.743904\n",
      "Train Epoch: 0, mini-batch 3470 of 25000, training loss: 0.039371\n",
      "Train Epoch: 0, mini-batch 3480 of 25000, training loss: 0.059144\n",
      "Train Epoch: 0, mini-batch 3490 of 25000, training loss: 0.074053\n",
      "Train Epoch: 0, mini-batch 3500 of 25000, training loss: 0.693439\n",
      "Train Epoch: 0, mini-batch 3510 of 25000, training loss: 0.546296\n",
      "Train Epoch: 0, mini-batch 3520 of 25000, training loss: 1.696913\n",
      "Train Epoch: 0, mini-batch 3530 of 25000, training loss: 0.692011\n",
      "Train Epoch: 0, mini-batch 3540 of 25000, training loss: 0.084590\n",
      "Train Epoch: 0, mini-batch 3550 of 25000, training loss: 0.011355\n",
      "Train Epoch: 0, mini-batch 3560 of 25000, training loss: 0.027221\n",
      "Train Epoch: 0, mini-batch 3570 of 25000, training loss: 1.576903\n",
      "Train Epoch: 0, mini-batch 3580 of 25000, training loss: 0.544704\n",
      "Train Epoch: 0, mini-batch 3590 of 25000, training loss: 0.222208\n",
      "Train Epoch: 0, mini-batch 3600 of 25000, training loss: 0.086205\n",
      "Train Epoch: 0, mini-batch 3610 of 25000, training loss: 0.653684\n",
      "Train Epoch: 0, mini-batch 3620 of 25000, training loss: 0.059433\n",
      "Train Epoch: 0, mini-batch 3630 of 25000, training loss: 0.044389\n",
      "Train Epoch: 0, mini-batch 3640 of 25000, training loss: 0.990392\n",
      "Train Epoch: 0, mini-batch 3650 of 25000, training loss: 4.682056\n",
      "Train Epoch: 0, mini-batch 3660 of 25000, training loss: 0.064656\n",
      "Train Epoch: 0, mini-batch 3670 of 25000, training loss: 0.029748\n",
      "Train Epoch: 0, mini-batch 3680 of 25000, training loss: 0.142645\n",
      "Train Epoch: 0, mini-batch 3690 of 25000, training loss: 1.261743\n",
      "Train Epoch: 0, mini-batch 3700 of 25000, training loss: 4.121974\n",
      "Train Epoch: 0, mini-batch 3710 of 25000, training loss: 0.310868\n",
      "Train Epoch: 0, mini-batch 3720 of 25000, training loss: 0.070937\n",
      "Train Epoch: 0, mini-batch 3730 of 25000, training loss: 0.073559\n",
      "Train Epoch: 0, mini-batch 3740 of 25000, training loss: 1.131834\n",
      "Train Epoch: 0, mini-batch 3750 of 25000, training loss: 1.781628\n",
      "Train Epoch: 0, mini-batch 3760 of 25000, training loss: 0.021435\n",
      "Train Epoch: 0, mini-batch 3770 of 25000, training loss: 0.113767\n",
      "Train Epoch: 0, mini-batch 3780 of 25000, training loss: 0.123100\n",
      "Train Epoch: 0, mini-batch 3790 of 25000, training loss: 1.856894\n",
      "Train Epoch: 0, mini-batch 3800 of 25000, training loss: 0.842492\n",
      "Train Epoch: 0, mini-batch 3810 of 25000, training loss: 0.105158\n",
      "Train Epoch: 0, mini-batch 3820 of 25000, training loss: 0.267428\n",
      "Train Epoch: 0, mini-batch 3830 of 25000, training loss: 0.056046\n",
      "Train Epoch: 0, mini-batch 3840 of 25000, training loss: 0.998295\n",
      "Train Epoch: 0, mini-batch 3850 of 25000, training loss: 0.152862\n",
      "Train Epoch: 0, mini-batch 3860 of 25000, training loss: 0.533417\n",
      "Train Epoch: 0, mini-batch 3870 of 25000, training loss: 0.849962\n",
      "Train Epoch: 0, mini-batch 3880 of 25000, training loss: 0.017294\n",
      "Train Epoch: 0, mini-batch 3890 of 25000, training loss: 0.211773\n",
      "Train Epoch: 0, mini-batch 3900 of 25000, training loss: 0.028817\n",
      "Train Epoch: 0, mini-batch 3910 of 25000, training loss: 1.256891\n",
      "Train Epoch: 0, mini-batch 3920 of 25000, training loss: 0.164452\n",
      "Train Epoch: 0, mini-batch 3930 of 25000, training loss: 1.015398\n",
      "Train Epoch: 0, mini-batch 3940 of 25000, training loss: 0.055796\n",
      "Train Epoch: 0, mini-batch 3950 of 25000, training loss: 0.518019\n",
      "Train Epoch: 0, mini-batch 3960 of 25000, training loss: 0.061057\n",
      "Train Epoch: 0, mini-batch 3970 of 25000, training loss: 0.033471\n",
      "Train Epoch: 0, mini-batch 3980 of 25000, training loss: 0.044926\n",
      "Train Epoch: 0, mini-batch 3990 of 25000, training loss: 1.632264\n",
      "Train Epoch: 0, mini-batch 4000 of 25000, training loss: 0.779952\n",
      "Train Epoch: 0, mini-batch 4010 of 25000, training loss: 0.913176\n",
      "Train Epoch: 0, mini-batch 4020 of 25000, training loss: 0.281145\n",
      "Train Epoch: 0, mini-batch 4030 of 25000, training loss: 0.020145\n",
      "Train Epoch: 0, mini-batch 4040 of 25000, training loss: 0.080111\n",
      "Train Epoch: 0, mini-batch 4050 of 25000, training loss: 0.026421\n",
      "Train Epoch: 0, mini-batch 4060 of 25000, training loss: 0.495535\n",
      "Train Epoch: 0, mini-batch 4070 of 25000, training loss: 0.449798\n",
      "Train Epoch: 0, mini-batch 4080 of 25000, training loss: 0.064851\n",
      "Train Epoch: 0, mini-batch 4090 of 25000, training loss: 2.015389\n",
      "Train Epoch: 0, mini-batch 4100 of 25000, training loss: 0.152125\n",
      "Train Epoch: 0, mini-batch 4110 of 25000, training loss: 1.235784\n",
      "Train Epoch: 0, mini-batch 4120 of 25000, training loss: 0.117220\n",
      "Train Epoch: 0, mini-batch 4130 of 25000, training loss: 0.396083\n",
      "Train Epoch: 0, mini-batch 4140 of 25000, training loss: 0.038640\n",
      "Train Epoch: 0, mini-batch 4150 of 25000, training loss: 0.089953\n",
      "Train Epoch: 0, mini-batch 4160 of 25000, training loss: 0.032665\n",
      "Train Epoch: 0, mini-batch 4170 of 25000, training loss: 0.534000\n",
      "Train Epoch: 0, mini-batch 4180 of 25000, training loss: 0.020469\n",
      "Train Epoch: 0, mini-batch 4190 of 25000, training loss: 1.037612\n",
      "Train Epoch: 0, mini-batch 4200 of 25000, training loss: 0.075671\n",
      "Train Epoch: 0, mini-batch 4210 of 25000, training loss: 0.002468\n",
      "Train Epoch: 0, mini-batch 4220 of 25000, training loss: 0.187885\n",
      "Train Epoch: 0, mini-batch 4230 of 25000, training loss: 0.333535\n",
      "Train Epoch: 0, mini-batch 4240 of 25000, training loss: 0.281830\n",
      "Train Epoch: 0, mini-batch 4250 of 25000, training loss: 0.118940\n",
      "Train Epoch: 0, mini-batch 4260 of 25000, training loss: 0.054642\n",
      "Train Epoch: 0, mini-batch 4270 of 25000, training loss: 0.567127\n",
      "Train Epoch: 0, mini-batch 4280 of 25000, training loss: 0.080903\n",
      "Train Epoch: 0, mini-batch 4290 of 25000, training loss: 0.173481\n",
      "Train Epoch: 0, mini-batch 4300 of 25000, training loss: 0.076883\n",
      "Train Epoch: 0, mini-batch 4310 of 25000, training loss: 0.137941\n",
      "Train Epoch: 0, mini-batch 4320 of 25000, training loss: 0.011590\n",
      "Train Epoch: 0, mini-batch 4330 of 25000, training loss: 0.778501\n",
      "Train Epoch: 0, mini-batch 4340 of 25000, training loss: 2.005795\n",
      "Train Epoch: 0, mini-batch 4350 of 25000, training loss: 0.042909\n",
      "Train Epoch: 0, mini-batch 4360 of 25000, training loss: 0.059626\n",
      "Train Epoch: 0, mini-batch 4370 of 25000, training loss: 0.761391\n",
      "Train Epoch: 0, mini-batch 4380 of 25000, training loss: 0.667254\n",
      "Train Epoch: 0, mini-batch 4390 of 25000, training loss: 0.219897\n",
      "Train Epoch: 0, mini-batch 4400 of 25000, training loss: 0.441094\n",
      "Train Epoch: 0, mini-batch 4410 of 25000, training loss: 0.035839\n",
      "Train Epoch: 0, mini-batch 4420 of 25000, training loss: 0.013417\n",
      "Train Epoch: 0, mini-batch 4430 of 25000, training loss: 0.001200\n",
      "Train Epoch: 0, mini-batch 4440 of 25000, training loss: 0.122574\n",
      "Train Epoch: 0, mini-batch 4450 of 25000, training loss: 0.004291\n",
      "Train Epoch: 0, mini-batch 4460 of 25000, training loss: 1.231612\n",
      "Train Epoch: 0, mini-batch 4470 of 25000, training loss: 0.007682\n",
      "Train Epoch: 0, mini-batch 4480 of 25000, training loss: 0.350403\n",
      "Train Epoch: 0, mini-batch 4490 of 25000, training loss: 0.016045\n",
      "Train Epoch: 0, mini-batch 4500 of 25000, training loss: 0.002914\n",
      "Train Epoch: 0, mini-batch 4510 of 25000, training loss: 0.433706\n",
      "Train Epoch: 0, mini-batch 4520 of 25000, training loss: 0.219036\n",
      "Train Epoch: 0, mini-batch 4530 of 25000, training loss: 0.131626\n",
      "Train Epoch: 0, mini-batch 4540 of 25000, training loss: 3.608984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 4550 of 25000, training loss: 1.632124\n",
      "Train Epoch: 0, mini-batch 4560 of 25000, training loss: 0.137966\n",
      "Train Epoch: 0, mini-batch 4570 of 25000, training loss: 0.108778\n",
      "Train Epoch: 0, mini-batch 4580 of 25000, training loss: 0.541218\n",
      "Train Epoch: 0, mini-batch 4590 of 25000, training loss: 0.527060\n",
      "Train Epoch: 0, mini-batch 4600 of 25000, training loss: 0.017891\n",
      "Train Epoch: 0, mini-batch 4610 of 25000, training loss: 0.006248\n",
      "Train Epoch: 0, mini-batch 4620 of 25000, training loss: 0.056907\n",
      "Train Epoch: 0, mini-batch 4630 of 25000, training loss: 0.262572\n",
      "Train Epoch: 0, mini-batch 4640 of 25000, training loss: 0.962585\n",
      "Train Epoch: 0, mini-batch 4650 of 25000, training loss: 0.288561\n",
      "Train Epoch: 0, mini-batch 4660 of 25000, training loss: 0.045156\n",
      "Train Epoch: 0, mini-batch 4670 of 25000, training loss: 0.089328\n",
      "Train Epoch: 0, mini-batch 4680 of 25000, training loss: 0.297483\n",
      "Train Epoch: 0, mini-batch 4690 of 25000, training loss: 0.159139\n",
      "Train Epoch: 0, mini-batch 4700 of 25000, training loss: 0.065966\n",
      "Train Epoch: 0, mini-batch 4710 of 25000, training loss: 0.575690\n",
      "Train Epoch: 0, mini-batch 4720 of 25000, training loss: 0.385073\n",
      "Train Epoch: 0, mini-batch 4730 of 25000, training loss: 1.852003\n",
      "Train Epoch: 0, mini-batch 4740 of 25000, training loss: 0.084932\n",
      "Train Epoch: 0, mini-batch 4750 of 25000, training loss: 0.185453\n",
      "Train Epoch: 0, mini-batch 4760 of 25000, training loss: 0.009975\n",
      "Train Epoch: 0, mini-batch 4770 of 25000, training loss: 0.044570\n",
      "Train Epoch: 0, mini-batch 4780 of 25000, training loss: 0.188384\n",
      "Train Epoch: 0, mini-batch 4790 of 25000, training loss: 2.476158\n",
      "Train Epoch: 0, mini-batch 4800 of 25000, training loss: 0.193194\n",
      "Train Epoch: 0, mini-batch 4810 of 25000, training loss: 0.086821\n",
      "Train Epoch: 0, mini-batch 4820 of 25000, training loss: 0.202115\n",
      "Train Epoch: 0, mini-batch 4830 of 25000, training loss: 0.709442\n",
      "Train Epoch: 0, mini-batch 4840 of 25000, training loss: 0.314588\n",
      "Train Epoch: 0, mini-batch 4850 of 25000, training loss: 0.032546\n",
      "Train Epoch: 0, mini-batch 4860 of 25000, training loss: 0.137353\n",
      "Train Epoch: 0, mini-batch 4870 of 25000, training loss: 0.421625\n",
      "Train Epoch: 0, mini-batch 4880 of 25000, training loss: 0.627751\n",
      "Train Epoch: 0, mini-batch 4890 of 25000, training loss: 0.347919\n",
      "Train Epoch: 0, mini-batch 4900 of 25000, training loss: 0.102542\n",
      "Train Epoch: 0, mini-batch 4910 of 25000, training loss: 0.912577\n",
      "Train Epoch: 0, mini-batch 4920 of 25000, training loss: 0.016047\n",
      "Train Epoch: 0, mini-batch 4930 of 25000, training loss: 0.052432\n",
      "Train Epoch: 0, mini-batch 4940 of 25000, training loss: 0.527287\n",
      "Train Epoch: 0, mini-batch 4950 of 25000, training loss: 2.593853\n",
      "Train Epoch: 0, mini-batch 4960 of 25000, training loss: 0.107647\n",
      "Train Epoch: 0, mini-batch 4970 of 25000, training loss: 0.268560\n",
      "Train Epoch: 0, mini-batch 4980 of 25000, training loss: 0.034515\n",
      "Train Epoch: 0, mini-batch 4990 of 25000, training loss: 1.450768\n",
      "Train Epoch: 0, mini-batch 5000 of 25000, training loss: 0.084566\n",
      "Train Epoch: 0, mini-batch 5010 of 25000, training loss: 0.324333\n",
      "Train Epoch: 0, mini-batch 5020 of 25000, training loss: 0.010674\n",
      "Train Epoch: 0, mini-batch 5030 of 25000, training loss: 0.709746\n",
      "Train Epoch: 0, mini-batch 5040 of 25000, training loss: 0.003625\n",
      "Train Epoch: 0, mini-batch 5050 of 25000, training loss: 0.086817\n",
      "Train Epoch: 0, mini-batch 5060 of 25000, training loss: 0.009072\n",
      "Train Epoch: 0, mini-batch 5070 of 25000, training loss: 0.124546\n",
      "Train Epoch: 0, mini-batch 5080 of 25000, training loss: 0.021524\n",
      "Train Epoch: 0, mini-batch 5090 of 25000, training loss: 0.025689\n",
      "Train Epoch: 0, mini-batch 5100 of 25000, training loss: 1.114245\n",
      "Train Epoch: 0, mini-batch 5110 of 25000, training loss: 1.751355\n",
      "Train Epoch: 0, mini-batch 5120 of 25000, training loss: 0.073991\n",
      "Train Epoch: 0, mini-batch 5130 of 25000, training loss: 0.173695\n",
      "Train Epoch: 0, mini-batch 5140 of 25000, training loss: 0.256256\n",
      "Train Epoch: 0, mini-batch 5150 of 25000, training loss: 0.047599\n",
      "Train Epoch: 0, mini-batch 5160 of 25000, training loss: 0.026245\n",
      "Train Epoch: 0, mini-batch 5170 of 25000, training loss: 0.824153\n",
      "Train Epoch: 0, mini-batch 5180 of 25000, training loss: 0.046516\n",
      "Train Epoch: 0, mini-batch 5190 of 25000, training loss: 0.081434\n",
      "Train Epoch: 0, mini-batch 5200 of 25000, training loss: 0.622780\n",
      "Train Epoch: 0, mini-batch 5210 of 25000, training loss: 0.747359\n",
      "Train Epoch: 0, mini-batch 5220 of 25000, training loss: 0.332595\n",
      "Train Epoch: 0, mini-batch 5230 of 25000, training loss: 0.005824\n",
      "Train Epoch: 0, mini-batch 5240 of 25000, training loss: 0.074444\n",
      "Train Epoch: 0, mini-batch 5250 of 25000, training loss: 0.332551\n",
      "Train Epoch: 0, mini-batch 5260 of 25000, training loss: 0.052259\n",
      "Train Epoch: 0, mini-batch 5270 of 25000, training loss: 0.343618\n",
      "Train Epoch: 0, mini-batch 5280 of 25000, training loss: 0.034973\n",
      "Train Epoch: 0, mini-batch 5290 of 25000, training loss: 0.130208\n",
      "Train Epoch: 0, mini-batch 5300 of 25000, training loss: 0.153283\n",
      "Train Epoch: 0, mini-batch 5310 of 25000, training loss: 0.009444\n",
      "Train Epoch: 0, mini-batch 5320 of 25000, training loss: 0.003212\n",
      "Train Epoch: 0, mini-batch 5330 of 25000, training loss: 0.038517\n",
      "Train Epoch: 0, mini-batch 5340 of 25000, training loss: 1.728859\n",
      "Train Epoch: 0, mini-batch 5350 of 25000, training loss: 0.690896\n",
      "Train Epoch: 0, mini-batch 5360 of 25000, training loss: 0.710069\n",
      "Train Epoch: 0, mini-batch 5370 of 25000, training loss: 0.099759\n",
      "Train Epoch: 0, mini-batch 5380 of 25000, training loss: 0.015823\n",
      "Train Epoch: 0, mini-batch 5390 of 25000, training loss: 0.047126\n",
      "Train Epoch: 0, mini-batch 5400 of 25000, training loss: 0.252165\n",
      "Train Epoch: 0, mini-batch 5410 of 25000, training loss: 0.108222\n",
      "Train Epoch: 0, mini-batch 5420 of 25000, training loss: 1.449661\n",
      "Train Epoch: 0, mini-batch 5430 of 25000, training loss: 0.061764\n",
      "Train Epoch: 0, mini-batch 5440 of 25000, training loss: 0.132318\n",
      "Train Epoch: 0, mini-batch 5450 of 25000, training loss: 0.223201\n",
      "Train Epoch: 0, mini-batch 5460 of 25000, training loss: 2.035474\n",
      "Train Epoch: 0, mini-batch 5470 of 25000, training loss: 0.439888\n",
      "Train Epoch: 0, mini-batch 5480 of 25000, training loss: 0.023401\n",
      "Train Epoch: 0, mini-batch 5490 of 25000, training loss: 0.042508\n",
      "Train Epoch: 0, mini-batch 5500 of 25000, training loss: 0.034831\n",
      "Train Epoch: 0, mini-batch 5510 of 25000, training loss: 0.037677\n",
      "Train Epoch: 0, mini-batch 5520 of 25000, training loss: 0.088420\n",
      "Train Epoch: 0, mini-batch 5530 of 25000, training loss: 0.105967\n",
      "Train Epoch: 0, mini-batch 5540 of 25000, training loss: 0.008217\n",
      "Train Epoch: 0, mini-batch 5550 of 25000, training loss: 0.087219\n",
      "Train Epoch: 0, mini-batch 5560 of 25000, training loss: 0.117924\n",
      "Train Epoch: 0, mini-batch 5570 of 25000, training loss: 0.629199\n",
      "Train Epoch: 0, mini-batch 5580 of 25000, training loss: 0.038249\n",
      "Train Epoch: 0, mini-batch 5590 of 25000, training loss: 0.071932\n",
      "Train Epoch: 0, mini-batch 5600 of 25000, training loss: 0.165820\n",
      "Train Epoch: 0, mini-batch 5610 of 25000, training loss: 1.377912\n",
      "Train Epoch: 0, mini-batch 5620 of 25000, training loss: 0.130575\n",
      "Train Epoch: 0, mini-batch 5630 of 25000, training loss: 0.071579\n",
      "Train Epoch: 0, mini-batch 5640 of 25000, training loss: 0.016792\n",
      "Train Epoch: 0, mini-batch 5650 of 25000, training loss: 0.046293\n",
      "Train Epoch: 0, mini-batch 5660 of 25000, training loss: 0.023305\n",
      "Train Epoch: 0, mini-batch 5670 of 25000, training loss: 0.072396\n",
      "Train Epoch: 0, mini-batch 5680 of 25000, training loss: 0.156144\n",
      "Train Epoch: 0, mini-batch 5690 of 25000, training loss: 0.355862\n",
      "Train Epoch: 0, mini-batch 5700 of 25000, training loss: 0.117553\n",
      "Train Epoch: 0, mini-batch 5710 of 25000, training loss: 0.658853\n",
      "Train Epoch: 0, mini-batch 5720 of 25000, training loss: 0.114205\n",
      "Train Epoch: 0, mini-batch 5730 of 25000, training loss: 0.050862\n",
      "Train Epoch: 0, mini-batch 5740 of 25000, training loss: 0.118885\n",
      "Train Epoch: 0, mini-batch 5750 of 25000, training loss: 0.036077\n",
      "Train Epoch: 0, mini-batch 5760 of 25000, training loss: 0.017079\n",
      "Train Epoch: 0, mini-batch 5770 of 25000, training loss: 0.070143\n",
      "Train Epoch: 0, mini-batch 5780 of 25000, training loss: 0.034580\n",
      "Train Epoch: 0, mini-batch 5790 of 25000, training loss: 0.181172\n",
      "Train Epoch: 0, mini-batch 5800 of 25000, training loss: 0.040526\n",
      "Train Epoch: 0, mini-batch 5810 of 25000, training loss: 0.038461\n",
      "Train Epoch: 0, mini-batch 5820 of 25000, training loss: 0.240293\n",
      "Train Epoch: 0, mini-batch 5830 of 25000, training loss: 0.149036\n",
      "Train Epoch: 0, mini-batch 5840 of 25000, training loss: 0.094835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 5850 of 25000, training loss: 0.271334\n",
      "Train Epoch: 0, mini-batch 5860 of 25000, training loss: 0.320831\n",
      "Train Epoch: 0, mini-batch 5870 of 25000, training loss: 0.517711\n",
      "Train Epoch: 0, mini-batch 5880 of 25000, training loss: 0.570382\n",
      "Train Epoch: 0, mini-batch 5890 of 25000, training loss: 0.024826\n",
      "Train Epoch: 0, mini-batch 5900 of 25000, training loss: 0.016204\n",
      "Train Epoch: 0, mini-batch 5910 of 25000, training loss: 0.212834\n",
      "Train Epoch: 0, mini-batch 5920 of 25000, training loss: 0.058024\n",
      "Train Epoch: 0, mini-batch 5930 of 25000, training loss: 0.157301\n",
      "Train Epoch: 0, mini-batch 5940 of 25000, training loss: 1.177568\n",
      "Train Epoch: 0, mini-batch 5950 of 25000, training loss: 0.001837\n",
      "Train Epoch: 0, mini-batch 5960 of 25000, training loss: 1.190034\n",
      "Train Epoch: 0, mini-batch 5970 of 25000, training loss: 0.060796\n",
      "Train Epoch: 0, mini-batch 5980 of 25000, training loss: 0.038264\n",
      "Train Epoch: 0, mini-batch 5990 of 25000, training loss: 0.116352\n",
      "Train Epoch: 0, mini-batch 6000 of 25000, training loss: 0.025138\n",
      "Train Epoch: 0, mini-batch 6010 of 25000, training loss: 0.185640\n",
      "Train Epoch: 0, mini-batch 6020 of 25000, training loss: 0.247601\n",
      "Train Epoch: 0, mini-batch 6030 of 25000, training loss: 3.601956\n",
      "Train Epoch: 0, mini-batch 6040 of 25000, training loss: 0.214564\n",
      "Train Epoch: 0, mini-batch 6050 of 25000, training loss: 1.204884\n",
      "Train Epoch: 0, mini-batch 6060 of 25000, training loss: 0.024105\n",
      "Train Epoch: 0, mini-batch 6070 of 25000, training loss: 0.217372\n",
      "Train Epoch: 0, mini-batch 6080 of 25000, training loss: 0.687304\n",
      "Train Epoch: 0, mini-batch 6090 of 25000, training loss: 0.379960\n",
      "Train Epoch: 0, mini-batch 6100 of 25000, training loss: 0.124226\n",
      "Train Epoch: 0, mini-batch 6110 of 25000, training loss: 0.040901\n",
      "Train Epoch: 0, mini-batch 6120 of 25000, training loss: 0.066198\n",
      "Train Epoch: 0, mini-batch 6130 of 25000, training loss: 0.058676\n",
      "Train Epoch: 0, mini-batch 6140 of 25000, training loss: 0.039872\n",
      "Train Epoch: 0, mini-batch 6150 of 25000, training loss: 1.643468\n",
      "Train Epoch: 0, mini-batch 6160 of 25000, training loss: 0.874194\n",
      "Train Epoch: 0, mini-batch 6170 of 25000, training loss: 0.064372\n",
      "Train Epoch: 0, mini-batch 6180 of 25000, training loss: 0.272573\n",
      "Train Epoch: 0, mini-batch 6190 of 25000, training loss: 0.046076\n",
      "Train Epoch: 0, mini-batch 6200 of 25000, training loss: 0.031868\n",
      "Train Epoch: 0, mini-batch 6210 of 25000, training loss: 0.072675\n",
      "Train Epoch: 0, mini-batch 6220 of 25000, training loss: 0.055663\n",
      "Train Epoch: 0, mini-batch 6230 of 25000, training loss: 0.034958\n",
      "Train Epoch: 0, mini-batch 6240 of 25000, training loss: 0.055500\n",
      "Train Epoch: 0, mini-batch 6250 of 25000, training loss: 0.900410\n",
      "Train Epoch: 0, mini-batch 6260 of 25000, training loss: 0.028341\n",
      "Train Epoch: 0, mini-batch 6270 of 25000, training loss: 0.103508\n",
      "Train Epoch: 0, mini-batch 6280 of 25000, training loss: 0.058671\n",
      "Train Epoch: 0, mini-batch 6290 of 25000, training loss: 0.051067\n",
      "Train Epoch: 0, mini-batch 6300 of 25000, training loss: 0.211518\n",
      "Train Epoch: 0, mini-batch 6310 of 25000, training loss: 0.022315\n",
      "Train Epoch: 0, mini-batch 6320 of 25000, training loss: 0.104457\n",
      "Train Epoch: 0, mini-batch 6330 of 25000, training loss: 0.733069\n",
      "Train Epoch: 0, mini-batch 6340 of 25000, training loss: 0.053589\n",
      "Train Epoch: 0, mini-batch 6350 of 25000, training loss: 0.116210\n",
      "Train Epoch: 0, mini-batch 6360 of 25000, training loss: 0.096921\n",
      "Train Epoch: 0, mini-batch 6370 of 25000, training loss: 0.128853\n",
      "Train Epoch: 0, mini-batch 6380 of 25000, training loss: 0.083749\n",
      "Train Epoch: 0, mini-batch 6390 of 25000, training loss: 2.126110\n",
      "Train Epoch: 0, mini-batch 6400 of 25000, training loss: 0.008870\n",
      "Train Epoch: 0, mini-batch 6410 of 25000, training loss: 0.325253\n",
      "Train Epoch: 0, mini-batch 6420 of 25000, training loss: 0.123245\n",
      "Train Epoch: 0, mini-batch 6430 of 25000, training loss: 0.007315\n",
      "Train Epoch: 0, mini-batch 6440 of 25000, training loss: 0.011261\n",
      "Train Epoch: 0, mini-batch 6450 of 25000, training loss: 0.009294\n",
      "Train Epoch: 0, mini-batch 6460 of 25000, training loss: 0.243748\n",
      "Train Epoch: 0, mini-batch 6470 of 25000, training loss: 0.164665\n",
      "Train Epoch: 0, mini-batch 6480 of 25000, training loss: 1.323652\n",
      "Train Epoch: 0, mini-batch 6490 of 25000, training loss: 0.014147\n",
      "Train Epoch: 0, mini-batch 6500 of 25000, training loss: 0.007727\n",
      "Train Epoch: 0, mini-batch 6510 of 25000, training loss: 0.613688\n",
      "Train Epoch: 0, mini-batch 6520 of 25000, training loss: 0.659453\n",
      "Train Epoch: 0, mini-batch 6530 of 25000, training loss: 0.008915\n",
      "Train Epoch: 0, mini-batch 6540 of 25000, training loss: 0.350695\n",
      "Train Epoch: 0, mini-batch 6550 of 25000, training loss: 0.386326\n",
      "Train Epoch: 0, mini-batch 6560 of 25000, training loss: 0.014221\n",
      "Train Epoch: 0, mini-batch 6570 of 25000, training loss: 0.690700\n",
      "Train Epoch: 0, mini-batch 6580 of 25000, training loss: 0.212928\n",
      "Train Epoch: 0, mini-batch 6590 of 25000, training loss: 0.027189\n",
      "Train Epoch: 0, mini-batch 6600 of 25000, training loss: 0.230685\n",
      "Train Epoch: 0, mini-batch 6610 of 25000, training loss: 0.087403\n",
      "Train Epoch: 0, mini-batch 6620 of 25000, training loss: 0.011007\n",
      "Train Epoch: 0, mini-batch 6630 of 25000, training loss: 0.808062\n",
      "Train Epoch: 0, mini-batch 6640 of 25000, training loss: 0.038086\n",
      "Train Epoch: 0, mini-batch 6650 of 25000, training loss: 0.066164\n",
      "Train Epoch: 0, mini-batch 6660 of 25000, training loss: 0.802847\n",
      "Train Epoch: 0, mini-batch 6670 of 25000, training loss: 0.134239\n",
      "Train Epoch: 0, mini-batch 6680 of 25000, training loss: 0.296012\n",
      "Train Epoch: 0, mini-batch 6690 of 25000, training loss: 1.977373\n",
      "Train Epoch: 0, mini-batch 6700 of 25000, training loss: 0.026460\n",
      "Train Epoch: 0, mini-batch 6710 of 25000, training loss: 0.060286\n",
      "Train Epoch: 0, mini-batch 6720 of 25000, training loss: 0.020499\n",
      "Train Epoch: 0, mini-batch 6730 of 25000, training loss: 0.017449\n",
      "Train Epoch: 0, mini-batch 6740 of 25000, training loss: 0.316166\n",
      "Train Epoch: 0, mini-batch 6750 of 25000, training loss: 0.020857\n",
      "Train Epoch: 0, mini-batch 6760 of 25000, training loss: 0.076605\n",
      "Train Epoch: 0, mini-batch 6770 of 25000, training loss: 0.001658\n",
      "Train Epoch: 0, mini-batch 6780 of 25000, training loss: 0.020461\n",
      "Train Epoch: 0, mini-batch 6790 of 25000, training loss: 0.014195\n",
      "Train Epoch: 0, mini-batch 6800 of 25000, training loss: 0.013673\n",
      "Train Epoch: 0, mini-batch 6810 of 25000, training loss: 0.071693\n",
      "Train Epoch: 0, mini-batch 6820 of 25000, training loss: 0.028567\n",
      "Train Epoch: 0, mini-batch 6830 of 25000, training loss: 0.022296\n",
      "Train Epoch: 0, mini-batch 6840 of 25000, training loss: 0.021523\n",
      "Train Epoch: 0, mini-batch 6850 of 25000, training loss: 0.029047\n",
      "Train Epoch: 0, mini-batch 6860 of 25000, training loss: 0.178790\n",
      "Train Epoch: 0, mini-batch 6870 of 25000, training loss: 1.340006\n",
      "Train Epoch: 0, mini-batch 6880 of 25000, training loss: 0.032010\n",
      "Train Epoch: 0, mini-batch 6890 of 25000, training loss: 0.074276\n",
      "Train Epoch: 0, mini-batch 6900 of 25000, training loss: 0.012241\n",
      "Train Epoch: 0, mini-batch 6910 of 25000, training loss: 0.468434\n",
      "Train Epoch: 0, mini-batch 6920 of 25000, training loss: 0.020276\n",
      "Train Epoch: 0, mini-batch 6930 of 25000, training loss: 1.124629\n",
      "Train Epoch: 0, mini-batch 6940 of 25000, training loss: 1.202831\n",
      "Train Epoch: 0, mini-batch 6950 of 25000, training loss: 0.028383\n",
      "Train Epoch: 0, mini-batch 6960 of 25000, training loss: 0.239578\n",
      "Train Epoch: 0, mini-batch 6970 of 25000, training loss: 0.003392\n",
      "Train Epoch: 0, mini-batch 6980 of 25000, training loss: 0.156028\n",
      "Train Epoch: 0, mini-batch 6990 of 25000, training loss: 0.015902\n",
      "Train Epoch: 0, mini-batch 7000 of 25000, training loss: 0.338733\n",
      "Train Epoch: 0, mini-batch 7010 of 25000, training loss: 0.172579\n",
      "Train Epoch: 0, mini-batch 7020 of 25000, training loss: 1.535406\n",
      "Train Epoch: 0, mini-batch 7030 of 25000, training loss: 1.175048\n",
      "Train Epoch: 0, mini-batch 7040 of 25000, training loss: 0.436594\n",
      "Train Epoch: 0, mini-batch 7050 of 25000, training loss: 0.086430\n",
      "Train Epoch: 0, mini-batch 7060 of 25000, training loss: 0.550710\n",
      "Train Epoch: 0, mini-batch 7070 of 25000, training loss: 0.053399\n",
      "Train Epoch: 0, mini-batch 7080 of 25000, training loss: 0.113869\n",
      "Train Epoch: 0, mini-batch 7090 of 25000, training loss: 1.479676\n",
      "Train Epoch: 0, mini-batch 7100 of 25000, training loss: 0.027861\n",
      "Train Epoch: 0, mini-batch 7110 of 25000, training loss: 0.068517\n",
      "Train Epoch: 0, mini-batch 7120 of 25000, training loss: 0.139817\n",
      "Train Epoch: 0, mini-batch 7130 of 25000, training loss: 0.194204\n",
      "Train Epoch: 0, mini-batch 7140 of 25000, training loss: 0.834523\n",
      "Train Epoch: 0, mini-batch 7150 of 25000, training loss: 0.225411\n",
      "Train Epoch: 0, mini-batch 7160 of 25000, training loss: 1.088677\n",
      "Train Epoch: 0, mini-batch 7170 of 25000, training loss: 0.533822\n",
      "Train Epoch: 0, mini-batch 7180 of 25000, training loss: 0.594353\n",
      "Train Epoch: 0, mini-batch 7190 of 25000, training loss: 0.050743\n",
      "Train Epoch: 0, mini-batch 7200 of 25000, training loss: 0.023339\n",
      "Train Epoch: 0, mini-batch 7210 of 25000, training loss: 0.213224\n",
      "Train Epoch: 0, mini-batch 7220 of 25000, training loss: 0.473771\n",
      "Train Epoch: 0, mini-batch 7230 of 25000, training loss: 0.008568\n",
      "Train Epoch: 0, mini-batch 7240 of 25000, training loss: 0.133547\n",
      "Train Epoch: 0, mini-batch 7250 of 25000, training loss: 0.054372\n",
      "Train Epoch: 0, mini-batch 7260 of 25000, training loss: 0.311889\n",
      "Train Epoch: 0, mini-batch 7270 of 25000, training loss: 0.047180\n",
      "Train Epoch: 0, mini-batch 7280 of 25000, training loss: 0.658760\n",
      "Train Epoch: 0, mini-batch 7290 of 25000, training loss: 0.019022\n",
      "Train Epoch: 0, mini-batch 7300 of 25000, training loss: 0.007523\n",
      "Train Epoch: 0, mini-batch 7310 of 25000, training loss: 1.320107\n",
      "Train Epoch: 0, mini-batch 7320 of 25000, training loss: 0.341500\n",
      "Train Epoch: 0, mini-batch 7330 of 25000, training loss: 1.067339\n",
      "Train Epoch: 0, mini-batch 7340 of 25000, training loss: 5.206224\n",
      "Train Epoch: 0, mini-batch 7350 of 25000, training loss: 0.819632\n",
      "Train Epoch: 0, mini-batch 7360 of 25000, training loss: 0.258983\n",
      "Train Epoch: 0, mini-batch 7370 of 25000, training loss: 0.022938\n",
      "Train Epoch: 0, mini-batch 7380 of 25000, training loss: 0.000828\n",
      "Train Epoch: 0, mini-batch 7390 of 25000, training loss: 0.036694\n",
      "Train Epoch: 0, mini-batch 7400 of 25000, training loss: 0.072119\n",
      "Train Epoch: 0, mini-batch 7410 of 25000, training loss: 0.427794\n",
      "Train Epoch: 0, mini-batch 7420 of 25000, training loss: 0.072551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 7430 of 25000, training loss: 0.108693\n",
      "Train Epoch: 0, mini-batch 7440 of 25000, training loss: 0.057230\n",
      "Train Epoch: 0, mini-batch 7450 of 25000, training loss: 0.573595\n",
      "Train Epoch: 0, mini-batch 7460 of 25000, training loss: 0.161639\n",
      "Train Epoch: 0, mini-batch 7470 of 25000, training loss: 1.975173\n",
      "Train Epoch: 0, mini-batch 7480 of 25000, training loss: 0.363071\n",
      "Train Epoch: 0, mini-batch 7490 of 25000, training loss: 0.302737\n",
      "Train Epoch: 0, mini-batch 7500 of 25000, training loss: 0.437858\n",
      "Train Epoch: 0, mini-batch 7510 of 25000, training loss: 0.262641\n",
      "Train Epoch: 0, mini-batch 7520 of 25000, training loss: 0.063130\n",
      "Train Epoch: 0, mini-batch 7530 of 25000, training loss: 0.592833\n",
      "Train Epoch: 0, mini-batch 7540 of 25000, training loss: 0.506257\n",
      "Train Epoch: 0, mini-batch 7550 of 25000, training loss: 0.053897\n",
      "Train Epoch: 0, mini-batch 7560 of 25000, training loss: 0.659386\n",
      "Train Epoch: 0, mini-batch 7570 of 25000, training loss: 0.075486\n",
      "Train Epoch: 0, mini-batch 7580 of 25000, training loss: 0.004554\n",
      "Train Epoch: 0, mini-batch 7590 of 25000, training loss: 0.454686\n",
      "Train Epoch: 0, mini-batch 7600 of 25000, training loss: 0.029916\n",
      "Train Epoch: 0, mini-batch 7610 of 25000, training loss: 0.288158\n",
      "Train Epoch: 0, mini-batch 7620 of 25000, training loss: 0.413267\n",
      "Train Epoch: 0, mini-batch 7630 of 25000, training loss: 1.148526\n",
      "Train Epoch: 0, mini-batch 7640 of 25000, training loss: 0.996273\n",
      "Train Epoch: 0, mini-batch 7650 of 25000, training loss: 0.982242\n",
      "Train Epoch: 0, mini-batch 7660 of 25000, training loss: 0.106744\n",
      "Train Epoch: 0, mini-batch 7670 of 25000, training loss: 0.005709\n",
      "Train Epoch: 0, mini-batch 7680 of 25000, training loss: 0.340157\n",
      "Train Epoch: 0, mini-batch 7690 of 25000, training loss: 0.155490\n",
      "Train Epoch: 0, mini-batch 7700 of 25000, training loss: 0.010894\n",
      "Train Epoch: 0, mini-batch 7710 of 25000, training loss: 2.109710\n",
      "Train Epoch: 0, mini-batch 7720 of 25000, training loss: 2.785479\n",
      "Train Epoch: 0, mini-batch 7730 of 25000, training loss: 0.242841\n",
      "Train Epoch: 0, mini-batch 7740 of 25000, training loss: 1.361321\n",
      "Train Epoch: 0, mini-batch 7750 of 25000, training loss: 0.044694\n",
      "Train Epoch: 0, mini-batch 7760 of 25000, training loss: 0.997801\n",
      "Train Epoch: 0, mini-batch 7770 of 25000, training loss: 0.098601\n",
      "Train Epoch: 0, mini-batch 7780 of 25000, training loss: 0.743439\n",
      "Train Epoch: 0, mini-batch 7790 of 25000, training loss: 1.205476\n",
      "Train Epoch: 0, mini-batch 7800 of 25000, training loss: 0.197285\n",
      "Train Epoch: 0, mini-batch 7810 of 25000, training loss: 0.030385\n",
      "Train Epoch: 0, mini-batch 7820 of 25000, training loss: 0.120042\n",
      "Train Epoch: 0, mini-batch 7830 of 25000, training loss: 0.064832\n",
      "Train Epoch: 0, mini-batch 7840 of 25000, training loss: 0.010765\n",
      "Train Epoch: 0, mini-batch 7850 of 25000, training loss: 0.346860\n",
      "Train Epoch: 0, mini-batch 7860 of 25000, training loss: 0.186832\n",
      "Train Epoch: 0, mini-batch 7870 of 25000, training loss: 0.161544\n",
      "Train Epoch: 0, mini-batch 7880 of 25000, training loss: 0.050943\n",
      "Train Epoch: 0, mini-batch 7890 of 25000, training loss: 0.097697\n",
      "Train Epoch: 0, mini-batch 7900 of 25000, training loss: 0.818791\n",
      "Train Epoch: 0, mini-batch 7910 of 25000, training loss: 0.012891\n",
      "Train Epoch: 0, mini-batch 7920 of 25000, training loss: 0.002376\n",
      "Train Epoch: 0, mini-batch 7930 of 25000, training loss: 0.315522\n",
      "Train Epoch: 0, mini-batch 7940 of 25000, training loss: 0.019417\n",
      "Train Epoch: 0, mini-batch 7950 of 25000, training loss: 0.414569\n",
      "Train Epoch: 0, mini-batch 7960 of 25000, training loss: 0.036391\n",
      "Train Epoch: 0, mini-batch 7970 of 25000, training loss: 0.257857\n",
      "Train Epoch: 0, mini-batch 7980 of 25000, training loss: 0.131992\n",
      "Train Epoch: 0, mini-batch 7990 of 25000, training loss: 0.015684\n",
      "Train Epoch: 0, mini-batch 8000 of 25000, training loss: 0.110067\n",
      "Train Epoch: 0, mini-batch 8010 of 25000, training loss: 0.114357\n",
      "Train Epoch: 0, mini-batch 8020 of 25000, training loss: 0.042168\n",
      "Train Epoch: 0, mini-batch 8030 of 25000, training loss: 0.227439\n",
      "Train Epoch: 0, mini-batch 8040 of 25000, training loss: 0.262576\n",
      "Train Epoch: 0, mini-batch 8050 of 25000, training loss: 0.026093\n",
      "Train Epoch: 0, mini-batch 8060 of 25000, training loss: 0.517806\n",
      "Train Epoch: 0, mini-batch 8070 of 25000, training loss: 0.018044\n",
      "Train Epoch: 0, mini-batch 8080 of 25000, training loss: 0.369432\n",
      "Train Epoch: 0, mini-batch 8090 of 25000, training loss: 0.092997\n",
      "Train Epoch: 0, mini-batch 8100 of 25000, training loss: 0.830356\n",
      "Train Epoch: 0, mini-batch 8110 of 25000, training loss: 0.005970\n",
      "Train Epoch: 0, mini-batch 8120 of 25000, training loss: 0.901300\n",
      "Train Epoch: 0, mini-batch 8130 of 25000, training loss: 1.550802\n",
      "Train Epoch: 0, mini-batch 8140 of 25000, training loss: 0.092249\n",
      "Train Epoch: 0, mini-batch 8150 of 25000, training loss: 0.056494\n",
      "Train Epoch: 0, mini-batch 8160 of 25000, training loss: 2.435005\n",
      "Train Epoch: 0, mini-batch 8170 of 25000, training loss: 2.534604\n",
      "Train Epoch: 0, mini-batch 8180 of 25000, training loss: 0.285990\n",
      "Train Epoch: 0, mini-batch 8190 of 25000, training loss: 0.045388\n",
      "Train Epoch: 0, mini-batch 8200 of 25000, training loss: 0.339490\n",
      "Train Epoch: 0, mini-batch 8210 of 25000, training loss: 0.115469\n",
      "Train Epoch: 0, mini-batch 8220 of 25000, training loss: 0.599222\n",
      "Train Epoch: 0, mini-batch 8230 of 25000, training loss: 1.033099\n",
      "Train Epoch: 0, mini-batch 8240 of 25000, training loss: 0.001811\n",
      "Train Epoch: 0, mini-batch 8250 of 25000, training loss: 0.027954\n",
      "Train Epoch: 0, mini-batch 8260 of 25000, training loss: 0.735533\n",
      "Train Epoch: 0, mini-batch 8270 of 25000, training loss: 0.120348\n",
      "Train Epoch: 0, mini-batch 8280 of 25000, training loss: 0.028886\n",
      "Train Epoch: 0, mini-batch 8290 of 25000, training loss: 0.152486\n",
      "Train Epoch: 0, mini-batch 8300 of 25000, training loss: 0.057695\n",
      "Train Epoch: 0, mini-batch 8310 of 25000, training loss: 0.067100\n",
      "Train Epoch: 0, mini-batch 8320 of 25000, training loss: 0.023338\n",
      "Train Epoch: 0, mini-batch 8330 of 25000, training loss: 0.104111\n",
      "Train Epoch: 0, mini-batch 8340 of 25000, training loss: 0.318271\n",
      "Train Epoch: 0, mini-batch 8350 of 25000, training loss: 0.170239\n",
      "Train Epoch: 0, mini-batch 8360 of 25000, training loss: 0.520941\n",
      "Train Epoch: 0, mini-batch 8370 of 25000, training loss: 3.961991\n",
      "Train Epoch: 0, mini-batch 8380 of 25000, training loss: 0.813126\n",
      "Train Epoch: 0, mini-batch 8390 of 25000, training loss: 0.242792\n",
      "Train Epoch: 0, mini-batch 8400 of 25000, training loss: 0.066210\n",
      "Train Epoch: 0, mini-batch 8410 of 25000, training loss: 0.002602\n",
      "Train Epoch: 0, mini-batch 8420 of 25000, training loss: 0.711519\n",
      "Train Epoch: 0, mini-batch 8430 of 25000, training loss: 0.055397\n",
      "Train Epoch: 0, mini-batch 8440 of 25000, training loss: 0.055875\n",
      "Train Epoch: 0, mini-batch 8450 of 25000, training loss: 0.001729\n",
      "Train Epoch: 0, mini-batch 8460 of 25000, training loss: 0.001713\n",
      "Train Epoch: 0, mini-batch 8470 of 25000, training loss: 0.125178\n",
      "Train Epoch: 0, mini-batch 8480 of 25000, training loss: 0.013183\n",
      "Train Epoch: 0, mini-batch 8490 of 25000, training loss: 0.132775\n",
      "Train Epoch: 0, mini-batch 8500 of 25000, training loss: 0.015162\n",
      "Train Epoch: 0, mini-batch 8510 of 25000, training loss: 0.183471\n",
      "Train Epoch: 0, mini-batch 8520 of 25000, training loss: 0.904723\n",
      "Train Epoch: 0, mini-batch 8530 of 25000, training loss: 0.480461\n",
      "Train Epoch: 0, mini-batch 8540 of 25000, training loss: 0.654139\n",
      "Train Epoch: 0, mini-batch 8550 of 25000, training loss: 0.081197\n",
      "Train Epoch: 0, mini-batch 8560 of 25000, training loss: 0.227760\n",
      "Train Epoch: 0, mini-batch 8570 of 25000, training loss: 0.169893\n",
      "Train Epoch: 0, mini-batch 8580 of 25000, training loss: 0.328287\n",
      "Train Epoch: 0, mini-batch 8590 of 25000, training loss: 0.398924\n",
      "Train Epoch: 0, mini-batch 8600 of 25000, training loss: 0.009428\n",
      "Train Epoch: 0, mini-batch 8610 of 25000, training loss: 0.058347\n",
      "Train Epoch: 0, mini-batch 8620 of 25000, training loss: 0.039017\n",
      "Train Epoch: 0, mini-batch 8630 of 25000, training loss: 0.166623\n",
      "Train Epoch: 0, mini-batch 8640 of 25000, training loss: 0.017365\n",
      "Train Epoch: 0, mini-batch 8650 of 25000, training loss: 0.713706\n",
      "Train Epoch: 0, mini-batch 8660 of 25000, training loss: 0.001110\n",
      "Train Epoch: 0, mini-batch 8670 of 25000, training loss: 1.061597\n",
      "Train Epoch: 0, mini-batch 8680 of 25000, training loss: 0.055198\n",
      "Train Epoch: 0, mini-batch 8690 of 25000, training loss: 1.233659\n",
      "Train Epoch: 0, mini-batch 8700 of 25000, training loss: 0.052090\n",
      "Train Epoch: 0, mini-batch 8710 of 25000, training loss: 0.039638\n",
      "Train Epoch: 0, mini-batch 8720 of 25000, training loss: 0.083610\n",
      "Train Epoch: 0, mini-batch 8730 of 25000, training loss: 0.044303\n",
      "Train Epoch: 0, mini-batch 8740 of 25000, training loss: 0.120688\n",
      "Train Epoch: 0, mini-batch 8750 of 25000, training loss: 2.078692\n",
      "Train Epoch: 0, mini-batch 8760 of 25000, training loss: 0.430840\n",
      "Train Epoch: 0, mini-batch 8770 of 25000, training loss: 0.163019\n",
      "Train Epoch: 0, mini-batch 8780 of 25000, training loss: 0.349460\n",
      "Train Epoch: 0, mini-batch 8790 of 25000, training loss: 0.061791\n",
      "Train Epoch: 0, mini-batch 8800 of 25000, training loss: 0.247211\n",
      "Train Epoch: 0, mini-batch 8810 of 25000, training loss: 0.096518\n",
      "Train Epoch: 0, mini-batch 8820 of 25000, training loss: 0.738855\n",
      "Train Epoch: 0, mini-batch 8830 of 25000, training loss: 2.124275\n",
      "Train Epoch: 0, mini-batch 8840 of 25000, training loss: 0.113739\n",
      "Train Epoch: 0, mini-batch 8850 of 25000, training loss: 0.060962\n",
      "Train Epoch: 0, mini-batch 8860 of 25000, training loss: 1.199615\n",
      "Train Epoch: 0, mini-batch 8870 of 25000, training loss: 0.010677\n",
      "Train Epoch: 0, mini-batch 8880 of 25000, training loss: 0.108465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 8890 of 25000, training loss: 1.183868\n",
      "Train Epoch: 0, mini-batch 8900 of 25000, training loss: 0.241556\n",
      "Train Epoch: 0, mini-batch 8910 of 25000, training loss: 0.792867\n",
      "Train Epoch: 0, mini-batch 8920 of 25000, training loss: 0.043702\n",
      "Train Epoch: 0, mini-batch 8930 of 25000, training loss: 0.223766\n",
      "Train Epoch: 0, mini-batch 8940 of 25000, training loss: 0.399048\n",
      "Train Epoch: 0, mini-batch 8950 of 25000, training loss: 0.019720\n",
      "Train Epoch: 0, mini-batch 8960 of 25000, training loss: 0.015890\n",
      "Train Epoch: 0, mini-batch 8970 of 25000, training loss: 0.029978\n",
      "Train Epoch: 0, mini-batch 8980 of 25000, training loss: 0.359792\n",
      "Train Epoch: 0, mini-batch 8990 of 25000, training loss: 0.014356\n",
      "Train Epoch: 0, mini-batch 9000 of 25000, training loss: 0.848552\n",
      "Train Epoch: 0, mini-batch 9010 of 25000, training loss: 0.046054\n",
      "Train Epoch: 0, mini-batch 9020 of 25000, training loss: 0.840518\n",
      "Train Epoch: 0, mini-batch 9030 of 25000, training loss: 0.010565\n",
      "Train Epoch: 0, mini-batch 9040 of 25000, training loss: 0.362919\n",
      "Train Epoch: 0, mini-batch 9050 of 25000, training loss: 0.211199\n",
      "Train Epoch: 0, mini-batch 9060 of 25000, training loss: 0.381114\n",
      "Train Epoch: 0, mini-batch 9070 of 25000, training loss: 0.050176\n",
      "Train Epoch: 0, mini-batch 9080 of 25000, training loss: 0.254819\n",
      "Train Epoch: 0, mini-batch 9090 of 25000, training loss: 0.967618\n",
      "Train Epoch: 0, mini-batch 9100 of 25000, training loss: 0.807000\n",
      "Train Epoch: 0, mini-batch 9110 of 25000, training loss: 0.034118\n",
      "Train Epoch: 0, mini-batch 9120 of 25000, training loss: 0.102730\n",
      "Train Epoch: 0, mini-batch 9130 of 25000, training loss: 0.071141\n",
      "Train Epoch: 0, mini-batch 9140 of 25000, training loss: 0.046344\n",
      "Train Epoch: 0, mini-batch 9150 of 25000, training loss: 0.197699\n",
      "Train Epoch: 0, mini-batch 9160 of 25000, training loss: 0.269644\n",
      "Train Epoch: 0, mini-batch 9170 of 25000, training loss: 0.035478\n",
      "Train Epoch: 0, mini-batch 9180 of 25000, training loss: 3.547250\n",
      "Train Epoch: 0, mini-batch 9190 of 25000, training loss: 0.010826\n",
      "Train Epoch: 0, mini-batch 9200 of 25000, training loss: 0.166609\n",
      "Train Epoch: 0, mini-batch 9210 of 25000, training loss: 0.935895\n",
      "Train Epoch: 0, mini-batch 9220 of 25000, training loss: 0.369731\n",
      "Train Epoch: 0, mini-batch 9230 of 25000, training loss: 0.037687\n",
      "Train Epoch: 0, mini-batch 9240 of 25000, training loss: 0.000011\n",
      "Train Epoch: 0, mini-batch 9250 of 25000, training loss: 2.003081\n",
      "Train Epoch: 0, mini-batch 9260 of 25000, training loss: 0.002166\n",
      "Train Epoch: 0, mini-batch 9270 of 25000, training loss: 0.263262\n",
      "Train Epoch: 0, mini-batch 9280 of 25000, training loss: 0.004934\n",
      "Train Epoch: 0, mini-batch 9290 of 25000, training loss: 0.018613\n",
      "Train Epoch: 0, mini-batch 9300 of 25000, training loss: 0.040293\n",
      "Train Epoch: 0, mini-batch 9310 of 25000, training loss: 0.031620\n",
      "Train Epoch: 0, mini-batch 9320 of 25000, training loss: 0.002941\n",
      "Train Epoch: 0, mini-batch 9330 of 25000, training loss: 0.289409\n",
      "Train Epoch: 0, mini-batch 9340 of 25000, training loss: 0.366877\n",
      "Train Epoch: 0, mini-batch 9350 of 25000, training loss: 0.156012\n",
      "Train Epoch: 0, mini-batch 9360 of 25000, training loss: 0.887866\n",
      "Train Epoch: 0, mini-batch 9370 of 25000, training loss: 0.170088\n",
      "Train Epoch: 0, mini-batch 9380 of 25000, training loss: 0.083436\n",
      "Train Epoch: 0, mini-batch 9390 of 25000, training loss: 0.690928\n",
      "Train Epoch: 0, mini-batch 9400 of 25000, training loss: 0.014068\n",
      "Train Epoch: 0, mini-batch 9410 of 25000, training loss: 1.519319\n",
      "Train Epoch: 0, mini-batch 9420 of 25000, training loss: 0.047648\n",
      "Train Epoch: 0, mini-batch 9430 of 25000, training loss: 0.017304\n",
      "Train Epoch: 0, mini-batch 9440 of 25000, training loss: 0.004680\n",
      "Train Epoch: 0, mini-batch 9450 of 25000, training loss: 0.014564\n",
      "Train Epoch: 0, mini-batch 9460 of 25000, training loss: 0.055449\n",
      "Train Epoch: 0, mini-batch 9470 of 25000, training loss: 0.029981\n",
      "Train Epoch: 0, mini-batch 9480 of 25000, training loss: 0.033145\n",
      "Train Epoch: 0, mini-batch 9490 of 25000, training loss: 0.377120\n",
      "Train Epoch: 0, mini-batch 9500 of 25000, training loss: 0.062325\n",
      "Train Epoch: 0, mini-batch 9510 of 25000, training loss: 0.054396\n",
      "Train Epoch: 0, mini-batch 9520 of 25000, training loss: 0.474236\n",
      "Train Epoch: 0, mini-batch 9530 of 25000, training loss: 0.031600\n",
      "Train Epoch: 0, mini-batch 9540 of 25000, training loss: 0.019600\n",
      "Train Epoch: 0, mini-batch 9550 of 25000, training loss: 0.030520\n",
      "Train Epoch: 0, mini-batch 9560 of 25000, training loss: 0.025967\n",
      "Train Epoch: 0, mini-batch 9570 of 25000, training loss: 0.297944\n",
      "Train Epoch: 0, mini-batch 9580 of 25000, training loss: 0.077495\n",
      "Train Epoch: 0, mini-batch 9590 of 25000, training loss: 0.016275\n",
      "Train Epoch: 0, mini-batch 9600 of 25000, training loss: 0.004254\n",
      "Train Epoch: 0, mini-batch 9610 of 25000, training loss: 0.058580\n",
      "Train Epoch: 0, mini-batch 9620 of 25000, training loss: 0.567074\n",
      "Train Epoch: 0, mini-batch 9630 of 25000, training loss: 0.203330\n",
      "Train Epoch: 0, mini-batch 9640 of 25000, training loss: 0.004358\n",
      "Train Epoch: 0, mini-batch 9650 of 25000, training loss: 0.017382\n",
      "Train Epoch: 0, mini-batch 9660 of 25000, training loss: 0.138865\n",
      "Train Epoch: 0, mini-batch 9670 of 25000, training loss: 0.042344\n",
      "Train Epoch: 0, mini-batch 9680 of 25000, training loss: 1.122981\n",
      "Train Epoch: 0, mini-batch 9690 of 25000, training loss: 1.258630\n",
      "Train Epoch: 0, mini-batch 9700 of 25000, training loss: 0.194378\n",
      "Train Epoch: 0, mini-batch 9710 of 25000, training loss: 0.093967\n",
      "Train Epoch: 0, mini-batch 9720 of 25000, training loss: 1.546532\n",
      "Train Epoch: 0, mini-batch 9730 of 25000, training loss: 0.010025\n",
      "Train Epoch: 0, mini-batch 9740 of 25000, training loss: 0.347968\n",
      "Train Epoch: 0, mini-batch 9750 of 25000, training loss: 0.013055\n",
      "Train Epoch: 0, mini-batch 9760 of 25000, training loss: 0.029135\n",
      "Train Epoch: 0, mini-batch 9770 of 25000, training loss: 0.405528\n",
      "Train Epoch: 0, mini-batch 9780 of 25000, training loss: 0.002084\n",
      "Train Epoch: 0, mini-batch 9790 of 25000, training loss: 1.979149\n",
      "Train Epoch: 0, mini-batch 9800 of 25000, training loss: 0.020680\n",
      "Train Epoch: 0, mini-batch 9810 of 25000, training loss: 0.019074\n",
      "Train Epoch: 0, mini-batch 9820 of 25000, training loss: 0.005972\n",
      "Train Epoch: 0, mini-batch 9830 of 25000, training loss: 2.582785\n",
      "Train Epoch: 0, mini-batch 9840 of 25000, training loss: 0.231400\n",
      "Train Epoch: 0, mini-batch 9850 of 25000, training loss: 0.006194\n",
      "Train Epoch: 0, mini-batch 9860 of 25000, training loss: 0.026360\n",
      "Train Epoch: 0, mini-batch 9870 of 25000, training loss: 0.254634\n",
      "Train Epoch: 0, mini-batch 9880 of 25000, training loss: 0.106264\n",
      "Train Epoch: 0, mini-batch 9890 of 25000, training loss: 2.088838\n",
      "Train Epoch: 0, mini-batch 9900 of 25000, training loss: 0.171086\n",
      "Train Epoch: 0, mini-batch 9910 of 25000, training loss: 0.122626\n",
      "Train Epoch: 0, mini-batch 9920 of 25000, training loss: 0.111720\n",
      "Train Epoch: 0, mini-batch 9930 of 25000, training loss: 0.024464\n",
      "Train Epoch: 0, mini-batch 9940 of 25000, training loss: 0.008537\n",
      "Train Epoch: 0, mini-batch 9950 of 25000, training loss: 0.003321\n",
      "Train Epoch: 0, mini-batch 9960 of 25000, training loss: 0.026473\n",
      "Train Epoch: 0, mini-batch 9970 of 25000, training loss: 0.072271\n",
      "Train Epoch: 0, mini-batch 9980 of 25000, training loss: 0.010901\n",
      "Train Epoch: 0, mini-batch 9990 of 25000, training loss: 0.652754\n",
      "Train Epoch: 0, mini-batch 10000 of 25000, training loss: 0.563643\n",
      "Train Epoch: 0, mini-batch 10010 of 25000, training loss: 0.022104\n",
      "Train Epoch: 0, mini-batch 10020 of 25000, training loss: 0.012420\n",
      "Train Epoch: 0, mini-batch 10030 of 25000, training loss: 0.022958\n",
      "Train Epoch: 0, mini-batch 10040 of 25000, training loss: 0.086382\n",
      "Train Epoch: 0, mini-batch 10050 of 25000, training loss: 0.003159\n",
      "Train Epoch: 0, mini-batch 10060 of 25000, training loss: 0.920517\n",
      "Train Epoch: 0, mini-batch 10070 of 25000, training loss: 0.268146\n",
      "Train Epoch: 0, mini-batch 10080 of 25000, training loss: 0.017640\n",
      "Train Epoch: 0, mini-batch 10090 of 25000, training loss: 0.016003\n",
      "Train Epoch: 0, mini-batch 10100 of 25000, training loss: 0.087274\n",
      "Train Epoch: 0, mini-batch 10110 of 25000, training loss: 0.115364\n",
      "Train Epoch: 0, mini-batch 10120 of 25000, training loss: 0.048659\n",
      "Train Epoch: 0, mini-batch 10130 of 25000, training loss: 0.007024\n",
      "Train Epoch: 0, mini-batch 10140 of 25000, training loss: 0.025227\n",
      "Train Epoch: 0, mini-batch 10150 of 25000, training loss: 0.489048\n",
      "Train Epoch: 0, mini-batch 10160 of 25000, training loss: 0.068875\n",
      "Train Epoch: 0, mini-batch 10170 of 25000, training loss: 0.018305\n",
      "Train Epoch: 0, mini-batch 10180 of 25000, training loss: 0.039265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 10190 of 25000, training loss: 0.171108\n",
      "Train Epoch: 0, mini-batch 10200 of 25000, training loss: 0.062050\n",
      "Train Epoch: 0, mini-batch 10210 of 25000, training loss: 0.302470\n",
      "Train Epoch: 0, mini-batch 10220 of 25000, training loss: 0.845729\n",
      "Train Epoch: 0, mini-batch 10230 of 25000, training loss: 0.123123\n",
      "Train Epoch: 0, mini-batch 10240 of 25000, training loss: 0.055507\n",
      "Train Epoch: 0, mini-batch 10250 of 25000, training loss: 0.014978\n",
      "Train Epoch: 0, mini-batch 10260 of 25000, training loss: 2.682865\n",
      "Train Epoch: 0, mini-batch 10270 of 25000, training loss: 0.119537\n",
      "Train Epoch: 0, mini-batch 10280 of 25000, training loss: 0.148235\n",
      "Train Epoch: 0, mini-batch 10290 of 25000, training loss: 0.056917\n",
      "Train Epoch: 0, mini-batch 10300 of 25000, training loss: 0.048143\n",
      "Train Epoch: 0, mini-batch 10310 of 25000, training loss: 0.033685\n",
      "Train Epoch: 0, mini-batch 10320 of 25000, training loss: 1.293919\n",
      "Train Epoch: 0, mini-batch 10330 of 25000, training loss: 0.061001\n",
      "Train Epoch: 0, mini-batch 10340 of 25000, training loss: 0.441757\n",
      "Train Epoch: 0, mini-batch 10350 of 25000, training loss: 0.173959\n",
      "Train Epoch: 0, mini-batch 10360 of 25000, training loss: 0.031252\n",
      "Train Epoch: 0, mini-batch 10370 of 25000, training loss: 0.000008\n",
      "Train Epoch: 0, mini-batch 10380 of 25000, training loss: 0.377786\n",
      "Train Epoch: 0, mini-batch 10390 of 25000, training loss: 0.028307\n",
      "Train Epoch: 0, mini-batch 10400 of 25000, training loss: 0.114822\n",
      "Train Epoch: 0, mini-batch 10410 of 25000, training loss: 0.007686\n",
      "Train Epoch: 0, mini-batch 10420 of 25000, training loss: 0.032541\n",
      "Train Epoch: 0, mini-batch 10430 of 25000, training loss: 0.013404\n",
      "Train Epoch: 0, mini-batch 10440 of 25000, training loss: 0.005827\n",
      "Train Epoch: 0, mini-batch 10450 of 25000, training loss: 0.885584\n",
      "Train Epoch: 0, mini-batch 10460 of 25000, training loss: 0.080584\n",
      "Train Epoch: 0, mini-batch 10470 of 25000, training loss: 0.355973\n",
      "Train Epoch: 0, mini-batch 10480 of 25000, training loss: 0.054152\n",
      "Train Epoch: 0, mini-batch 10490 of 25000, training loss: 1.632450\n",
      "Train Epoch: 0, mini-batch 10500 of 25000, training loss: 0.017022\n",
      "Train Epoch: 0, mini-batch 10510 of 25000, training loss: 0.705607\n",
      "Train Epoch: 0, mini-batch 10520 of 25000, training loss: 0.029814\n",
      "Train Epoch: 0, mini-batch 10530 of 25000, training loss: 0.011862\n",
      "Train Epoch: 0, mini-batch 10540 of 25000, training loss: 0.017629\n",
      "Train Epoch: 0, mini-batch 10550 of 25000, training loss: 0.077819\n",
      "Train Epoch: 0, mini-batch 10560 of 25000, training loss: 0.679244\n",
      "Train Epoch: 0, mini-batch 10570 of 25000, training loss: 0.108089\n",
      "Train Epoch: 0, mini-batch 10580 of 25000, training loss: 1.420820\n",
      "Train Epoch: 0, mini-batch 10590 of 25000, training loss: 0.068838\n",
      "Train Epoch: 0, mini-batch 10600 of 25000, training loss: 0.013657\n",
      "Train Epoch: 0, mini-batch 10610 of 25000, training loss: 0.478203\n",
      "Train Epoch: 0, mini-batch 10620 of 25000, training loss: 0.172864\n",
      "Train Epoch: 0, mini-batch 10630 of 25000, training loss: 0.009965\n",
      "Train Epoch: 0, mini-batch 10640 of 25000, training loss: 0.638507\n",
      "Train Epoch: 0, mini-batch 10650 of 25000, training loss: 0.035811\n",
      "Train Epoch: 0, mini-batch 10660 of 25000, training loss: 0.748657\n",
      "Train Epoch: 0, mini-batch 10670 of 25000, training loss: 2.588434\n",
      "Train Epoch: 0, mini-batch 10680 of 25000, training loss: 0.037086\n",
      "Train Epoch: 0, mini-batch 10690 of 25000, training loss: 0.826686\n",
      "Train Epoch: 0, mini-batch 10700 of 25000, training loss: 0.034846\n",
      "Train Epoch: 0, mini-batch 10710 of 25000, training loss: 0.012714\n",
      "Train Epoch: 0, mini-batch 10720 of 25000, training loss: 0.033485\n",
      "Train Epoch: 0, mini-batch 10730 of 25000, training loss: 0.005869\n",
      "Train Epoch: 0, mini-batch 10740 of 25000, training loss: 0.055813\n",
      "Train Epoch: 0, mini-batch 10750 of 25000, training loss: 0.009421\n",
      "Train Epoch: 0, mini-batch 10760 of 25000, training loss: 0.054054\n",
      "Train Epoch: 0, mini-batch 10770 of 25000, training loss: 0.550273\n",
      "Train Epoch: 0, mini-batch 10780 of 25000, training loss: 0.042840\n",
      "Train Epoch: 0, mini-batch 10790 of 25000, training loss: 1.598945\n",
      "Train Epoch: 0, mini-batch 10800 of 25000, training loss: 0.110089\n",
      "Train Epoch: 0, mini-batch 10810 of 25000, training loss: 0.973437\n",
      "Train Epoch: 0, mini-batch 10820 of 25000, training loss: 0.485919\n",
      "Train Epoch: 0, mini-batch 10830 of 25000, training loss: 0.022781\n",
      "Train Epoch: 0, mini-batch 10840 of 25000, training loss: 0.041841\n",
      "Train Epoch: 0, mini-batch 10850 of 25000, training loss: 0.218940\n",
      "Train Epoch: 0, mini-batch 10860 of 25000, training loss: 0.025722\n",
      "Train Epoch: 0, mini-batch 10870 of 25000, training loss: 0.265740\n",
      "Train Epoch: 0, mini-batch 10880 of 25000, training loss: 0.012256\n",
      "Train Epoch: 0, mini-batch 10890 of 25000, training loss: 2.122072\n",
      "Train Epoch: 0, mini-batch 10900 of 25000, training loss: 0.012135\n",
      "Train Epoch: 0, mini-batch 10910 of 25000, training loss: 0.775319\n",
      "Train Epoch: 0, mini-batch 10920 of 25000, training loss: 0.100795\n",
      "Train Epoch: 0, mini-batch 10930 of 25000, training loss: 0.017395\n",
      "Train Epoch: 0, mini-batch 10940 of 25000, training loss: 0.118719\n",
      "Train Epoch: 0, mini-batch 10950 of 25000, training loss: 0.042523\n",
      "Train Epoch: 0, mini-batch 10960 of 25000, training loss: 0.061611\n",
      "Train Epoch: 0, mini-batch 10970 of 25000, training loss: 0.280148\n",
      "Train Epoch: 0, mini-batch 10980 of 25000, training loss: 0.099788\n",
      "Train Epoch: 0, mini-batch 10990 of 25000, training loss: 0.028279\n",
      "Train Epoch: 0, mini-batch 11000 of 25000, training loss: 0.045010\n",
      "Train Epoch: 0, mini-batch 11010 of 25000, training loss: 0.025510\n",
      "Train Epoch: 0, mini-batch 11020 of 25000, training loss: 0.086521\n",
      "Train Epoch: 0, mini-batch 11030 of 25000, training loss: 0.073370\n",
      "Train Epoch: 0, mini-batch 11040 of 25000, training loss: 0.001232\n",
      "Train Epoch: 0, mini-batch 11050 of 25000, training loss: 0.458269\n",
      "Train Epoch: 0, mini-batch 11060 of 25000, training loss: 0.135544\n",
      "Train Epoch: 0, mini-batch 11070 of 25000, training loss: 0.141395\n",
      "Train Epoch: 0, mini-batch 11080 of 25000, training loss: 0.395084\n",
      "Train Epoch: 0, mini-batch 11090 of 25000, training loss: 0.009920\n",
      "Train Epoch: 0, mini-batch 11100 of 25000, training loss: 0.048408\n",
      "Train Epoch: 0, mini-batch 11110 of 25000, training loss: 0.101535\n",
      "Train Epoch: 0, mini-batch 11120 of 25000, training loss: 0.018218\n",
      "Train Epoch: 0, mini-batch 11130 of 25000, training loss: 0.002759\n",
      "Train Epoch: 0, mini-batch 11140 of 25000, training loss: 0.000905\n",
      "Train Epoch: 0, mini-batch 11150 of 25000, training loss: 0.205203\n",
      "Train Epoch: 0, mini-batch 11160 of 25000, training loss: 0.060720\n",
      "Train Epoch: 0, mini-batch 11170 of 25000, training loss: 1.659076\n",
      "Train Epoch: 0, mini-batch 11180 of 25000, training loss: 0.146603\n",
      "Train Epoch: 0, mini-batch 11190 of 25000, training loss: 0.270040\n",
      "Train Epoch: 0, mini-batch 11200 of 25000, training loss: 0.494908\n",
      "Train Epoch: 0, mini-batch 11210 of 25000, training loss: 0.161741\n",
      "Train Epoch: 0, mini-batch 11220 of 25000, training loss: 0.039243\n",
      "Train Epoch: 0, mini-batch 11230 of 25000, training loss: 0.302373\n",
      "Train Epoch: 0, mini-batch 11240 of 25000, training loss: 0.275310\n",
      "Train Epoch: 0, mini-batch 11250 of 25000, training loss: 0.209232\n",
      "Train Epoch: 0, mini-batch 11260 of 25000, training loss: 0.463166\n",
      "Train Epoch: 0, mini-batch 11270 of 25000, training loss: 0.391729\n",
      "Train Epoch: 0, mini-batch 11280 of 25000, training loss: 0.209892\n",
      "Train Epoch: 0, mini-batch 11290 of 25000, training loss: 0.004335\n",
      "Train Epoch: 0, mini-batch 11300 of 25000, training loss: 0.675511\n",
      "Train Epoch: 0, mini-batch 11310 of 25000, training loss: 0.876072\n",
      "Train Epoch: 0, mini-batch 11320 of 25000, training loss: 0.022850\n",
      "Train Epoch: 0, mini-batch 11330 of 25000, training loss: 0.042435\n",
      "Train Epoch: 0, mini-batch 11340 of 25000, training loss: 0.217930\n",
      "Train Epoch: 0, mini-batch 11350 of 25000, training loss: 0.154841\n",
      "Train Epoch: 0, mini-batch 11360 of 25000, training loss: 0.001204\n",
      "Train Epoch: 0, mini-batch 11370 of 25000, training loss: 1.606284\n",
      "Train Epoch: 0, mini-batch 11380 of 25000, training loss: 0.112804\n",
      "Train Epoch: 0, mini-batch 11390 of 25000, training loss: 0.022360\n",
      "Train Epoch: 0, mini-batch 11400 of 25000, training loss: 0.048214\n",
      "Train Epoch: 0, mini-batch 11410 of 25000, training loss: 1.383644\n",
      "Train Epoch: 0, mini-batch 11420 of 25000, training loss: 0.010138\n",
      "Train Epoch: 0, mini-batch 11430 of 25000, training loss: 0.415560\n",
      "Train Epoch: 0, mini-batch 11440 of 25000, training loss: 0.483411\n",
      "Train Epoch: 0, mini-batch 11450 of 25000, training loss: 0.299892\n",
      "Train Epoch: 0, mini-batch 11460 of 25000, training loss: 0.373526\n",
      "Train Epoch: 0, mini-batch 11470 of 25000, training loss: 0.023443\n",
      "Train Epoch: 0, mini-batch 11480 of 25000, training loss: 0.092059\n",
      "Train Epoch: 0, mini-batch 11490 of 25000, training loss: 0.690174\n",
      "Train Epoch: 0, mini-batch 11500 of 25000, training loss: 1.227216\n",
      "Train Epoch: 0, mini-batch 11510 of 25000, training loss: 0.457949\n",
      "Train Epoch: 0, mini-batch 11520 of 25000, training loss: 0.004562\n",
      "Train Epoch: 0, mini-batch 11530 of 25000, training loss: 0.011810\n",
      "Train Epoch: 0, mini-batch 11540 of 25000, training loss: 0.449301\n",
      "Train Epoch: 0, mini-batch 11550 of 25000, training loss: 0.036776\n",
      "Train Epoch: 0, mini-batch 11560 of 25000, training loss: 0.131903\n",
      "Train Epoch: 0, mini-batch 11570 of 25000, training loss: 0.023997\n",
      "Train Epoch: 0, mini-batch 11580 of 25000, training loss: 0.222343\n",
      "Train Epoch: 0, mini-batch 11590 of 25000, training loss: 0.045692\n",
      "Train Epoch: 0, mini-batch 11600 of 25000, training loss: 0.047555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 11610 of 25000, training loss: 1.663843\n",
      "Train Epoch: 0, mini-batch 11620 of 25000, training loss: 0.002781\n",
      "Train Epoch: 0, mini-batch 11630 of 25000, training loss: 0.079943\n",
      "Train Epoch: 0, mini-batch 11640 of 25000, training loss: 0.172699\n",
      "Train Epoch: 0, mini-batch 11650 of 25000, training loss: 0.000084\n",
      "Train Epoch: 0, mini-batch 11660 of 25000, training loss: 0.498539\n",
      "Train Epoch: 0, mini-batch 11670 of 25000, training loss: 0.016300\n",
      "Train Epoch: 0, mini-batch 11680 of 25000, training loss: 4.620917\n",
      "Train Epoch: 0, mini-batch 11690 of 25000, training loss: 0.007803\n",
      "Train Epoch: 0, mini-batch 11700 of 25000, training loss: 0.332415\n",
      "Train Epoch: 0, mini-batch 11710 of 25000, training loss: 0.073644\n",
      "Train Epoch: 0, mini-batch 11720 of 25000, training loss: 0.045147\n",
      "Train Epoch: 0, mini-batch 11730 of 25000, training loss: 0.013823\n",
      "Train Epoch: 0, mini-batch 11740 of 25000, training loss: 0.050757\n",
      "Train Epoch: 0, mini-batch 11750 of 25000, training loss: 0.258312\n",
      "Train Epoch: 0, mini-batch 11760 of 25000, training loss: 0.031126\n",
      "Train Epoch: 0, mini-batch 11770 of 25000, training loss: 1.953663\n",
      "Train Epoch: 0, mini-batch 11780 of 25000, training loss: 0.478188\n",
      "Train Epoch: 0, mini-batch 11790 of 25000, training loss: 2.166979\n",
      "Train Epoch: 0, mini-batch 11800 of 25000, training loss: 0.313378\n",
      "Train Epoch: 0, mini-batch 11810 of 25000, training loss: 0.073103\n",
      "Train Epoch: 0, mini-batch 11820 of 25000, training loss: 0.499632\n",
      "Train Epoch: 0, mini-batch 11830 of 25000, training loss: 0.005902\n",
      "Train Epoch: 0, mini-batch 11840 of 25000, training loss: 0.243779\n",
      "Train Epoch: 0, mini-batch 11850 of 25000, training loss: 0.017399\n",
      "Train Epoch: 0, mini-batch 11860 of 25000, training loss: 0.724865\n",
      "Train Epoch: 0, mini-batch 11870 of 25000, training loss: 0.070907\n",
      "Train Epoch: 0, mini-batch 11880 of 25000, training loss: 0.084165\n",
      "Train Epoch: 0, mini-batch 11890 of 25000, training loss: 0.043899\n",
      "Train Epoch: 0, mini-batch 11900 of 25000, training loss: 0.001110\n",
      "Train Epoch: 0, mini-batch 11910 of 25000, training loss: 0.003541\n",
      "Train Epoch: 0, mini-batch 11920 of 25000, training loss: 0.281157\n",
      "Train Epoch: 0, mini-batch 11930 of 25000, training loss: 0.345993\n",
      "Train Epoch: 0, mini-batch 11940 of 25000, training loss: 0.004537\n",
      "Train Epoch: 0, mini-batch 11950 of 25000, training loss: 0.236678\n",
      "Train Epoch: 0, mini-batch 11960 of 25000, training loss: 0.003271\n",
      "Train Epoch: 0, mini-batch 11970 of 25000, training loss: 0.208202\n",
      "Train Epoch: 0, mini-batch 11980 of 25000, training loss: 1.290833\n",
      "Train Epoch: 0, mini-batch 11990 of 25000, training loss: 0.000709\n",
      "Train Epoch: 0, mini-batch 12000 of 25000, training loss: 0.012613\n",
      "Train Epoch: 0, mini-batch 12010 of 25000, training loss: 0.090120\n",
      "Train Epoch: 0, mini-batch 12020 of 25000, training loss: 0.028059\n",
      "Train Epoch: 0, mini-batch 12030 of 25000, training loss: 0.999046\n",
      "Train Epoch: 0, mini-batch 12040 of 25000, training loss: 0.062548\n",
      "Train Epoch: 0, mini-batch 12050 of 25000, training loss: 1.973789\n",
      "Train Epoch: 0, mini-batch 12060 of 25000, training loss: 0.040423\n",
      "Train Epoch: 0, mini-batch 12070 of 25000, training loss: 0.718808\n",
      "Train Epoch: 0, mini-batch 12080 of 25000, training loss: 0.185144\n",
      "Train Epoch: 0, mini-batch 12090 of 25000, training loss: 1.011498\n",
      "Train Epoch: 0, mini-batch 12100 of 25000, training loss: 0.085121\n",
      "Train Epoch: 0, mini-batch 12110 of 25000, training loss: 0.104035\n",
      "Train Epoch: 0, mini-batch 12120 of 25000, training loss: 0.057078\n",
      "Train Epoch: 0, mini-batch 12130 of 25000, training loss: 0.081825\n",
      "Train Epoch: 0, mini-batch 12140 of 25000, training loss: 0.027843\n",
      "Train Epoch: 0, mini-batch 12150 of 25000, training loss: 0.008797\n",
      "Train Epoch: 0, mini-batch 12160 of 25000, training loss: 0.028636\n",
      "Train Epoch: 0, mini-batch 12170 of 25000, training loss: 0.508665\n",
      "Train Epoch: 0, mini-batch 12180 of 25000, training loss: 0.169067\n",
      "Train Epoch: 0, mini-batch 12190 of 25000, training loss: 0.263398\n",
      "Train Epoch: 0, mini-batch 12200 of 25000, training loss: 3.052902\n",
      "Train Epoch: 0, mini-batch 12210 of 25000, training loss: 0.053249\n",
      "Train Epoch: 0, mini-batch 12220 of 25000, training loss: 0.122162\n",
      "Train Epoch: 0, mini-batch 12230 of 25000, training loss: 0.602474\n",
      "Train Epoch: 0, mini-batch 12240 of 25000, training loss: 0.020049\n",
      "Train Epoch: 0, mini-batch 12250 of 25000, training loss: 0.540342\n",
      "Train Epoch: 0, mini-batch 12260 of 25000, training loss: 0.048433\n",
      "Train Epoch: 0, mini-batch 12270 of 25000, training loss: 0.037468\n",
      "Train Epoch: 0, mini-batch 12280 of 25000, training loss: 0.103426\n",
      "Train Epoch: 0, mini-batch 12290 of 25000, training loss: 2.069191\n",
      "Train Epoch: 0, mini-batch 12300 of 25000, training loss: 0.022605\n",
      "Train Epoch: 0, mini-batch 12310 of 25000, training loss: 0.074822\n",
      "Train Epoch: 0, mini-batch 12320 of 25000, training loss: 0.081111\n",
      "Train Epoch: 0, mini-batch 12330 of 25000, training loss: 0.448514\n",
      "Train Epoch: 0, mini-batch 12340 of 25000, training loss: 2.754206\n",
      "Train Epoch: 0, mini-batch 12350 of 25000, training loss: 0.029437\n",
      "Train Epoch: 0, mini-batch 12360 of 25000, training loss: 0.092824\n",
      "Train Epoch: 0, mini-batch 12370 of 25000, training loss: 0.059379\n",
      "Train Epoch: 0, mini-batch 12380 of 25000, training loss: 0.055875\n",
      "Train Epoch: 0, mini-batch 12390 of 25000, training loss: 0.084442\n",
      "Train Epoch: 0, mini-batch 12400 of 25000, training loss: 0.132823\n",
      "Train Epoch: 0, mini-batch 12410 of 25000, training loss: 1.262944\n",
      "Train Epoch: 0, mini-batch 12420 of 25000, training loss: 0.072771\n",
      "Train Epoch: 0, mini-batch 12430 of 25000, training loss: 0.334954\n",
      "Train Epoch: 0, mini-batch 12440 of 25000, training loss: 2.367393\n",
      "Train Epoch: 0, mini-batch 12450 of 25000, training loss: 0.586219\n",
      "Train Epoch: 0, mini-batch 12460 of 25000, training loss: 0.071816\n",
      "Train Epoch: 0, mini-batch 12470 of 25000, training loss: 0.256013\n",
      "Train Epoch: 0, mini-batch 12480 of 25000, training loss: 0.794263\n",
      "Train Epoch: 0, mini-batch 12490 of 25000, training loss: 0.728139\n",
      "Train Epoch: 0, mini-batch 12500 of 25000, training loss: 0.534797\n",
      "Train Epoch: 0, mini-batch 12510 of 25000, training loss: 0.173134\n",
      "Train Epoch: 0, mini-batch 12520 of 25000, training loss: 0.110667\n",
      "Train Epoch: 0, mini-batch 12530 of 25000, training loss: 0.012268\n",
      "Train Epoch: 0, mini-batch 12540 of 25000, training loss: 0.167887\n",
      "Train Epoch: 0, mini-batch 12550 of 25000, training loss: 0.280221\n",
      "Train Epoch: 0, mini-batch 12560 of 25000, training loss: 0.251057\n",
      "Train Epoch: 0, mini-batch 12570 of 25000, training loss: 0.647594\n",
      "Train Epoch: 0, mini-batch 12580 of 25000, training loss: 0.085129\n",
      "Train Epoch: 0, mini-batch 12590 of 25000, training loss: 0.204013\n",
      "Train Epoch: 0, mini-batch 12600 of 25000, training loss: 2.678482\n",
      "Train Epoch: 0, mini-batch 12610 of 25000, training loss: 0.075939\n",
      "Train Epoch: 0, mini-batch 12620 of 25000, training loss: 0.858901\n",
      "Train Epoch: 0, mini-batch 12630 of 25000, training loss: 0.099500\n",
      "Train Epoch: 0, mini-batch 12640 of 25000, training loss: 0.193245\n",
      "Train Epoch: 0, mini-batch 12650 of 25000, training loss: 1.100868\n",
      "Train Epoch: 0, mini-batch 12660 of 25000, training loss: 0.188032\n",
      "Train Epoch: 0, mini-batch 12670 of 25000, training loss: 0.662625\n",
      "Train Epoch: 0, mini-batch 12680 of 25000, training loss: 0.101135\n",
      "Train Epoch: 0, mini-batch 12690 of 25000, training loss: 0.683067\n",
      "Train Epoch: 0, mini-batch 12700 of 25000, training loss: 0.020461\n",
      "Train Epoch: 0, mini-batch 12710 of 25000, training loss: 0.036913\n",
      "Train Epoch: 0, mini-batch 12720 of 25000, training loss: 0.066923\n",
      "Train Epoch: 0, mini-batch 12730 of 25000, training loss: 0.040275\n",
      "Train Epoch: 0, mini-batch 12740 of 25000, training loss: 0.000626\n",
      "Train Epoch: 0, mini-batch 12750 of 25000, training loss: 2.387649\n",
      "Train Epoch: 0, mini-batch 12760 of 25000, training loss: 0.014272\n",
      "Train Epoch: 0, mini-batch 12770 of 25000, training loss: 0.009106\n",
      "Train Epoch: 0, mini-batch 12780 of 25000, training loss: 0.005737\n",
      "Train Epoch: 0, mini-batch 12790 of 25000, training loss: 0.324696\n",
      "Train Epoch: 0, mini-batch 12800 of 25000, training loss: 0.737918\n",
      "Train Epoch: 0, mini-batch 12810 of 25000, training loss: 0.035561\n",
      "Train Epoch: 0, mini-batch 12820 of 25000, training loss: 0.072800\n",
      "Train Epoch: 0, mini-batch 12830 of 25000, training loss: 1.755330\n",
      "Train Epoch: 0, mini-batch 12840 of 25000, training loss: 0.630857\n",
      "Train Epoch: 0, mini-batch 12850 of 25000, training loss: 0.112470\n",
      "Train Epoch: 0, mini-batch 12860 of 25000, training loss: 0.021413\n",
      "Train Epoch: 0, mini-batch 12870 of 25000, training loss: 0.142157\n",
      "Train Epoch: 0, mini-batch 12880 of 25000, training loss: 0.983096\n",
      "Train Epoch: 0, mini-batch 12890 of 25000, training loss: 0.008251\n",
      "Train Epoch: 0, mini-batch 12900 of 25000, training loss: 0.105581\n",
      "Train Epoch: 0, mini-batch 12910 of 25000, training loss: 0.205573\n",
      "Train Epoch: 0, mini-batch 12920 of 25000, training loss: 1.686130\n",
      "Train Epoch: 0, mini-batch 12930 of 25000, training loss: 0.080447\n",
      "Train Epoch: 0, mini-batch 12940 of 25000, training loss: 0.044944\n",
      "Train Epoch: 0, mini-batch 12950 of 25000, training loss: 0.064534\n",
      "Train Epoch: 0, mini-batch 12960 of 25000, training loss: 0.745038\n",
      "Train Epoch: 0, mini-batch 12970 of 25000, training loss: 0.032963\n",
      "Train Epoch: 0, mini-batch 12980 of 25000, training loss: 0.024141\n",
      "Train Epoch: 0, mini-batch 12990 of 25000, training loss: 0.637553\n",
      "Train Epoch: 0, mini-batch 13000 of 25000, training loss: 0.110183\n",
      "Train Epoch: 0, mini-batch 13010 of 25000, training loss: 0.026529\n",
      "Train Epoch: 0, mini-batch 13020 of 25000, training loss: 0.011941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 13030 of 25000, training loss: 0.007072\n",
      "Train Epoch: 0, mini-batch 13040 of 25000, training loss: 0.840688\n",
      "Train Epoch: 0, mini-batch 13050 of 25000, training loss: 0.381166\n",
      "Train Epoch: 0, mini-batch 13060 of 25000, training loss: 0.014791\n",
      "Train Epoch: 0, mini-batch 13070 of 25000, training loss: 0.122918\n",
      "Train Epoch: 0, mini-batch 13080 of 25000, training loss: 0.040537\n",
      "Train Epoch: 0, mini-batch 13090 of 25000, training loss: 0.199675\n",
      "Train Epoch: 0, mini-batch 13100 of 25000, training loss: 0.628531\n",
      "Train Epoch: 0, mini-batch 13110 of 25000, training loss: 0.330659\n",
      "Train Epoch: 0, mini-batch 13120 of 25000, training loss: 0.155867\n",
      "Train Epoch: 0, mini-batch 13130 of 25000, training loss: 0.085374\n",
      "Train Epoch: 0, mini-batch 13140 of 25000, training loss: 0.488998\n",
      "Train Epoch: 0, mini-batch 13150 of 25000, training loss: 0.009565\n",
      "Train Epoch: 0, mini-batch 13160 of 25000, training loss: 0.021618\n",
      "Train Epoch: 0, mini-batch 13170 of 25000, training loss: 0.054326\n",
      "Train Epoch: 0, mini-batch 13180 of 25000, training loss: 1.350978\n",
      "Train Epoch: 0, mini-batch 13190 of 25000, training loss: 0.054233\n",
      "Train Epoch: 0, mini-batch 13200 of 25000, training loss: 0.008035\n",
      "Train Epoch: 0, mini-batch 13210 of 25000, training loss: 0.044824\n",
      "Train Epoch: 0, mini-batch 13220 of 25000, training loss: 0.138118\n",
      "Train Epoch: 0, mini-batch 13230 of 25000, training loss: 0.068995\n",
      "Train Epoch: 0, mini-batch 13240 of 25000, training loss: 0.074342\n",
      "Train Epoch: 0, mini-batch 13250 of 25000, training loss: 0.224136\n",
      "Train Epoch: 0, mini-batch 13260 of 25000, training loss: 1.363714\n",
      "Train Epoch: 0, mini-batch 13270 of 25000, training loss: 0.121011\n",
      "Train Epoch: 0, mini-batch 13280 of 25000, training loss: 0.209445\n",
      "Train Epoch: 0, mini-batch 13290 of 25000, training loss: 0.085011\n",
      "Train Epoch: 0, mini-batch 13300 of 25000, training loss: 0.010849\n",
      "Train Epoch: 0, mini-batch 13310 of 25000, training loss: 0.053192\n",
      "Train Epoch: 0, mini-batch 13320 of 25000, training loss: 0.098990\n",
      "Train Epoch: 0, mini-batch 13330 of 25000, training loss: 0.135038\n",
      "Train Epoch: 0, mini-batch 13340 of 25000, training loss: 0.153032\n",
      "Train Epoch: 0, mini-batch 13350 of 25000, training loss: 0.052328\n",
      "Train Epoch: 0, mini-batch 13360 of 25000, training loss: 3.799932\n",
      "Train Epoch: 0, mini-batch 13370 of 25000, training loss: 0.029093\n",
      "Train Epoch: 0, mini-batch 13380 of 25000, training loss: 0.016558\n",
      "Train Epoch: 0, mini-batch 13390 of 25000, training loss: 1.337678\n",
      "Train Epoch: 0, mini-batch 13400 of 25000, training loss: 0.037410\n",
      "Train Epoch: 0, mini-batch 13410 of 25000, training loss: 0.142178\n",
      "Train Epoch: 0, mini-batch 13420 of 25000, training loss: 0.090280\n",
      "Train Epoch: 0, mini-batch 13430 of 25000, training loss: 0.046584\n",
      "Train Epoch: 0, mini-batch 13440 of 25000, training loss: 0.018095\n",
      "Train Epoch: 0, mini-batch 13450 of 25000, training loss: 0.010804\n",
      "Train Epoch: 0, mini-batch 13460 of 25000, training loss: 0.016625\n",
      "Train Epoch: 0, mini-batch 13470 of 25000, training loss: 0.207454\n",
      "Train Epoch: 0, mini-batch 13480 of 25000, training loss: 0.041996\n",
      "Train Epoch: 0, mini-batch 13490 of 25000, training loss: 0.011383\n",
      "Train Epoch: 0, mini-batch 13500 of 25000, training loss: 0.219718\n",
      "Train Epoch: 0, mini-batch 13510 of 25000, training loss: 0.149681\n",
      "Train Epoch: 0, mini-batch 13520 of 25000, training loss: 2.055172\n",
      "Train Epoch: 0, mini-batch 13530 of 25000, training loss: 1.029759\n",
      "Train Epoch: 0, mini-batch 13540 of 25000, training loss: 0.031135\n",
      "Train Epoch: 0, mini-batch 13550 of 25000, training loss: 0.209694\n",
      "Train Epoch: 0, mini-batch 13560 of 25000, training loss: 0.041895\n",
      "Train Epoch: 0, mini-batch 13570 of 25000, training loss: 0.595674\n",
      "Train Epoch: 0, mini-batch 13580 of 25000, training loss: 0.051750\n",
      "Train Epoch: 0, mini-batch 13590 of 25000, training loss: 0.024492\n",
      "Train Epoch: 0, mini-batch 13600 of 25000, training loss: 0.016141\n",
      "Train Epoch: 0, mini-batch 13610 of 25000, training loss: 0.453828\n",
      "Train Epoch: 0, mini-batch 13620 of 25000, training loss: 0.015613\n",
      "Train Epoch: 0, mini-batch 13630 of 25000, training loss: 0.016377\n",
      "Train Epoch: 0, mini-batch 13640 of 25000, training loss: 0.810272\n",
      "Train Epoch: 0, mini-batch 13650 of 25000, training loss: 0.054468\n",
      "Train Epoch: 0, mini-batch 13660 of 25000, training loss: 0.162887\n",
      "Train Epoch: 0, mini-batch 13670 of 25000, training loss: 0.424422\n",
      "Train Epoch: 0, mini-batch 13680 of 25000, training loss: 0.065271\n",
      "Train Epoch: 0, mini-batch 13690 of 25000, training loss: 0.058035\n",
      "Train Epoch: 0, mini-batch 13700 of 25000, training loss: 0.058677\n",
      "Train Epoch: 0, mini-batch 13710 of 25000, training loss: 0.004641\n",
      "Train Epoch: 0, mini-batch 13720 of 25000, training loss: 0.110162\n",
      "Train Epoch: 0, mini-batch 13730 of 25000, training loss: 0.063664\n",
      "Train Epoch: 0, mini-batch 13740 of 25000, training loss: 0.029334\n",
      "Train Epoch: 0, mini-batch 13750 of 25000, training loss: 0.000593\n",
      "Train Epoch: 0, mini-batch 13760 of 25000, training loss: 0.675967\n",
      "Train Epoch: 0, mini-batch 13770 of 25000, training loss: 0.189779\n",
      "Train Epoch: 0, mini-batch 13780 of 25000, training loss: 1.479760\n",
      "Train Epoch: 0, mini-batch 13790 of 25000, training loss: 0.365931\n",
      "Train Epoch: 0, mini-batch 13800 of 25000, training loss: 1.005970\n",
      "Train Epoch: 0, mini-batch 13810 of 25000, training loss: 0.006688\n",
      "Train Epoch: 0, mini-batch 13820 of 25000, training loss: 0.021871\n",
      "Train Epoch: 0, mini-batch 13830 of 25000, training loss: 0.030402\n",
      "Train Epoch: 0, mini-batch 13840 of 25000, training loss: 0.009677\n",
      "Train Epoch: 0, mini-batch 13850 of 25000, training loss: 0.942408\n",
      "Train Epoch: 0, mini-batch 13860 of 25000, training loss: 0.421866\n",
      "Train Epoch: 0, mini-batch 13870 of 25000, training loss: 0.180467\n",
      "Train Epoch: 0, mini-batch 13880 of 25000, training loss: 0.008654\n",
      "Train Epoch: 0, mini-batch 13890 of 25000, training loss: 0.034748\n",
      "Train Epoch: 0, mini-batch 13900 of 25000, training loss: 0.045558\n",
      "Train Epoch: 0, mini-batch 13910 of 25000, training loss: 0.006797\n",
      "Train Epoch: 0, mini-batch 13920 of 25000, training loss: 0.074604\n",
      "Train Epoch: 0, mini-batch 13930 of 25000, training loss: 0.005160\n",
      "Train Epoch: 0, mini-batch 13940 of 25000, training loss: 1.196637\n",
      "Train Epoch: 0, mini-batch 13950 of 25000, training loss: 0.428412\n",
      "Train Epoch: 0, mini-batch 13960 of 25000, training loss: 0.182114\n",
      "Train Epoch: 0, mini-batch 13970 of 25000, training loss: 2.463850\n",
      "Train Epoch: 0, mini-batch 13980 of 25000, training loss: 0.347221\n",
      "Train Epoch: 0, mini-batch 13990 of 25000, training loss: 1.891924\n",
      "Train Epoch: 0, mini-batch 14000 of 25000, training loss: 0.168356\n",
      "Train Epoch: 0, mini-batch 14010 of 25000, training loss: 0.227983\n",
      "Train Epoch: 0, mini-batch 14020 of 25000, training loss: 0.033679\n",
      "Train Epoch: 0, mini-batch 14030 of 25000, training loss: 0.018687\n",
      "Train Epoch: 0, mini-batch 14040 of 25000, training loss: 0.644276\n",
      "Train Epoch: 0, mini-batch 14050 of 25000, training loss: 0.546810\n",
      "Train Epoch: 0, mini-batch 14060 of 25000, training loss: 0.060705\n",
      "Train Epoch: 0, mini-batch 14070 of 25000, training loss: 0.638620\n",
      "Train Epoch: 0, mini-batch 14080 of 25000, training loss: 0.549100\n",
      "Train Epoch: 0, mini-batch 14090 of 25000, training loss: 0.227311\n",
      "Train Epoch: 0, mini-batch 14100 of 25000, training loss: 1.598433\n",
      "Train Epoch: 0, mini-batch 14110 of 25000, training loss: 0.193925\n",
      "Train Epoch: 0, mini-batch 14120 of 25000, training loss: 0.082088\n",
      "Train Epoch: 0, mini-batch 14130 of 25000, training loss: 0.018412\n",
      "Train Epoch: 0, mini-batch 14140 of 25000, training loss: 0.033618\n",
      "Train Epoch: 0, mini-batch 14150 of 25000, training loss: 0.011606\n",
      "Train Epoch: 0, mini-batch 14160 of 25000, training loss: 4.899904\n",
      "Train Epoch: 0, mini-batch 14170 of 25000, training loss: 1.421985\n",
      "Train Epoch: 0, mini-batch 14180 of 25000, training loss: 0.015791\n",
      "Train Epoch: 0, mini-batch 14190 of 25000, training loss: 0.833338\n",
      "Train Epoch: 0, mini-batch 14200 of 25000, training loss: 0.188731\n",
      "Train Epoch: 0, mini-batch 14210 of 25000, training loss: 0.109267\n",
      "Train Epoch: 0, mini-batch 14220 of 25000, training loss: 6.114052\n",
      "Train Epoch: 0, mini-batch 14230 of 25000, training loss: 0.258837\n",
      "Train Epoch: 0, mini-batch 14240 of 25000, training loss: 0.247686\n",
      "Train Epoch: 0, mini-batch 14250 of 25000, training loss: 0.042129\n",
      "Train Epoch: 0, mini-batch 14260 of 25000, training loss: 1.900883\n",
      "Train Epoch: 0, mini-batch 14270 of 25000, training loss: 1.246216\n",
      "Train Epoch: 0, mini-batch 14280 of 25000, training loss: 0.252538\n",
      "Train Epoch: 0, mini-batch 14290 of 25000, training loss: 0.000184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 14300 of 25000, training loss: 0.906031\n",
      "Train Epoch: 0, mini-batch 14310 of 25000, training loss: 0.003332\n",
      "Train Epoch: 0, mini-batch 14320 of 25000, training loss: 0.660801\n",
      "Train Epoch: 0, mini-batch 14330 of 25000, training loss: 0.096784\n",
      "Train Epoch: 0, mini-batch 14340 of 25000, training loss: 0.000538\n",
      "Train Epoch: 0, mini-batch 14350 of 25000, training loss: 0.059953\n",
      "Train Epoch: 0, mini-batch 14360 of 25000, training loss: 1.561834\n",
      "Train Epoch: 0, mini-batch 14370 of 25000, training loss: 0.071790\n",
      "Train Epoch: 0, mini-batch 14380 of 25000, training loss: 0.017299\n",
      "Train Epoch: 0, mini-batch 14390 of 25000, training loss: 0.005296\n",
      "Train Epoch: 0, mini-batch 14400 of 25000, training loss: 0.421634\n",
      "Train Epoch: 0, mini-batch 14410 of 25000, training loss: 0.067129\n",
      "Train Epoch: 0, mini-batch 14420 of 25000, training loss: 0.675174\n",
      "Train Epoch: 0, mini-batch 14430 of 25000, training loss: 0.005837\n",
      "Train Epoch: 0, mini-batch 14440 of 25000, training loss: 0.016158\n",
      "Train Epoch: 0, mini-batch 14450 of 25000, training loss: 0.101746\n",
      "Train Epoch: 0, mini-batch 14460 of 25000, training loss: 0.065932\n",
      "Train Epoch: 0, mini-batch 14470 of 25000, training loss: 0.287127\n",
      "Train Epoch: 0, mini-batch 14480 of 25000, training loss: 0.001702\n",
      "Train Epoch: 0, mini-batch 14490 of 25000, training loss: 0.242481\n",
      "Train Epoch: 0, mini-batch 14500 of 25000, training loss: 0.545621\n",
      "Train Epoch: 0, mini-batch 14510 of 25000, training loss: 5.031487\n",
      "Train Epoch: 0, mini-batch 14520 of 25000, training loss: 0.408677\n",
      "Train Epoch: 0, mini-batch 14530 of 25000, training loss: 0.038142\n",
      "Train Epoch: 0, mini-batch 14540 of 25000, training loss: 0.304029\n",
      "Train Epoch: 0, mini-batch 14550 of 25000, training loss: 0.021822\n",
      "Train Epoch: 0, mini-batch 14560 of 25000, training loss: 0.156071\n",
      "Train Epoch: 0, mini-batch 14570 of 25000, training loss: 0.048373\n",
      "Train Epoch: 0, mini-batch 14580 of 25000, training loss: 0.138202\n",
      "Train Epoch: 0, mini-batch 14590 of 25000, training loss: 0.045671\n",
      "Train Epoch: 0, mini-batch 14600 of 25000, training loss: 1.736173\n",
      "Train Epoch: 0, mini-batch 14610 of 25000, training loss: 0.225707\n",
      "Train Epoch: 0, mini-batch 14620 of 25000, training loss: 1.111786\n",
      "Train Epoch: 0, mini-batch 14630 of 25000, training loss: 0.049501\n",
      "Train Epoch: 0, mini-batch 14640 of 25000, training loss: 0.026052\n",
      "Train Epoch: 0, mini-batch 14650 of 25000, training loss: 1.156211\n",
      "Train Epoch: 0, mini-batch 14660 of 25000, training loss: 0.060036\n",
      "Train Epoch: 0, mini-batch 14670 of 25000, training loss: 0.400793\n",
      "Train Epoch: 0, mini-batch 14680 of 25000, training loss: 0.581966\n",
      "Train Epoch: 0, mini-batch 14690 of 25000, training loss: 0.013872\n",
      "Train Epoch: 0, mini-batch 14700 of 25000, training loss: 0.125911\n",
      "Train Epoch: 0, mini-batch 14710 of 25000, training loss: 0.047438\n",
      "Train Epoch: 0, mini-batch 14720 of 25000, training loss: 1.493836\n",
      "Train Epoch: 0, mini-batch 14730 of 25000, training loss: 0.186219\n",
      "Train Epoch: 0, mini-batch 14740 of 25000, training loss: 0.076724\n",
      "Train Epoch: 0, mini-batch 14750 of 25000, training loss: 0.451059\n",
      "Train Epoch: 0, mini-batch 14760 of 25000, training loss: 0.072779\n",
      "Train Epoch: 0, mini-batch 14770 of 25000, training loss: 0.007934\n",
      "Train Epoch: 0, mini-batch 14780 of 25000, training loss: 1.399106\n",
      "Train Epoch: 0, mini-batch 14790 of 25000, training loss: 0.028633\n",
      "Train Epoch: 0, mini-batch 14800 of 25000, training loss: 0.009287\n",
      "Train Epoch: 0, mini-batch 14810 of 25000, training loss: 0.024342\n",
      "Train Epoch: 0, mini-batch 14820 of 25000, training loss: 0.327699\n",
      "Train Epoch: 0, mini-batch 14830 of 25000, training loss: 0.186307\n",
      "Train Epoch: 0, mini-batch 14840 of 25000, training loss: 0.166483\n",
      "Train Epoch: 0, mini-batch 14850 of 25000, training loss: 0.223736\n",
      "Train Epoch: 0, mini-batch 14860 of 25000, training loss: 0.029613\n",
      "Train Epoch: 0, mini-batch 14870 of 25000, training loss: 0.020172\n",
      "Train Epoch: 0, mini-batch 14880 of 25000, training loss: 0.096881\n",
      "Train Epoch: 0, mini-batch 14890 of 25000, training loss: 1.012125\n",
      "Train Epoch: 0, mini-batch 14900 of 25000, training loss: 0.085907\n",
      "Train Epoch: 0, mini-batch 14910 of 25000, training loss: 1.598300\n",
      "Train Epoch: 0, mini-batch 14920 of 25000, training loss: 0.490360\n",
      "Train Epoch: 0, mini-batch 14930 of 25000, training loss: 0.168759\n",
      "Train Epoch: 0, mini-batch 14940 of 25000, training loss: 0.111051\n",
      "Train Epoch: 0, mini-batch 14950 of 25000, training loss: 1.363038\n",
      "Train Epoch: 0, mini-batch 14960 of 25000, training loss: 0.000011\n",
      "Train Epoch: 0, mini-batch 14970 of 25000, training loss: 0.013827\n",
      "Train Epoch: 0, mini-batch 14980 of 25000, training loss: 0.033585\n",
      "Train Epoch: 0, mini-batch 14990 of 25000, training loss: 0.005769\n",
      "Train Epoch: 0, mini-batch 15000 of 25000, training loss: 0.410071\n",
      "Train Epoch: 0, mini-batch 15010 of 25000, training loss: 0.863358\n",
      "Train Epoch: 0, mini-batch 15020 of 25000, training loss: 0.034298\n",
      "Train Epoch: 0, mini-batch 15030 of 25000, training loss: 0.009022\n",
      "Train Epoch: 0, mini-batch 15040 of 25000, training loss: 0.052819\n",
      "Train Epoch: 0, mini-batch 15050 of 25000, training loss: 0.140226\n",
      "Train Epoch: 0, mini-batch 15060 of 25000, training loss: 0.982852\n",
      "Train Epoch: 0, mini-batch 15070 of 25000, training loss: 0.041602\n",
      "Train Epoch: 0, mini-batch 15080 of 25000, training loss: 2.062290\n",
      "Train Epoch: 0, mini-batch 15090 of 25000, training loss: 0.054090\n",
      "Train Epoch: 0, mini-batch 15100 of 25000, training loss: 0.829143\n",
      "Train Epoch: 0, mini-batch 15110 of 25000, training loss: 0.017434\n",
      "Train Epoch: 0, mini-batch 15120 of 25000, training loss: 0.228105\n",
      "Train Epoch: 0, mini-batch 15130 of 25000, training loss: 0.170160\n",
      "Train Epoch: 0, mini-batch 15140 of 25000, training loss: 0.005569\n",
      "Train Epoch: 0, mini-batch 15150 of 25000, training loss: 0.132143\n",
      "Train Epoch: 0, mini-batch 15160 of 25000, training loss: 0.264574\n",
      "Train Epoch: 0, mini-batch 15170 of 25000, training loss: 0.512598\n",
      "Train Epoch: 0, mini-batch 15180 of 25000, training loss: 0.859800\n",
      "Train Epoch: 0, mini-batch 15190 of 25000, training loss: 1.006764\n",
      "Train Epoch: 0, mini-batch 15200 of 25000, training loss: 0.156388\n",
      "Train Epoch: 0, mini-batch 15210 of 25000, training loss: 0.015579\n",
      "Train Epoch: 0, mini-batch 15220 of 25000, training loss: 0.076869\n",
      "Train Epoch: 0, mini-batch 15230 of 25000, training loss: 0.034275\n",
      "Train Epoch: 0, mini-batch 15240 of 25000, training loss: 0.233619\n",
      "Train Epoch: 0, mini-batch 15250 of 25000, training loss: 0.156683\n",
      "Train Epoch: 0, mini-batch 15260 of 25000, training loss: 0.521923\n",
      "Train Epoch: 0, mini-batch 15270 of 25000, training loss: 2.097843\n",
      "Train Epoch: 0, mini-batch 15280 of 25000, training loss: 0.018110\n",
      "Train Epoch: 0, mini-batch 15290 of 25000, training loss: 0.025822\n",
      "Train Epoch: 0, mini-batch 15300 of 25000, training loss: 0.013027\n",
      "Train Epoch: 0, mini-batch 15310 of 25000, training loss: 0.213999\n",
      "Train Epoch: 0, mini-batch 15320 of 25000, training loss: 0.264580\n",
      "Train Epoch: 0, mini-batch 15330 of 25000, training loss: 0.000107\n",
      "Train Epoch: 0, mini-batch 15340 of 25000, training loss: 0.032997\n",
      "Train Epoch: 0, mini-batch 15350 of 25000, training loss: 0.460227\n",
      "Train Epoch: 0, mini-batch 15360 of 25000, training loss: 0.024008\n",
      "Train Epoch: 0, mini-batch 15370 of 25000, training loss: 2.105788\n",
      "Train Epoch: 0, mini-batch 15380 of 25000, training loss: 0.048299\n",
      "Train Epoch: 0, mini-batch 15390 of 25000, training loss: 0.569465\n",
      "Train Epoch: 0, mini-batch 15400 of 25000, training loss: 0.219660\n",
      "Train Epoch: 0, mini-batch 15410 of 25000, training loss: 0.239340\n",
      "Train Epoch: 0, mini-batch 15420 of 25000, training loss: 0.066827\n",
      "Train Epoch: 0, mini-batch 15430 of 25000, training loss: 0.003350\n",
      "Train Epoch: 0, mini-batch 15440 of 25000, training loss: 0.019511\n",
      "Train Epoch: 0, mini-batch 15450 of 25000, training loss: 0.097692\n",
      "Train Epoch: 0, mini-batch 15460 of 25000, training loss: 0.003910\n",
      "Train Epoch: 0, mini-batch 15470 of 25000, training loss: 0.067837\n",
      "Train Epoch: 0, mini-batch 15480 of 25000, training loss: 0.026272\n",
      "Train Epoch: 0, mini-batch 15490 of 25000, training loss: 0.650810\n",
      "Train Epoch: 0, mini-batch 15500 of 25000, training loss: 0.008560\n",
      "Train Epoch: 0, mini-batch 15510 of 25000, training loss: 0.250920\n",
      "Train Epoch: 0, mini-batch 15520 of 25000, training loss: 0.021674\n",
      "Train Epoch: 0, mini-batch 15530 of 25000, training loss: 0.018482\n",
      "Train Epoch: 0, mini-batch 15540 of 25000, training loss: 0.042591\n",
      "Train Epoch: 0, mini-batch 15550 of 25000, training loss: 0.308761\n",
      "Train Epoch: 0, mini-batch 15560 of 25000, training loss: 1.265039\n",
      "Train Epoch: 0, mini-batch 15570 of 25000, training loss: 0.591628\n",
      "Train Epoch: 0, mini-batch 15580 of 25000, training loss: 0.012182\n",
      "Train Epoch: 0, mini-batch 15590 of 25000, training loss: 0.023149\n",
      "Train Epoch: 0, mini-batch 15600 of 25000, training loss: 0.140697\n",
      "Train Epoch: 0, mini-batch 15610 of 25000, training loss: 0.135091\n",
      "Train Epoch: 0, mini-batch 15620 of 25000, training loss: 3.955771\n",
      "Train Epoch: 0, mini-batch 15630 of 25000, training loss: 0.045770\n",
      "Train Epoch: 0, mini-batch 15640 of 25000, training loss: 5.223677\n",
      "Train Epoch: 0, mini-batch 15650 of 25000, training loss: 0.183297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 15660 of 25000, training loss: 0.032134\n",
      "Train Epoch: 0, mini-batch 15670 of 25000, training loss: 0.008799\n",
      "Train Epoch: 0, mini-batch 15680 of 25000, training loss: 0.167831\n",
      "Train Epoch: 0, mini-batch 15690 of 25000, training loss: 0.049764\n",
      "Train Epoch: 0, mini-batch 15700 of 25000, training loss: 0.002557\n",
      "Train Epoch: 0, mini-batch 15710 of 25000, training loss: 0.022602\n",
      "Train Epoch: 0, mini-batch 15720 of 25000, training loss: 0.028805\n",
      "Train Epoch: 0, mini-batch 15730 of 25000, training loss: 0.121387\n",
      "Train Epoch: 0, mini-batch 15740 of 25000, training loss: 0.103959\n",
      "Train Epoch: 0, mini-batch 15750 of 25000, training loss: 0.024588\n",
      "Train Epoch: 0, mini-batch 15760 of 25000, training loss: 0.070786\n",
      "Train Epoch: 0, mini-batch 15770 of 25000, training loss: 0.035964\n",
      "Train Epoch: 0, mini-batch 15780 of 25000, training loss: 0.136340\n",
      "Train Epoch: 0, mini-batch 15790 of 25000, training loss: 0.006177\n",
      "Train Epoch: 0, mini-batch 15800 of 25000, training loss: 4.909271\n",
      "Train Epoch: 0, mini-batch 15810 of 25000, training loss: 0.167039\n",
      "Train Epoch: 0, mini-batch 15820 of 25000, training loss: 0.184829\n",
      "Train Epoch: 0, mini-batch 15830 of 25000, training loss: 0.042056\n",
      "Train Epoch: 0, mini-batch 15840 of 25000, training loss: 0.056355\n",
      "Train Epoch: 0, mini-batch 15850 of 25000, training loss: 0.080163\n",
      "Train Epoch: 0, mini-batch 15860 of 25000, training loss: 0.153168\n",
      "Train Epoch: 0, mini-batch 15870 of 25000, training loss: 0.048338\n",
      "Train Epoch: 0, mini-batch 15880 of 25000, training loss: 0.172259\n",
      "Train Epoch: 0, mini-batch 15890 of 25000, training loss: 0.242522\n",
      "Train Epoch: 0, mini-batch 15900 of 25000, training loss: 0.742057\n",
      "Train Epoch: 0, mini-batch 15910 of 25000, training loss: 0.162857\n",
      "Train Epoch: 0, mini-batch 15920 of 25000, training loss: 0.062008\n",
      "Train Epoch: 0, mini-batch 15930 of 25000, training loss: 0.036962\n",
      "Train Epoch: 0, mini-batch 15940 of 25000, training loss: 0.082665\n",
      "Train Epoch: 0, mini-batch 15950 of 25000, training loss: 1.793154\n",
      "Train Epoch: 0, mini-batch 15960 of 25000, training loss: 0.009579\n",
      "Train Epoch: 0, mini-batch 15970 of 25000, training loss: 0.737002\n",
      "Train Epoch: 0, mini-batch 15980 of 25000, training loss: 0.300183\n",
      "Train Epoch: 0, mini-batch 15990 of 25000, training loss: 0.003515\n",
      "Train Epoch: 0, mini-batch 16000 of 25000, training loss: 0.395023\n",
      "Train Epoch: 0, mini-batch 16010 of 25000, training loss: 0.202678\n",
      "Train Epoch: 0, mini-batch 16020 of 25000, training loss: 0.410302\n",
      "Train Epoch: 0, mini-batch 16030 of 25000, training loss: 0.270335\n",
      "Train Epoch: 0, mini-batch 16040 of 25000, training loss: 0.018891\n",
      "Train Epoch: 0, mini-batch 16050 of 25000, training loss: 0.055252\n",
      "Train Epoch: 0, mini-batch 16060 of 25000, training loss: 0.064463\n",
      "Train Epoch: 0, mini-batch 16070 of 25000, training loss: 0.015913\n",
      "Train Epoch: 0, mini-batch 16080 of 25000, training loss: 0.012933\n",
      "Train Epoch: 0, mini-batch 16090 of 25000, training loss: 0.248699\n",
      "Train Epoch: 0, mini-batch 16100 of 25000, training loss: 0.034113\n",
      "Train Epoch: 0, mini-batch 16110 of 25000, training loss: 0.032561\n",
      "Train Epoch: 0, mini-batch 16120 of 25000, training loss: 1.027686\n",
      "Train Epoch: 0, mini-batch 16130 of 25000, training loss: 0.016300\n",
      "Train Epoch: 0, mini-batch 16140 of 25000, training loss: 0.160789\n",
      "Train Epoch: 0, mini-batch 16150 of 25000, training loss: 0.022747\n",
      "Train Epoch: 0, mini-batch 16160 of 25000, training loss: 0.077274\n",
      "Train Epoch: 0, mini-batch 16170 of 25000, training loss: 0.245054\n",
      "Train Epoch: 0, mini-batch 16180 of 25000, training loss: 0.161564\n",
      "Train Epoch: 0, mini-batch 16190 of 25000, training loss: 0.076615\n",
      "Train Epoch: 0, mini-batch 16200 of 25000, training loss: 0.057229\n",
      "Train Epoch: 0, mini-batch 16210 of 25000, training loss: 0.019177\n",
      "Train Epoch: 0, mini-batch 16220 of 25000, training loss: 0.449887\n",
      "Train Epoch: 0, mini-batch 16230 of 25000, training loss: 0.124021\n",
      "Train Epoch: 0, mini-batch 16240 of 25000, training loss: 0.173224\n",
      "Train Epoch: 0, mini-batch 16250 of 25000, training loss: 0.119675\n",
      "Train Epoch: 0, mini-batch 16260 of 25000, training loss: 0.008795\n",
      "Train Epoch: 0, mini-batch 16270 of 25000, training loss: 0.069178\n",
      "Train Epoch: 0, mini-batch 16280 of 25000, training loss: 0.021067\n",
      "Train Epoch: 0, mini-batch 16290 of 25000, training loss: 0.073930\n",
      "Train Epoch: 0, mini-batch 16300 of 25000, training loss: 0.012440\n",
      "Train Epoch: 0, mini-batch 16310 of 25000, training loss: 0.085964\n",
      "Train Epoch: 0, mini-batch 16320 of 25000, training loss: 0.171072\n",
      "Train Epoch: 0, mini-batch 16330 of 25000, training loss: 0.034406\n",
      "Train Epoch: 0, mini-batch 16340 of 25000, training loss: 0.261400\n",
      "Train Epoch: 0, mini-batch 16350 of 25000, training loss: 0.124309\n",
      "Train Epoch: 0, mini-batch 16360 of 25000, training loss: 0.518486\n",
      "Train Epoch: 0, mini-batch 16370 of 25000, training loss: 0.147955\n",
      "Train Epoch: 0, mini-batch 16380 of 25000, training loss: 0.066315\n",
      "Train Epoch: 0, mini-batch 16390 of 25000, training loss: 0.628969\n",
      "Train Epoch: 0, mini-batch 16400 of 25000, training loss: 0.005379\n",
      "Train Epoch: 0, mini-batch 16410 of 25000, training loss: 0.076197\n",
      "Train Epoch: 0, mini-batch 16420 of 25000, training loss: 0.072735\n",
      "Train Epoch: 0, mini-batch 16430 of 25000, training loss: 0.112014\n",
      "Train Epoch: 0, mini-batch 16440 of 25000, training loss: 0.072597\n",
      "Train Epoch: 0, mini-batch 16450 of 25000, training loss: 0.075627\n",
      "Train Epoch: 0, mini-batch 16460 of 25000, training loss: 0.304746\n",
      "Train Epoch: 0, mini-batch 16470 of 25000, training loss: 0.002516\n",
      "Train Epoch: 0, mini-batch 16480 of 25000, training loss: 0.566735\n",
      "Train Epoch: 0, mini-batch 16490 of 25000, training loss: 0.007105\n",
      "Train Epoch: 0, mini-batch 16500 of 25000, training loss: 1.761458\n",
      "Train Epoch: 0, mini-batch 16510 of 25000, training loss: 0.070573\n",
      "Train Epoch: 0, mini-batch 16520 of 25000, training loss: 1.987024\n",
      "Train Epoch: 0, mini-batch 16530 of 25000, training loss: 0.471708\n",
      "Train Epoch: 0, mini-batch 16540 of 25000, training loss: 0.012431\n",
      "Train Epoch: 0, mini-batch 16550 of 25000, training loss: 0.142852\n",
      "Train Epoch: 0, mini-batch 16560 of 25000, training loss: 0.024261\n",
      "Train Epoch: 0, mini-batch 16570 of 25000, training loss: 1.263237\n",
      "Train Epoch: 0, mini-batch 16580 of 25000, training loss: 0.200323\n",
      "Train Epoch: 0, mini-batch 16590 of 25000, training loss: 0.470257\n",
      "Train Epoch: 0, mini-batch 16600 of 25000, training loss: 0.106610\n",
      "Train Epoch: 0, mini-batch 16610 of 25000, training loss: 0.267268\n",
      "Train Epoch: 0, mini-batch 16620 of 25000, training loss: 0.085034\n",
      "Train Epoch: 0, mini-batch 16630 of 25000, training loss: 0.024552\n",
      "Train Epoch: 0, mini-batch 16640 of 25000, training loss: 0.160268\n",
      "Train Epoch: 0, mini-batch 16650 of 25000, training loss: 0.062201\n",
      "Train Epoch: 0, mini-batch 16660 of 25000, training loss: 0.403717\n",
      "Train Epoch: 0, mini-batch 16670 of 25000, training loss: 0.026885\n",
      "Train Epoch: 0, mini-batch 16680 of 25000, training loss: 0.120524\n",
      "Train Epoch: 0, mini-batch 16690 of 25000, training loss: 0.094211\n",
      "Train Epoch: 0, mini-batch 16700 of 25000, training loss: 0.262497\n",
      "Train Epoch: 0, mini-batch 16710 of 25000, training loss: 0.008794\n",
      "Train Epoch: 0, mini-batch 16720 of 25000, training loss: 0.441776\n",
      "Train Epoch: 0, mini-batch 16730 of 25000, training loss: 0.070312\n",
      "Train Epoch: 0, mini-batch 16740 of 25000, training loss: 0.053808\n",
      "Train Epoch: 0, mini-batch 16750 of 25000, training loss: 0.210515\n",
      "Train Epoch: 0, mini-batch 16760 of 25000, training loss: 0.078636\n",
      "Train Epoch: 0, mini-batch 16770 of 25000, training loss: 0.991839\n",
      "Train Epoch: 0, mini-batch 16780 of 25000, training loss: 1.999874\n",
      "Train Epoch: 0, mini-batch 16790 of 25000, training loss: 0.154136\n",
      "Train Epoch: 0, mini-batch 16800 of 25000, training loss: 1.669527\n",
      "Train Epoch: 0, mini-batch 16810 of 25000, training loss: 0.706176\n",
      "Train Epoch: 0, mini-batch 16820 of 25000, training loss: 0.043437\n",
      "Train Epoch: 0, mini-batch 16830 of 25000, training loss: 0.000030\n",
      "Train Epoch: 0, mini-batch 16840 of 25000, training loss: 0.003216\n",
      "Train Epoch: 0, mini-batch 16850 of 25000, training loss: 0.120829\n",
      "Train Epoch: 0, mini-batch 16860 of 25000, training loss: 0.127134\n",
      "Train Epoch: 0, mini-batch 16870 of 25000, training loss: 0.003993\n",
      "Train Epoch: 0, mini-batch 16880 of 25000, training loss: 0.000151\n",
      "Train Epoch: 0, mini-batch 16890 of 25000, training loss: 0.076722\n",
      "Train Epoch: 0, mini-batch 16900 of 25000, training loss: 0.004015\n",
      "Train Epoch: 0, mini-batch 16910 of 25000, training loss: 0.087425\n",
      "Train Epoch: 0, mini-batch 16920 of 25000, training loss: 0.007535\n",
      "Train Epoch: 0, mini-batch 16930 of 25000, training loss: 1.101553\n",
      "Train Epoch: 0, mini-batch 16940 of 25000, training loss: 0.111786\n",
      "Train Epoch: 0, mini-batch 16950 of 25000, training loss: 0.028196\n",
      "Train Epoch: 0, mini-batch 16960 of 25000, training loss: 0.091883\n",
      "Train Epoch: 0, mini-batch 16970 of 25000, training loss: 0.643814\n",
      "Train Epoch: 0, mini-batch 16980 of 25000, training loss: 0.127368\n",
      "Train Epoch: 0, mini-batch 16990 of 25000, training loss: 0.085689\n",
      "Train Epoch: 0, mini-batch 17000 of 25000, training loss: 0.158809\n",
      "Train Epoch: 0, mini-batch 17010 of 25000, training loss: 0.087988\n",
      "Train Epoch: 0, mini-batch 17020 of 25000, training loss: 0.009829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 17030 of 25000, training loss: 0.043910\n",
      "Train Epoch: 0, mini-batch 17040 of 25000, training loss: 0.009846\n",
      "Train Epoch: 0, mini-batch 17050 of 25000, training loss: 0.002393\n",
      "Train Epoch: 0, mini-batch 17060 of 25000, training loss: 0.145874\n",
      "Train Epoch: 0, mini-batch 17070 of 25000, training loss: 0.578337\n",
      "Train Epoch: 0, mini-batch 17080 of 25000, training loss: 0.044177\n",
      "Train Epoch: 0, mini-batch 17090 of 25000, training loss: 0.044597\n",
      "Train Epoch: 0, mini-batch 17100 of 25000, training loss: 0.051240\n",
      "Train Epoch: 0, mini-batch 17110 of 25000, training loss: 0.402948\n",
      "Train Epoch: 0, mini-batch 17120 of 25000, training loss: 3.510507\n",
      "Train Epoch: 0, mini-batch 17130 of 25000, training loss: 0.014514\n",
      "Train Epoch: 0, mini-batch 17140 of 25000, training loss: 0.026179\n",
      "Train Epoch: 0, mini-batch 17150 of 25000, training loss: 0.092106\n",
      "Train Epoch: 0, mini-batch 17160 of 25000, training loss: 0.013053\n",
      "Train Epoch: 0, mini-batch 17170 of 25000, training loss: 1.645897\n",
      "Train Epoch: 0, mini-batch 17180 of 25000, training loss: 2.209477\n",
      "Train Epoch: 0, mini-batch 17190 of 25000, training loss: 1.822993\n",
      "Train Epoch: 0, mini-batch 17200 of 25000, training loss: 0.088706\n",
      "Train Epoch: 0, mini-batch 17210 of 25000, training loss: 1.007351\n",
      "Train Epoch: 0, mini-batch 17220 of 25000, training loss: 0.042815\n",
      "Train Epoch: 0, mini-batch 17230 of 25000, training loss: 0.088407\n",
      "Train Epoch: 0, mini-batch 17240 of 25000, training loss: 0.054880\n",
      "Train Epoch: 0, mini-batch 17250 of 25000, training loss: 0.003313\n",
      "Train Epoch: 0, mini-batch 17260 of 25000, training loss: 0.161814\n",
      "Train Epoch: 0, mini-batch 17270 of 25000, training loss: 0.080347\n",
      "Train Epoch: 0, mini-batch 17280 of 25000, training loss: 1.265754\n",
      "Train Epoch: 0, mini-batch 17290 of 25000, training loss: 0.017329\n",
      "Train Epoch: 0, mini-batch 17300 of 25000, training loss: 0.259877\n",
      "Train Epoch: 0, mini-batch 17310 of 25000, training loss: 0.993788\n",
      "Train Epoch: 0, mini-batch 17320 of 25000, training loss: 0.021557\n",
      "Train Epoch: 0, mini-batch 17330 of 25000, training loss: 2.353198\n",
      "Train Epoch: 0, mini-batch 17340 of 25000, training loss: 0.100648\n",
      "Train Epoch: 0, mini-batch 17350 of 25000, training loss: 2.556118\n",
      "Train Epoch: 0, mini-batch 17360 of 25000, training loss: 0.095129\n",
      "Train Epoch: 0, mini-batch 17370 of 25000, training loss: 0.967224\n",
      "Train Epoch: 0, mini-batch 17380 of 25000, training loss: 0.082408\n",
      "Train Epoch: 0, mini-batch 17390 of 25000, training loss: 0.904063\n",
      "Train Epoch: 0, mini-batch 17400 of 25000, training loss: 0.000495\n",
      "Train Epoch: 0, mini-batch 17410 of 25000, training loss: 0.004773\n",
      "Train Epoch: 0, mini-batch 17420 of 25000, training loss: 0.798981\n",
      "Train Epoch: 0, mini-batch 17430 of 25000, training loss: 0.394790\n",
      "Train Epoch: 0, mini-batch 17440 of 25000, training loss: 0.455927\n",
      "Train Epoch: 0, mini-batch 17450 of 25000, training loss: 0.257404\n",
      "Train Epoch: 0, mini-batch 17460 of 25000, training loss: 0.039665\n",
      "Train Epoch: 0, mini-batch 17470 of 25000, training loss: 0.056383\n",
      "Train Epoch: 0, mini-batch 17480 of 25000, training loss: 0.034812\n",
      "Train Epoch: 0, mini-batch 17490 of 25000, training loss: 0.075416\n",
      "Train Epoch: 0, mini-batch 17500 of 25000, training loss: 0.055731\n",
      "Train Epoch: 0, mini-batch 17510 of 25000, training loss: 0.012677\n",
      "Train Epoch: 0, mini-batch 17520 of 25000, training loss: 1.124440\n",
      "Train Epoch: 0, mini-batch 17530 of 25000, training loss: 0.144025\n",
      "Train Epoch: 0, mini-batch 17540 of 25000, training loss: 0.019580\n",
      "Train Epoch: 0, mini-batch 17550 of 25000, training loss: 0.192228\n",
      "Train Epoch: 0, mini-batch 17560 of 25000, training loss: 0.025926\n",
      "Train Epoch: 0, mini-batch 17570 of 25000, training loss: 0.130695\n",
      "Train Epoch: 0, mini-batch 17580 of 25000, training loss: 0.056101\n",
      "Train Epoch: 0, mini-batch 17590 of 25000, training loss: 0.290215\n",
      "Train Epoch: 0, mini-batch 17600 of 25000, training loss: 0.024155\n",
      "Train Epoch: 0, mini-batch 17610 of 25000, training loss: 0.361881\n",
      "Train Epoch: 0, mini-batch 17620 of 25000, training loss: 0.154449\n",
      "Train Epoch: 0, mini-batch 17630 of 25000, training loss: 0.265927\n",
      "Train Epoch: 0, mini-batch 17640 of 25000, training loss: 0.891084\n",
      "Train Epoch: 0, mini-batch 17650 of 25000, training loss: 0.217307\n",
      "Train Epoch: 0, mini-batch 17660 of 25000, training loss: 0.074651\n",
      "Train Epoch: 0, mini-batch 17670 of 25000, training loss: 0.437845\n",
      "Train Epoch: 0, mini-batch 17680 of 25000, training loss: 0.002924\n",
      "Train Epoch: 0, mini-batch 17690 of 25000, training loss: 0.022481\n",
      "Train Epoch: 0, mini-batch 17700 of 25000, training loss: 0.414450\n",
      "Train Epoch: 0, mini-batch 17710 of 25000, training loss: 0.587320\n",
      "Train Epoch: 0, mini-batch 17720 of 25000, training loss: 0.031591\n",
      "Train Epoch: 0, mini-batch 17730 of 25000, training loss: 0.003722\n",
      "Train Epoch: 0, mini-batch 17740 of 25000, training loss: 0.321795\n",
      "Train Epoch: 0, mini-batch 17750 of 25000, training loss: 0.092296\n",
      "Train Epoch: 0, mini-batch 17760 of 25000, training loss: 0.242862\n",
      "Train Epoch: 0, mini-batch 17770 of 25000, training loss: 0.002134\n",
      "Train Epoch: 0, mini-batch 17780 of 25000, training loss: 0.010635\n",
      "Train Epoch: 0, mini-batch 17790 of 25000, training loss: 0.153654\n",
      "Train Epoch: 0, mini-batch 17800 of 25000, training loss: 0.064541\n",
      "Train Epoch: 0, mini-batch 17810 of 25000, training loss: 1.303606\n",
      "Train Epoch: 0, mini-batch 17820 of 25000, training loss: 0.032950\n",
      "Train Epoch: 0, mini-batch 17830 of 25000, training loss: 0.048059\n",
      "Train Epoch: 0, mini-batch 17840 of 25000, training loss: 0.220647\n",
      "Train Epoch: 0, mini-batch 17850 of 25000, training loss: 0.084554\n",
      "Train Epoch: 0, mini-batch 17860 of 25000, training loss: 0.314400\n",
      "Train Epoch: 0, mini-batch 17870 of 25000, training loss: 0.283448\n",
      "Train Epoch: 0, mini-batch 17880 of 25000, training loss: 0.002936\n",
      "Train Epoch: 0, mini-batch 17890 of 25000, training loss: 0.150612\n",
      "Train Epoch: 0, mini-batch 17900 of 25000, training loss: 0.000107\n",
      "Train Epoch: 0, mini-batch 17910 of 25000, training loss: 1.024880\n",
      "Train Epoch: 0, mini-batch 17920 of 25000, training loss: 0.418867\n",
      "Train Epoch: 0, mini-batch 17930 of 25000, training loss: 1.495366\n",
      "Train Epoch: 0, mini-batch 17940 of 25000, training loss: 0.034755\n",
      "Train Epoch: 0, mini-batch 17950 of 25000, training loss: 0.005613\n",
      "Train Epoch: 0, mini-batch 17960 of 25000, training loss: 0.057141\n",
      "Train Epoch: 0, mini-batch 17970 of 25000, training loss: 0.775237\n",
      "Train Epoch: 0, mini-batch 17980 of 25000, training loss: 0.046487\n",
      "Train Epoch: 0, mini-batch 17990 of 25000, training loss: 0.000278\n",
      "Train Epoch: 0, mini-batch 18000 of 25000, training loss: 0.011747\n",
      "Train Epoch: 0, mini-batch 18010 of 25000, training loss: 0.096322\n",
      "Train Epoch: 0, mini-batch 18020 of 25000, training loss: 0.022186\n",
      "Train Epoch: 0, mini-batch 18030 of 25000, training loss: 3.580572\n",
      "Train Epoch: 0, mini-batch 18040 of 25000, training loss: 0.075842\n",
      "Train Epoch: 0, mini-batch 18050 of 25000, training loss: 0.004341\n",
      "Train Epoch: 0, mini-batch 18060 of 25000, training loss: 0.019982\n",
      "Train Epoch: 0, mini-batch 18070 of 25000, training loss: 0.007424\n",
      "Train Epoch: 0, mini-batch 18080 of 25000, training loss: 0.327280\n",
      "Train Epoch: 0, mini-batch 18090 of 25000, training loss: 0.051496\n",
      "Train Epoch: 0, mini-batch 18100 of 25000, training loss: 0.564133\n",
      "Train Epoch: 0, mini-batch 18110 of 25000, training loss: 0.284182\n",
      "Train Epoch: 0, mini-batch 18120 of 25000, training loss: 0.200661\n",
      "Train Epoch: 0, mini-batch 18130 of 25000, training loss: 0.065853\n",
      "Train Epoch: 0, mini-batch 18140 of 25000, training loss: 0.148362\n",
      "Train Epoch: 0, mini-batch 18150 of 25000, training loss: 0.072825\n",
      "Train Epoch: 0, mini-batch 18160 of 25000, training loss: 0.006036\n",
      "Train Epoch: 0, mini-batch 18170 of 25000, training loss: 0.612883\n",
      "Train Epoch: 0, mini-batch 18180 of 25000, training loss: 0.021305\n",
      "Train Epoch: 0, mini-batch 18190 of 25000, training loss: 1.302244\n",
      "Train Epoch: 0, mini-batch 18200 of 25000, training loss: 0.010564\n",
      "Train Epoch: 0, mini-batch 18210 of 25000, training loss: 0.009376\n",
      "Train Epoch: 0, mini-batch 18220 of 25000, training loss: 0.049870\n",
      "Train Epoch: 0, mini-batch 18230 of 25000, training loss: 1.410846\n",
      "Train Epoch: 0, mini-batch 18240 of 25000, training loss: 0.002050\n",
      "Train Epoch: 0, mini-batch 18250 of 25000, training loss: 0.008038\n",
      "Train Epoch: 0, mini-batch 18260 of 25000, training loss: 0.067217\n",
      "Train Epoch: 0, mini-batch 18270 of 25000, training loss: 0.370794\n",
      "Train Epoch: 0, mini-batch 18280 of 25000, training loss: 0.359431\n",
      "Train Epoch: 0, mini-batch 18290 of 25000, training loss: 0.000434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 18300 of 25000, training loss: 0.003130\n",
      "Train Epoch: 0, mini-batch 18310 of 25000, training loss: 0.287468\n",
      "Train Epoch: 0, mini-batch 18320 of 25000, training loss: 0.548827\n",
      "Train Epoch: 0, mini-batch 18330 of 25000, training loss: 0.256612\n",
      "Train Epoch: 0, mini-batch 18340 of 25000, training loss: 0.039735\n",
      "Train Epoch: 0, mini-batch 18350 of 25000, training loss: 0.399009\n",
      "Train Epoch: 0, mini-batch 18360 of 25000, training loss: 0.006139\n",
      "Train Epoch: 0, mini-batch 18370 of 25000, training loss: 1.448768\n",
      "Train Epoch: 0, mini-batch 18380 of 25000, training loss: 0.016089\n",
      "Train Epoch: 0, mini-batch 18390 of 25000, training loss: 0.185790\n",
      "Train Epoch: 0, mini-batch 18400 of 25000, training loss: 0.092042\n",
      "Train Epoch: 0, mini-batch 18410 of 25000, training loss: 0.558647\n",
      "Train Epoch: 0, mini-batch 18420 of 25000, training loss: 1.066081\n",
      "Train Epoch: 0, mini-batch 18430 of 25000, training loss: 0.503614\n",
      "Train Epoch: 0, mini-batch 18440 of 25000, training loss: 0.101331\n",
      "Train Epoch: 0, mini-batch 18450 of 25000, training loss: 0.933561\n",
      "Train Epoch: 0, mini-batch 18460 of 25000, training loss: 1.681746\n",
      "Train Epoch: 0, mini-batch 18470 of 25000, training loss: 0.554267\n",
      "Train Epoch: 0, mini-batch 18480 of 25000, training loss: 0.942769\n",
      "Train Epoch: 0, mini-batch 18490 of 25000, training loss: 0.075878\n",
      "Train Epoch: 0, mini-batch 18500 of 25000, training loss: 1.063754\n",
      "Train Epoch: 0, mini-batch 18510 of 25000, training loss: 0.253275\n",
      "Train Epoch: 0, mini-batch 18520 of 25000, training loss: 0.060295\n",
      "Train Epoch: 0, mini-batch 18530 of 25000, training loss: 0.132160\n",
      "Train Epoch: 0, mini-batch 18540 of 25000, training loss: 0.085069\n",
      "Train Epoch: 0, mini-batch 18550 of 25000, training loss: 0.054767\n",
      "Train Epoch: 0, mini-batch 18560 of 25000, training loss: 0.110680\n",
      "Train Epoch: 0, mini-batch 18570 of 25000, training loss: 0.015103\n",
      "Train Epoch: 0, mini-batch 18580 of 25000, training loss: 0.072714\n",
      "Train Epoch: 0, mini-batch 18590 of 25000, training loss: 0.008453\n",
      "Train Epoch: 0, mini-batch 18600 of 25000, training loss: 1.447947\n",
      "Train Epoch: 0, mini-batch 18610 of 25000, training loss: 0.023986\n",
      "Train Epoch: 0, mini-batch 18620 of 25000, training loss: 0.040255\n",
      "Train Epoch: 0, mini-batch 18630 of 25000, training loss: 0.005654\n",
      "Train Epoch: 0, mini-batch 18640 of 25000, training loss: 0.149106\n",
      "Train Epoch: 0, mini-batch 18650 of 25000, training loss: 0.206062\n",
      "Train Epoch: 0, mini-batch 18660 of 25000, training loss: 0.002165\n",
      "Train Epoch: 0, mini-batch 18670 of 25000, training loss: 0.005067\n",
      "Train Epoch: 0, mini-batch 18680 of 25000, training loss: 0.488711\n",
      "Train Epoch: 0, mini-batch 18690 of 25000, training loss: 0.319158\n",
      "Train Epoch: 0, mini-batch 18700 of 25000, training loss: 0.519132\n",
      "Train Epoch: 0, mini-batch 18710 of 25000, training loss: 0.028481\n",
      "Train Epoch: 0, mini-batch 18720 of 25000, training loss: 1.494450\n",
      "Train Epoch: 0, mini-batch 18730 of 25000, training loss: 1.241681\n",
      "Train Epoch: 0, mini-batch 18740 of 25000, training loss: 0.059366\n",
      "Train Epoch: 0, mini-batch 18750 of 25000, training loss: 0.581868\n",
      "Train Epoch: 0, mini-batch 18760 of 25000, training loss: 1.425931\n",
      "Train Epoch: 0, mini-batch 18770 of 25000, training loss: 0.037971\n",
      "Train Epoch: 0, mini-batch 18780 of 25000, training loss: 0.007816\n",
      "Train Epoch: 0, mini-batch 18790 of 25000, training loss: 0.011779\n",
      "Train Epoch: 0, mini-batch 18800 of 25000, training loss: 0.325970\n",
      "Train Epoch: 0, mini-batch 18810 of 25000, training loss: 0.054832\n",
      "Train Epoch: 0, mini-batch 18820 of 25000, training loss: 0.079219\n",
      "Train Epoch: 0, mini-batch 18830 of 25000, training loss: 0.303820\n",
      "Train Epoch: 0, mini-batch 18840 of 25000, training loss: 0.526251\n",
      "Train Epoch: 0, mini-batch 18850 of 25000, training loss: 0.200681\n",
      "Train Epoch: 0, mini-batch 18860 of 25000, training loss: 0.015128\n",
      "Train Epoch: 0, mini-batch 18870 of 25000, training loss: 0.582175\n",
      "Train Epoch: 0, mini-batch 18880 of 25000, training loss: 0.015334\n",
      "Train Epoch: 0, mini-batch 18890 of 25000, training loss: 0.006679\n",
      "Train Epoch: 0, mini-batch 18900 of 25000, training loss: 0.185461\n",
      "Train Epoch: 0, mini-batch 18910 of 25000, training loss: 0.203944\n",
      "Train Epoch: 0, mini-batch 18920 of 25000, training loss: 0.057161\n",
      "Train Epoch: 0, mini-batch 18930 of 25000, training loss: 0.002270\n",
      "Train Epoch: 0, mini-batch 18940 of 25000, training loss: 0.043843\n",
      "Train Epoch: 0, mini-batch 18950 of 25000, training loss: 0.002799\n",
      "Train Epoch: 0, mini-batch 18960 of 25000, training loss: 0.863770\n",
      "Train Epoch: 0, mini-batch 18970 of 25000, training loss: 0.044000\n",
      "Train Epoch: 0, mini-batch 18980 of 25000, training loss: 0.003013\n",
      "Train Epoch: 0, mini-batch 18990 of 25000, training loss: 0.135913\n",
      "Train Epoch: 0, mini-batch 19000 of 25000, training loss: 0.403711\n",
      "Train Epoch: 0, mini-batch 19010 of 25000, training loss: 0.986110\n",
      "Train Epoch: 0, mini-batch 19020 of 25000, training loss: 0.112610\n",
      "Train Epoch: 0, mini-batch 19030 of 25000, training loss: 0.038793\n",
      "Train Epoch: 0, mini-batch 19040 of 25000, training loss: 0.054932\n",
      "Train Epoch: 0, mini-batch 19050 of 25000, training loss: 0.665464\n",
      "Train Epoch: 0, mini-batch 19060 of 25000, training loss: 0.014121\n",
      "Train Epoch: 0, mini-batch 19070 of 25000, training loss: 0.380397\n",
      "Train Epoch: 0, mini-batch 19080 of 25000, training loss: 0.028704\n",
      "Train Epoch: 0, mini-batch 19090 of 25000, training loss: 0.114890\n",
      "Train Epoch: 0, mini-batch 19100 of 25000, training loss: 0.127078\n",
      "Train Epoch: 0, mini-batch 19110 of 25000, training loss: 0.830015\n",
      "Train Epoch: 0, mini-batch 19120 of 25000, training loss: 0.017531\n",
      "Train Epoch: 0, mini-batch 19130 of 25000, training loss: 0.128492\n",
      "Train Epoch: 0, mini-batch 19140 of 25000, training loss: 0.004133\n",
      "Train Epoch: 0, mini-batch 19150 of 25000, training loss: 0.041890\n",
      "Train Epoch: 0, mini-batch 19160 of 25000, training loss: 0.021003\n",
      "Train Epoch: 0, mini-batch 19170 of 25000, training loss: 0.047300\n",
      "Train Epoch: 0, mini-batch 19180 of 25000, training loss: 1.930273\n",
      "Train Epoch: 0, mini-batch 19190 of 25000, training loss: 1.691075\n",
      "Train Epoch: 0, mini-batch 19200 of 25000, training loss: 0.012247\n",
      "Train Epoch: 0, mini-batch 19210 of 25000, training loss: 0.427789\n",
      "Train Epoch: 0, mini-batch 19220 of 25000, training loss: 0.415620\n",
      "Train Epoch: 0, mini-batch 19230 of 25000, training loss: 0.047187\n",
      "Train Epoch: 0, mini-batch 19240 of 25000, training loss: 0.008609\n",
      "Train Epoch: 0, mini-batch 19250 of 25000, training loss: 0.008602\n",
      "Train Epoch: 0, mini-batch 19260 of 25000, training loss: 0.038335\n",
      "Train Epoch: 0, mini-batch 19270 of 25000, training loss: 0.055479\n",
      "Train Epoch: 0, mini-batch 19280 of 25000, training loss: 0.684831\n",
      "Train Epoch: 0, mini-batch 19290 of 25000, training loss: 0.039693\n",
      "Train Epoch: 0, mini-batch 19300 of 25000, training loss: 0.013090\n",
      "Train Epoch: 0, mini-batch 19310 of 25000, training loss: 0.219969\n",
      "Train Epoch: 0, mini-batch 19320 of 25000, training loss: 0.013703\n",
      "Train Epoch: 0, mini-batch 19330 of 25000, training loss: 0.001555\n",
      "Train Epoch: 0, mini-batch 19340 of 25000, training loss: 0.339394\n",
      "Train Epoch: 0, mini-batch 19350 of 25000, training loss: 0.135670\n",
      "Train Epoch: 0, mini-batch 19360 of 25000, training loss: 0.230985\n",
      "Train Epoch: 0, mini-batch 19370 of 25000, training loss: 0.005279\n",
      "Train Epoch: 0, mini-batch 19380 of 25000, training loss: 0.514864\n",
      "Train Epoch: 0, mini-batch 19390 of 25000, training loss: 0.022099\n",
      "Train Epoch: 0, mini-batch 19400 of 25000, training loss: 1.514947\n",
      "Train Epoch: 0, mini-batch 19410 of 25000, training loss: 0.135071\n",
      "Train Epoch: 0, mini-batch 19420 of 25000, training loss: 0.025197\n",
      "Train Epoch: 0, mini-batch 19430 of 25000, training loss: 0.100170\n",
      "Train Epoch: 0, mini-batch 19440 of 25000, training loss: 0.003798\n",
      "Train Epoch: 0, mini-batch 19450 of 25000, training loss: 0.000521\n",
      "Train Epoch: 0, mini-batch 19460 of 25000, training loss: 0.027610\n",
      "Train Epoch: 0, mini-batch 19470 of 25000, training loss: 0.349007\n",
      "Train Epoch: 0, mini-batch 19480 of 25000, training loss: 0.006374\n",
      "Train Epoch: 0, mini-batch 19490 of 25000, training loss: 0.021045\n",
      "Train Epoch: 0, mini-batch 19500 of 25000, training loss: 0.022392\n",
      "Train Epoch: 0, mini-batch 19510 of 25000, training loss: 0.001952\n",
      "Train Epoch: 0, mini-batch 19520 of 25000, training loss: 0.374275\n",
      "Train Epoch: 0, mini-batch 19530 of 25000, training loss: 0.192358\n",
      "Train Epoch: 0, mini-batch 19540 of 25000, training loss: 0.047572\n",
      "Train Epoch: 0, mini-batch 19550 of 25000, training loss: 0.484314\n",
      "Train Epoch: 0, mini-batch 19560 of 25000, training loss: 0.060158\n",
      "Train Epoch: 0, mini-batch 19570 of 25000, training loss: 0.121838\n",
      "Train Epoch: 0, mini-batch 19580 of 25000, training loss: 0.001038\n",
      "Train Epoch: 0, mini-batch 19590 of 25000, training loss: 0.046143\n",
      "Train Epoch: 0, mini-batch 19600 of 25000, training loss: 0.015365\n",
      "Train Epoch: 0, mini-batch 19610 of 25000, training loss: 0.045942\n",
      "Train Epoch: 0, mini-batch 19620 of 25000, training loss: 0.174000\n",
      "Train Epoch: 0, mini-batch 19630 of 25000, training loss: 0.000533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 19640 of 25000, training loss: 0.034479\n",
      "Train Epoch: 0, mini-batch 19650 of 25000, training loss: 0.037970\n",
      "Train Epoch: 0, mini-batch 19660 of 25000, training loss: 0.047217\n",
      "Train Epoch: 0, mini-batch 19670 of 25000, training loss: 0.116568\n",
      "Train Epoch: 0, mini-batch 19680 of 25000, training loss: 1.234512\n",
      "Train Epoch: 0, mini-batch 19690 of 25000, training loss: 1.420160\n",
      "Train Epoch: 0, mini-batch 19700 of 25000, training loss: 0.319989\n",
      "Train Epoch: 0, mini-batch 19710 of 25000, training loss: 0.017221\n",
      "Train Epoch: 0, mini-batch 19720 of 25000, training loss: 0.565980\n",
      "Train Epoch: 0, mini-batch 19730 of 25000, training loss: 0.595008\n",
      "Train Epoch: 0, mini-batch 19740 of 25000, training loss: 0.203936\n",
      "Train Epoch: 0, mini-batch 19750 of 25000, training loss: 0.019414\n",
      "Train Epoch: 0, mini-batch 19760 of 25000, training loss: 0.064930\n",
      "Train Epoch: 0, mini-batch 19770 of 25000, training loss: 0.028954\n",
      "Train Epoch: 0, mini-batch 19780 of 25000, training loss: 0.120937\n",
      "Train Epoch: 0, mini-batch 19790 of 25000, training loss: 1.546239\n",
      "Train Epoch: 0, mini-batch 19800 of 25000, training loss: 0.456623\n",
      "Train Epoch: 0, mini-batch 19810 of 25000, training loss: 0.001557\n",
      "Train Epoch: 0, mini-batch 19820 of 25000, training loss: 0.000004\n",
      "Train Epoch: 0, mini-batch 19830 of 25000, training loss: 0.061979\n",
      "Train Epoch: 0, mini-batch 19840 of 25000, training loss: 0.710975\n",
      "Train Epoch: 0, mini-batch 19850 of 25000, training loss: 0.035634\n",
      "Train Epoch: 0, mini-batch 19860 of 25000, training loss: 0.050814\n",
      "Train Epoch: 0, mini-batch 19870 of 25000, training loss: 0.001402\n",
      "Train Epoch: 0, mini-batch 19880 of 25000, training loss: 0.355578\n",
      "Train Epoch: 0, mini-batch 19890 of 25000, training loss: 0.123060\n",
      "Train Epoch: 0, mini-batch 19900 of 25000, training loss: 3.073474\n",
      "Train Epoch: 0, mini-batch 19910 of 25000, training loss: 0.545302\n",
      "Train Epoch: 0, mini-batch 19920 of 25000, training loss: 2.467646\n",
      "Train Epoch: 0, mini-batch 19930 of 25000, training loss: 0.083173\n",
      "Train Epoch: 0, mini-batch 19940 of 25000, training loss: 0.957451\n",
      "Train Epoch: 0, mini-batch 19950 of 25000, training loss: 0.010410\n",
      "Train Epoch: 0, mini-batch 19960 of 25000, training loss: 0.041718\n",
      "Train Epoch: 0, mini-batch 19970 of 25000, training loss: 0.006668\n",
      "Train Epoch: 0, mini-batch 19980 of 25000, training loss: 1.616886\n",
      "Train Epoch: 0, mini-batch 19990 of 25000, training loss: 0.128769\n",
      "Train Epoch: 0, mini-batch 20000 of 25000, training loss: 0.979630\n",
      "Train Epoch: 0, mini-batch 20010 of 25000, training loss: 0.046079\n",
      "Train Epoch: 0, mini-batch 20020 of 25000, training loss: 0.013652\n",
      "Train Epoch: 0, mini-batch 20030 of 25000, training loss: 0.107966\n",
      "Train Epoch: 0, mini-batch 20040 of 25000, training loss: 0.030998\n",
      "Train Epoch: 0, mini-batch 20050 of 25000, training loss: 0.061352\n",
      "Train Epoch: 0, mini-batch 20060 of 25000, training loss: 0.036758\n",
      "Train Epoch: 0, mini-batch 20070 of 25000, training loss: 0.030191\n",
      "Train Epoch: 0, mini-batch 20080 of 25000, training loss: 0.383043\n",
      "Train Epoch: 0, mini-batch 20090 of 25000, training loss: 0.041728\n",
      "Train Epoch: 0, mini-batch 20100 of 25000, training loss: 0.041084\n",
      "Train Epoch: 0, mini-batch 20110 of 25000, training loss: 0.203334\n",
      "Train Epoch: 0, mini-batch 20120 of 25000, training loss: 0.177895\n",
      "Train Epoch: 0, mini-batch 20130 of 25000, training loss: 2.012215\n",
      "Train Epoch: 0, mini-batch 20140 of 25000, training loss: 0.848701\n",
      "Train Epoch: 0, mini-batch 20150 of 25000, training loss: 0.044842\n",
      "Train Epoch: 0, mini-batch 20160 of 25000, training loss: 0.485323\n",
      "Train Epoch: 0, mini-batch 20170 of 25000, training loss: 1.318008\n",
      "Train Epoch: 0, mini-batch 20180 of 25000, training loss: 0.040239\n",
      "Train Epoch: 0, mini-batch 20190 of 25000, training loss: 0.838018\n",
      "Train Epoch: 0, mini-batch 20200 of 25000, training loss: 0.182413\n",
      "Train Epoch: 0, mini-batch 20210 of 25000, training loss: 0.031651\n",
      "Train Epoch: 0, mini-batch 20220 of 25000, training loss: 0.004988\n",
      "Train Epoch: 0, mini-batch 20230 of 25000, training loss: 0.018589\n",
      "Train Epoch: 0, mini-batch 20240 of 25000, training loss: 0.675027\n",
      "Train Epoch: 0, mini-batch 20250 of 25000, training loss: 1.143786\n",
      "Train Epoch: 0, mini-batch 20260 of 25000, training loss: 0.071264\n",
      "Train Epoch: 0, mini-batch 20270 of 25000, training loss: 0.059935\n",
      "Train Epoch: 0, mini-batch 20280 of 25000, training loss: 0.000239\n",
      "Train Epoch: 0, mini-batch 20290 of 25000, training loss: 0.015922\n",
      "Train Epoch: 0, mini-batch 20300 of 25000, training loss: 0.007036\n",
      "Train Epoch: 0, mini-batch 20310 of 25000, training loss: 0.018907\n",
      "Train Epoch: 0, mini-batch 20320 of 25000, training loss: 0.777808\n",
      "Train Epoch: 0, mini-batch 20330 of 25000, training loss: 0.058125\n",
      "Train Epoch: 0, mini-batch 20340 of 25000, training loss: 0.083633\n",
      "Train Epoch: 0, mini-batch 20350 of 25000, training loss: 0.001720\n",
      "Train Epoch: 0, mini-batch 20360 of 25000, training loss: 0.421878\n",
      "Train Epoch: 0, mini-batch 20370 of 25000, training loss: 0.001342\n",
      "Train Epoch: 0, mini-batch 20380 of 25000, training loss: 0.527399\n",
      "Train Epoch: 0, mini-batch 20390 of 25000, training loss: 0.037162\n",
      "Train Epoch: 0, mini-batch 20400 of 25000, training loss: 1.023019\n",
      "Train Epoch: 0, mini-batch 20410 of 25000, training loss: 0.001264\n",
      "Train Epoch: 0, mini-batch 20420 of 25000, training loss: 0.016371\n",
      "Train Epoch: 0, mini-batch 20430 of 25000, training loss: 0.000794\n",
      "Train Epoch: 0, mini-batch 20440 of 25000, training loss: 0.059118\n",
      "Train Epoch: 0, mini-batch 20450 of 25000, training loss: 0.005061\n",
      "Train Epoch: 0, mini-batch 20460 of 25000, training loss: 0.095489\n",
      "Train Epoch: 0, mini-batch 20470 of 25000, training loss: 0.176639\n",
      "Train Epoch: 0, mini-batch 20480 of 25000, training loss: 0.190961\n",
      "Train Epoch: 0, mini-batch 20490 of 25000, training loss: 2.473113\n",
      "Train Epoch: 0, mini-batch 20500 of 25000, training loss: 0.635575\n",
      "Train Epoch: 0, mini-batch 20510 of 25000, training loss: 0.349312\n",
      "Train Epoch: 0, mini-batch 20520 of 25000, training loss: 0.004321\n",
      "Train Epoch: 0, mini-batch 20530 of 25000, training loss: 0.050253\n",
      "Train Epoch: 0, mini-batch 20540 of 25000, training loss: 0.013895\n",
      "Train Epoch: 0, mini-batch 20550 of 25000, training loss: 0.450115\n",
      "Train Epoch: 0, mini-batch 20560 of 25000, training loss: 0.000763\n",
      "Train Epoch: 0, mini-batch 20570 of 25000, training loss: 0.001539\n",
      "Train Epoch: 0, mini-batch 20580 of 25000, training loss: 0.361104\n",
      "Train Epoch: 0, mini-batch 20590 of 25000, training loss: 0.338333\n",
      "Train Epoch: 0, mini-batch 20600 of 25000, training loss: 0.141505\n",
      "Train Epoch: 0, mini-batch 20610 of 25000, training loss: 0.014714\n",
      "Train Epoch: 0, mini-batch 20620 of 25000, training loss: 1.213141\n",
      "Train Epoch: 0, mini-batch 20630 of 25000, training loss: 0.146627\n",
      "Train Epoch: 0, mini-batch 20640 of 25000, training loss: 0.211521\n",
      "Train Epoch: 0, mini-batch 20650 of 25000, training loss: 0.147237\n",
      "Train Epoch: 0, mini-batch 20660 of 25000, training loss: 0.051760\n",
      "Train Epoch: 0, mini-batch 20670 of 25000, training loss: 1.456594\n",
      "Train Epoch: 0, mini-batch 20680 of 25000, training loss: 0.034231\n",
      "Train Epoch: 0, mini-batch 20690 of 25000, training loss: 0.049886\n",
      "Train Epoch: 0, mini-batch 20700 of 25000, training loss: 0.005339\n",
      "Train Epoch: 0, mini-batch 20710 of 25000, training loss: 0.033797\n",
      "Train Epoch: 0, mini-batch 20720 of 25000, training loss: 0.012035\n",
      "Train Epoch: 0, mini-batch 20730 of 25000, training loss: 0.040345\n",
      "Train Epoch: 0, mini-batch 20740 of 25000, training loss: 0.072253\n",
      "Train Epoch: 0, mini-batch 20750 of 25000, training loss: 1.288832\n",
      "Train Epoch: 0, mini-batch 20760 of 25000, training loss: 0.972530\n",
      "Train Epoch: 0, mini-batch 20770 of 25000, training loss: 0.118947\n",
      "Train Epoch: 0, mini-batch 20780 of 25000, training loss: 0.298879\n",
      "Train Epoch: 0, mini-batch 20790 of 25000, training loss: 0.928060\n",
      "Train Epoch: 0, mini-batch 20800 of 25000, training loss: 0.557338\n",
      "Train Epoch: 0, mini-batch 20810 of 25000, training loss: 0.109324\n",
      "Train Epoch: 0, mini-batch 20820 of 25000, training loss: 0.220128\n",
      "Train Epoch: 0, mini-batch 20830 of 25000, training loss: 0.311359\n",
      "Train Epoch: 0, mini-batch 20840 of 25000, training loss: 0.002339\n",
      "Train Epoch: 0, mini-batch 20850 of 25000, training loss: 0.006358\n",
      "Train Epoch: 0, mini-batch 20860 of 25000, training loss: 0.155402\n",
      "Train Epoch: 0, mini-batch 20870 of 25000, training loss: 0.109055\n",
      "Train Epoch: 0, mini-batch 20880 of 25000, training loss: 1.063880\n",
      "Train Epoch: 0, mini-batch 20890 of 25000, training loss: 0.012875\n",
      "Train Epoch: 0, mini-batch 20900 of 25000, training loss: 1.907030\n",
      "Train Epoch: 0, mini-batch 20910 of 25000, training loss: 0.019887\n",
      "Train Epoch: 0, mini-batch 20920 of 25000, training loss: 0.002191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 20930 of 25000, training loss: 0.250753\n",
      "Train Epoch: 0, mini-batch 20940 of 25000, training loss: 0.216835\n",
      "Train Epoch: 0, mini-batch 20950 of 25000, training loss: 0.367369\n",
      "Train Epoch: 0, mini-batch 20960 of 25000, training loss: 0.206165\n",
      "Train Epoch: 0, mini-batch 20970 of 25000, training loss: 0.150257\n",
      "Train Epoch: 0, mini-batch 20980 of 25000, training loss: 0.001044\n",
      "Train Epoch: 0, mini-batch 20990 of 25000, training loss: 0.013733\n",
      "Train Epoch: 0, mini-batch 21000 of 25000, training loss: 0.109545\n",
      "Train Epoch: 0, mini-batch 21010 of 25000, training loss: 2.128257\n",
      "Train Epoch: 0, mini-batch 21020 of 25000, training loss: 0.007414\n",
      "Train Epoch: 0, mini-batch 21030 of 25000, training loss: 0.063479\n",
      "Train Epoch: 0, mini-batch 21040 of 25000, training loss: 1.159721\n",
      "Train Epoch: 0, mini-batch 21050 of 25000, training loss: 0.457270\n",
      "Train Epoch: 0, mini-batch 21060 of 25000, training loss: 0.605487\n",
      "Train Epoch: 0, mini-batch 21070 of 25000, training loss: 0.001069\n",
      "Train Epoch: 0, mini-batch 21080 of 25000, training loss: 0.672993\n",
      "Train Epoch: 0, mini-batch 21090 of 25000, training loss: 0.108587\n",
      "Train Epoch: 0, mini-batch 21100 of 25000, training loss: 0.012529\n",
      "Train Epoch: 0, mini-batch 21110 of 25000, training loss: 0.055768\n",
      "Train Epoch: 0, mini-batch 21120 of 25000, training loss: 0.087745\n",
      "Train Epoch: 0, mini-batch 21130 of 25000, training loss: 0.313846\n",
      "Train Epoch: 0, mini-batch 21140 of 25000, training loss: 0.000003\n",
      "Train Epoch: 0, mini-batch 21150 of 25000, training loss: 0.146160\n",
      "Train Epoch: 0, mini-batch 21160 of 25000, training loss: 0.104693\n",
      "Train Epoch: 0, mini-batch 21170 of 25000, training loss: 0.104195\n",
      "Train Epoch: 0, mini-batch 21180 of 25000, training loss: 0.003826\n",
      "Train Epoch: 0, mini-batch 21190 of 25000, training loss: 0.061828\n",
      "Train Epoch: 0, mini-batch 21200 of 25000, training loss: 0.106285\n",
      "Train Epoch: 0, mini-batch 21210 of 25000, training loss: 0.034941\n",
      "Train Epoch: 0, mini-batch 21220 of 25000, training loss: 0.463117\n",
      "Train Epoch: 0, mini-batch 21230 of 25000, training loss: 0.350506\n",
      "Train Epoch: 0, mini-batch 21240 of 25000, training loss: 0.042189\n",
      "Train Epoch: 0, mini-batch 21250 of 25000, training loss: 0.073249\n",
      "Train Epoch: 0, mini-batch 21260 of 25000, training loss: 0.017493\n",
      "Train Epoch: 0, mini-batch 21270 of 25000, training loss: 0.946225\n",
      "Train Epoch: 0, mini-batch 21280 of 25000, training loss: 1.767739\n",
      "Train Epoch: 0, mini-batch 21290 of 25000, training loss: 0.050410\n",
      "Train Epoch: 0, mini-batch 21300 of 25000, training loss: 0.019211\n",
      "Train Epoch: 0, mini-batch 21310 of 25000, training loss: 0.153751\n",
      "Train Epoch: 0, mini-batch 21320 of 25000, training loss: 0.001730\n",
      "Train Epoch: 0, mini-batch 21330 of 25000, training loss: 0.080827\n",
      "Train Epoch: 0, mini-batch 21340 of 25000, training loss: 0.032528\n",
      "Train Epoch: 0, mini-batch 21350 of 25000, training loss: 1.021556\n",
      "Train Epoch: 0, mini-batch 21360 of 25000, training loss: 0.180410\n",
      "Train Epoch: 0, mini-batch 21370 of 25000, training loss: 3.907590\n",
      "Train Epoch: 0, mini-batch 21380 of 25000, training loss: 0.069119\n",
      "Train Epoch: 0, mini-batch 21390 of 25000, training loss: 0.022106\n",
      "Train Epoch: 0, mini-batch 21400 of 25000, training loss: 0.000158\n",
      "Train Epoch: 0, mini-batch 21410 of 25000, training loss: 1.664079\n",
      "Train Epoch: 0, mini-batch 21420 of 25000, training loss: 0.084030\n",
      "Train Epoch: 0, mini-batch 21430 of 25000, training loss: 0.080678\n",
      "Train Epoch: 0, mini-batch 21440 of 25000, training loss: 0.204320\n",
      "Train Epoch: 0, mini-batch 21450 of 25000, training loss: 0.055637\n",
      "Train Epoch: 0, mini-batch 21460 of 25000, training loss: 0.177401\n",
      "Train Epoch: 0, mini-batch 21470 of 25000, training loss: 0.004033\n",
      "Train Epoch: 0, mini-batch 21480 of 25000, training loss: 0.041070\n",
      "Train Epoch: 0, mini-batch 21490 of 25000, training loss: 0.000204\n",
      "Train Epoch: 0, mini-batch 21500 of 25000, training loss: 0.652962\n",
      "Train Epoch: 0, mini-batch 21510 of 25000, training loss: 0.677899\n",
      "Train Epoch: 0, mini-batch 21520 of 25000, training loss: 0.023589\n",
      "Train Epoch: 0, mini-batch 21530 of 25000, training loss: 0.147550\n",
      "Train Epoch: 0, mini-batch 21540 of 25000, training loss: 0.279594\n",
      "Train Epoch: 0, mini-batch 21550 of 25000, training loss: 0.678131\n",
      "Train Epoch: 0, mini-batch 21560 of 25000, training loss: 0.318542\n",
      "Train Epoch: 0, mini-batch 21570 of 25000, training loss: 1.157726\n",
      "Train Epoch: 0, mini-batch 21580 of 25000, training loss: 0.046803\n",
      "Train Epoch: 0, mini-batch 21590 of 25000, training loss: 0.085994\n",
      "Train Epoch: 0, mini-batch 21600 of 25000, training loss: 0.002600\n",
      "Train Epoch: 0, mini-batch 21610 of 25000, training loss: 0.018450\n",
      "Train Epoch: 0, mini-batch 21620 of 25000, training loss: 0.057825\n",
      "Train Epoch: 0, mini-batch 21630 of 25000, training loss: 0.527436\n",
      "Train Epoch: 0, mini-batch 21640 of 25000, training loss: 0.097459\n",
      "Train Epoch: 0, mini-batch 21650 of 25000, training loss: 0.265399\n",
      "Train Epoch: 0, mini-batch 21660 of 25000, training loss: 0.001221\n",
      "Train Epoch: 0, mini-batch 21670 of 25000, training loss: 1.067145\n",
      "Train Epoch: 0, mini-batch 21680 of 25000, training loss: 1.984938\n",
      "Train Epoch: 0, mini-batch 21690 of 25000, training loss: 0.000095\n",
      "Train Epoch: 0, mini-batch 21700 of 25000, training loss: 0.014204\n",
      "Train Epoch: 0, mini-batch 21710 of 25000, training loss: 0.099891\n",
      "Train Epoch: 0, mini-batch 21720 of 25000, training loss: 0.290192\n",
      "Train Epoch: 0, mini-batch 21730 of 25000, training loss: 0.012716\n",
      "Train Epoch: 0, mini-batch 21740 of 25000, training loss: 0.003731\n",
      "Train Epoch: 0, mini-batch 21750 of 25000, training loss: 0.088727\n",
      "Train Epoch: 0, mini-batch 21760 of 25000, training loss: 0.009596\n",
      "Train Epoch: 0, mini-batch 21770 of 25000, training loss: 0.060348\n",
      "Train Epoch: 0, mini-batch 21780 of 25000, training loss: 0.024365\n",
      "Train Epoch: 0, mini-batch 21790 of 25000, training loss: 0.000120\n",
      "Train Epoch: 0, mini-batch 21800 of 25000, training loss: 0.005589\n",
      "Train Epoch: 0, mini-batch 21810 of 25000, training loss: 0.141496\n",
      "Train Epoch: 0, mini-batch 21820 of 25000, training loss: 0.350348\n",
      "Train Epoch: 0, mini-batch 21830 of 25000, training loss: 0.063950\n",
      "Train Epoch: 0, mini-batch 21840 of 25000, training loss: 0.164301\n",
      "Train Epoch: 0, mini-batch 21850 of 25000, training loss: 3.520641\n",
      "Train Epoch: 0, mini-batch 21860 of 25000, training loss: 0.000406\n",
      "Train Epoch: 0, mini-batch 21870 of 25000, training loss: 0.000002\n",
      "Train Epoch: 0, mini-batch 21880 of 25000, training loss: 0.729269\n",
      "Train Epoch: 0, mini-batch 21890 of 25000, training loss: 0.025678\n",
      "Train Epoch: 0, mini-batch 21900 of 25000, training loss: 0.015716\n",
      "Train Epoch: 0, mini-batch 21910 of 25000, training loss: 0.548783\n",
      "Train Epoch: 0, mini-batch 21920 of 25000, training loss: 0.098718\n",
      "Train Epoch: 0, mini-batch 21930 of 25000, training loss: 0.012524\n",
      "Train Epoch: 0, mini-batch 21940 of 25000, training loss: 0.090334\n",
      "Train Epoch: 0, mini-batch 21950 of 25000, training loss: 0.316156\n",
      "Train Epoch: 0, mini-batch 21960 of 25000, training loss: 5.056024\n",
      "Train Epoch: 0, mini-batch 21970 of 25000, training loss: 0.049429\n",
      "Train Epoch: 0, mini-batch 21980 of 25000, training loss: 0.581150\n",
      "Train Epoch: 0, mini-batch 21990 of 25000, training loss: 0.300483\n",
      "Train Epoch: 0, mini-batch 22000 of 25000, training loss: 0.032518\n",
      "Train Epoch: 0, mini-batch 22010 of 25000, training loss: 0.729442\n",
      "Train Epoch: 0, mini-batch 22020 of 25000, training loss: 0.085912\n",
      "Train Epoch: 0, mini-batch 22030 of 25000, training loss: 0.947098\n",
      "Train Epoch: 0, mini-batch 22040 of 25000, training loss: 0.375213\n",
      "Train Epoch: 0, mini-batch 22050 of 25000, training loss: 0.039082\n",
      "Train Epoch: 0, mini-batch 22060 of 25000, training loss: 0.212890\n",
      "Train Epoch: 0, mini-batch 22070 of 25000, training loss: 0.421469\n",
      "Train Epoch: 0, mini-batch 22080 of 25000, training loss: 0.042121\n",
      "Train Epoch: 0, mini-batch 22090 of 25000, training loss: 0.526433\n",
      "Train Epoch: 0, mini-batch 22100 of 25000, training loss: 0.016523\n",
      "Train Epoch: 0, mini-batch 22110 of 25000, training loss: 0.089694\n",
      "Train Epoch: 0, mini-batch 22120 of 25000, training loss: 0.096690\n",
      "Train Epoch: 0, mini-batch 22130 of 25000, training loss: 0.087115\n",
      "Train Epoch: 0, mini-batch 22140 of 25000, training loss: 0.051730\n",
      "Train Epoch: 0, mini-batch 22150 of 25000, training loss: 0.866696\n",
      "Train Epoch: 0, mini-batch 22160 of 25000, training loss: 0.104877\n",
      "Train Epoch: 0, mini-batch 22170 of 25000, training loss: 0.010518\n",
      "Train Epoch: 0, mini-batch 22180 of 25000, training loss: 0.064245\n",
      "Train Epoch: 0, mini-batch 22190 of 25000, training loss: 0.012846\n",
      "Train Epoch: 0, mini-batch 22200 of 25000, training loss: 0.009088\n",
      "Train Epoch: 0, mini-batch 22210 of 25000, training loss: 0.370037\n",
      "Train Epoch: 0, mini-batch 22220 of 25000, training loss: 0.006480\n",
      "Train Epoch: 0, mini-batch 22230 of 25000, training loss: 0.688982\n",
      "Train Epoch: 0, mini-batch 22240 of 25000, training loss: 0.017069\n",
      "Train Epoch: 0, mini-batch 22250 of 25000, training loss: 0.023247\n",
      "Train Epoch: 0, mini-batch 22260 of 25000, training loss: 1.595852\n",
      "Train Epoch: 0, mini-batch 22270 of 25000, training loss: 0.084893\n",
      "Train Epoch: 0, mini-batch 22280 of 25000, training loss: 1.578982\n",
      "Train Epoch: 0, mini-batch 22290 of 25000, training loss: 0.028760\n",
      "Train Epoch: 0, mini-batch 22300 of 25000, training loss: 0.012782\n",
      "Train Epoch: 0, mini-batch 22310 of 25000, training loss: 0.004328\n",
      "Train Epoch: 0, mini-batch 22320 of 25000, training loss: 0.005744\n",
      "Train Epoch: 0, mini-batch 22330 of 25000, training loss: 0.088962\n",
      "Train Epoch: 0, mini-batch 22340 of 25000, training loss: 0.147566\n",
      "Train Epoch: 0, mini-batch 22350 of 25000, training loss: 0.013366\n",
      "Train Epoch: 0, mini-batch 22360 of 25000, training loss: 0.055124\n",
      "Train Epoch: 0, mini-batch 22370 of 25000, training loss: 0.045263\n",
      "Train Epoch: 0, mini-batch 22380 of 25000, training loss: 0.001676\n",
      "Train Epoch: 0, mini-batch 22390 of 25000, training loss: 0.898243\n",
      "Train Epoch: 0, mini-batch 22400 of 25000, training loss: 0.000945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 22410 of 25000, training loss: 0.004585\n",
      "Train Epoch: 0, mini-batch 22420 of 25000, training loss: 0.178204\n",
      "Train Epoch: 0, mini-batch 22430 of 25000, training loss: 0.027846\n",
      "Train Epoch: 0, mini-batch 22440 of 25000, training loss: 0.031034\n",
      "Train Epoch: 0, mini-batch 22450 of 25000, training loss: 0.113693\n",
      "Train Epoch: 0, mini-batch 22460 of 25000, training loss: 0.002285\n",
      "Train Epoch: 0, mini-batch 22470 of 25000, training loss: 0.025713\n",
      "Train Epoch: 0, mini-batch 22480 of 25000, training loss: 0.000117\n",
      "Train Epoch: 0, mini-batch 22490 of 25000, training loss: 0.175566\n",
      "Train Epoch: 0, mini-batch 22500 of 25000, training loss: 0.015178\n",
      "Train Epoch: 0, mini-batch 22510 of 25000, training loss: 0.016775\n",
      "Train Epoch: 0, mini-batch 22520 of 25000, training loss: 0.171407\n",
      "Train Epoch: 0, mini-batch 22530 of 25000, training loss: 0.609514\n",
      "Train Epoch: 0, mini-batch 22540 of 25000, training loss: 0.141514\n",
      "Train Epoch: 0, mini-batch 22550 of 25000, training loss: 0.365159\n",
      "Train Epoch: 0, mini-batch 22560 of 25000, training loss: 0.577093\n",
      "Train Epoch: 0, mini-batch 22570 of 25000, training loss: 0.008607\n",
      "Train Epoch: 0, mini-batch 22580 of 25000, training loss: 0.120565\n",
      "Train Epoch: 0, mini-batch 22590 of 25000, training loss: 0.795275\n",
      "Train Epoch: 0, mini-batch 22600 of 25000, training loss: 0.668278\n",
      "Train Epoch: 0, mini-batch 22610 of 25000, training loss: 0.588351\n",
      "Train Epoch: 0, mini-batch 22620 of 25000, training loss: 0.307604\n",
      "Train Epoch: 0, mini-batch 22630 of 25000, training loss: 0.010588\n",
      "Train Epoch: 0, mini-batch 22640 of 25000, training loss: 0.019784\n",
      "Train Epoch: 0, mini-batch 22650 of 25000, training loss: 0.035037\n",
      "Train Epoch: 0, mini-batch 22660 of 25000, training loss: 0.000419\n",
      "Train Epoch: 0, mini-batch 22670 of 25000, training loss: 0.092802\n",
      "Train Epoch: 0, mini-batch 22680 of 25000, training loss: 0.679053\n",
      "Train Epoch: 0, mini-batch 22690 of 25000, training loss: 0.002242\n",
      "Train Epoch: 0, mini-batch 22700 of 25000, training loss: 0.014619\n",
      "Train Epoch: 0, mini-batch 22710 of 25000, training loss: 0.006737\n",
      "Train Epoch: 0, mini-batch 22720 of 25000, training loss: 0.155924\n",
      "Train Epoch: 0, mini-batch 22730 of 25000, training loss: 0.838903\n",
      "Train Epoch: 0, mini-batch 22740 of 25000, training loss: 0.019903\n",
      "Train Epoch: 0, mini-batch 22750 of 25000, training loss: 0.007403\n",
      "Train Epoch: 0, mini-batch 22760 of 25000, training loss: 0.063869\n",
      "Train Epoch: 0, mini-batch 22770 of 25000, training loss: 0.868907\n",
      "Train Epoch: 0, mini-batch 22780 of 25000, training loss: 0.128161\n",
      "Train Epoch: 0, mini-batch 22790 of 25000, training loss: 0.597601\n",
      "Train Epoch: 0, mini-batch 22800 of 25000, training loss: 0.246865\n",
      "Train Epoch: 0, mini-batch 22810 of 25000, training loss: 0.889776\n",
      "Train Epoch: 0, mini-batch 22820 of 25000, training loss: 0.360978\n",
      "Train Epoch: 0, mini-batch 22830 of 25000, training loss: 0.242951\n",
      "Train Epoch: 0, mini-batch 22840 of 25000, training loss: 0.059619\n",
      "Train Epoch: 0, mini-batch 22850 of 25000, training loss: 0.800595\n",
      "Train Epoch: 0, mini-batch 22860 of 25000, training loss: 1.088995\n",
      "Train Epoch: 0, mini-batch 22870 of 25000, training loss: 0.535763\n",
      "Train Epoch: 0, mini-batch 22880 of 25000, training loss: 0.116638\n",
      "Train Epoch: 0, mini-batch 22890 of 25000, training loss: 1.303311\n",
      "Train Epoch: 0, mini-batch 22900 of 25000, training loss: 1.141062\n",
      "Train Epoch: 0, mini-batch 22910 of 25000, training loss: 0.013197\n",
      "Train Epoch: 0, mini-batch 22920 of 25000, training loss: 0.715254\n",
      "Train Epoch: 0, mini-batch 22930 of 25000, training loss: 0.000818\n",
      "Train Epoch: 0, mini-batch 22940 of 25000, training loss: 0.753995\n",
      "Train Epoch: 0, mini-batch 22950 of 25000, training loss: 0.765909\n",
      "Train Epoch: 0, mini-batch 22960 of 25000, training loss: 0.141664\n",
      "Train Epoch: 0, mini-batch 22970 of 25000, training loss: 0.027010\n",
      "Train Epoch: 0, mini-batch 22980 of 25000, training loss: 0.403360\n",
      "Train Epoch: 0, mini-batch 22990 of 25000, training loss: 0.556249\n",
      "Train Epoch: 0, mini-batch 23000 of 25000, training loss: 0.260140\n",
      "Train Epoch: 0, mini-batch 23010 of 25000, training loss: 0.021835\n",
      "Train Epoch: 0, mini-batch 23020 of 25000, training loss: 1.850492\n",
      "Train Epoch: 0, mini-batch 23030 of 25000, training loss: 0.168327\n",
      "Train Epoch: 0, mini-batch 23040 of 25000, training loss: 0.004000\n",
      "Train Epoch: 0, mini-batch 23050 of 25000, training loss: 0.010202\n",
      "Train Epoch: 0, mini-batch 23060 of 25000, training loss: 0.098169\n",
      "Train Epoch: 0, mini-batch 23070 of 25000, training loss: 0.051816\n",
      "Train Epoch: 0, mini-batch 23080 of 25000, training loss: 0.133223\n",
      "Train Epoch: 0, mini-batch 23090 of 25000, training loss: 0.047062\n",
      "Train Epoch: 0, mini-batch 23100 of 25000, training loss: 0.046625\n",
      "Train Epoch: 0, mini-batch 23110 of 25000, training loss: 0.050548\n",
      "Train Epoch: 0, mini-batch 23120 of 25000, training loss: 0.014775\n",
      "Train Epoch: 0, mini-batch 23130 of 25000, training loss: 0.020546\n",
      "Train Epoch: 0, mini-batch 23140 of 25000, training loss: 0.033686\n",
      "Train Epoch: 0, mini-batch 23150 of 25000, training loss: 0.078357\n",
      "Train Epoch: 0, mini-batch 23160 of 25000, training loss: 0.110277\n",
      "Train Epoch: 0, mini-batch 23170 of 25000, training loss: 0.152948\n",
      "Train Epoch: 0, mini-batch 23180 of 25000, training loss: 0.293520\n",
      "Train Epoch: 0, mini-batch 23190 of 25000, training loss: 0.075038\n",
      "Train Epoch: 0, mini-batch 23200 of 25000, training loss: 0.004070\n",
      "Train Epoch: 0, mini-batch 23210 of 25000, training loss: 0.027446\n",
      "Train Epoch: 0, mini-batch 23220 of 25000, training loss: 0.251659\n",
      "Train Epoch: 0, mini-batch 23230 of 25000, training loss: 0.012768\n",
      "Train Epoch: 0, mini-batch 23240 of 25000, training loss: 1.013221\n",
      "Train Epoch: 0, mini-batch 23250 of 25000, training loss: 0.677242\n",
      "Train Epoch: 0, mini-batch 23260 of 25000, training loss: 0.001238\n",
      "Train Epoch: 0, mini-batch 23270 of 25000, training loss: 0.000420\n",
      "Train Epoch: 0, mini-batch 23280 of 25000, training loss: 0.085451\n",
      "Train Epoch: 0, mini-batch 23290 of 25000, training loss: 0.445647\n",
      "Train Epoch: 0, mini-batch 23300 of 25000, training loss: 0.023630\n",
      "Train Epoch: 0, mini-batch 23310 of 25000, training loss: 0.000849\n",
      "Train Epoch: 0, mini-batch 23320 of 25000, training loss: 0.110487\n",
      "Train Epoch: 0, mini-batch 23330 of 25000, training loss: 0.095115\n",
      "Train Epoch: 0, mini-batch 23340 of 25000, training loss: 0.327229\n",
      "Train Epoch: 0, mini-batch 23350 of 25000, training loss: 0.168578\n",
      "Train Epoch: 0, mini-batch 23360 of 25000, training loss: 0.016923\n",
      "Train Epoch: 0, mini-batch 23370 of 25000, training loss: 0.183191\n",
      "Train Epoch: 0, mini-batch 23380 of 25000, training loss: 0.036560\n",
      "Train Epoch: 0, mini-batch 23390 of 25000, training loss: 0.002583\n",
      "Train Epoch: 0, mini-batch 23400 of 25000, training loss: 0.134020\n",
      "Train Epoch: 0, mini-batch 23410 of 25000, training loss: 0.155677\n",
      "Train Epoch: 0, mini-batch 23420 of 25000, training loss: 0.091215\n",
      "Train Epoch: 0, mini-batch 23430 of 25000, training loss: 0.147524\n",
      "Train Epoch: 0, mini-batch 23440 of 25000, training loss: 0.040260\n",
      "Train Epoch: 0, mini-batch 23450 of 25000, training loss: 0.016218\n",
      "Train Epoch: 0, mini-batch 23460 of 25000, training loss: 0.181055\n",
      "Train Epoch: 0, mini-batch 23470 of 25000, training loss: 0.075671\n",
      "Train Epoch: 0, mini-batch 23480 of 25000, training loss: 0.937310\n",
      "Train Epoch: 0, mini-batch 23490 of 25000, training loss: 0.665750\n",
      "Train Epoch: 0, mini-batch 23500 of 25000, training loss: 0.003655\n",
      "Train Epoch: 0, mini-batch 23510 of 25000, training loss: 0.132810\n",
      "Train Epoch: 0, mini-batch 23520 of 25000, training loss: 0.646393\n",
      "Train Epoch: 0, mini-batch 23530 of 25000, training loss: 0.024360\n",
      "Train Epoch: 0, mini-batch 23540 of 25000, training loss: 0.346384\n",
      "Train Epoch: 0, mini-batch 23550 of 25000, training loss: 0.111735\n",
      "Train Epoch: 0, mini-batch 23560 of 25000, training loss: 0.023463\n",
      "Train Epoch: 0, mini-batch 23570 of 25000, training loss: 8.687633\n",
      "Train Epoch: 0, mini-batch 23580 of 25000, training loss: 0.647796\n",
      "Train Epoch: 0, mini-batch 23590 of 25000, training loss: 0.022969\n",
      "Train Epoch: 0, mini-batch 23600 of 25000, training loss: 1.700427\n",
      "Train Epoch: 0, mini-batch 23610 of 25000, training loss: 0.394692\n",
      "Train Epoch: 0, mini-batch 23620 of 25000, training loss: 0.077876\n",
      "Train Epoch: 0, mini-batch 23630 of 25000, training loss: 0.001839\n",
      "Train Epoch: 0, mini-batch 23640 of 25000, training loss: 0.065295\n",
      "Train Epoch: 0, mini-batch 23650 of 25000, training loss: 0.173208\n",
      "Train Epoch: 0, mini-batch 23660 of 25000, training loss: 0.050218\n",
      "Train Epoch: 0, mini-batch 23670 of 25000, training loss: 0.213924\n",
      "Train Epoch: 0, mini-batch 23680 of 25000, training loss: 0.320938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 23690 of 25000, training loss: 0.051803\n",
      "Train Epoch: 0, mini-batch 23700 of 25000, training loss: 0.284521\n",
      "Train Epoch: 0, mini-batch 23710 of 25000, training loss: 0.118840\n",
      "Train Epoch: 0, mini-batch 23720 of 25000, training loss: 1.698763\n",
      "Train Epoch: 0, mini-batch 23730 of 25000, training loss: 0.001330\n",
      "Train Epoch: 0, mini-batch 23740 of 25000, training loss: 0.001398\n",
      "Train Epoch: 0, mini-batch 23750 of 25000, training loss: 0.005917\n",
      "Train Epoch: 0, mini-batch 23760 of 25000, training loss: 0.099938\n",
      "Train Epoch: 0, mini-batch 23770 of 25000, training loss: 0.457634\n",
      "Train Epoch: 0, mini-batch 23780 of 25000, training loss: 0.005029\n",
      "Train Epoch: 0, mini-batch 23790 of 25000, training loss: 0.180113\n",
      "Train Epoch: 0, mini-batch 23800 of 25000, training loss: 0.020613\n",
      "Train Epoch: 0, mini-batch 23810 of 25000, training loss: 0.200635\n",
      "Train Epoch: 0, mini-batch 23820 of 25000, training loss: 0.049420\n",
      "Train Epoch: 0, mini-batch 23830 of 25000, training loss: 0.585810\n",
      "Train Epoch: 0, mini-batch 23840 of 25000, training loss: 0.212236\n",
      "Train Epoch: 0, mini-batch 23850 of 25000, training loss: 0.105225\n",
      "Train Epoch: 0, mini-batch 23860 of 25000, training loss: 0.209263\n",
      "Train Epoch: 0, mini-batch 23870 of 25000, training loss: 0.009311\n",
      "Train Epoch: 0, mini-batch 23880 of 25000, training loss: 0.162803\n",
      "Train Epoch: 0, mini-batch 23890 of 25000, training loss: 0.067515\n",
      "Train Epoch: 0, mini-batch 23900 of 25000, training loss: 0.020797\n",
      "Train Epoch: 0, mini-batch 23910 of 25000, training loss: 0.046279\n",
      "Train Epoch: 0, mini-batch 23920 of 25000, training loss: 0.055029\n",
      "Train Epoch: 0, mini-batch 23930 of 25000, training loss: 0.715376\n",
      "Train Epoch: 0, mini-batch 23940 of 25000, training loss: 0.054970\n",
      "Train Epoch: 0, mini-batch 23950 of 25000, training loss: 0.100692\n",
      "Train Epoch: 0, mini-batch 23960 of 25000, training loss: 0.037400\n",
      "Train Epoch: 0, mini-batch 23970 of 25000, training loss: 0.022403\n",
      "Train Epoch: 0, mini-batch 23980 of 25000, training loss: 0.350300\n",
      "Train Epoch: 0, mini-batch 23990 of 25000, training loss: 0.111038\n",
      "Train Epoch: 0, mini-batch 24000 of 25000, training loss: 0.007188\n",
      "Train Epoch: 0, mini-batch 24010 of 25000, training loss: 0.479052\n",
      "Train Epoch: 0, mini-batch 24020 of 25000, training loss: 4.396238\n",
      "Train Epoch: 0, mini-batch 24030 of 25000, training loss: 0.556418\n",
      "Train Epoch: 0, mini-batch 24040 of 25000, training loss: 0.160989\n",
      "Train Epoch: 0, mini-batch 24050 of 25000, training loss: 0.021009\n",
      "Train Epoch: 0, mini-batch 24060 of 25000, training loss: 0.071069\n",
      "Train Epoch: 0, mini-batch 24070 of 25000, training loss: 0.040805\n",
      "Train Epoch: 0, mini-batch 24080 of 25000, training loss: 0.087681\n",
      "Train Epoch: 0, mini-batch 24090 of 25000, training loss: 0.011719\n",
      "Train Epoch: 0, mini-batch 24100 of 25000, training loss: 0.063700\n",
      "Train Epoch: 0, mini-batch 24110 of 25000, training loss: 0.071413\n",
      "Train Epoch: 0, mini-batch 24120 of 25000, training loss: 0.255864\n",
      "Train Epoch: 0, mini-batch 24130 of 25000, training loss: 0.548853\n",
      "Train Epoch: 0, mini-batch 24140 of 25000, training loss: 0.030991\n",
      "Train Epoch: 0, mini-batch 24150 of 25000, training loss: 0.006537\n",
      "Train Epoch: 0, mini-batch 24160 of 25000, training loss: 0.066338\n",
      "Train Epoch: 0, mini-batch 24170 of 25000, training loss: 0.775269\n",
      "Train Epoch: 0, mini-batch 24180 of 25000, training loss: 0.041345\n",
      "Train Epoch: 0, mini-batch 24190 of 25000, training loss: 0.116682\n",
      "Train Epoch: 0, mini-batch 24200 of 25000, training loss: 0.079059\n",
      "Train Epoch: 0, mini-batch 24210 of 25000, training loss: 0.148774\n",
      "Train Epoch: 0, mini-batch 24220 of 25000, training loss: 1.905640\n",
      "Train Epoch: 0, mini-batch 24230 of 25000, training loss: 0.022051\n",
      "Train Epoch: 0, mini-batch 24240 of 25000, training loss: 0.008949\n",
      "Train Epoch: 0, mini-batch 24250 of 25000, training loss: 0.012507\n",
      "Train Epoch: 0, mini-batch 24260 of 25000, training loss: 0.529410\n",
      "Train Epoch: 0, mini-batch 24270 of 25000, training loss: 0.018486\n",
      "Train Epoch: 0, mini-batch 24280 of 25000, training loss: 0.292022\n",
      "Train Epoch: 0, mini-batch 24290 of 25000, training loss: 0.001354\n",
      "Train Epoch: 0, mini-batch 24300 of 25000, training loss: 0.046762\n",
      "Train Epoch: 0, mini-batch 24310 of 25000, training loss: 0.038416\n",
      "Train Epoch: 0, mini-batch 24320 of 25000, training loss: 1.764993\n",
      "Train Epoch: 0, mini-batch 24330 of 25000, training loss: 0.478149\n",
      "Train Epoch: 0, mini-batch 24340 of 25000, training loss: 0.000774\n",
      "Train Epoch: 0, mini-batch 24350 of 25000, training loss: 0.012765\n",
      "Train Epoch: 0, mini-batch 24360 of 25000, training loss: 0.371038\n",
      "Train Epoch: 0, mini-batch 24370 of 25000, training loss: 1.155737\n",
      "Train Epoch: 0, mini-batch 24380 of 25000, training loss: 0.268651\n",
      "Train Epoch: 0, mini-batch 24390 of 25000, training loss: 0.026020\n",
      "Train Epoch: 0, mini-batch 24400 of 25000, training loss: 0.487359\n",
      "Train Epoch: 0, mini-batch 24410 of 25000, training loss: 1.795994\n",
      "Train Epoch: 0, mini-batch 24420 of 25000, training loss: 0.011325\n",
      "Train Epoch: 0, mini-batch 24430 of 25000, training loss: 0.046999\n",
      "Train Epoch: 0, mini-batch 24440 of 25000, training loss: 0.297268\n",
      "Train Epoch: 0, mini-batch 24450 of 25000, training loss: 0.253332\n",
      "Train Epoch: 0, mini-batch 24460 of 25000, training loss: 1.136261\n",
      "Train Epoch: 0, mini-batch 24470 of 25000, training loss: 1.414636\n",
      "Train Epoch: 0, mini-batch 24480 of 25000, training loss: 0.028170\n",
      "Train Epoch: 0, mini-batch 24490 of 25000, training loss: 0.077280\n",
      "Train Epoch: 0, mini-batch 24500 of 25000, training loss: 0.055282\n",
      "Train Epoch: 0, mini-batch 24510 of 25000, training loss: 0.113375\n",
      "Train Epoch: 0, mini-batch 24520 of 25000, training loss: 0.076186\n",
      "Train Epoch: 0, mini-batch 24530 of 25000, training loss: 0.626003\n",
      "Train Epoch: 0, mini-batch 24540 of 25000, training loss: 0.140676\n",
      "Train Epoch: 0, mini-batch 24550 of 25000, training loss: 0.101394\n",
      "Train Epoch: 0, mini-batch 24560 of 25000, training loss: 0.009058\n",
      "Train Epoch: 0, mini-batch 24570 of 25000, training loss: 0.067266\n",
      "Train Epoch: 0, mini-batch 24580 of 25000, training loss: 0.956319\n",
      "Train Epoch: 0, mini-batch 24590 of 25000, training loss: 0.059514\n",
      "Train Epoch: 0, mini-batch 24600 of 25000, training loss: 0.256092\n",
      "Train Epoch: 0, mini-batch 24610 of 25000, training loss: 0.174594\n",
      "Train Epoch: 0, mini-batch 24620 of 25000, training loss: 0.179798\n",
      "Train Epoch: 0, mini-batch 24630 of 25000, training loss: 0.175935\n",
      "Train Epoch: 0, mini-batch 24640 of 25000, training loss: 0.428567\n",
      "Train Epoch: 0, mini-batch 24650 of 25000, training loss: 3.091706\n",
      "Train Epoch: 0, mini-batch 24660 of 25000, training loss: 0.035582\n",
      "Train Epoch: 0, mini-batch 24670 of 25000, training loss: 0.031932\n",
      "Train Epoch: 0, mini-batch 24680 of 25000, training loss: 0.178019\n",
      "Train Epoch: 0, mini-batch 24690 of 25000, training loss: 0.081292\n",
      "Train Epoch: 0, mini-batch 24700 of 25000, training loss: 1.986680\n",
      "Train Epoch: 0, mini-batch 24710 of 25000, training loss: 0.016140\n",
      "Train Epoch: 0, mini-batch 24720 of 25000, training loss: 0.029537\n",
      "Train Epoch: 0, mini-batch 24730 of 25000, training loss: 0.110522\n",
      "Train Epoch: 0, mini-batch 24740 of 25000, training loss: 0.014847\n",
      "Train Epoch: 0, mini-batch 24750 of 25000, training loss: 0.267721\n",
      "Train Epoch: 0, mini-batch 24760 of 25000, training loss: 0.148574\n",
      "Train Epoch: 0, mini-batch 24770 of 25000, training loss: 0.018888\n",
      "Train Epoch: 0, mini-batch 24780 of 25000, training loss: 0.280316\n",
      "Train Epoch: 0, mini-batch 24790 of 25000, training loss: 0.004554\n",
      "Train Epoch: 0, mini-batch 24800 of 25000, training loss: 0.025803\n",
      "Train Epoch: 0, mini-batch 24810 of 25000, training loss: 0.053160\n",
      "Train Epoch: 0, mini-batch 24820 of 25000, training loss: 0.160378\n",
      "Train Epoch: 0, mini-batch 24830 of 25000, training loss: 0.339660\n",
      "Train Epoch: 0, mini-batch 24840 of 25000, training loss: 0.055187\n",
      "Train Epoch: 0, mini-batch 24850 of 25000, training loss: 0.380478\n",
      "Train Epoch: 0, mini-batch 24860 of 25000, training loss: 0.044508\n",
      "Train Epoch: 0, mini-batch 24870 of 25000, training loss: 0.019370\n",
      "Train Epoch: 0, mini-batch 24880 of 25000, training loss: 0.437233\n",
      "Train Epoch: 0, mini-batch 24890 of 25000, training loss: 0.236408\n",
      "Train Epoch: 0, mini-batch 24900 of 25000, training loss: 0.110804\n",
      "Train Epoch: 0, mini-batch 24910 of 25000, training loss: 0.252736\n",
      "Train Epoch: 0, mini-batch 24920 of 25000, training loss: 0.200888\n",
      "Train Epoch: 0, mini-batch 24930 of 25000, training loss: 0.435788\n",
      "Train Epoch: 0, mini-batch 24940 of 25000, training loss: 0.127359\n",
      "Train Epoch: 0, mini-batch 24950 of 25000, training loss: 0.005992\n",
      "Train Epoch: 0, mini-batch 24960 of 25000, training loss: 0.058423\n",
      "Train Epoch: 0, mini-batch 24970 of 25000, training loss: 0.098801\n",
      "Train Epoch: 0, mini-batch 24980 of 25000, training loss: 0.198107\n",
      "Train Epoch: 0, mini-batch 24990 of 25000, training loss: 0.236492\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "train_data_gen = zip(train_features, train_target)\n",
    "train_size = len(train_target)\n",
    "\n",
    "while epoch < epochs:\n",
    "    predictions = []\n",
    "    truth_values = []\n",
    "\n",
    "    for batch_idx, (xs, y) in enumerate(train_data_gen):\n",
    "        xs, y = torch.from_numpy(xs).float(), torch.FloatTensor([y])\n",
    "\n",
    "        y_pred = model(xs)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        #nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions.append(y_pred.cpu().data.numpy().ravel())\n",
    "        truth_values.append(y)\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {}, mini-batch {} of {}, training loss: {:.6f}'.format(\n",
    "                epoch, batch_idx, train_size, loss.item()))\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls  # toggle 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test accuracy histories\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch, train_loss)\n",
    "plt.plot(epoch, test_loss)\n",
    "# plt.plot(no_reg['epoch'], no_reg['train_loss'])  # toggle 0\n",
    "# plt.plot(no_reg['epoch'], no_reg['test_loss'])  # toggle 0\n",
    "\n",
    "plt.legend(['Train loss', 'Test loss', 'Train no-reg', 'Test no-reg'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss score')\n",
    "\n",
    "# Get training and test accuracy histories\n",
    "train_accuracy = history.history['acc']\n",
    "test_accuracy = history.history['val_acc']\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch, train_accuracy)\n",
    "plt.plot(epoch, test_accuracy)\n",
    "# plt.plot(no_reg['epoch'], no_reg['train_accuracy'])  # toggle 0\n",
    "# plt.plot(no_reg['epoch'], no_reg['test_accuracy'])  # toggle 0\n",
    "\n",
    "plt.legend(['Train accuracy', 'Test accuracy', 'Train no-reg', 'Test no-reg'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "\n",
    "no_reg = {                             # toggle 0\n",
    "    'epoch': epoch,                    # toggle 0\n",
    "    'train_loss': train_loss,          # toggle 0\n",
    "    'test_loss': test_loss,            # toggle 0\n",
    "    'train_accuracy': train_accuracy,  # toggle 0\n",
    "    'test_accuracy': test_accuracy,    # toggle 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup weights\n",
    "weights = network.layers[0].get_weights()[0]  # toggle 0\n",
    "# weights_L1 = network.layers[0].get_weights()[0]  # toggle 1\n",
    "# weights_L2 = network.layers[0].get_weights()[0]  # toggle 2\n",
    "# weights_max = network.layers[0].get_weights()[0]  # toggle 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you got to toggle `# toggle 3`, execute the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show weight distribution\n",
    "plt.hist((\n",
    "    weights.reshape(-1),\n",
    "    weights_L1.reshape(-1),\n",
    "    weights_L2.reshape(-1),\n",
    "    weights_max.reshape(-1),\n",
    "), 49, range=(-.5, .5), label=(\n",
    "    'No-reg',\n",
    "    'L1',\n",
    "    'L2',\n",
    "    'Max',\n",
    "))\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codas ML",
   "language": "python",
   "name": "codasml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
