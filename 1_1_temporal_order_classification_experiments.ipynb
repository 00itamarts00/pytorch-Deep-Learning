{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114767df0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sequential_tasks import TemporalOrderExp6aSequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, rnn_hidden_size, output_size):\n",
    "\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size, rnn_hidden_size, num_layers=1, nonlinearity='relu', batch_first=True)\n",
    "        #self.h_0 = self.initialize_hidden(rnn_hidden_size)\n",
    "        self.linear = torch.nn.Linear(rnn_hidden_size, output_size) \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(0)\n",
    "        #self.rnn.flatten_parameters()\n",
    "        #out, self.h_0 = self.rnn(x, self.h_0)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.linear(out)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "    #def initialize_hidden(self, rnn_hidden_size):\n",
    "    #    return Variable(torch.randn(2, 1, rnn_hidden_size), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp6a_experiment(settings):\n",
    "    train_data_gen = TemporalOrderExp6aSequence.get_predefined_generator(\n",
    "        settings['difficulty'],\n",
    "        settings['batch_size'])\n",
    "\n",
    "    model = SimpleRNN(train_data_gen.n_symbols, settings['h_units'], train_data_gen.n_classes)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "    epochs = settings['max_epochs']\n",
    "    log_interval = settings['log_interval']\n",
    "\n",
    "    epoch = 0\n",
    "    while epoch < epochs:\n",
    "        predictions = []\n",
    "        truth_values = []\n",
    "   \n",
    "        for batch_idx, (xs, ys) in enumerate(train_data_gen):\n",
    "            xs, ys = torch.from_numpy(xs).float(), torch.from_numpy(ys).long()\n",
    "\n",
    "            y_pred = model(xs)\n",
    "            loss = criterion(y_pred, ys)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "            predictions.append(y_pred.cpu().data.numpy().ravel())\n",
    "            truth_values.append(ys.cpu().data.numpy().ravel())\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {}, mini-batch {} of {}, training loss: {:.6f}'.format(\n",
    "                    epoch, batch_idx, len(train_data_gen), loss.item()))\n",
    "\n",
    "        epoch += 1\n",
    "    \n",
    "    # testing\n",
    "    test_data_gen = TemporalOrderExp6aSequence.get_predefined_generator(\n",
    "        settings['difficulty'],\n",
    "        settings['batch_size'])\n",
    "\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (xs, ys) in enumerate(test_data_gen):\n",
    "            xs, ys = torch.from_numpy(xs).float(), torch.from_numpy(ys).long()\n",
    "            output = model(xs)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(ys.view_as(pred)).sum().item()\n",
    "\n",
    "    test_accuracy = float(correct) / len(test_data_gen)\n",
    "    print('\\nAccuracy: {}'.format(test_accuracy))\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 0 of 31, training loss: 2.223053\n",
      "Train Epoch: 0, mini-batch 10 of 31, training loss: 2.174639\n",
      "Train Epoch: 0, mini-batch 20 of 31, training loss: 2.136809\n",
      "Train Epoch: 0, mini-batch 30 of 31, training loss: 2.114726\n",
      "Train Epoch: 0, mini-batch 40 of 31, training loss: 2.083107\n",
      "Train Epoch: 0, mini-batch 50 of 31, training loss: 2.044508\n",
      "Train Epoch: 0, mini-batch 60 of 31, training loss: 2.015424\n",
      "Train Epoch: 0, mini-batch 70 of 31, training loss: 1.956085\n",
      "Train Epoch: 0, mini-batch 80 of 31, training loss: 1.902780\n",
      "Train Epoch: 0, mini-batch 90 of 31, training loss: 1.773027\n",
      "Train Epoch: 0, mini-batch 100 of 31, training loss: 1.618411\n",
      "Train Epoch: 0, mini-batch 110 of 31, training loss: 1.461884\n",
      "Train Epoch: 0, mini-batch 120 of 31, training loss: 1.294207\n",
      "Train Epoch: 0, mini-batch 130 of 31, training loss: 1.150648\n",
      "Train Epoch: 0, mini-batch 140 of 31, training loss: 1.032733\n",
      "Train Epoch: 0, mini-batch 150 of 31, training loss: 0.936927\n",
      "Train Epoch: 0, mini-batch 160 of 31, training loss: 0.858517\n",
      "Train Epoch: 0, mini-batch 170 of 31, training loss: 0.814164\n",
      "Train Epoch: 0, mini-batch 180 of 31, training loss: 0.744698\n",
      "Train Epoch: 0, mini-batch 190 of 31, training loss: 0.727627\n",
      "Train Epoch: 0, mini-batch 200 of 31, training loss: 0.697054\n",
      "Train Epoch: 0, mini-batch 210 of 31, training loss: 0.691242\n",
      "Train Epoch: 0, mini-batch 220 of 31, training loss: 0.654069\n",
      "Train Epoch: 0, mini-batch 230 of 31, training loss: 0.689736\n",
      "Train Epoch: 0, mini-batch 240 of 31, training loss: 0.666665\n",
      "Train Epoch: 0, mini-batch 250 of 31, training loss: 0.642565\n",
      "Train Epoch: 0, mini-batch 260 of 31, training loss: 0.648577\n",
      "Train Epoch: 0, mini-batch 270 of 31, training loss: 0.634606\n",
      "Train Epoch: 0, mini-batch 280 of 31, training loss: 0.635846\n",
      "Train Epoch: 0, mini-batch 290 of 31, training loss: 0.615042\n",
      "Train Epoch: 0, mini-batch 300 of 31, training loss: 0.618632\n",
      "Train Epoch: 0, mini-batch 310 of 31, training loss: 0.598240\n",
      "Train Epoch: 0, mini-batch 320 of 31, training loss: 0.599187\n",
      "Train Epoch: 0, mini-batch 330 of 31, training loss: 0.611583\n",
      "Train Epoch: 0, mini-batch 340 of 31, training loss: 0.606862\n",
      "Train Epoch: 0, mini-batch 350 of 31, training loss: 0.610989\n",
      "Train Epoch: 0, mini-batch 360 of 31, training loss: 0.621694\n",
      "Train Epoch: 0, mini-batch 370 of 31, training loss: 0.589442\n",
      "Train Epoch: 0, mini-batch 380 of 31, training loss: 0.610094\n",
      "Train Epoch: 0, mini-batch 390 of 31, training loss: 0.591123\n",
      "Train Epoch: 0, mini-batch 400 of 31, training loss: 0.596739\n",
      "Train Epoch: 0, mini-batch 410 of 31, training loss: 0.597678\n",
      "Train Epoch: 0, mini-batch 420 of 31, training loss: 0.601603\n",
      "Train Epoch: 0, mini-batch 430 of 31, training loss: 0.615163\n",
      "Train Epoch: 0, mini-batch 440 of 31, training loss: 0.591480\n",
      "Train Epoch: 0, mini-batch 450 of 31, training loss: 0.593099\n",
      "Train Epoch: 0, mini-batch 460 of 31, training loss: 0.589758\n",
      "Train Epoch: 0, mini-batch 470 of 31, training loss: 0.606415\n",
      "Train Epoch: 0, mini-batch 480 of 31, training loss: 0.604369\n",
      "Train Epoch: 0, mini-batch 490 of 31, training loss: 0.584099\n",
      "Train Epoch: 0, mini-batch 500 of 31, training loss: 0.587835\n",
      "Train Epoch: 0, mini-batch 510 of 31, training loss: 0.586587\n",
      "Train Epoch: 0, mini-batch 520 of 31, training loss: 0.589214\n",
      "Train Epoch: 0, mini-batch 530 of 31, training loss: 0.580998\n",
      "Train Epoch: 0, mini-batch 540 of 31, training loss: 0.575759\n",
      "Train Epoch: 0, mini-batch 550 of 31, training loss: 0.574508\n",
      "Train Epoch: 0, mini-batch 560 of 31, training loss: 0.586126\n",
      "Train Epoch: 0, mini-batch 570 of 31, training loss: 0.585841\n",
      "Train Epoch: 0, mini-batch 580 of 31, training loss: 0.577021\n",
      "Train Epoch: 0, mini-batch 590 of 31, training loss: 0.566515\n",
      "Train Epoch: 0, mini-batch 600 of 31, training loss: 0.581522\n",
      "Train Epoch: 0, mini-batch 610 of 31, training loss: 0.576979\n",
      "Train Epoch: 0, mini-batch 620 of 31, training loss: 0.576720\n",
      "Train Epoch: 0, mini-batch 630 of 31, training loss: 0.578184\n",
      "Train Epoch: 0, mini-batch 640 of 31, training loss: 0.580134\n",
      "Train Epoch: 0, mini-batch 650 of 31, training loss: 0.568047\n",
      "Train Epoch: 0, mini-batch 660 of 31, training loss: 0.575097\n",
      "Train Epoch: 0, mini-batch 670 of 31, training loss: 0.579638\n",
      "Train Epoch: 0, mini-batch 680 of 31, training loss: 0.578574\n",
      "Train Epoch: 0, mini-batch 690 of 31, training loss: 0.571198\n",
      "Train Epoch: 0, mini-batch 700 of 31, training loss: 0.565817\n",
      "Train Epoch: 0, mini-batch 710 of 31, training loss: 0.575239\n",
      "Train Epoch: 0, mini-batch 720 of 31, training loss: 0.570681\n",
      "Train Epoch: 0, mini-batch 730 of 31, training loss: 0.567601\n",
      "Train Epoch: 0, mini-batch 740 of 31, training loss: 0.572374\n",
      "Train Epoch: 0, mini-batch 750 of 31, training loss: 0.570272\n",
      "Train Epoch: 0, mini-batch 760 of 31, training loss: 0.568730\n",
      "Train Epoch: 0, mini-batch 770 of 31, training loss: 0.566193\n",
      "Train Epoch: 0, mini-batch 780 of 31, training loss: 0.572244\n",
      "Train Epoch: 0, mini-batch 790 of 31, training loss: 0.571805\n",
      "Train Epoch: 0, mini-batch 800 of 31, training loss: 0.569508\n",
      "Train Epoch: 0, mini-batch 810 of 31, training loss: 0.565438\n",
      "Train Epoch: 0, mini-batch 820 of 31, training loss: 0.569320\n",
      "Train Epoch: 0, mini-batch 830 of 31, training loss: 0.571812\n",
      "Train Epoch: 0, mini-batch 840 of 31, training loss: 0.563290\n",
      "Train Epoch: 0, mini-batch 850 of 31, training loss: 0.567781\n",
      "Train Epoch: 0, mini-batch 860 of 31, training loss: 0.565390\n",
      "Train Epoch: 0, mini-batch 870 of 31, training loss: 0.565395\n",
      "Train Epoch: 0, mini-batch 880 of 31, training loss: 0.565574\n",
      "Train Epoch: 0, mini-batch 890 of 31, training loss: 0.566695\n",
      "Train Epoch: 0, mini-batch 900 of 31, training loss: 0.565001\n",
      "Train Epoch: 0, mini-batch 910 of 31, training loss: 0.566135\n",
      "Train Epoch: 0, mini-batch 920 of 31, training loss: 0.565901\n",
      "Train Epoch: 0, mini-batch 930 of 31, training loss: 0.568563\n",
      "Train Epoch: 0, mini-batch 940 of 31, training loss: 0.564898\n",
      "Train Epoch: 0, mini-batch 950 of 31, training loss: 0.567385\n",
      "Train Epoch: 0, mini-batch 960 of 31, training loss: 0.565949\n",
      "Train Epoch: 0, mini-batch 970 of 31, training loss: 0.563443\n",
      "Train Epoch: 0, mini-batch 980 of 31, training loss: 0.564179\n",
      "Train Epoch: 0, mini-batch 990 of 31, training loss: 0.563465\n",
      "Train Epoch: 0, mini-batch 1000 of 31, training loss: 0.566528\n",
      "Train Epoch: 0, mini-batch 1010 of 31, training loss: 0.563799\n",
      "Train Epoch: 0, mini-batch 1020 of 31, training loss: 0.565094\n",
      "Train Epoch: 0, mini-batch 1030 of 31, training loss: 0.566061\n",
      "Train Epoch: 0, mini-batch 1040 of 31, training loss: 0.563163\n",
      "Train Epoch: 0, mini-batch 1050 of 31, training loss: 0.564197\n",
      "Train Epoch: 0, mini-batch 1060 of 31, training loss: 0.563497\n",
      "Train Epoch: 0, mini-batch 1070 of 31, training loss: 0.566163\n",
      "Train Epoch: 0, mini-batch 1080 of 31, training loss: 0.563044\n",
      "Train Epoch: 0, mini-batch 1090 of 31, training loss: 0.562923\n",
      "Train Epoch: 0, mini-batch 1100 of 31, training loss: 0.563027\n",
      "Train Epoch: 0, mini-batch 1110 of 31, training loss: 0.568384\n",
      "Train Epoch: 0, mini-batch 1120 of 31, training loss: 0.568224\n",
      "Train Epoch: 0, mini-batch 1130 of 31, training loss: 0.558425\n",
      "Train Epoch: 0, mini-batch 1140 of 31, training loss: 0.565390\n",
      "Train Epoch: 0, mini-batch 1150 of 31, training loss: 0.563774\n",
      "Train Epoch: 0, mini-batch 1160 of 31, training loss: 0.563025\n",
      "Train Epoch: 0, mini-batch 1170 of 31, training loss: 0.562198\n",
      "Train Epoch: 0, mini-batch 1180 of 31, training loss: 0.564425\n",
      "Train Epoch: 0, mini-batch 1190 of 31, training loss: 0.564824\n",
      "Train Epoch: 0, mini-batch 1200 of 31, training loss: 0.561475\n",
      "Train Epoch: 0, mini-batch 1210 of 31, training loss: 0.560529\n",
      "Train Epoch: 0, mini-batch 1220 of 31, training loss: 0.564079\n",
      "Train Epoch: 0, mini-batch 1230 of 31, training loss: 0.561828\n",
      "Train Epoch: 0, mini-batch 1240 of 31, training loss: 0.564870\n",
      "Train Epoch: 0, mini-batch 1250 of 31, training loss: 0.561925\n",
      "Train Epoch: 0, mini-batch 1260 of 31, training loss: 0.563156\n",
      "Train Epoch: 0, mini-batch 1270 of 31, training loss: 0.562072\n",
      "Train Epoch: 0, mini-batch 1280 of 31, training loss: 0.560939\n",
      "Train Epoch: 0, mini-batch 1290 of 31, training loss: 0.562973\n",
      "Train Epoch: 0, mini-batch 1300 of 31, training loss: 0.563767\n",
      "Train Epoch: 0, mini-batch 1310 of 31, training loss: 0.562443\n",
      "Train Epoch: 0, mini-batch 1320 of 31, training loss: 0.562646\n",
      "Train Epoch: 0, mini-batch 1330 of 31, training loss: 0.565975\n",
      "Train Epoch: 0, mini-batch 1340 of 31, training loss: 0.560162\n",
      "Train Epoch: 0, mini-batch 1350 of 31, training loss: 0.560978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 1360 of 31, training loss: 0.564101\n",
      "Train Epoch: 0, mini-batch 1370 of 31, training loss: 0.562060\n",
      "Train Epoch: 0, mini-batch 1380 of 31, training loss: 0.561283\n",
      "Train Epoch: 0, mini-batch 1390 of 31, training loss: 0.563563\n",
      "Train Epoch: 0, mini-batch 1400 of 31, training loss: 0.564927\n",
      "Train Epoch: 0, mini-batch 1410 of 31, training loss: 0.561556\n",
      "Train Epoch: 0, mini-batch 1420 of 31, training loss: 0.563803\n",
      "Train Epoch: 0, mini-batch 1430 of 31, training loss: 0.563216\n",
      "Train Epoch: 0, mini-batch 1440 of 31, training loss: 0.563819\n",
      "Train Epoch: 0, mini-batch 1450 of 31, training loss: 0.562274\n",
      "Train Epoch: 0, mini-batch 1460 of 31, training loss: 0.563354\n",
      "Train Epoch: 0, mini-batch 1470 of 31, training loss: 0.564777\n",
      "Train Epoch: 0, mini-batch 1480 of 31, training loss: 0.562981\n",
      "Train Epoch: 0, mini-batch 1490 of 31, training loss: 0.562601\n",
      "Train Epoch: 0, mini-batch 1500 of 31, training loss: 0.563900\n",
      "Train Epoch: 0, mini-batch 1510 of 31, training loss: 0.562622\n",
      "Train Epoch: 0, mini-batch 1520 of 31, training loss: 0.558763\n",
      "Train Epoch: 0, mini-batch 1530 of 31, training loss: 0.562135\n",
      "Train Epoch: 0, mini-batch 1540 of 31, training loss: 0.563433\n",
      "Train Epoch: 0, mini-batch 1550 of 31, training loss: 0.562148\n",
      "Train Epoch: 0, mini-batch 1560 of 31, training loss: 0.563421\n",
      "Train Epoch: 0, mini-batch 1570 of 31, training loss: 0.563760\n",
      "Train Epoch: 0, mini-batch 1580 of 31, training loss: 0.562333\n",
      "Train Epoch: 0, mini-batch 1590 of 31, training loss: 0.563693\n",
      "Train Epoch: 0, mini-batch 1600 of 31, training loss: 0.561786\n",
      "Train Epoch: 0, mini-batch 1610 of 31, training loss: 0.561231\n",
      "Train Epoch: 0, mini-batch 1620 of 31, training loss: 0.565378\n",
      "Train Epoch: 0, mini-batch 1630 of 31, training loss: 0.564004\n",
      "Train Epoch: 0, mini-batch 1640 of 31, training loss: 0.562275\n",
      "Train Epoch: 0, mini-batch 1650 of 31, training loss: 0.562126\n",
      "Train Epoch: 0, mini-batch 1660 of 31, training loss: 0.561368\n",
      "Train Epoch: 0, mini-batch 1670 of 31, training loss: 0.563612\n",
      "Train Epoch: 0, mini-batch 1680 of 31, training loss: 0.561301\n",
      "Train Epoch: 0, mini-batch 1690 of 31, training loss: 0.562117\n",
      "Train Epoch: 0, mini-batch 1700 of 31, training loss: 0.562958\n",
      "Train Epoch: 0, mini-batch 1710 of 31, training loss: 0.561299\n",
      "Train Epoch: 0, mini-batch 1720 of 31, training loss: 0.562329\n",
      "Train Epoch: 0, mini-batch 1730 of 31, training loss: 0.562970\n",
      "Train Epoch: 0, mini-batch 1740 of 31, training loss: 0.564619\n",
      "Train Epoch: 0, mini-batch 1750 of 31, training loss: 0.561801\n",
      "Train Epoch: 0, mini-batch 1760 of 31, training loss: 0.562414\n",
      "Train Epoch: 0, mini-batch 1770 of 31, training loss: 0.563828\n",
      "Train Epoch: 0, mini-batch 1780 of 31, training loss: 0.561650\n",
      "Train Epoch: 0, mini-batch 1790 of 31, training loss: 0.562946\n",
      "Train Epoch: 0, mini-batch 1800 of 31, training loss: 0.561427\n",
      "Train Epoch: 0, mini-batch 1810 of 31, training loss: 0.563024\n",
      "Train Epoch: 0, mini-batch 1820 of 31, training loss: 0.560417\n",
      "Train Epoch: 0, mini-batch 1830 of 31, training loss: 0.568049\n",
      "Train Epoch: 0, mini-batch 1840 of 31, training loss: 0.564302\n",
      "Train Epoch: 0, mini-batch 1850 of 31, training loss: 0.561560\n",
      "Train Epoch: 0, mini-batch 1860 of 31, training loss: 0.561728\n",
      "Train Epoch: 0, mini-batch 1870 of 31, training loss: 0.559527\n",
      "Train Epoch: 0, mini-batch 1880 of 31, training loss: 0.557011\n",
      "Train Epoch: 0, mini-batch 1890 of 31, training loss: 0.565348\n",
      "Train Epoch: 0, mini-batch 1900 of 31, training loss: 0.560907\n",
      "Train Epoch: 0, mini-batch 1910 of 31, training loss: 0.564022\n",
      "Train Epoch: 0, mini-batch 1920 of 31, training loss: 0.563912\n",
      "Train Epoch: 0, mini-batch 1930 of 31, training loss: 0.563428\n",
      "Train Epoch: 0, mini-batch 1940 of 31, training loss: 0.564223\n",
      "Train Epoch: 0, mini-batch 1950 of 31, training loss: 0.562602\n",
      "Train Epoch: 0, mini-batch 1960 of 31, training loss: 0.563792\n",
      "Train Epoch: 0, mini-batch 1970 of 31, training loss: 0.562388\n",
      "Train Epoch: 0, mini-batch 1980 of 31, training loss: 0.562522\n",
      "Train Epoch: 0, mini-batch 1990 of 31, training loss: 0.563874\n",
      "Train Epoch: 0, mini-batch 2000 of 31, training loss: 0.563760\n",
      "Train Epoch: 0, mini-batch 2010 of 31, training loss: 0.564236\n",
      "Train Epoch: 0, mini-batch 2020 of 31, training loss: 0.562479\n",
      "Train Epoch: 0, mini-batch 2030 of 31, training loss: 0.563371\n",
      "Train Epoch: 0, mini-batch 2040 of 31, training loss: 0.563585\n",
      "Train Epoch: 0, mini-batch 2050 of 31, training loss: 0.561626\n",
      "Train Epoch: 0, mini-batch 2060 of 31, training loss: 0.564436\n",
      "Train Epoch: 0, mini-batch 2070 of 31, training loss: 0.562667\n",
      "Train Epoch: 0, mini-batch 2080 of 31, training loss: 0.562090\n",
      "Train Epoch: 0, mini-batch 2090 of 31, training loss: 0.561408\n",
      "Train Epoch: 0, mini-batch 2100 of 31, training loss: 0.562299\n",
      "Train Epoch: 0, mini-batch 2110 of 31, training loss: 0.561828\n",
      "Train Epoch: 0, mini-batch 2120 of 31, training loss: 0.562355\n",
      "Train Epoch: 0, mini-batch 2130 of 31, training loss: 0.561934\n",
      "Train Epoch: 0, mini-batch 2140 of 31, training loss: 0.564616\n",
      "Train Epoch: 0, mini-batch 2150 of 31, training loss: 0.562620\n",
      "Train Epoch: 0, mini-batch 2160 of 31, training loss: 0.563298\n",
      "Train Epoch: 0, mini-batch 2170 of 31, training loss: 0.562396\n",
      "Train Epoch: 0, mini-batch 2180 of 31, training loss: 0.561704\n",
      "Train Epoch: 0, mini-batch 2190 of 31, training loss: 0.562039\n",
      "Train Epoch: 0, mini-batch 2200 of 31, training loss: 0.564059\n",
      "Train Epoch: 0, mini-batch 2210 of 31, training loss: 0.563612\n",
      "Train Epoch: 0, mini-batch 2220 of 31, training loss: 0.563312\n",
      "Train Epoch: 0, mini-batch 2230 of 31, training loss: 0.563977\n",
      "Train Epoch: 0, mini-batch 2240 of 31, training loss: 0.562468\n",
      "Train Epoch: 0, mini-batch 2250 of 31, training loss: 0.563876\n",
      "Train Epoch: 0, mini-batch 2260 of 31, training loss: 0.562641\n",
      "Train Epoch: 0, mini-batch 2270 of 31, training loss: 0.561697\n",
      "Train Epoch: 0, mini-batch 2280 of 31, training loss: 0.561459\n",
      "Train Epoch: 0, mini-batch 2290 of 31, training loss: 0.563433\n",
      "Train Epoch: 0, mini-batch 2300 of 31, training loss: 0.562663\n",
      "Train Epoch: 0, mini-batch 2310 of 31, training loss: 0.561579\n",
      "Train Epoch: 0, mini-batch 2320 of 31, training loss: 0.564364\n",
      "Train Epoch: 0, mini-batch 2330 of 31, training loss: 0.562369\n",
      "Train Epoch: 0, mini-batch 2340 of 31, training loss: 0.559035\n",
      "Train Epoch: 0, mini-batch 2350 of 31, training loss: 0.560034\n",
      "Train Epoch: 0, mini-batch 2360 of 31, training loss: 0.563911\n",
      "Train Epoch: 0, mini-batch 2370 of 31, training loss: 0.563652\n",
      "Train Epoch: 0, mini-batch 2380 of 31, training loss: 0.559563\n",
      "Train Epoch: 0, mini-batch 2390 of 31, training loss: 0.561535\n",
      "Train Epoch: 0, mini-batch 2400 of 31, training loss: 0.562653\n",
      "Train Epoch: 0, mini-batch 2410 of 31, training loss: 0.562266\n",
      "Train Epoch: 0, mini-batch 2420 of 31, training loss: 0.562136\n",
      "Train Epoch: 0, mini-batch 2430 of 31, training loss: 0.564504\n",
      "Train Epoch: 0, mini-batch 2440 of 31, training loss: 0.562935\n",
      "Train Epoch: 0, mini-batch 2450 of 31, training loss: 0.562712\n",
      "Train Epoch: 0, mini-batch 2460 of 31, training loss: 0.562906\n",
      "Train Epoch: 0, mini-batch 2470 of 31, training loss: 0.564341\n",
      "Train Epoch: 0, mini-batch 2480 of 31, training loss: 0.564345\n",
      "Train Epoch: 0, mini-batch 2490 of 31, training loss: 0.565113\n",
      "Train Epoch: 0, mini-batch 2500 of 31, training loss: 0.563920\n",
      "Train Epoch: 0, mini-batch 2510 of 31, training loss: 0.562617\n",
      "Train Epoch: 0, mini-batch 2520 of 31, training loss: 0.563707\n",
      "Train Epoch: 0, mini-batch 2530 of 31, training loss: 0.563164\n",
      "Train Epoch: 0, mini-batch 2540 of 31, training loss: 0.561817\n",
      "Train Epoch: 0, mini-batch 2550 of 31, training loss: 0.559488\n",
      "Train Epoch: 0, mini-batch 2560 of 31, training loss: 0.561369\n",
      "Train Epoch: 0, mini-batch 2570 of 31, training loss: 0.562916\n",
      "Train Epoch: 0, mini-batch 2580 of 31, training loss: 0.564419\n",
      "Train Epoch: 0, mini-batch 2590 of 31, training loss: 0.562471\n",
      "Train Epoch: 0, mini-batch 2600 of 31, training loss: 0.562708\n",
      "Train Epoch: 0, mini-batch 2610 of 31, training loss: 0.564071\n",
      "Train Epoch: 0, mini-batch 2620 of 31, training loss: 0.563798\n",
      "Train Epoch: 0, mini-batch 2630 of 31, training loss: 0.561806\n",
      "Train Epoch: 0, mini-batch 2640 of 31, training loss: 0.559888\n",
      "Train Epoch: 0, mini-batch 2650 of 31, training loss: 0.561089\n",
      "Train Epoch: 0, mini-batch 2660 of 31, training loss: 0.560143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 2670 of 31, training loss: 0.563423\n",
      "Train Epoch: 0, mini-batch 2680 of 31, training loss: 0.560111\n",
      "Train Epoch: 0, mini-batch 2690 of 31, training loss: 0.568801\n",
      "Train Epoch: 0, mini-batch 2700 of 31, training loss: 0.564765\n",
      "Train Epoch: 0, mini-batch 2710 of 31, training loss: 0.561211\n",
      "Train Epoch: 0, mini-batch 2720 of 31, training loss: 0.561496\n",
      "Train Epoch: 0, mini-batch 2730 of 31, training loss: 0.561914\n",
      "Train Epoch: 0, mini-batch 2740 of 31, training loss: 0.561319\n",
      "Train Epoch: 0, mini-batch 2750 of 31, training loss: 0.563060\n",
      "Train Epoch: 0, mini-batch 2760 of 31, training loss: 0.563344\n",
      "Train Epoch: 0, mini-batch 2770 of 31, training loss: 0.563499\n",
      "Train Epoch: 0, mini-batch 2780 of 31, training loss: 0.561237\n",
      "Train Epoch: 0, mini-batch 2790 of 31, training loss: 0.562534\n",
      "Train Epoch: 0, mini-batch 2800 of 31, training loss: 0.562207\n",
      "Train Epoch: 0, mini-batch 2810 of 31, training loss: 0.560933\n",
      "Train Epoch: 0, mini-batch 2820 of 31, training loss: 0.560774\n",
      "Train Epoch: 0, mini-batch 2830 of 31, training loss: 0.562875\n",
      "Train Epoch: 0, mini-batch 2840 of 31, training loss: 0.563281\n",
      "Train Epoch: 0, mini-batch 2850 of 31, training loss: 0.562993\n",
      "Train Epoch: 0, mini-batch 2860 of 31, training loss: 0.560735\n",
      "Train Epoch: 0, mini-batch 2870 of 31, training loss: 0.563134\n",
      "Train Epoch: 0, mini-batch 2880 of 31, training loss: 0.562214\n",
      "Train Epoch: 0, mini-batch 2890 of 31, training loss: 0.563417\n",
      "Train Epoch: 0, mini-batch 2900 of 31, training loss: 0.563016\n",
      "Train Epoch: 0, mini-batch 2910 of 31, training loss: 0.564274\n",
      "Train Epoch: 0, mini-batch 2920 of 31, training loss: 0.561360\n",
      "Train Epoch: 0, mini-batch 2930 of 31, training loss: 0.561836\n",
      "Train Epoch: 0, mini-batch 2940 of 31, training loss: 0.562628\n",
      "Train Epoch: 0, mini-batch 2950 of 31, training loss: 0.562589\n",
      "Train Epoch: 0, mini-batch 2960 of 31, training loss: 0.560704\n",
      "Train Epoch: 0, mini-batch 2970 of 31, training loss: 0.560375\n",
      "Train Epoch: 0, mini-batch 2980 of 31, training loss: 0.565376\n",
      "Train Epoch: 0, mini-batch 2990 of 31, training loss: 0.562301\n",
      "Train Epoch: 0, mini-batch 3000 of 31, training loss: 0.561800\n",
      "Train Epoch: 0, mini-batch 3010 of 31, training loss: 0.557565\n",
      "Train Epoch: 0, mini-batch 3020 of 31, training loss: 0.560577\n",
      "Train Epoch: 0, mini-batch 3030 of 31, training loss: 0.562698\n",
      "Train Epoch: 0, mini-batch 3040 of 31, training loss: 0.563739\n",
      "Train Epoch: 0, mini-batch 3050 of 31, training loss: 0.562812\n",
      "Train Epoch: 0, mini-batch 3060 of 31, training loss: 0.561307\n",
      "Train Epoch: 0, mini-batch 3070 of 31, training loss: 0.561574\n",
      "Train Epoch: 0, mini-batch 3080 of 31, training loss: 0.561719\n",
      "Train Epoch: 0, mini-batch 3090 of 31, training loss: 0.564790\n",
      "Train Epoch: 0, mini-batch 3100 of 31, training loss: 0.564445\n",
      "Train Epoch: 0, mini-batch 3110 of 31, training loss: 0.561066\n",
      "Train Epoch: 0, mini-batch 3120 of 31, training loss: 0.564817\n",
      "Train Epoch: 0, mini-batch 3130 of 31, training loss: 0.561243\n",
      "Train Epoch: 0, mini-batch 3140 of 31, training loss: 0.561834\n",
      "Train Epoch: 0, mini-batch 3150 of 31, training loss: 0.560970\n",
      "Train Epoch: 0, mini-batch 3160 of 31, training loss: 0.561915\n",
      "Train Epoch: 0, mini-batch 3170 of 31, training loss: 0.561179\n",
      "Train Epoch: 0, mini-batch 3180 of 31, training loss: 0.560387\n",
      "Train Epoch: 0, mini-batch 3190 of 31, training loss: 0.561868\n",
      "Train Epoch: 0, mini-batch 3200 of 31, training loss: 0.565912\n",
      "Train Epoch: 0, mini-batch 3210 of 31, training loss: 0.564274\n",
      "Train Epoch: 0, mini-batch 3220 of 31, training loss: 0.561130\n",
      "Train Epoch: 0, mini-batch 3230 of 31, training loss: 0.562271\n",
      "Train Epoch: 0, mini-batch 3240 of 31, training loss: 0.562891\n",
      "Train Epoch: 0, mini-batch 3250 of 31, training loss: 0.561467\n",
      "Train Epoch: 0, mini-batch 3260 of 31, training loss: 0.563271\n",
      "Train Epoch: 0, mini-batch 3270 of 31, training loss: 0.563886\n",
      "Train Epoch: 0, mini-batch 3280 of 31, training loss: 0.564189\n",
      "Train Epoch: 0, mini-batch 3290 of 31, training loss: 0.561910\n",
      "Train Epoch: 0, mini-batch 3300 of 31, training loss: 0.561909\n",
      "Train Epoch: 0, mini-batch 3310 of 31, training loss: 0.564892\n",
      "Train Epoch: 0, mini-batch 3320 of 31, training loss: 0.561948\n",
      "Train Epoch: 0, mini-batch 3330 of 31, training loss: 0.563923\n",
      "Train Epoch: 0, mini-batch 3340 of 31, training loss: 0.563538\n",
      "Train Epoch: 0, mini-batch 3350 of 31, training loss: 0.560723\n",
      "Train Epoch: 0, mini-batch 3360 of 31, training loss: 0.566353\n",
      "Train Epoch: 0, mini-batch 3370 of 31, training loss: 0.567332\n",
      "Train Epoch: 0, mini-batch 3380 of 31, training loss: 0.560485\n",
      "Train Epoch: 0, mini-batch 3390 of 31, training loss: 0.560492\n",
      "Train Epoch: 0, mini-batch 3400 of 31, training loss: 0.561522\n",
      "Train Epoch: 0, mini-batch 3410 of 31, training loss: 0.561037\n",
      "Train Epoch: 0, mini-batch 3420 of 31, training loss: 0.561296\n",
      "Train Epoch: 0, mini-batch 3430 of 31, training loss: 0.563874\n",
      "Train Epoch: 0, mini-batch 3440 of 31, training loss: 0.561657\n",
      "Train Epoch: 0, mini-batch 3450 of 31, training loss: 0.562305\n",
      "Train Epoch: 0, mini-batch 3460 of 31, training loss: 0.564035\n",
      "Train Epoch: 0, mini-batch 3470 of 31, training loss: 0.563679\n",
      "Train Epoch: 0, mini-batch 3480 of 31, training loss: 0.560687\n",
      "Train Epoch: 0, mini-batch 3490 of 31, training loss: 0.554658\n",
      "Train Epoch: 0, mini-batch 3500 of 31, training loss: 0.561310\n",
      "Train Epoch: 0, mini-batch 3510 of 31, training loss: 0.562521\n",
      "Train Epoch: 0, mini-batch 3520 of 31, training loss: 0.560662\n",
      "Train Epoch: 0, mini-batch 3530 of 31, training loss: 0.560371\n",
      "Train Epoch: 0, mini-batch 3540 of 31, training loss: 0.565512\n",
      "Train Epoch: 0, mini-batch 3550 of 31, training loss: 0.561917\n",
      "Train Epoch: 0, mini-batch 3560 of 31, training loss: 0.563256\n",
      "Train Epoch: 0, mini-batch 3570 of 31, training loss: 0.562720\n",
      "Train Epoch: 0, mini-batch 3580 of 31, training loss: 0.564082\n",
      "Train Epoch: 0, mini-batch 3590 of 31, training loss: 0.563684\n",
      "Train Epoch: 0, mini-batch 3600 of 31, training loss: 0.564154\n",
      "Train Epoch: 0, mini-batch 3610 of 31, training loss: 0.562627\n",
      "Train Epoch: 0, mini-batch 3620 of 31, training loss: 0.562172\n",
      "Train Epoch: 0, mini-batch 3630 of 31, training loss: 0.561151\n",
      "Train Epoch: 0, mini-batch 3640 of 31, training loss: 0.560599\n",
      "Train Epoch: 0, mini-batch 3650 of 31, training loss: 0.564925\n",
      "Train Epoch: 0, mini-batch 3660 of 31, training loss: 0.562496\n",
      "Train Epoch: 0, mini-batch 3670 of 31, training loss: 0.560833\n",
      "Train Epoch: 0, mini-batch 3680 of 31, training loss: 0.563594\n",
      "Train Epoch: 0, mini-batch 3690 of 31, training loss: 0.561855\n",
      "Train Epoch: 0, mini-batch 3700 of 31, training loss: 0.561636\n",
      "Train Epoch: 0, mini-batch 3710 of 31, training loss: 0.562088\n",
      "Train Epoch: 0, mini-batch 3720 of 31, training loss: 0.562980\n",
      "Train Epoch: 0, mini-batch 3730 of 31, training loss: 0.561065\n",
      "Train Epoch: 0, mini-batch 3740 of 31, training loss: 0.563003\n",
      "Train Epoch: 0, mini-batch 3750 of 31, training loss: 0.562607\n",
      "Train Epoch: 0, mini-batch 3760 of 31, training loss: 0.563055\n",
      "Train Epoch: 0, mini-batch 3770 of 31, training loss: 0.562724\n",
      "Train Epoch: 0, mini-batch 3780 of 31, training loss: 0.560974\n",
      "Train Epoch: 0, mini-batch 3790 of 31, training loss: 0.561758\n",
      "Train Epoch: 0, mini-batch 3800 of 31, training loss: 0.562990\n",
      "Train Epoch: 0, mini-batch 3810 of 31, training loss: 0.563223\n",
      "Train Epoch: 0, mini-batch 3820 of 31, training loss: 0.562274\n",
      "Train Epoch: 0, mini-batch 3830 of 31, training loss: 0.563442\n",
      "Train Epoch: 0, mini-batch 3840 of 31, training loss: 0.564556\n",
      "Train Epoch: 0, mini-batch 3850 of 31, training loss: 0.564757\n",
      "Train Epoch: 0, mini-batch 3860 of 31, training loss: 0.563905\n",
      "Train Epoch: 0, mini-batch 3870 of 31, training loss: 0.564335\n",
      "Train Epoch: 0, mini-batch 3880 of 31, training loss: 0.563015\n",
      "Train Epoch: 0, mini-batch 3890 of 31, training loss: 0.565041\n",
      "Train Epoch: 0, mini-batch 3900 of 31, training loss: 0.561858\n",
      "Train Epoch: 0, mini-batch 3910 of 31, training loss: 0.563017\n",
      "Train Epoch: 0, mini-batch 3920 of 31, training loss: 0.562705\n",
      "Train Epoch: 0, mini-batch 3930 of 31, training loss: 0.561399\n",
      "Train Epoch: 0, mini-batch 3940 of 31, training loss: 0.564382\n",
      "Train Epoch: 0, mini-batch 3950 of 31, training loss: 0.562825\n",
      "Train Epoch: 0, mini-batch 3960 of 31, training loss: 0.563556\n",
      "Train Epoch: 0, mini-batch 3970 of 31, training loss: 0.563226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 3980 of 31, training loss: 0.560223\n",
      "Train Epoch: 0, mini-batch 3990 of 31, training loss: 0.561195\n",
      "Train Epoch: 0, mini-batch 4000 of 31, training loss: 0.561496\n",
      "Train Epoch: 0, mini-batch 4010 of 31, training loss: 0.564278\n",
      "Train Epoch: 0, mini-batch 4020 of 31, training loss: 0.564955\n",
      "Train Epoch: 0, mini-batch 4030 of 31, training loss: 0.564873\n",
      "Train Epoch: 0, mini-batch 4040 of 31, training loss: 0.562009\n",
      "Train Epoch: 0, mini-batch 4050 of 31, training loss: 0.560021\n",
      "Train Epoch: 0, mini-batch 4060 of 31, training loss: 0.557637\n",
      "Train Epoch: 0, mini-batch 4070 of 31, training loss: 0.562466\n",
      "Train Epoch: 0, mini-batch 4080 of 31, training loss: 0.563855\n",
      "Train Epoch: 0, mini-batch 4090 of 31, training loss: 0.562744\n",
      "Train Epoch: 0, mini-batch 4100 of 31, training loss: 0.561262\n",
      "Train Epoch: 0, mini-batch 4110 of 31, training loss: 0.560494\n",
      "Train Epoch: 0, mini-batch 4120 of 31, training loss: 0.566025\n",
      "Train Epoch: 0, mini-batch 4130 of 31, training loss: 0.559787\n",
      "Train Epoch: 0, mini-batch 4140 of 31, training loss: 0.561318\n",
      "Train Epoch: 0, mini-batch 4150 of 31, training loss: 0.563656\n",
      "Train Epoch: 0, mini-batch 4160 of 31, training loss: 0.562671\n",
      "Train Epoch: 0, mini-batch 4170 of 31, training loss: 0.562419\n",
      "Train Epoch: 0, mini-batch 4180 of 31, training loss: 0.563827\n",
      "Train Epoch: 0, mini-batch 4190 of 31, training loss: 0.564120\n",
      "Train Epoch: 0, mini-batch 4200 of 31, training loss: 0.559957\n",
      "Train Epoch: 0, mini-batch 4210 of 31, training loss: 0.568810\n",
      "Train Epoch: 0, mini-batch 4220 of 31, training loss: 0.564746\n",
      "Train Epoch: 0, mini-batch 4230 of 31, training loss: 0.563575\n",
      "Train Epoch: 0, mini-batch 4240 of 31, training loss: 0.561362\n",
      "Train Epoch: 0, mini-batch 4250 of 31, training loss: 0.561990\n",
      "Train Epoch: 0, mini-batch 4260 of 31, training loss: 0.562708\n",
      "Train Epoch: 0, mini-batch 4270 of 31, training loss: 0.564248\n",
      "Train Epoch: 0, mini-batch 4280 of 31, training loss: 0.564031\n",
      "Train Epoch: 0, mini-batch 4290 of 31, training loss: 0.562280\n",
      "Train Epoch: 0, mini-batch 4300 of 31, training loss: 0.560737\n",
      "Train Epoch: 0, mini-batch 4310 of 31, training loss: 0.563119\n",
      "Train Epoch: 0, mini-batch 4320 of 31, training loss: 0.562504\n",
      "Train Epoch: 0, mini-batch 4330 of 31, training loss: 0.562314\n",
      "Train Epoch: 0, mini-batch 4340 of 31, training loss: 0.562648\n",
      "Train Epoch: 0, mini-batch 4350 of 31, training loss: 0.562969\n",
      "Train Epoch: 0, mini-batch 4360 of 31, training loss: 0.562135\n",
      "Train Epoch: 0, mini-batch 4370 of 31, training loss: 0.560969\n",
      "Train Epoch: 0, mini-batch 4380 of 31, training loss: 0.564140\n",
      "Train Epoch: 0, mini-batch 4390 of 31, training loss: 0.561219\n",
      "Train Epoch: 0, mini-batch 4400 of 31, training loss: 0.563168\n",
      "Train Epoch: 0, mini-batch 4410 of 31, training loss: 0.563792\n",
      "Train Epoch: 0, mini-batch 4420 of 31, training loss: 0.562508\n",
      "Train Epoch: 0, mini-batch 4430 of 31, training loss: 0.564768\n",
      "Train Epoch: 0, mini-batch 4440 of 31, training loss: 0.560845\n",
      "Train Epoch: 0, mini-batch 4450 of 31, training loss: 0.561697\n",
      "Train Epoch: 0, mini-batch 4460 of 31, training loss: 0.565681\n",
      "Train Epoch: 0, mini-batch 4470 of 31, training loss: 0.562790\n",
      "Train Epoch: 0, mini-batch 4480 of 31, training loss: 0.562230\n",
      "Train Epoch: 0, mini-batch 4490 of 31, training loss: 0.564676\n",
      "Train Epoch: 0, mini-batch 4500 of 31, training loss: 0.563064\n",
      "Train Epoch: 0, mini-batch 4510 of 31, training loss: 0.562853\n",
      "Train Epoch: 0, mini-batch 4520 of 31, training loss: 0.562844\n",
      "Train Epoch: 0, mini-batch 4530 of 31, training loss: 0.563140\n",
      "Train Epoch: 0, mini-batch 4540 of 31, training loss: 0.563364\n",
      "Train Epoch: 0, mini-batch 4550 of 31, training loss: 0.561754\n",
      "Train Epoch: 0, mini-batch 4560 of 31, training loss: 0.560802\n",
      "Train Epoch: 0, mini-batch 4570 of 31, training loss: 0.562036\n",
      "Train Epoch: 0, mini-batch 4580 of 31, training loss: 0.563973\n",
      "Train Epoch: 0, mini-batch 4590 of 31, training loss: 0.562058\n",
      "Train Epoch: 0, mini-batch 4600 of 31, training loss: 0.559234\n",
      "Train Epoch: 0, mini-batch 4610 of 31, training loss: 0.564994\n",
      "Train Epoch: 0, mini-batch 4620 of 31, training loss: 0.561782\n",
      "Train Epoch: 0, mini-batch 4630 of 31, training loss: 0.565517\n",
      "Train Epoch: 0, mini-batch 4640 of 31, training loss: 0.561660\n",
      "Train Epoch: 0, mini-batch 4650 of 31, training loss: 0.562955\n",
      "Train Epoch: 0, mini-batch 4660 of 31, training loss: 0.560058\n",
      "Train Epoch: 0, mini-batch 4670 of 31, training loss: 0.562396\n",
      "Train Epoch: 0, mini-batch 4680 of 31, training loss: 0.560041\n",
      "Train Epoch: 0, mini-batch 4690 of 31, training loss: 0.564114\n",
      "Train Epoch: 0, mini-batch 4700 of 31, training loss: 0.562907\n",
      "Train Epoch: 0, mini-batch 4710 of 31, training loss: 0.562187\n",
      "Train Epoch: 0, mini-batch 4720 of 31, training loss: 0.560104\n",
      "Train Epoch: 0, mini-batch 4730 of 31, training loss: 0.563370\n",
      "Train Epoch: 0, mini-batch 4740 of 31, training loss: 0.562029\n",
      "Train Epoch: 0, mini-batch 4750 of 31, training loss: 0.563653\n",
      "Train Epoch: 0, mini-batch 4760 of 31, training loss: 0.565698\n",
      "Train Epoch: 0, mini-batch 4770 of 31, training loss: 0.562253\n",
      "Train Epoch: 0, mini-batch 4780 of 31, training loss: 0.562021\n",
      "Train Epoch: 0, mini-batch 4790 of 31, training loss: 0.563156\n",
      "Train Epoch: 0, mini-batch 4800 of 31, training loss: 0.561499\n",
      "Train Epoch: 0, mini-batch 4810 of 31, training loss: 0.563638\n",
      "Train Epoch: 0, mini-batch 4820 of 31, training loss: 0.561414\n",
      "Train Epoch: 0, mini-batch 4830 of 31, training loss: 0.559365\n",
      "Train Epoch: 0, mini-batch 4840 of 31, training loss: 0.561619\n",
      "Train Epoch: 0, mini-batch 4850 of 31, training loss: 0.563486\n",
      "Train Epoch: 0, mini-batch 4860 of 31, training loss: 0.563851\n",
      "Train Epoch: 0, mini-batch 4870 of 31, training loss: 0.559736\n",
      "Train Epoch: 0, mini-batch 4880 of 31, training loss: 0.563048\n",
      "Train Epoch: 0, mini-batch 4890 of 31, training loss: 0.566654\n",
      "Train Epoch: 0, mini-batch 4900 of 31, training loss: 0.567868\n",
      "Train Epoch: 0, mini-batch 4910 of 31, training loss: 0.563699\n",
      "Train Epoch: 0, mini-batch 4920 of 31, training loss: 0.562088\n",
      "Train Epoch: 0, mini-batch 4930 of 31, training loss: 0.562818\n",
      "Train Epoch: 0, mini-batch 4940 of 31, training loss: 0.561504\n",
      "Train Epoch: 0, mini-batch 4950 of 31, training loss: 0.563855\n",
      "Train Epoch: 0, mini-batch 4960 of 31, training loss: 0.562900\n",
      "Train Epoch: 0, mini-batch 4970 of 31, training loss: 0.561983\n",
      "Train Epoch: 0, mini-batch 4980 of 31, training loss: 0.563104\n",
      "Train Epoch: 0, mini-batch 4990 of 31, training loss: 0.562931\n",
      "Train Epoch: 0, mini-batch 5000 of 31, training loss: 0.562224\n",
      "Train Epoch: 0, mini-batch 5010 of 31, training loss: 0.561846\n",
      "Train Epoch: 0, mini-batch 5020 of 31, training loss: 0.561109\n",
      "Train Epoch: 0, mini-batch 5030 of 31, training loss: 0.564437\n",
      "Train Epoch: 0, mini-batch 5040 of 31, training loss: 0.561340\n",
      "Train Epoch: 0, mini-batch 5050 of 31, training loss: 0.564592\n",
      "Train Epoch: 0, mini-batch 5060 of 31, training loss: 0.564243\n",
      "Train Epoch: 0, mini-batch 5070 of 31, training loss: 0.561347\n",
      "Train Epoch: 0, mini-batch 5080 of 31, training loss: 0.561493\n",
      "Train Epoch: 0, mini-batch 5090 of 31, training loss: 0.562314\n",
      "Train Epoch: 0, mini-batch 5100 of 31, training loss: 0.564033\n",
      "Train Epoch: 0, mini-batch 5110 of 31, training loss: 0.563318\n",
      "Train Epoch: 0, mini-batch 5120 of 31, training loss: 0.563825\n",
      "Train Epoch: 0, mini-batch 5130 of 31, training loss: 0.560645\n",
      "Train Epoch: 0, mini-batch 5140 of 31, training loss: 0.563616\n",
      "Train Epoch: 0, mini-batch 5150 of 31, training loss: 0.562797\n",
      "Train Epoch: 0, mini-batch 5160 of 31, training loss: 0.564232\n",
      "Train Epoch: 0, mini-batch 5170 of 31, training loss: 0.564009\n",
      "Train Epoch: 0, mini-batch 5180 of 31, training loss: 0.563451\n",
      "Train Epoch: 0, mini-batch 5190 of 31, training loss: 0.562934\n",
      "Train Epoch: 0, mini-batch 5200 of 31, training loss: 0.563858\n",
      "Train Epoch: 0, mini-batch 5210 of 31, training loss: 0.562600\n",
      "Train Epoch: 0, mini-batch 5220 of 31, training loss: 0.562473\n",
      "Train Epoch: 0, mini-batch 5230 of 31, training loss: 0.562039\n",
      "Train Epoch: 0, mini-batch 5240 of 31, training loss: 0.561359\n",
      "Train Epoch: 0, mini-batch 5250 of 31, training loss: 0.565949\n",
      "Train Epoch: 0, mini-batch 5260 of 31, training loss: 0.563351\n",
      "Train Epoch: 0, mini-batch 5270 of 31, training loss: 0.561399\n",
      "Train Epoch: 0, mini-batch 5280 of 31, training loss: 0.562356\n",
      "Train Epoch: 0, mini-batch 5290 of 31, training loss: 0.560617\n",
      "Train Epoch: 0, mini-batch 5300 of 31, training loss: 0.562122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 5310 of 31, training loss: 0.561818\n",
      "Train Epoch: 0, mini-batch 5320 of 31, training loss: 0.561537\n",
      "Train Epoch: 0, mini-batch 5330 of 31, training loss: 0.561457\n",
      "Train Epoch: 0, mini-batch 5340 of 31, training loss: 0.562035\n",
      "Train Epoch: 0, mini-batch 5350 of 31, training loss: 0.562940\n",
      "Train Epoch: 0, mini-batch 5360 of 31, training loss: 0.561329\n",
      "Train Epoch: 0, mini-batch 5370 of 31, training loss: 0.559641\n",
      "Train Epoch: 0, mini-batch 5380 of 31, training loss: 0.562144\n",
      "Train Epoch: 0, mini-batch 5390 of 31, training loss: 0.562394\n",
      "Train Epoch: 0, mini-batch 5400 of 31, training loss: 0.560663\n",
      "Train Epoch: 0, mini-batch 5410 of 31, training loss: 0.561620\n",
      "Train Epoch: 0, mini-batch 5420 of 31, training loss: 0.565256\n",
      "Train Epoch: 0, mini-batch 5430 of 31, training loss: 0.564751\n",
      "Train Epoch: 0, mini-batch 5440 of 31, training loss: 0.559852\n",
      "Train Epoch: 0, mini-batch 5450 of 31, training loss: 0.566071\n",
      "Train Epoch: 0, mini-batch 5460 of 31, training loss: 0.560558\n",
      "Train Epoch: 0, mini-batch 5470 of 31, training loss: 0.560195\n",
      "Train Epoch: 0, mini-batch 5480 of 31, training loss: 0.562391\n",
      "Train Epoch: 0, mini-batch 5490 of 31, training loss: 0.566753\n",
      "Train Epoch: 0, mini-batch 5500 of 31, training loss: 0.561639\n",
      "Train Epoch: 0, mini-batch 5510 of 31, training loss: 0.562808\n",
      "Train Epoch: 0, mini-batch 5520 of 31, training loss: 0.558308\n",
      "Train Epoch: 0, mini-batch 5530 of 31, training loss: 0.564204\n",
      "Train Epoch: 0, mini-batch 5540 of 31, training loss: 0.558565\n",
      "Train Epoch: 0, mini-batch 5550 of 31, training loss: 0.560848\n",
      "Train Epoch: 0, mini-batch 5560 of 31, training loss: 0.564178\n",
      "Train Epoch: 0, mini-batch 5570 of 31, training loss: 0.561502\n",
      "Train Epoch: 0, mini-batch 5580 of 31, training loss: 0.559746\n",
      "Train Epoch: 0, mini-batch 5590 of 31, training loss: 0.559027\n",
      "Train Epoch: 0, mini-batch 5600 of 31, training loss: 0.562581\n",
      "Train Epoch: 0, mini-batch 5610 of 31, training loss: 0.557996\n",
      "Train Epoch: 0, mini-batch 5620 of 31, training loss: 0.557626\n",
      "Train Epoch: 0, mini-batch 5630 of 31, training loss: 0.559779\n",
      "Train Epoch: 0, mini-batch 5640 of 31, training loss: 0.561963\n",
      "Train Epoch: 0, mini-batch 5650 of 31, training loss: 0.558485\n",
      "Train Epoch: 0, mini-batch 5660 of 31, training loss: 0.561935\n",
      "Train Epoch: 0, mini-batch 5670 of 31, training loss: 0.563439\n",
      "Train Epoch: 0, mini-batch 5680 of 31, training loss: 0.562243\n",
      "Train Epoch: 0, mini-batch 5690 of 31, training loss: 0.562452\n",
      "Train Epoch: 0, mini-batch 5700 of 31, training loss: 0.560483\n",
      "Train Epoch: 0, mini-batch 5710 of 31, training loss: 0.561763\n",
      "Train Epoch: 0, mini-batch 5720 of 31, training loss: 0.563374\n",
      "Train Epoch: 0, mini-batch 5730 of 31, training loss: 0.563503\n",
      "Train Epoch: 0, mini-batch 5740 of 31, training loss: 0.562658\n",
      "Train Epoch: 0, mini-batch 5750 of 31, training loss: 0.565337\n",
      "Train Epoch: 0, mini-batch 5760 of 31, training loss: 0.562202\n",
      "Train Epoch: 0, mini-batch 5770 of 31, training loss: 0.564133\n",
      "Train Epoch: 0, mini-batch 5780 of 31, training loss: 0.562900\n",
      "Train Epoch: 0, mini-batch 5790 of 31, training loss: 0.562001\n",
      "Train Epoch: 0, mini-batch 5800 of 31, training loss: 0.562261\n",
      "Train Epoch: 0, mini-batch 5810 of 31, training loss: 0.560089\n",
      "Train Epoch: 0, mini-batch 5820 of 31, training loss: 0.565048\n",
      "Train Epoch: 0, mini-batch 5830 of 31, training loss: 0.563828\n",
      "Train Epoch: 0, mini-batch 5840 of 31, training loss: 0.560233\n",
      "Train Epoch: 0, mini-batch 5850 of 31, training loss: 0.560103\n",
      "Train Epoch: 0, mini-batch 5860 of 31, training loss: 0.561918\n",
      "Train Epoch: 0, mini-batch 5870 of 31, training loss: 0.566547\n",
      "Train Epoch: 0, mini-batch 5880 of 31, training loss: 0.564849\n",
      "Train Epoch: 0, mini-batch 5890 of 31, training loss: 0.563097\n",
      "Train Epoch: 0, mini-batch 5900 of 31, training loss: 0.562798\n",
      "Train Epoch: 0, mini-batch 5910 of 31, training loss: 0.558879\n",
      "Train Epoch: 0, mini-batch 5920 of 31, training loss: 0.562509\n",
      "Train Epoch: 0, mini-batch 5930 of 31, training loss: 0.562449\n",
      "Train Epoch: 0, mini-batch 5940 of 31, training loss: 0.565947\n",
      "Train Epoch: 0, mini-batch 5950 of 31, training loss: 0.560619\n",
      "Train Epoch: 0, mini-batch 5960 of 31, training loss: 0.560932\n",
      "Train Epoch: 0, mini-batch 5970 of 31, training loss: 0.564760\n",
      "Train Epoch: 0, mini-batch 5980 of 31, training loss: 0.563336\n",
      "Train Epoch: 0, mini-batch 5990 of 31, training loss: 0.561455\n",
      "Train Epoch: 0, mini-batch 6000 of 31, training loss: 0.563768\n",
      "Train Epoch: 0, mini-batch 6010 of 31, training loss: 0.561760\n",
      "Train Epoch: 0, mini-batch 6020 of 31, training loss: 0.562884\n",
      "Train Epoch: 0, mini-batch 6030 of 31, training loss: 0.562136\n",
      "Train Epoch: 0, mini-batch 6040 of 31, training loss: 0.562176\n",
      "Train Epoch: 0, mini-batch 6050 of 31, training loss: 0.559812\n",
      "Train Epoch: 0, mini-batch 6060 of 31, training loss: 0.562861\n",
      "Train Epoch: 0, mini-batch 6070 of 31, training loss: 0.561307\n",
      "Train Epoch: 0, mini-batch 6080 of 31, training loss: 0.559831\n",
      "Train Epoch: 0, mini-batch 6090 of 31, training loss: 0.562831\n",
      "Train Epoch: 0, mini-batch 6100 of 31, training loss: 0.561861\n",
      "Train Epoch: 0, mini-batch 6110 of 31, training loss: 0.563376\n",
      "Train Epoch: 0, mini-batch 6120 of 31, training loss: 0.560983\n",
      "Train Epoch: 0, mini-batch 6130 of 31, training loss: 0.561565\n",
      "Train Epoch: 0, mini-batch 6140 of 31, training loss: 0.563232\n",
      "Train Epoch: 0, mini-batch 6150 of 31, training loss: 0.564182\n",
      "Train Epoch: 0, mini-batch 6160 of 31, training loss: 0.560155\n",
      "Train Epoch: 0, mini-batch 6170 of 31, training loss: 0.563421\n",
      "Train Epoch: 0, mini-batch 6180 of 31, training loss: 0.566765\n",
      "Train Epoch: 0, mini-batch 6190 of 31, training loss: 0.559477\n",
      "Train Epoch: 0, mini-batch 6200 of 31, training loss: 0.564065\n",
      "Train Epoch: 0, mini-batch 6210 of 31, training loss: 0.563553\n",
      "Train Epoch: 0, mini-batch 6220 of 31, training loss: 0.566175\n",
      "Train Epoch: 0, mini-batch 6230 of 31, training loss: 0.563221\n",
      "Train Epoch: 0, mini-batch 6240 of 31, training loss: 0.561433\n",
      "Train Epoch: 0, mini-batch 6250 of 31, training loss: 0.557310\n",
      "Train Epoch: 0, mini-batch 6260 of 31, training loss: 0.563837\n",
      "Train Epoch: 0, mini-batch 6270 of 31, training loss: 0.562647\n",
      "Train Epoch: 0, mini-batch 6280 of 31, training loss: 0.564049\n",
      "Train Epoch: 0, mini-batch 6290 of 31, training loss: 0.563444\n",
      "Train Epoch: 0, mini-batch 6300 of 31, training loss: 0.562707\n",
      "Train Epoch: 0, mini-batch 6310 of 31, training loss: 0.561843\n",
      "Train Epoch: 0, mini-batch 6320 of 31, training loss: 0.563750\n",
      "Train Epoch: 0, mini-batch 6330 of 31, training loss: 0.558956\n",
      "Train Epoch: 0, mini-batch 6340 of 31, training loss: 0.562929\n",
      "Train Epoch: 0, mini-batch 6350 of 31, training loss: 0.562086\n",
      "Train Epoch: 0, mini-batch 6360 of 31, training loss: 0.561309\n",
      "Train Epoch: 0, mini-batch 6370 of 31, training loss: 0.561716\n",
      "Train Epoch: 0, mini-batch 6380 of 31, training loss: 0.562370\n",
      "Train Epoch: 0, mini-batch 6390 of 31, training loss: 0.563595\n",
      "Train Epoch: 0, mini-batch 6400 of 31, training loss: 0.562845\n",
      "Train Epoch: 0, mini-batch 6410 of 31, training loss: 0.562205\n",
      "Train Epoch: 0, mini-batch 6420 of 31, training loss: 0.561056\n",
      "Train Epoch: 0, mini-batch 6430 of 31, training loss: 0.560633\n",
      "Train Epoch: 0, mini-batch 6440 of 31, training loss: 0.564365\n",
      "Train Epoch: 0, mini-batch 6450 of 31, training loss: 0.565277\n",
      "Train Epoch: 0, mini-batch 6460 of 31, training loss: 0.562408\n",
      "Train Epoch: 0, mini-batch 6470 of 31, training loss: 0.560861\n",
      "Train Epoch: 0, mini-batch 6480 of 31, training loss: 0.562532\n",
      "Train Epoch: 0, mini-batch 6490 of 31, training loss: 0.563406\n",
      "Train Epoch: 0, mini-batch 6500 of 31, training loss: 0.562915\n",
      "Train Epoch: 0, mini-batch 6510 of 31, training loss: 0.563427\n",
      "Train Epoch: 0, mini-batch 6520 of 31, training loss: 0.563924\n",
      "Train Epoch: 0, mini-batch 6530 of 31, training loss: 0.559919\n",
      "Train Epoch: 0, mini-batch 6540 of 31, training loss: 0.562027\n",
      "Train Epoch: 0, mini-batch 6550 of 31, training loss: 0.561495\n",
      "Train Epoch: 0, mini-batch 6560 of 31, training loss: 0.562472\n",
      "Train Epoch: 0, mini-batch 6570 of 31, training loss: 0.562141\n",
      "Train Epoch: 0, mini-batch 6580 of 31, training loss: 0.562567\n",
      "Train Epoch: 0, mini-batch 6590 of 31, training loss: 0.564283\n",
      "Train Epoch: 0, mini-batch 6600 of 31, training loss: 0.562560\n",
      "Train Epoch: 0, mini-batch 6610 of 31, training loss: 0.562673\n",
      "Train Epoch: 0, mini-batch 6620 of 31, training loss: 0.560358\n",
      "Train Epoch: 0, mini-batch 6630 of 31, training loss: 0.565352\n",
      "Train Epoch: 0, mini-batch 6640 of 31, training loss: 0.566229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 6650 of 31, training loss: 0.561926\n",
      "Train Epoch: 0, mini-batch 6660 of 31, training loss: 0.561436\n",
      "Train Epoch: 0, mini-batch 6670 of 31, training loss: 0.563306\n",
      "Train Epoch: 0, mini-batch 6680 of 31, training loss: 0.563068\n",
      "Train Epoch: 0, mini-batch 6690 of 31, training loss: 0.562051\n",
      "Train Epoch: 0, mini-batch 6700 of 31, training loss: 0.562962\n",
      "Train Epoch: 0, mini-batch 6710 of 31, training loss: 0.563059\n",
      "Train Epoch: 0, mini-batch 6720 of 31, training loss: 0.563354\n",
      "Train Epoch: 0, mini-batch 6730 of 31, training loss: 0.562873\n",
      "Train Epoch: 0, mini-batch 6740 of 31, training loss: 0.562599\n",
      "Train Epoch: 0, mini-batch 6750 of 31, training loss: 0.564277\n",
      "Train Epoch: 0, mini-batch 6760 of 31, training loss: 0.561319\n",
      "Train Epoch: 0, mini-batch 6770 of 31, training loss: 0.562817\n",
      "Train Epoch: 0, mini-batch 6780 of 31, training loss: 0.562372\n",
      "Train Epoch: 0, mini-batch 6790 of 31, training loss: 0.561882\n",
      "Train Epoch: 0, mini-batch 6800 of 31, training loss: 0.563933\n",
      "Train Epoch: 0, mini-batch 6810 of 31, training loss: 0.563349\n",
      "Train Epoch: 0, mini-batch 6820 of 31, training loss: 0.563712\n",
      "Train Epoch: 0, mini-batch 6830 of 31, training loss: 0.561798\n",
      "Train Epoch: 0, mini-batch 6840 of 31, training loss: 0.562629\n",
      "Train Epoch: 0, mini-batch 6850 of 31, training loss: 0.563884\n",
      "Train Epoch: 0, mini-batch 6860 of 31, training loss: 0.560469\n",
      "Train Epoch: 0, mini-batch 6870 of 31, training loss: 0.562645\n",
      "Train Epoch: 0, mini-batch 6880 of 31, training loss: 0.562087\n",
      "Train Epoch: 0, mini-batch 6890 of 31, training loss: 0.567556\n",
      "Train Epoch: 0, mini-batch 6900 of 31, training loss: 0.564915\n",
      "Train Epoch: 0, mini-batch 6910 of 31, training loss: 0.564203\n",
      "Train Epoch: 0, mini-batch 6920 of 31, training loss: 0.564072\n",
      "Train Epoch: 0, mini-batch 6930 of 31, training loss: 0.562425\n",
      "Train Epoch: 0, mini-batch 6940 of 31, training loss: 0.561462\n",
      "Train Epoch: 0, mini-batch 6950 of 31, training loss: 0.566342\n",
      "Train Epoch: 0, mini-batch 6960 of 31, training loss: 0.565234\n",
      "Train Epoch: 0, mini-batch 6970 of 31, training loss: 0.562802\n",
      "Train Epoch: 0, mini-batch 6980 of 31, training loss: 0.562669\n",
      "Train Epoch: 0, mini-batch 6990 of 31, training loss: 0.561700\n",
      "Train Epoch: 0, mini-batch 7000 of 31, training loss: 0.559453\n",
      "Train Epoch: 0, mini-batch 7010 of 31, training loss: 0.560158\n",
      "Train Epoch: 0, mini-batch 7020 of 31, training loss: 0.561972\n",
      "Train Epoch: 0, mini-batch 7030 of 31, training loss: 0.564509\n",
      "Train Epoch: 0, mini-batch 7040 of 31, training loss: 0.561311\n",
      "Train Epoch: 0, mini-batch 7050 of 31, training loss: 0.562101\n",
      "Train Epoch: 0, mini-batch 7060 of 31, training loss: 0.562631\n",
      "Train Epoch: 0, mini-batch 7070 of 31, training loss: 0.562348\n",
      "Train Epoch: 0, mini-batch 7080 of 31, training loss: 0.559435\n",
      "Train Epoch: 0, mini-batch 7090 of 31, training loss: 0.565632\n",
      "Train Epoch: 0, mini-batch 7100 of 31, training loss: 0.559251\n",
      "Train Epoch: 0, mini-batch 7110 of 31, training loss: 0.563165\n",
      "Train Epoch: 0, mini-batch 7120 of 31, training loss: 0.563984\n",
      "Train Epoch: 0, mini-batch 7130 of 31, training loss: 0.562926\n",
      "Train Epoch: 0, mini-batch 7140 of 31, training loss: 0.564716\n",
      "Train Epoch: 0, mini-batch 7150 of 31, training loss: 0.561198\n",
      "Train Epoch: 0, mini-batch 7160 of 31, training loss: 0.562889\n",
      "Train Epoch: 0, mini-batch 7170 of 31, training loss: 0.562412\n",
      "Train Epoch: 0, mini-batch 7180 of 31, training loss: 0.562816\n",
      "Train Epoch: 0, mini-batch 7190 of 31, training loss: 0.563882\n",
      "Train Epoch: 0, mini-batch 7200 of 31, training loss: 0.562603\n",
      "Train Epoch: 0, mini-batch 7210 of 31, training loss: 0.561593\n",
      "Train Epoch: 0, mini-batch 7220 of 31, training loss: 0.563607\n",
      "Train Epoch: 0, mini-batch 7230 of 31, training loss: 0.563532\n",
      "Train Epoch: 0, mini-batch 7240 of 31, training loss: 0.562339\n",
      "Train Epoch: 0, mini-batch 7250 of 31, training loss: 0.563629\n",
      "Train Epoch: 0, mini-batch 7260 of 31, training loss: 0.561241\n",
      "Train Epoch: 0, mini-batch 7270 of 31, training loss: 0.565717\n",
      "Train Epoch: 0, mini-batch 7280 of 31, training loss: 0.562375\n",
      "Train Epoch: 0, mini-batch 7290 of 31, training loss: 0.564628\n",
      "Train Epoch: 0, mini-batch 7300 of 31, training loss: 0.563340\n",
      "Train Epoch: 0, mini-batch 7310 of 31, training loss: 0.563735\n",
      "Train Epoch: 0, mini-batch 7320 of 31, training loss: 0.562401\n",
      "Train Epoch: 0, mini-batch 7330 of 31, training loss: 0.563459\n",
      "Train Epoch: 0, mini-batch 7340 of 31, training loss: 0.563696\n",
      "Train Epoch: 0, mini-batch 7350 of 31, training loss: 0.562507\n",
      "Train Epoch: 0, mini-batch 7360 of 31, training loss: 0.560437\n",
      "Train Epoch: 0, mini-batch 7370 of 31, training loss: 0.562186\n",
      "Train Epoch: 0, mini-batch 7380 of 31, training loss: 0.560142\n",
      "Train Epoch: 0, mini-batch 7390 of 31, training loss: 0.563734\n",
      "Train Epoch: 0, mini-batch 7400 of 31, training loss: 0.563904\n",
      "Train Epoch: 0, mini-batch 7410 of 31, training loss: 0.560915\n",
      "Train Epoch: 0, mini-batch 7420 of 31, training loss: 0.563857\n",
      "Train Epoch: 0, mini-batch 7430 of 31, training loss: 0.561863\n",
      "Train Epoch: 0, mini-batch 7440 of 31, training loss: 0.561852\n",
      "Train Epoch: 0, mini-batch 7450 of 31, training loss: 0.562310\n",
      "Train Epoch: 0, mini-batch 7460 of 31, training loss: 0.563627\n",
      "Train Epoch: 0, mini-batch 7470 of 31, training loss: 0.563123\n",
      "Train Epoch: 0, mini-batch 7480 of 31, training loss: 0.564440\n",
      "Train Epoch: 0, mini-batch 7490 of 31, training loss: 0.561423\n",
      "Train Epoch: 0, mini-batch 7500 of 31, training loss: 0.561515\n",
      "Train Epoch: 0, mini-batch 7510 of 31, training loss: 0.563777\n",
      "Train Epoch: 0, mini-batch 7520 of 31, training loss: 0.562545\n",
      "Train Epoch: 0, mini-batch 7530 of 31, training loss: 0.563041\n",
      "Train Epoch: 0, mini-batch 7540 of 31, training loss: 0.562363\n",
      "Train Epoch: 0, mini-batch 7550 of 31, training loss: 0.560967\n",
      "Train Epoch: 0, mini-batch 7560 of 31, training loss: 0.559668\n",
      "Train Epoch: 0, mini-batch 7570 of 31, training loss: 0.563730\n",
      "Train Epoch: 0, mini-batch 7580 of 31, training loss: 0.562839\n",
      "Train Epoch: 0, mini-batch 7590 of 31, training loss: 0.559719\n",
      "Train Epoch: 0, mini-batch 7600 of 31, training loss: 0.563230\n",
      "Train Epoch: 0, mini-batch 7610 of 31, training loss: 0.560948\n",
      "Train Epoch: 0, mini-batch 7620 of 31, training loss: 0.565420\n",
      "Train Epoch: 0, mini-batch 7630 of 31, training loss: 0.563201\n",
      "Train Epoch: 0, mini-batch 7640 of 31, training loss: 0.560480\n",
      "Train Epoch: 0, mini-batch 7650 of 31, training loss: 0.562103\n",
      "Train Epoch: 0, mini-batch 7660 of 31, training loss: 0.563267\n",
      "Train Epoch: 0, mini-batch 7670 of 31, training loss: 0.562589\n",
      "Train Epoch: 0, mini-batch 7680 of 31, training loss: 0.562194\n",
      "Train Epoch: 0, mini-batch 7690 of 31, training loss: 0.561550\n",
      "Train Epoch: 0, mini-batch 7700 of 31, training loss: 0.563650\n",
      "Train Epoch: 0, mini-batch 7710 of 31, training loss: 0.561933\n",
      "Train Epoch: 0, mini-batch 7720 of 31, training loss: 0.562443\n",
      "Train Epoch: 0, mini-batch 7730 of 31, training loss: 0.562649\n",
      "Train Epoch: 0, mini-batch 7740 of 31, training loss: 0.561398\n",
      "Train Epoch: 0, mini-batch 7750 of 31, training loss: 0.564578\n",
      "Train Epoch: 0, mini-batch 7760 of 31, training loss: 0.562300\n",
      "Train Epoch: 0, mini-batch 7770 of 31, training loss: 0.560309\n",
      "Train Epoch: 0, mini-batch 7780 of 31, training loss: 0.562093\n",
      "Train Epoch: 0, mini-batch 7790 of 31, training loss: 0.563101\n",
      "Train Epoch: 0, mini-batch 7800 of 31, training loss: 0.563585\n",
      "Train Epoch: 0, mini-batch 7810 of 31, training loss: 0.561240\n",
      "Train Epoch: 0, mini-batch 7820 of 31, training loss: 0.562502\n",
      "Train Epoch: 0, mini-batch 7830 of 31, training loss: 0.560362\n",
      "Train Epoch: 0, mini-batch 7840 of 31, training loss: 0.563643\n",
      "Train Epoch: 0, mini-batch 7850 of 31, training loss: 0.560731\n",
      "Train Epoch: 0, mini-batch 7860 of 31, training loss: 0.565054\n",
      "Train Epoch: 0, mini-batch 7870 of 31, training loss: 0.561148\n",
      "Train Epoch: 0, mini-batch 7880 of 31, training loss: 0.561036\n",
      "Train Epoch: 0, mini-batch 7890 of 31, training loss: 0.562504\n",
      "Train Epoch: 0, mini-batch 7900 of 31, training loss: 0.561650\n",
      "Train Epoch: 0, mini-batch 7910 of 31, training loss: 0.562283\n",
      "Train Epoch: 0, mini-batch 7920 of 31, training loss: 0.560032\n",
      "Train Epoch: 0, mini-batch 7930 of 31, training loss: 0.564283\n",
      "Train Epoch: 0, mini-batch 7940 of 31, training loss: 0.559548\n",
      "Train Epoch: 0, mini-batch 7950 of 31, training loss: 0.562654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 7960 of 31, training loss: 0.563664\n",
      "Train Epoch: 0, mini-batch 7970 of 31, training loss: 0.562228\n",
      "Train Epoch: 0, mini-batch 7980 of 31, training loss: 0.562773\n",
      "Train Epoch: 0, mini-batch 7990 of 31, training loss: 0.562136\n",
      "Train Epoch: 0, mini-batch 8000 of 31, training loss: 0.564356\n",
      "Train Epoch: 0, mini-batch 8010 of 31, training loss: 0.562143\n",
      "Train Epoch: 0, mini-batch 8020 of 31, training loss: 0.561475\n",
      "Train Epoch: 0, mini-batch 8030 of 31, training loss: 0.559853\n",
      "Train Epoch: 0, mini-batch 8040 of 31, training loss: 0.561395\n",
      "Train Epoch: 0, mini-batch 8050 of 31, training loss: 0.564509\n",
      "Train Epoch: 0, mini-batch 8060 of 31, training loss: 0.563770\n",
      "Train Epoch: 0, mini-batch 8070 of 31, training loss: 0.562580\n",
      "Train Epoch: 0, mini-batch 8080 of 31, training loss: 0.563681\n",
      "Train Epoch: 0, mini-batch 8090 of 31, training loss: 0.561273\n",
      "Train Epoch: 0, mini-batch 8100 of 31, training loss: 0.563844\n",
      "Train Epoch: 0, mini-batch 8110 of 31, training loss: 0.562093\n",
      "Train Epoch: 0, mini-batch 8120 of 31, training loss: 0.561939\n",
      "Train Epoch: 0, mini-batch 8130 of 31, training loss: 0.562749\n",
      "Train Epoch: 0, mini-batch 8140 of 31, training loss: 0.562669\n",
      "Train Epoch: 0, mini-batch 8150 of 31, training loss: 0.561461\n",
      "Train Epoch: 0, mini-batch 8160 of 31, training loss: 0.565257\n",
      "Train Epoch: 0, mini-batch 8170 of 31, training loss: 0.566932\n",
      "Train Epoch: 0, mini-batch 8180 of 31, training loss: 0.562557\n",
      "Train Epoch: 0, mini-batch 8190 of 31, training loss: 0.562507\n",
      "Train Epoch: 0, mini-batch 8200 of 31, training loss: 0.566233\n",
      "Train Epoch: 0, mini-batch 8210 of 31, training loss: 0.562768\n",
      "Train Epoch: 0, mini-batch 8220 of 31, training loss: 0.562654\n",
      "Train Epoch: 0, mini-batch 8230 of 31, training loss: 0.560322\n",
      "Train Epoch: 0, mini-batch 8240 of 31, training loss: 0.562912\n",
      "Train Epoch: 0, mini-batch 8250 of 31, training loss: 0.562189\n",
      "Train Epoch: 0, mini-batch 8260 of 31, training loss: 0.560735\n",
      "Train Epoch: 0, mini-batch 8270 of 31, training loss: 0.568388\n",
      "Train Epoch: 0, mini-batch 8280 of 31, training loss: 0.562611\n",
      "Train Epoch: 0, mini-batch 8290 of 31, training loss: 0.561221\n",
      "Train Epoch: 0, mini-batch 8300 of 31, training loss: 0.562168\n",
      "Train Epoch: 0, mini-batch 8310 of 31, training loss: 0.564350\n",
      "Train Epoch: 0, mini-batch 8320 of 31, training loss: 0.561576\n",
      "Train Epoch: 0, mini-batch 8330 of 31, training loss: 0.561573\n",
      "Train Epoch: 0, mini-batch 8340 of 31, training loss: 0.559385\n",
      "Train Epoch: 0, mini-batch 8350 of 31, training loss: 0.565359\n",
      "Train Epoch: 0, mini-batch 8360 of 31, training loss: 0.561785\n",
      "Train Epoch: 0, mini-batch 8370 of 31, training loss: 0.562825\n",
      "Train Epoch: 0, mini-batch 8380 of 31, training loss: 0.562491\n",
      "Train Epoch: 0, mini-batch 8390 of 31, training loss: 0.562976\n",
      "Train Epoch: 0, mini-batch 8400 of 31, training loss: 0.562514\n",
      "Train Epoch: 0, mini-batch 8410 of 31, training loss: 0.563877\n",
      "Train Epoch: 0, mini-batch 8420 of 31, training loss: 0.563280\n",
      "Train Epoch: 0, mini-batch 8430 of 31, training loss: 0.564462\n",
      "Train Epoch: 0, mini-batch 8440 of 31, training loss: 0.562361\n",
      "Train Epoch: 0, mini-batch 8450 of 31, training loss: 0.562678\n",
      "Train Epoch: 0, mini-batch 8460 of 31, training loss: 0.565215\n",
      "Train Epoch: 0, mini-batch 8470 of 31, training loss: 0.564230\n",
      "Train Epoch: 0, mini-batch 8480 of 31, training loss: 0.562958\n",
      "Train Epoch: 0, mini-batch 8490 of 31, training loss: 0.563249\n",
      "Train Epoch: 0, mini-batch 8500 of 31, training loss: 0.562455\n",
      "Train Epoch: 0, mini-batch 8510 of 31, training loss: 0.562557\n",
      "Train Epoch: 0, mini-batch 8520 of 31, training loss: 0.563105\n",
      "Train Epoch: 0, mini-batch 8530 of 31, training loss: 0.562851\n",
      "Train Epoch: 0, mini-batch 8540 of 31, training loss: 0.561095\n",
      "Train Epoch: 0, mini-batch 8550 of 31, training loss: 0.562280\n",
      "Train Epoch: 0, mini-batch 8560 of 31, training loss: 0.561138\n",
      "Train Epoch: 0, mini-batch 8570 of 31, training loss: 0.564302\n",
      "Train Epoch: 0, mini-batch 8580 of 31, training loss: 0.563617\n",
      "Train Epoch: 0, mini-batch 8590 of 31, training loss: 0.562733\n",
      "Train Epoch: 0, mini-batch 8600 of 31, training loss: 0.562661\n",
      "Train Epoch: 0, mini-batch 8610 of 31, training loss: 0.562317\n",
      "Train Epoch: 0, mini-batch 8620 of 31, training loss: 0.562728\n",
      "Train Epoch: 0, mini-batch 8630 of 31, training loss: 0.563164\n",
      "Train Epoch: 0, mini-batch 8640 of 31, training loss: 0.562805\n",
      "Train Epoch: 0, mini-batch 8650 of 31, training loss: 0.562486\n",
      "Train Epoch: 0, mini-batch 8660 of 31, training loss: 0.562314\n",
      "Train Epoch: 0, mini-batch 8670 of 31, training loss: 0.562348\n",
      "Train Epoch: 0, mini-batch 8680 of 31, training loss: 0.562438\n",
      "Train Epoch: 0, mini-batch 8690 of 31, training loss: 0.562091\n",
      "Train Epoch: 0, mini-batch 8700 of 31, training loss: 0.563083\n",
      "Train Epoch: 0, mini-batch 8710 of 31, training loss: 0.561915\n",
      "Train Epoch: 0, mini-batch 8720 of 31, training loss: 0.561833\n",
      "Train Epoch: 0, mini-batch 8730 of 31, training loss: 0.561307\n",
      "Train Epoch: 0, mini-batch 8740 of 31, training loss: 0.562919\n",
      "Train Epoch: 0, mini-batch 8750 of 31, training loss: 0.562948\n",
      "Train Epoch: 0, mini-batch 8760 of 31, training loss: 0.562257\n",
      "Train Epoch: 0, mini-batch 8770 of 31, training loss: 0.565332\n",
      "Train Epoch: 0, mini-batch 8780 of 31, training loss: 0.559161\n",
      "Train Epoch: 0, mini-batch 8790 of 31, training loss: 0.563794\n",
      "Train Epoch: 0, mini-batch 8800 of 31, training loss: 0.562527\n",
      "Train Epoch: 0, mini-batch 8810 of 31, training loss: 0.563117\n",
      "Train Epoch: 0, mini-batch 8820 of 31, training loss: 0.563586\n",
      "Train Epoch: 0, mini-batch 8830 of 31, training loss: 0.564849\n",
      "Train Epoch: 0, mini-batch 8840 of 31, training loss: 0.564750\n",
      "Train Epoch: 0, mini-batch 8850 of 31, training loss: 0.562698\n",
      "Train Epoch: 0, mini-batch 8860 of 31, training loss: 0.561386\n",
      "Train Epoch: 0, mini-batch 8870 of 31, training loss: 0.563034\n",
      "Train Epoch: 0, mini-batch 8880 of 31, training loss: 0.562061\n",
      "Train Epoch: 0, mini-batch 8890 of 31, training loss: 0.562422\n",
      "Train Epoch: 0, mini-batch 8900 of 31, training loss: 0.561535\n",
      "Train Epoch: 0, mini-batch 8910 of 31, training loss: 0.560750\n",
      "Train Epoch: 0, mini-batch 8920 of 31, training loss: 0.562806\n",
      "Train Epoch: 0, mini-batch 8930 of 31, training loss: 0.561944\n",
      "Train Epoch: 0, mini-batch 8940 of 31, training loss: 0.562147\n",
      "Train Epoch: 0, mini-batch 8950 of 31, training loss: 0.560367\n",
      "Train Epoch: 0, mini-batch 8960 of 31, training loss: 0.562055\n",
      "Train Epoch: 0, mini-batch 8970 of 31, training loss: 0.561931\n",
      "Train Epoch: 0, mini-batch 8980 of 31, training loss: 0.561652\n",
      "Train Epoch: 0, mini-batch 8990 of 31, training loss: 0.562199\n",
      "Train Epoch: 0, mini-batch 9000 of 31, training loss: 0.564792\n",
      "Train Epoch: 0, mini-batch 9010 of 31, training loss: 0.563476\n",
      "Train Epoch: 0, mini-batch 9020 of 31, training loss: 0.562676\n",
      "Train Epoch: 0, mini-batch 9030 of 31, training loss: 0.562929\n",
      "Train Epoch: 0, mini-batch 9040 of 31, training loss: 0.560416\n",
      "Train Epoch: 0, mini-batch 9050 of 31, training loss: 0.560752\n",
      "Train Epoch: 0, mini-batch 9060 of 31, training loss: 0.559642\n",
      "Train Epoch: 0, mini-batch 9070 of 31, training loss: 0.561012\n",
      "Train Epoch: 0, mini-batch 9080 of 31, training loss: 0.561114\n",
      "Train Epoch: 0, mini-batch 9090 of 31, training loss: 0.560251\n",
      "Train Epoch: 0, mini-batch 9100 of 31, training loss: 0.562172\n",
      "Train Epoch: 0, mini-batch 9110 of 31, training loss: 0.561432\n",
      "Train Epoch: 0, mini-batch 9120 of 31, training loss: 0.564374\n",
      "Train Epoch: 0, mini-batch 9130 of 31, training loss: 0.563849\n",
      "Train Epoch: 0, mini-batch 9140 of 31, training loss: 0.562718\n",
      "Train Epoch: 0, mini-batch 9150 of 31, training loss: 0.561848\n",
      "Train Epoch: 0, mini-batch 9160 of 31, training loss: 0.564409\n",
      "Train Epoch: 0, mini-batch 9170 of 31, training loss: 0.564148\n",
      "Train Epoch: 0, mini-batch 9180 of 31, training loss: 0.564164\n",
      "Train Epoch: 0, mini-batch 9190 of 31, training loss: 0.560658\n",
      "Train Epoch: 0, mini-batch 9200 of 31, training loss: 0.562526\n",
      "Train Epoch: 0, mini-batch 9210 of 31, training loss: 0.561758\n",
      "Train Epoch: 0, mini-batch 9220 of 31, training loss: 0.562386\n",
      "Train Epoch: 0, mini-batch 9230 of 31, training loss: 0.564224\n",
      "Train Epoch: 0, mini-batch 9240 of 31, training loss: 0.565916\n",
      "Train Epoch: 0, mini-batch 9250 of 31, training loss: 0.566126\n",
      "Train Epoch: 0, mini-batch 9260 of 31, training loss: 0.563584\n",
      "Train Epoch: 0, mini-batch 9270 of 31, training loss: 0.560903\n",
      "Train Epoch: 0, mini-batch 9280 of 31, training loss: 0.563603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 9290 of 31, training loss: 0.561900\n",
      "Train Epoch: 0, mini-batch 9300 of 31, training loss: 0.561013\n",
      "Train Epoch: 0, mini-batch 9310 of 31, training loss: 0.564253\n",
      "Train Epoch: 0, mini-batch 9320 of 31, training loss: 0.564790\n",
      "Train Epoch: 0, mini-batch 9330 of 31, training loss: 0.561672\n",
      "Train Epoch: 0, mini-batch 9340 of 31, training loss: 0.563145\n",
      "Train Epoch: 0, mini-batch 9350 of 31, training loss: 0.562158\n",
      "Train Epoch: 0, mini-batch 9360 of 31, training loss: 0.561904\n",
      "Train Epoch: 0, mini-batch 9370 of 31, training loss: 0.563083\n",
      "Train Epoch: 0, mini-batch 9380 of 31, training loss: 0.561453\n",
      "Train Epoch: 0, mini-batch 9390 of 31, training loss: 0.561786\n",
      "Train Epoch: 0, mini-batch 9400 of 31, training loss: 0.562263\n",
      "Train Epoch: 0, mini-batch 9410 of 31, training loss: 0.561558\n",
      "Train Epoch: 0, mini-batch 9420 of 31, training loss: 0.560305\n",
      "Train Epoch: 0, mini-batch 9430 of 31, training loss: 0.562880\n",
      "Train Epoch: 0, mini-batch 9440 of 31, training loss: 0.560548\n",
      "Train Epoch: 0, mini-batch 9450 of 31, training loss: 0.558665\n",
      "Train Epoch: 0, mini-batch 9460 of 31, training loss: 0.559522\n",
      "Train Epoch: 0, mini-batch 9470 of 31, training loss: 0.563221\n",
      "Train Epoch: 0, mini-batch 9480 of 31, training loss: 0.563870\n",
      "Train Epoch: 0, mini-batch 9490 of 31, training loss: 0.561347\n",
      "Train Epoch: 0, mini-batch 9500 of 31, training loss: 0.562718\n",
      "Train Epoch: 0, mini-batch 9510 of 31, training loss: 0.560646\n",
      "Train Epoch: 0, mini-batch 9520 of 31, training loss: 0.562415\n",
      "Train Epoch: 0, mini-batch 9530 of 31, training loss: 0.562646\n",
      "Train Epoch: 0, mini-batch 9540 of 31, training loss: 0.560215\n",
      "Train Epoch: 0, mini-batch 9550 of 31, training loss: 0.565129\n",
      "Train Epoch: 0, mini-batch 9560 of 31, training loss: 0.561752\n",
      "Train Epoch: 0, mini-batch 9570 of 31, training loss: 0.562810\n",
      "Train Epoch: 0, mini-batch 9580 of 31, training loss: 0.563371\n",
      "Train Epoch: 0, mini-batch 9590 of 31, training loss: 0.563002\n",
      "Train Epoch: 0, mini-batch 9600 of 31, training loss: 0.562326\n",
      "Train Epoch: 0, mini-batch 9610 of 31, training loss: 0.560834\n",
      "Train Epoch: 0, mini-batch 9620 of 31, training loss: 0.563281\n",
      "Train Epoch: 0, mini-batch 9630 of 31, training loss: 0.563713\n",
      "Train Epoch: 0, mini-batch 9640 of 31, training loss: 0.562282\n",
      "Train Epoch: 0, mini-batch 9650 of 31, training loss: 0.562942\n",
      "Train Epoch: 0, mini-batch 9660 of 31, training loss: 0.562332\n",
      "Train Epoch: 0, mini-batch 9670 of 31, training loss: 0.562504\n",
      "Train Epoch: 0, mini-batch 9680 of 31, training loss: 0.562929\n",
      "Train Epoch: 0, mini-batch 9690 of 31, training loss: 0.563883\n",
      "Train Epoch: 0, mini-batch 9700 of 31, training loss: 0.561676\n",
      "Train Epoch: 0, mini-batch 9710 of 31, training loss: 0.562428\n",
      "Train Epoch: 0, mini-batch 9720 of 31, training loss: 0.561398\n",
      "Train Epoch: 0, mini-batch 9730 of 31, training loss: 0.565028\n",
      "Train Epoch: 0, mini-batch 9740 of 31, training loss: 0.563886\n",
      "Train Epoch: 0, mini-batch 9750 of 31, training loss: 0.560335\n",
      "Train Epoch: 0, mini-batch 9760 of 31, training loss: 0.563127\n",
      "Train Epoch: 0, mini-batch 9770 of 31, training loss: 0.560853\n",
      "Train Epoch: 0, mini-batch 9780 of 31, training loss: 0.562854\n",
      "Train Epoch: 0, mini-batch 9790 of 31, training loss: 0.562410\n",
      "Train Epoch: 0, mini-batch 9800 of 31, training loss: 0.566145\n",
      "Train Epoch: 0, mini-batch 9810 of 31, training loss: 0.565171\n",
      "Train Epoch: 0, mini-batch 9820 of 31, training loss: 0.564466\n",
      "Train Epoch: 0, mini-batch 9830 of 31, training loss: 0.562981\n",
      "Train Epoch: 0, mini-batch 9840 of 31, training loss: 0.562643\n",
      "Train Epoch: 0, mini-batch 9850 of 31, training loss: 0.562802\n",
      "Train Epoch: 0, mini-batch 9860 of 31, training loss: 0.562907\n",
      "Train Epoch: 0, mini-batch 9870 of 31, training loss: 0.563457\n",
      "Train Epoch: 0, mini-batch 9880 of 31, training loss: 0.563645\n",
      "Train Epoch: 0, mini-batch 9890 of 31, training loss: 0.563255\n",
      "Train Epoch: 0, mini-batch 9900 of 31, training loss: 0.563694\n",
      "Train Epoch: 0, mini-batch 9910 of 31, training loss: 0.563998\n",
      "Train Epoch: 0, mini-batch 9920 of 31, training loss: 0.562329\n",
      "Train Epoch: 0, mini-batch 9930 of 31, training loss: 0.560647\n",
      "Train Epoch: 0, mini-batch 9940 of 31, training loss: 0.566770\n",
      "Train Epoch: 0, mini-batch 9950 of 31, training loss: 0.562279\n",
      "Train Epoch: 0, mini-batch 9960 of 31, training loss: 0.561924\n",
      "Train Epoch: 0, mini-batch 9970 of 31, training loss: 0.562747\n",
      "Train Epoch: 0, mini-batch 9980 of 31, training loss: 0.562557\n",
      "Train Epoch: 0, mini-batch 9990 of 31, training loss: 0.562936\n",
      "Train Epoch: 0, mini-batch 10000 of 31, training loss: 0.565511\n",
      "Train Epoch: 0, mini-batch 10010 of 31, training loss: 0.562354\n",
      "Train Epoch: 0, mini-batch 10020 of 31, training loss: 0.562530\n",
      "Train Epoch: 0, mini-batch 10030 of 31, training loss: 0.561779\n",
      "Train Epoch: 0, mini-batch 10040 of 31, training loss: 0.563379\n",
      "Train Epoch: 0, mini-batch 10050 of 31, training loss: 0.562167\n",
      "Train Epoch: 0, mini-batch 10060 of 31, training loss: 0.562458\n",
      "Train Epoch: 0, mini-batch 10070 of 31, training loss: 0.562188\n",
      "Train Epoch: 0, mini-batch 10080 of 31, training loss: 0.560830\n",
      "Train Epoch: 0, mini-batch 10090 of 31, training loss: 0.563918\n",
      "Train Epoch: 0, mini-batch 10100 of 31, training loss: 0.562311\n",
      "Train Epoch: 0, mini-batch 10110 of 31, training loss: 0.561646\n",
      "Train Epoch: 0, mini-batch 10120 of 31, training loss: 0.562150\n",
      "Train Epoch: 0, mini-batch 10130 of 31, training loss: 0.562045\n",
      "Train Epoch: 0, mini-batch 10140 of 31, training loss: 0.562414\n",
      "Train Epoch: 0, mini-batch 10150 of 31, training loss: 0.562084\n",
      "Train Epoch: 0, mini-batch 10160 of 31, training loss: 0.562839\n",
      "Train Epoch: 0, mini-batch 10170 of 31, training loss: 0.561753\n",
      "Train Epoch: 0, mini-batch 10180 of 31, training loss: 0.563326\n",
      "Train Epoch: 0, mini-batch 10190 of 31, training loss: 0.564173\n",
      "Train Epoch: 0, mini-batch 10200 of 31, training loss: 0.562891\n",
      "Train Epoch: 0, mini-batch 10210 of 31, training loss: 0.563801\n",
      "Train Epoch: 0, mini-batch 10220 of 31, training loss: 0.563267\n",
      "Train Epoch: 0, mini-batch 10230 of 31, training loss: 0.559471\n",
      "Train Epoch: 0, mini-batch 10240 of 31, training loss: 0.565205\n",
      "Train Epoch: 0, mini-batch 10250 of 31, training loss: 0.559400\n",
      "Train Epoch: 0, mini-batch 10260 of 31, training loss: 0.560256\n",
      "Train Epoch: 0, mini-batch 10270 of 31, training loss: 0.561051\n",
      "Train Epoch: 0, mini-batch 10280 of 31, training loss: 0.563287\n",
      "Train Epoch: 0, mini-batch 10290 of 31, training loss: 0.563246\n",
      "Train Epoch: 0, mini-batch 10300 of 31, training loss: 0.562872\n",
      "Train Epoch: 0, mini-batch 10310 of 31, training loss: 0.561865\n",
      "Train Epoch: 0, mini-batch 10320 of 31, training loss: 0.561082\n",
      "Train Epoch: 0, mini-batch 10330 of 31, training loss: 0.563663\n",
      "Train Epoch: 0, mini-batch 10340 of 31, training loss: 0.562267\n",
      "Train Epoch: 0, mini-batch 10350 of 31, training loss: 0.562599\n",
      "Train Epoch: 0, mini-batch 10360 of 31, training loss: 0.561465\n",
      "Train Epoch: 0, mini-batch 10370 of 31, training loss: 0.561561\n",
      "Train Epoch: 0, mini-batch 10380 of 31, training loss: 0.566140\n",
      "Train Epoch: 0, mini-batch 10390 of 31, training loss: 0.562279\n",
      "Train Epoch: 0, mini-batch 10400 of 31, training loss: 0.562433\n",
      "Train Epoch: 0, mini-batch 10410 of 31, training loss: 0.562025\n",
      "Train Epoch: 0, mini-batch 10420 of 31, training loss: 0.562343\n",
      "Train Epoch: 0, mini-batch 10430 of 31, training loss: 0.562974\n",
      "Train Epoch: 0, mini-batch 10440 of 31, training loss: 0.562412\n",
      "Train Epoch: 0, mini-batch 10450 of 31, training loss: 0.562385\n",
      "Train Epoch: 0, mini-batch 10460 of 31, training loss: 0.562373\n",
      "Train Epoch: 0, mini-batch 10470 of 31, training loss: 0.561400\n",
      "Train Epoch: 0, mini-batch 10480 of 31, training loss: 0.562816\n",
      "Train Epoch: 0, mini-batch 10490 of 31, training loss: 0.561694\n",
      "Train Epoch: 0, mini-batch 10500 of 31, training loss: 0.562987\n",
      "Train Epoch: 0, mini-batch 10510 of 31, training loss: 0.562678\n",
      "Train Epoch: 0, mini-batch 10520 of 31, training loss: 0.561907\n",
      "Train Epoch: 0, mini-batch 10530 of 31, training loss: 0.561791\n",
      "Train Epoch: 0, mini-batch 10540 of 31, training loss: 0.563205\n",
      "Train Epoch: 0, mini-batch 10550 of 31, training loss: 0.561752\n",
      "Train Epoch: 0, mini-batch 10560 of 31, training loss: 0.561894\n",
      "Train Epoch: 0, mini-batch 10570 of 31, training loss: 0.562658\n",
      "Train Epoch: 0, mini-batch 10580 of 31, training loss: 0.562762\n",
      "Train Epoch: 0, mini-batch 10590 of 31, training loss: 0.561777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 10600 of 31, training loss: 0.558874\n",
      "Train Epoch: 0, mini-batch 10610 of 31, training loss: 0.562432\n",
      "Train Epoch: 0, mini-batch 10620 of 31, training loss: 0.561168\n",
      "Train Epoch: 0, mini-batch 10630 of 31, training loss: 0.563641\n",
      "Train Epoch: 0, mini-batch 10640 of 31, training loss: 0.560828\n",
      "Train Epoch: 0, mini-batch 10650 of 31, training loss: 0.563246\n",
      "Train Epoch: 0, mini-batch 10660 of 31, training loss: 0.559376\n",
      "Train Epoch: 0, mini-batch 10670 of 31, training loss: 0.567615\n",
      "Train Epoch: 0, mini-batch 10680 of 31, training loss: 0.562137\n",
      "Train Epoch: 0, mini-batch 10690 of 31, training loss: 0.560118\n",
      "Train Epoch: 0, mini-batch 10700 of 31, training loss: 0.566124\n",
      "Train Epoch: 0, mini-batch 10710 of 31, training loss: 0.560333\n",
      "Train Epoch: 0, mini-batch 10720 of 31, training loss: 0.560192\n",
      "Train Epoch: 0, mini-batch 10730 of 31, training loss: 0.562171\n",
      "Train Epoch: 0, mini-batch 10740 of 31, training loss: 0.562297\n",
      "Train Epoch: 0, mini-batch 10750 of 31, training loss: 0.561354\n",
      "Train Epoch: 0, mini-batch 10760 of 31, training loss: 0.562235\n",
      "Train Epoch: 0, mini-batch 10770 of 31, training loss: 0.563629\n",
      "Train Epoch: 0, mini-batch 10780 of 31, training loss: 0.561793\n",
      "Train Epoch: 0, mini-batch 10790 of 31, training loss: 0.560654\n",
      "Train Epoch: 0, mini-batch 10800 of 31, training loss: 0.561769\n",
      "Train Epoch: 0, mini-batch 10810 of 31, training loss: 0.562934\n",
      "Train Epoch: 0, mini-batch 10820 of 31, training loss: 0.562436\n",
      "Train Epoch: 0, mini-batch 10830 of 31, training loss: 0.565361\n",
      "Train Epoch: 0, mini-batch 10840 of 31, training loss: 0.560583\n",
      "Train Epoch: 0, mini-batch 10850 of 31, training loss: 0.562017\n",
      "Train Epoch: 0, mini-batch 10860 of 31, training loss: 0.560328\n",
      "Train Epoch: 0, mini-batch 10870 of 31, training loss: 0.563396\n",
      "Train Epoch: 0, mini-batch 10880 of 31, training loss: 0.562049\n",
      "Train Epoch: 0, mini-batch 10890 of 31, training loss: 0.563045\n",
      "Train Epoch: 0, mini-batch 10900 of 31, training loss: 0.562251\n",
      "Train Epoch: 0, mini-batch 10910 of 31, training loss: 0.562275\n",
      "Train Epoch: 0, mini-batch 10920 of 31, training loss: 0.561990\n",
      "Train Epoch: 0, mini-batch 10930 of 31, training loss: 0.561858\n",
      "Train Epoch: 0, mini-batch 10940 of 31, training loss: 0.561770\n",
      "Train Epoch: 0, mini-batch 10950 of 31, training loss: 0.563535\n",
      "Train Epoch: 0, mini-batch 10960 of 31, training loss: 0.562821\n",
      "Train Epoch: 0, mini-batch 10970 of 31, training loss: 0.560730\n",
      "Train Epoch: 0, mini-batch 10980 of 31, training loss: 0.560210\n",
      "Train Epoch: 0, mini-batch 10990 of 31, training loss: 0.562784\n",
      "Train Epoch: 0, mini-batch 11000 of 31, training loss: 0.561550\n",
      "Train Epoch: 0, mini-batch 11010 of 31, training loss: 0.560906\n",
      "Train Epoch: 0, mini-batch 11020 of 31, training loss: 0.562552\n",
      "Train Epoch: 0, mini-batch 11030 of 31, training loss: 0.562523\n",
      "Train Epoch: 0, mini-batch 11040 of 31, training loss: 0.563453\n",
      "Train Epoch: 0, mini-batch 11050 of 31, training loss: 0.561865\n",
      "Train Epoch: 0, mini-batch 11060 of 31, training loss: 0.561094\n",
      "Train Epoch: 0, mini-batch 11070 of 31, training loss: 0.563564\n",
      "Train Epoch: 0, mini-batch 11080 of 31, training loss: 0.563475\n",
      "Train Epoch: 0, mini-batch 11090 of 31, training loss: 0.562734\n",
      "Train Epoch: 0, mini-batch 11100 of 31, training loss: 0.560530\n",
      "Train Epoch: 0, mini-batch 11110 of 31, training loss: 0.562545\n",
      "Train Epoch: 0, mini-batch 11120 of 31, training loss: 0.562077\n",
      "Train Epoch: 0, mini-batch 11130 of 31, training loss: 0.561726\n",
      "Train Epoch: 0, mini-batch 11140 of 31, training loss: 0.563347\n",
      "Train Epoch: 0, mini-batch 11150 of 31, training loss: 0.560318\n",
      "Train Epoch: 0, mini-batch 11160 of 31, training loss: 0.564875\n",
      "Train Epoch: 0, mini-batch 11170 of 31, training loss: 0.559369\n",
      "Train Epoch: 0, mini-batch 11180 of 31, training loss: 0.563754\n",
      "Train Epoch: 0, mini-batch 11190 of 31, training loss: 0.563115\n",
      "Train Epoch: 0, mini-batch 11200 of 31, training loss: 0.561987\n",
      "Train Epoch: 0, mini-batch 11210 of 31, training loss: 0.560293\n",
      "Train Epoch: 0, mini-batch 11220 of 31, training loss: 0.559248\n",
      "Train Epoch: 0, mini-batch 11230 of 31, training loss: 0.565273\n",
      "Train Epoch: 0, mini-batch 11240 of 31, training loss: 0.562461\n",
      "Train Epoch: 0, mini-batch 11250 of 31, training loss: 0.564511\n",
      "Train Epoch: 0, mini-batch 11260 of 31, training loss: 0.564016\n",
      "Train Epoch: 0, mini-batch 11270 of 31, training loss: 0.561841\n",
      "Train Epoch: 0, mini-batch 11280 of 31, training loss: 0.561794\n",
      "Train Epoch: 0, mini-batch 11290 of 31, training loss: 0.562929\n",
      "Train Epoch: 0, mini-batch 11300 of 31, training loss: 0.563288\n",
      "Train Epoch: 0, mini-batch 11310 of 31, training loss: 0.562335\n",
      "Train Epoch: 0, mini-batch 11320 of 31, training loss: 0.563217\n",
      "Train Epoch: 0, mini-batch 11330 of 31, training loss: 0.562324\n",
      "Train Epoch: 0, mini-batch 11340 of 31, training loss: 0.562771\n",
      "Train Epoch: 0, mini-batch 11350 of 31, training loss: 0.561823\n",
      "Train Epoch: 0, mini-batch 11360 of 31, training loss: 0.562143\n",
      "Train Epoch: 0, mini-batch 11370 of 31, training loss: 0.563345\n",
      "Train Epoch: 0, mini-batch 11380 of 31, training loss: 0.562806\n",
      "Train Epoch: 0, mini-batch 11390 of 31, training loss: 0.562829\n",
      "Train Epoch: 0, mini-batch 11400 of 31, training loss: 0.562247\n",
      "Train Epoch: 0, mini-batch 11410 of 31, training loss: 0.559335\n",
      "Train Epoch: 0, mini-batch 11420 of 31, training loss: 0.557373\n",
      "Train Epoch: 0, mini-batch 11430 of 31, training loss: 0.563782\n",
      "Train Epoch: 0, mini-batch 11440 of 31, training loss: 0.565541\n",
      "Train Epoch: 0, mini-batch 11450 of 31, training loss: 0.563020\n",
      "Train Epoch: 0, mini-batch 11460 of 31, training loss: 0.565066\n",
      "Train Epoch: 0, mini-batch 11470 of 31, training loss: 0.563426\n",
      "Train Epoch: 0, mini-batch 11480 of 31, training loss: 0.565888\n",
      "Train Epoch: 0, mini-batch 11490 of 31, training loss: 0.561479\n",
      "Train Epoch: 0, mini-batch 11500 of 31, training loss: 0.561952\n",
      "Train Epoch: 0, mini-batch 11510 of 31, training loss: 0.561868\n",
      "Train Epoch: 0, mini-batch 11520 of 31, training loss: 0.558806\n",
      "Train Epoch: 0, mini-batch 11530 of 31, training loss: 0.560634\n",
      "Train Epoch: 0, mini-batch 11540 of 31, training loss: 0.561895\n",
      "Train Epoch: 0, mini-batch 11550 of 31, training loss: 0.564881\n",
      "Train Epoch: 0, mini-batch 11560 of 31, training loss: 0.561316\n",
      "Train Epoch: 0, mini-batch 11570 of 31, training loss: 0.563897\n",
      "Train Epoch: 0, mini-batch 11580 of 31, training loss: 0.564817\n",
      "Train Epoch: 0, mini-batch 11590 of 31, training loss: 0.563434\n",
      "Train Epoch: 0, mini-batch 11600 of 31, training loss: 0.564212\n",
      "Train Epoch: 0, mini-batch 11610 of 31, training loss: 0.562348\n",
      "Train Epoch: 0, mini-batch 11620 of 31, training loss: 0.563061\n",
      "Train Epoch: 0, mini-batch 11630 of 31, training loss: 0.561234\n",
      "Train Epoch: 0, mini-batch 11640 of 31, training loss: 0.562575\n",
      "Train Epoch: 0, mini-batch 11650 of 31, training loss: 0.561071\n",
      "Train Epoch: 0, mini-batch 11660 of 31, training loss: 0.561601\n",
      "Train Epoch: 0, mini-batch 11670 of 31, training loss: 0.562537\n",
      "Train Epoch: 0, mini-batch 11680 of 31, training loss: 0.561202\n",
      "Train Epoch: 0, mini-batch 11690 of 31, training loss: 0.563342\n",
      "Train Epoch: 0, mini-batch 11700 of 31, training loss: 0.562294\n",
      "Train Epoch: 0, mini-batch 11710 of 31, training loss: 0.564729\n",
      "Train Epoch: 0, mini-batch 11720 of 31, training loss: 0.562959\n",
      "Train Epoch: 0, mini-batch 11730 of 31, training loss: 0.562215\n",
      "Train Epoch: 0, mini-batch 11740 of 31, training loss: 0.560919\n",
      "Train Epoch: 0, mini-batch 11750 of 31, training loss: 0.563409\n",
      "Train Epoch: 0, mini-batch 11760 of 31, training loss: 0.562531\n",
      "Train Epoch: 0, mini-batch 11770 of 31, training loss: 0.562359\n",
      "Train Epoch: 0, mini-batch 11780 of 31, training loss: 0.563026\n",
      "Train Epoch: 0, mini-batch 11790 of 31, training loss: 0.560456\n",
      "Train Epoch: 0, mini-batch 11800 of 31, training loss: 0.563715\n",
      "Train Epoch: 0, mini-batch 11810 of 31, training loss: 0.562848\n",
      "Train Epoch: 0, mini-batch 11820 of 31, training loss: 0.562791\n",
      "Train Epoch: 0, mini-batch 11830 of 31, training loss: 0.562662\n",
      "Train Epoch: 0, mini-batch 11840 of 31, training loss: 0.562931\n",
      "Train Epoch: 0, mini-batch 11850 of 31, training loss: 0.562380\n",
      "Train Epoch: 0, mini-batch 11860 of 31, training loss: 0.562605\n",
      "Train Epoch: 0, mini-batch 11870 of 31, training loss: 0.561801\n",
      "Train Epoch: 0, mini-batch 11880 of 31, training loss: 0.561390\n",
      "Train Epoch: 0, mini-batch 11890 of 31, training loss: 0.560850\n",
      "Train Epoch: 0, mini-batch 11900 of 31, training loss: 0.563332\n",
      "Train Epoch: 0, mini-batch 11910 of 31, training loss: 0.562780\n",
      "Train Epoch: 0, mini-batch 11920 of 31, training loss: 0.562851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 11930 of 31, training loss: 0.561872\n",
      "Train Epoch: 0, mini-batch 11940 of 31, training loss: 0.562422\n",
      "Train Epoch: 0, mini-batch 11950 of 31, training loss: 0.561809\n",
      "Train Epoch: 0, mini-batch 11960 of 31, training loss: 0.562094\n",
      "Train Epoch: 0, mini-batch 11970 of 31, training loss: 0.562759\n",
      "Train Epoch: 0, mini-batch 11980 of 31, training loss: 0.561777\n",
      "Train Epoch: 0, mini-batch 11990 of 31, training loss: 0.566926\n",
      "Train Epoch: 0, mini-batch 12000 of 31, training loss: 0.559420\n",
      "Train Epoch: 0, mini-batch 12010 of 31, training loss: 0.564612\n",
      "Train Epoch: 0, mini-batch 12020 of 31, training loss: 0.562961\n",
      "Train Epoch: 0, mini-batch 12030 of 31, training loss: 0.562523\n",
      "Train Epoch: 0, mini-batch 12040 of 31, training loss: 0.562188\n",
      "Train Epoch: 0, mini-batch 12050 of 31, training loss: 0.561512\n",
      "Train Epoch: 0, mini-batch 12060 of 31, training loss: 0.563349\n",
      "Train Epoch: 0, mini-batch 12070 of 31, training loss: 0.561538\n",
      "Train Epoch: 0, mini-batch 12080 of 31, training loss: 0.562565\n",
      "Train Epoch: 0, mini-batch 12090 of 31, training loss: 0.562794\n",
      "Train Epoch: 0, mini-batch 12100 of 31, training loss: 0.560537\n",
      "Train Epoch: 0, mini-batch 12110 of 31, training loss: 0.562269\n",
      "Train Epoch: 0, mini-batch 12120 of 31, training loss: 0.564531\n",
      "Train Epoch: 0, mini-batch 12130 of 31, training loss: 0.561784\n",
      "Train Epoch: 0, mini-batch 12140 of 31, training loss: 0.565979\n",
      "Train Epoch: 0, mini-batch 12150 of 31, training loss: 0.561254\n",
      "Train Epoch: 0, mini-batch 12160 of 31, training loss: 0.564214\n",
      "Train Epoch: 0, mini-batch 12170 of 31, training loss: 0.561324\n",
      "Train Epoch: 0, mini-batch 12180 of 31, training loss: 0.561090\n",
      "Train Epoch: 0, mini-batch 12190 of 31, training loss: 0.559633\n",
      "Train Epoch: 0, mini-batch 12200 of 31, training loss: 0.563401\n",
      "Train Epoch: 0, mini-batch 12210 of 31, training loss: 0.561258\n",
      "Train Epoch: 0, mini-batch 12220 of 31, training loss: 0.563586\n",
      "Train Epoch: 0, mini-batch 12230 of 31, training loss: 0.563042\n",
      "Train Epoch: 0, mini-batch 12240 of 31, training loss: 0.563031\n",
      "Train Epoch: 0, mini-batch 12250 of 31, training loss: 0.563088\n",
      "Train Epoch: 0, mini-batch 12260 of 31, training loss: 0.563661\n",
      "Train Epoch: 0, mini-batch 12270 of 31, training loss: 0.561191\n",
      "Train Epoch: 0, mini-batch 12280 of 31, training loss: 0.562366\n",
      "Train Epoch: 0, mini-batch 12290 of 31, training loss: 0.562666\n",
      "Train Epoch: 0, mini-batch 12300 of 31, training loss: 0.564457\n",
      "Train Epoch: 0, mini-batch 12310 of 31, training loss: 0.560165\n",
      "Train Epoch: 0, mini-batch 12320 of 31, training loss: 0.562702\n",
      "Train Epoch: 0, mini-batch 12330 of 31, training loss: 0.564068\n",
      "Train Epoch: 0, mini-batch 12340 of 31, training loss: 0.563032\n",
      "Train Epoch: 0, mini-batch 12350 of 31, training loss: 0.562476\n",
      "Train Epoch: 0, mini-batch 12360 of 31, training loss: 0.561320\n",
      "Train Epoch: 0, mini-batch 12370 of 31, training loss: 0.562476\n",
      "Train Epoch: 0, mini-batch 12380 of 31, training loss: 0.562647\n",
      "Train Epoch: 0, mini-batch 12390 of 31, training loss: 0.562268\n",
      "Train Epoch: 0, mini-batch 12400 of 31, training loss: 0.563586\n",
      "Train Epoch: 0, mini-batch 12410 of 31, training loss: 0.562882\n",
      "Train Epoch: 0, mini-batch 12420 of 31, training loss: 0.560015\n",
      "Train Epoch: 0, mini-batch 12430 of 31, training loss: 0.561682\n",
      "Train Epoch: 0, mini-batch 12440 of 31, training loss: 0.563825\n",
      "Train Epoch: 0, mini-batch 12450 of 31, training loss: 0.563280\n",
      "Train Epoch: 0, mini-batch 12460 of 31, training loss: 0.558287\n",
      "Train Epoch: 0, mini-batch 12470 of 31, training loss: 0.562423\n",
      "Train Epoch: 0, mini-batch 12480 of 31, training loss: 0.561243\n",
      "Train Epoch: 0, mini-batch 12490 of 31, training loss: 0.559934\n",
      "Train Epoch: 0, mini-batch 12500 of 31, training loss: 0.562670\n",
      "Train Epoch: 0, mini-batch 12510 of 31, training loss: 0.561260\n",
      "Train Epoch: 0, mini-batch 12520 of 31, training loss: 0.560986\n",
      "Train Epoch: 0, mini-batch 12530 of 31, training loss: 0.560611\n",
      "Train Epoch: 0, mini-batch 12540 of 31, training loss: 0.562030\n",
      "Train Epoch: 0, mini-batch 12550 of 31, training loss: 0.562875\n",
      "Train Epoch: 0, mini-batch 12560 of 31, training loss: 0.561999\n",
      "Train Epoch: 0, mini-batch 12570 of 31, training loss: 0.562654\n",
      "Train Epoch: 0, mini-batch 12580 of 31, training loss: 0.562168\n",
      "Train Epoch: 0, mini-batch 12590 of 31, training loss: 0.562844\n",
      "Train Epoch: 0, mini-batch 12600 of 31, training loss: 0.562240\n",
      "Train Epoch: 0, mini-batch 12610 of 31, training loss: 0.562410\n",
      "Train Epoch: 0, mini-batch 12620 of 31, training loss: 0.562090\n",
      "Train Epoch: 0, mini-batch 12630 of 31, training loss: 0.562424\n",
      "Train Epoch: 0, mini-batch 12640 of 31, training loss: 0.562755\n",
      "Train Epoch: 0, mini-batch 12650 of 31, training loss: 0.562780\n",
      "Train Epoch: 0, mini-batch 12660 of 31, training loss: 0.562042\n",
      "Train Epoch: 0, mini-batch 12670 of 31, training loss: 0.561814\n",
      "Train Epoch: 0, mini-batch 12680 of 31, training loss: 0.562605\n",
      "Train Epoch: 0, mini-batch 12690 of 31, training loss: 0.563896\n",
      "Train Epoch: 0, mini-batch 12700 of 31, training loss: 0.562175\n",
      "Train Epoch: 0, mini-batch 12710 of 31, training loss: 0.560839\n",
      "Train Epoch: 0, mini-batch 12720 of 31, training loss: 0.561808\n",
      "Train Epoch: 0, mini-batch 12730 of 31, training loss: 0.562660\n",
      "Train Epoch: 0, mini-batch 12740 of 31, training loss: 0.561620\n",
      "Train Epoch: 0, mini-batch 12750 of 31, training loss: 0.565479\n",
      "Train Epoch: 0, mini-batch 12760 of 31, training loss: 0.561434\n",
      "Train Epoch: 0, mini-batch 12770 of 31, training loss: 0.561685\n",
      "Train Epoch: 0, mini-batch 12780 of 31, training loss: 0.562592\n",
      "Train Epoch: 0, mini-batch 12790 of 31, training loss: 0.561279\n",
      "Train Epoch: 0, mini-batch 12800 of 31, training loss: 0.562198\n",
      "Train Epoch: 0, mini-batch 12810 of 31, training loss: 0.561826\n",
      "Train Epoch: 0, mini-batch 12820 of 31, training loss: 0.563359\n",
      "Train Epoch: 0, mini-batch 12830 of 31, training loss: 0.561803\n",
      "Train Epoch: 0, mini-batch 12840 of 31, training loss: 0.562120\n",
      "Train Epoch: 0, mini-batch 12850 of 31, training loss: 0.562911\n",
      "Train Epoch: 0, mini-batch 12860 of 31, training loss: 0.562847\n",
      "Train Epoch: 0, mini-batch 12870 of 31, training loss: 0.563360\n",
      "Train Epoch: 0, mini-batch 12880 of 31, training loss: 0.561959\n",
      "Train Epoch: 0, mini-batch 12890 of 31, training loss: 0.564577\n",
      "Train Epoch: 0, mini-batch 12900 of 31, training loss: 0.563562\n",
      "Train Epoch: 0, mini-batch 12910 of 31, training loss: 0.562404\n",
      "Train Epoch: 0, mini-batch 12920 of 31, training loss: 0.561652\n",
      "Train Epoch: 0, mini-batch 12930 of 31, training loss: 0.562329\n",
      "Train Epoch: 0, mini-batch 12940 of 31, training loss: 0.563643\n",
      "Train Epoch: 0, mini-batch 12950 of 31, training loss: 0.562443\n",
      "Train Epoch: 0, mini-batch 12960 of 31, training loss: 0.563265\n",
      "Train Epoch: 0, mini-batch 12970 of 31, training loss: 0.560874\n",
      "Train Epoch: 0, mini-batch 12980 of 31, training loss: 0.561804\n",
      "Train Epoch: 0, mini-batch 12990 of 31, training loss: 0.561500\n",
      "Train Epoch: 0, mini-batch 13000 of 31, training loss: 0.561348\n",
      "Train Epoch: 0, mini-batch 13010 of 31, training loss: 0.561980\n",
      "Train Epoch: 0, mini-batch 13020 of 31, training loss: 0.562263\n",
      "Train Epoch: 0, mini-batch 13030 of 31, training loss: 0.562778\n",
      "Train Epoch: 0, mini-batch 13040 of 31, training loss: 0.562103\n",
      "Train Epoch: 0, mini-batch 13050 of 31, training loss: 0.559622\n",
      "Train Epoch: 0, mini-batch 13060 of 31, training loss: 0.561353\n",
      "Train Epoch: 0, mini-batch 13070 of 31, training loss: 0.561749\n",
      "Train Epoch: 0, mini-batch 13080 of 31, training loss: 0.559548\n",
      "Train Epoch: 0, mini-batch 13090 of 31, training loss: 0.562037\n",
      "Train Epoch: 0, mini-batch 13100 of 31, training loss: 0.562121\n",
      "Train Epoch: 0, mini-batch 13110 of 31, training loss: 0.562520\n",
      "Train Epoch: 0, mini-batch 13120 of 31, training loss: 0.562807\n",
      "Train Epoch: 0, mini-batch 13130 of 31, training loss: 0.563211\n",
      "Train Epoch: 0, mini-batch 13140 of 31, training loss: 0.561913\n",
      "Train Epoch: 0, mini-batch 13150 of 31, training loss: 0.562227\n",
      "Train Epoch: 0, mini-batch 13160 of 31, training loss: 0.561010\n",
      "Train Epoch: 0, mini-batch 13170 of 31, training loss: 0.561288\n",
      "Train Epoch: 0, mini-batch 13180 of 31, training loss: 0.561619\n",
      "Train Epoch: 0, mini-batch 13190 of 31, training loss: 0.564007\n",
      "Train Epoch: 0, mini-batch 13200 of 31, training loss: 0.562503\n",
      "Train Epoch: 0, mini-batch 13210 of 31, training loss: 0.562013\n",
      "Train Epoch: 0, mini-batch 13220 of 31, training loss: 0.562329\n",
      "Train Epoch: 0, mini-batch 13230 of 31, training loss: 0.561411\n",
      "Train Epoch: 0, mini-batch 13240 of 31, training loss: 0.561419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 13250 of 31, training loss: 0.562617\n",
      "Train Epoch: 0, mini-batch 13260 of 31, training loss: 0.561796\n",
      "Train Epoch: 0, mini-batch 13270 of 31, training loss: 0.562802\n",
      "Train Epoch: 0, mini-batch 13280 of 31, training loss: 0.560153\n",
      "Train Epoch: 0, mini-batch 13290 of 31, training loss: 0.563558\n",
      "Train Epoch: 0, mini-batch 13300 of 31, training loss: 0.564732\n",
      "Train Epoch: 0, mini-batch 13310 of 31, training loss: 0.563825\n",
      "Train Epoch: 0, mini-batch 13320 of 31, training loss: 0.562513\n",
      "Train Epoch: 0, mini-batch 13330 of 31, training loss: 0.562475\n",
      "Train Epoch: 0, mini-batch 13340 of 31, training loss: 0.563486\n",
      "Train Epoch: 0, mini-batch 13350 of 31, training loss: 0.562467\n",
      "Train Epoch: 0, mini-batch 13360 of 31, training loss: 0.561285\n",
      "Train Epoch: 0, mini-batch 13370 of 31, training loss: 0.562154\n",
      "Train Epoch: 0, mini-batch 13380 of 31, training loss: 0.562795\n",
      "Train Epoch: 0, mini-batch 13390 of 31, training loss: 0.562404\n",
      "Train Epoch: 0, mini-batch 13400 of 31, training loss: 0.561063\n",
      "Train Epoch: 0, mini-batch 13410 of 31, training loss: 0.563196\n",
      "Train Epoch: 0, mini-batch 13420 of 31, training loss: 0.562116\n",
      "Train Epoch: 0, mini-batch 13430 of 31, training loss: 0.559832\n",
      "Train Epoch: 0, mini-batch 13440 of 31, training loss: 0.560639\n",
      "Train Epoch: 0, mini-batch 13450 of 31, training loss: 0.564770\n",
      "Train Epoch: 0, mini-batch 13460 of 31, training loss: 0.563698\n",
      "Train Epoch: 0, mini-batch 13470 of 31, training loss: 0.561888\n",
      "Train Epoch: 0, mini-batch 13480 of 31, training loss: 0.564304\n",
      "Train Epoch: 0, mini-batch 13490 of 31, training loss: 0.562162\n",
      "Train Epoch: 0, mini-batch 13500 of 31, training loss: 0.563373\n",
      "Train Epoch: 0, mini-batch 13510 of 31, training loss: 0.563494\n",
      "Train Epoch: 0, mini-batch 13520 of 31, training loss: 0.560985\n",
      "Train Epoch: 0, mini-batch 13530 of 31, training loss: 0.563967\n",
      "Train Epoch: 0, mini-batch 13540 of 31, training loss: 0.562394\n",
      "Train Epoch: 0, mini-batch 13550 of 31, training loss: 0.565297\n",
      "Train Epoch: 0, mini-batch 13560 of 31, training loss: 0.562397\n",
      "Train Epoch: 0, mini-batch 13570 of 31, training loss: 0.562003\n",
      "Train Epoch: 0, mini-batch 13580 of 31, training loss: 0.562680\n",
      "Train Epoch: 0, mini-batch 13590 of 31, training loss: 0.561877\n",
      "Train Epoch: 0, mini-batch 13600 of 31, training loss: 0.562671\n",
      "Train Epoch: 0, mini-batch 13610 of 31, training loss: 0.564249\n",
      "Train Epoch: 0, mini-batch 13620 of 31, training loss: 0.562657\n",
      "Train Epoch: 0, mini-batch 13630 of 31, training loss: 0.561927\n",
      "Train Epoch: 0, mini-batch 13640 of 31, training loss: 0.562576\n",
      "Train Epoch: 0, mini-batch 13650 of 31, training loss: 0.562228\n",
      "Train Epoch: 0, mini-batch 13660 of 31, training loss: 0.562128\n",
      "Train Epoch: 0, mini-batch 13670 of 31, training loss: 0.562527\n",
      "Train Epoch: 0, mini-batch 13680 of 31, training loss: 0.562662\n",
      "Train Epoch: 0, mini-batch 13690 of 31, training loss: 0.562477\n",
      "Train Epoch: 0, mini-batch 13700 of 31, training loss: 0.562908\n",
      "Train Epoch: 0, mini-batch 13710 of 31, training loss: 0.561780\n",
      "Train Epoch: 0, mini-batch 13720 of 31, training loss: 0.561404\n",
      "Train Epoch: 0, mini-batch 13730 of 31, training loss: 0.562371\n",
      "Train Epoch: 0, mini-batch 13740 of 31, training loss: 0.564836\n",
      "Train Epoch: 0, mini-batch 13750 of 31, training loss: 0.562078\n",
      "Train Epoch: 0, mini-batch 13760 of 31, training loss: 0.563136\n",
      "Train Epoch: 0, mini-batch 13770 of 31, training loss: 0.562431\n",
      "Train Epoch: 0, mini-batch 13780 of 31, training loss: 0.562233\n",
      "Train Epoch: 0, mini-batch 13790 of 31, training loss: 0.562710\n",
      "Train Epoch: 0, mini-batch 13800 of 31, training loss: 0.562658\n",
      "Train Epoch: 0, mini-batch 13810 of 31, training loss: 0.562157\n",
      "Train Epoch: 0, mini-batch 13820 of 31, training loss: 0.561843\n",
      "Train Epoch: 0, mini-batch 13830 of 31, training loss: 0.562029\n",
      "Train Epoch: 0, mini-batch 13840 of 31, training loss: 0.564161\n",
      "Train Epoch: 0, mini-batch 13850 of 31, training loss: 0.563803\n",
      "Train Epoch: 0, mini-batch 13860 of 31, training loss: 0.562599\n",
      "Train Epoch: 0, mini-batch 13870 of 31, training loss: 0.563028\n",
      "Train Epoch: 0, mini-batch 13880 of 31, training loss: 0.561542\n",
      "Train Epoch: 0, mini-batch 13890 of 31, training loss: 0.561178\n",
      "Train Epoch: 0, mini-batch 13900 of 31, training loss: 0.562124\n",
      "Train Epoch: 0, mini-batch 13910 of 31, training loss: 0.561164\n",
      "Train Epoch: 0, mini-batch 13920 of 31, training loss: 0.560660\n",
      "Train Epoch: 0, mini-batch 13930 of 31, training loss: 0.560051\n",
      "Train Epoch: 0, mini-batch 13940 of 31, training loss: 0.564680\n",
      "Train Epoch: 0, mini-batch 13950 of 31, training loss: 0.560251\n",
      "Train Epoch: 0, mini-batch 13960 of 31, training loss: 0.561311\n",
      "Train Epoch: 0, mini-batch 13970 of 31, training loss: 0.563684\n",
      "Train Epoch: 0, mini-batch 13980 of 31, training loss: 0.563282\n",
      "Train Epoch: 0, mini-batch 13990 of 31, training loss: 0.563640\n",
      "Train Epoch: 0, mini-batch 14000 of 31, training loss: 0.561964\n",
      "Train Epoch: 0, mini-batch 14010 of 31, training loss: 0.561498\n",
      "Train Epoch: 0, mini-batch 14020 of 31, training loss: 0.562783\n",
      "Train Epoch: 0, mini-batch 14030 of 31, training loss: 0.562150\n",
      "Train Epoch: 0, mini-batch 14040 of 31, training loss: 0.561510\n",
      "Train Epoch: 0, mini-batch 14050 of 31, training loss: 0.563522\n",
      "Train Epoch: 0, mini-batch 14060 of 31, training loss: 0.561317\n",
      "Train Epoch: 0, mini-batch 14070 of 31, training loss: 0.562338\n",
      "Train Epoch: 0, mini-batch 14080 of 31, training loss: 0.562785\n",
      "Train Epoch: 0, mini-batch 14090 of 31, training loss: 0.561880\n",
      "Train Epoch: 0, mini-batch 14100 of 31, training loss: 0.563825\n",
      "Train Epoch: 0, mini-batch 14110 of 31, training loss: 0.562246\n",
      "Train Epoch: 0, mini-batch 14120 of 31, training loss: 0.559217\n",
      "Train Epoch: 0, mini-batch 14130 of 31, training loss: 0.563833\n",
      "Train Epoch: 0, mini-batch 14140 of 31, training loss: 0.565036\n",
      "Train Epoch: 0, mini-batch 14150 of 31, training loss: 0.563501\n",
      "Train Epoch: 0, mini-batch 14160 of 31, training loss: 0.562624\n",
      "Train Epoch: 0, mini-batch 14170 of 31, training loss: 0.560060\n",
      "Train Epoch: 0, mini-batch 14180 of 31, training loss: 0.561650\n",
      "Train Epoch: 0, mini-batch 14190 of 31, training loss: 0.564001\n",
      "Train Epoch: 0, mini-batch 14200 of 31, training loss: 0.562558\n",
      "Train Epoch: 0, mini-batch 14210 of 31, training loss: 0.563118\n",
      "Train Epoch: 0, mini-batch 14220 of 31, training loss: 0.560461\n",
      "Train Epoch: 0, mini-batch 14230 of 31, training loss: 0.562694\n",
      "Train Epoch: 0, mini-batch 14240 of 31, training loss: 0.561213\n",
      "Train Epoch: 0, mini-batch 14250 of 31, training loss: 0.563377\n",
      "Train Epoch: 0, mini-batch 14260 of 31, training loss: 0.563820\n",
      "Train Epoch: 0, mini-batch 14270 of 31, training loss: 0.564408\n",
      "Train Epoch: 0, mini-batch 14280 of 31, training loss: 0.561806\n",
      "Train Epoch: 0, mini-batch 14290 of 31, training loss: 0.563420\n",
      "Train Epoch: 0, mini-batch 14300 of 31, training loss: 0.562736\n",
      "Train Epoch: 0, mini-batch 14310 of 31, training loss: 0.562254\n",
      "Train Epoch: 0, mini-batch 14320 of 31, training loss: 0.561632\n",
      "Train Epoch: 0, mini-batch 14330 of 31, training loss: 0.561606\n",
      "Train Epoch: 0, mini-batch 14340 of 31, training loss: 0.561432\n",
      "Train Epoch: 0, mini-batch 14350 of 31, training loss: 0.562522\n",
      "Train Epoch: 0, mini-batch 14360 of 31, training loss: 0.562108\n",
      "Train Epoch: 0, mini-batch 14370 of 31, training loss: 0.560644\n",
      "Train Epoch: 0, mini-batch 14380 of 31, training loss: 0.562190\n",
      "Train Epoch: 0, mini-batch 14390 of 31, training loss: 0.561686\n",
      "Train Epoch: 0, mini-batch 14400 of 31, training loss: 0.562642\n",
      "Train Epoch: 0, mini-batch 14410 of 31, training loss: 0.563170\n",
      "Train Epoch: 0, mini-batch 14420 of 31, training loss: 0.561365\n",
      "Train Epoch: 0, mini-batch 14430 of 31, training loss: 0.562321\n",
      "Train Epoch: 0, mini-batch 14440 of 31, training loss: 0.564224\n",
      "Train Epoch: 0, mini-batch 14450 of 31, training loss: 0.562108\n",
      "Train Epoch: 0, mini-batch 14460 of 31, training loss: 0.562000\n",
      "Train Epoch: 0, mini-batch 14470 of 31, training loss: 0.564260\n",
      "Train Epoch: 0, mini-batch 14480 of 31, training loss: 0.563623\n",
      "Train Epoch: 0, mini-batch 14490 of 31, training loss: 0.564740\n",
      "Train Epoch: 0, mini-batch 14500 of 31, training loss: 0.562425\n",
      "Train Epoch: 0, mini-batch 14510 of 31, training loss: 0.561225\n",
      "Train Epoch: 0, mini-batch 14520 of 31, training loss: 0.561967\n",
      "Train Epoch: 0, mini-batch 14530 of 31, training loss: 0.562136\n",
      "Train Epoch: 0, mini-batch 14540 of 31, training loss: 0.563070\n",
      "Train Epoch: 0, mini-batch 14550 of 31, training loss: 0.562446\n",
      "Train Epoch: 0, mini-batch 14560 of 31, training loss: 0.560327\n",
      "Train Epoch: 0, mini-batch 14570 of 31, training loss: 0.560015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 14580 of 31, training loss: 0.561915\n",
      "Train Epoch: 0, mini-batch 14590 of 31, training loss: 0.561720\n",
      "Train Epoch: 0, mini-batch 14600 of 31, training loss: 0.561952\n",
      "Train Epoch: 0, mini-batch 14610 of 31, training loss: 0.562340\n",
      "Train Epoch: 0, mini-batch 14620 of 31, training loss: 0.560088\n",
      "Train Epoch: 0, mini-batch 14630 of 31, training loss: 0.562531\n",
      "Train Epoch: 0, mini-batch 14640 of 31, training loss: 0.562195\n",
      "Train Epoch: 0, mini-batch 14650 of 31, training loss: 0.561496\n",
      "Train Epoch: 0, mini-batch 14660 of 31, training loss: 0.562059\n",
      "Train Epoch: 0, mini-batch 14670 of 31, training loss: 0.562352\n",
      "Train Epoch: 0, mini-batch 14680 of 31, training loss: 0.562858\n",
      "Train Epoch: 0, mini-batch 14690 of 31, training loss: 0.561796\n",
      "Train Epoch: 0, mini-batch 14700 of 31, training loss: 0.563050\n",
      "Train Epoch: 0, mini-batch 14710 of 31, training loss: 0.562737\n",
      "Train Epoch: 0, mini-batch 14720 of 31, training loss: 0.562474\n",
      "Train Epoch: 0, mini-batch 14730 of 31, training loss: 0.562663\n",
      "Train Epoch: 0, mini-batch 14740 of 31, training loss: 0.561838\n",
      "Train Epoch: 0, mini-batch 14750 of 31, training loss: 0.563797\n",
      "Train Epoch: 0, mini-batch 14760 of 31, training loss: 0.561986\n",
      "Train Epoch: 0, mini-batch 14770 of 31, training loss: 0.562487\n",
      "Train Epoch: 0, mini-batch 14780 of 31, training loss: 0.562015\n",
      "Train Epoch: 0, mini-batch 14790 of 31, training loss: 0.562209\n",
      "Train Epoch: 0, mini-batch 14800 of 31, training loss: 0.562515\n",
      "Train Epoch: 0, mini-batch 14810 of 31, training loss: 0.561201\n",
      "Train Epoch: 0, mini-batch 14820 of 31, training loss: 0.564689\n",
      "Train Epoch: 0, mini-batch 14830 of 31, training loss: 0.563061\n",
      "Train Epoch: 0, mini-batch 14840 of 31, training loss: 0.563427\n",
      "Train Epoch: 0, mini-batch 14850 of 31, training loss: 0.562590\n",
      "Train Epoch: 0, mini-batch 14860 of 31, training loss: 0.562069\n",
      "Train Epoch: 0, mini-batch 14870 of 31, training loss: 0.562769\n",
      "Train Epoch: 0, mini-batch 14880 of 31, training loss: 0.561813\n",
      "Train Epoch: 0, mini-batch 14890 of 31, training loss: 0.562505\n",
      "Train Epoch: 0, mini-batch 14900 of 31, training loss: 0.563396\n",
      "Train Epoch: 0, mini-batch 14910 of 31, training loss: 0.563315\n",
      "Train Epoch: 0, mini-batch 14920 of 31, training loss: 0.562837\n",
      "Train Epoch: 0, mini-batch 14930 of 31, training loss: 0.564200\n",
      "Train Epoch: 0, mini-batch 14940 of 31, training loss: 0.561620\n",
      "Train Epoch: 0, mini-batch 14950 of 31, training loss: 0.564080\n",
      "Train Epoch: 0, mini-batch 14960 of 31, training loss: 0.560910\n",
      "Train Epoch: 0, mini-batch 14970 of 31, training loss: 0.562449\n",
      "Train Epoch: 0, mini-batch 14980 of 31, training loss: 0.562114\n",
      "Train Epoch: 0, mini-batch 14990 of 31, training loss: 0.562740\n",
      "Train Epoch: 0, mini-batch 15000 of 31, training loss: 0.562355\n",
      "Train Epoch: 0, mini-batch 15010 of 31, training loss: 0.562750\n",
      "Train Epoch: 0, mini-batch 15020 of 31, training loss: 0.562336\n",
      "Train Epoch: 0, mini-batch 15030 of 31, training loss: 0.563746\n",
      "Train Epoch: 0, mini-batch 15040 of 31, training loss: 0.563554\n",
      "Train Epoch: 0, mini-batch 15050 of 31, training loss: 0.562545\n",
      "Train Epoch: 0, mini-batch 15060 of 31, training loss: 0.562249\n",
      "Train Epoch: 0, mini-batch 15070 of 31, training loss: 0.561833\n",
      "Train Epoch: 0, mini-batch 15080 of 31, training loss: 0.563231\n",
      "Train Epoch: 0, mini-batch 15090 of 31, training loss: 0.562638\n",
      "Train Epoch: 0, mini-batch 15100 of 31, training loss: 0.562909\n",
      "Train Epoch: 0, mini-batch 15110 of 31, training loss: 0.562513\n",
      "Train Epoch: 0, mini-batch 15120 of 31, training loss: 0.561710\n",
      "Train Epoch: 0, mini-batch 15130 of 31, training loss: 0.563283\n",
      "Train Epoch: 0, mini-batch 15140 of 31, training loss: 0.561675\n",
      "Train Epoch: 0, mini-batch 15150 of 31, training loss: 0.562012\n",
      "Train Epoch: 0, mini-batch 15160 of 31, training loss: 0.560164\n",
      "Train Epoch: 0, mini-batch 15170 of 31, training loss: 0.562002\n",
      "Train Epoch: 0, mini-batch 15180 of 31, training loss: 0.561498\n",
      "Train Epoch: 0, mini-batch 15190 of 31, training loss: 0.562240\n",
      "Train Epoch: 0, mini-batch 15200 of 31, training loss: 0.563005\n",
      "Train Epoch: 0, mini-batch 15210 of 31, training loss: 0.562329\n",
      "Train Epoch: 0, mini-batch 15220 of 31, training loss: 0.562575\n",
      "Train Epoch: 0, mini-batch 15230 of 31, training loss: 0.560654\n",
      "Train Epoch: 0, mini-batch 15240 of 31, training loss: 0.562226\n",
      "Train Epoch: 0, mini-batch 15250 of 31, training loss: 0.561718\n",
      "Train Epoch: 0, mini-batch 15260 of 31, training loss: 0.562194\n",
      "Train Epoch: 0, mini-batch 15270 of 31, training loss: 0.561481\n",
      "Train Epoch: 0, mini-batch 15280 of 31, training loss: 0.563527\n",
      "Train Epoch: 0, mini-batch 15290 of 31, training loss: 0.563054\n",
      "Train Epoch: 0, mini-batch 15300 of 31, training loss: 0.563493\n",
      "Train Epoch: 0, mini-batch 15310 of 31, training loss: 0.562892\n",
      "Train Epoch: 0, mini-batch 15320 of 31, training loss: 0.560762\n",
      "Train Epoch: 0, mini-batch 15330 of 31, training loss: 0.561045\n",
      "Train Epoch: 0, mini-batch 15340 of 31, training loss: 0.563037\n",
      "Train Epoch: 0, mini-batch 15350 of 31, training loss: 0.562268\n",
      "Train Epoch: 0, mini-batch 15360 of 31, training loss: 0.562762\n",
      "Train Epoch: 0, mini-batch 15370 of 31, training loss: 0.561362\n",
      "Train Epoch: 0, mini-batch 15380 of 31, training loss: 0.562401\n",
      "Train Epoch: 0, mini-batch 15390 of 31, training loss: 0.561822\n",
      "Train Epoch: 0, mini-batch 15400 of 31, training loss: 0.565270\n",
      "Train Epoch: 0, mini-batch 15410 of 31, training loss: 0.560313\n",
      "Train Epoch: 0, mini-batch 15420 of 31, training loss: 0.563436\n",
      "Train Epoch: 0, mini-batch 15430 of 31, training loss: 0.562801\n",
      "Train Epoch: 0, mini-batch 15440 of 31, training loss: 0.560912\n",
      "Train Epoch: 0, mini-batch 15450 of 31, training loss: 0.564117\n",
      "Train Epoch: 0, mini-batch 15460 of 31, training loss: 0.560905\n",
      "Train Epoch: 0, mini-batch 15470 of 31, training loss: 0.561141\n",
      "Train Epoch: 0, mini-batch 15480 of 31, training loss: 0.558710\n",
      "Train Epoch: 0, mini-batch 15490 of 31, training loss: 0.562436\n",
      "Train Epoch: 0, mini-batch 15500 of 31, training loss: 0.562574\n",
      "Train Epoch: 0, mini-batch 15510 of 31, training loss: 0.564837\n",
      "Train Epoch: 0, mini-batch 15520 of 31, training loss: 0.563918\n",
      "Train Epoch: 0, mini-batch 15530 of 31, training loss: 0.563401\n",
      "Train Epoch: 0, mini-batch 15540 of 31, training loss: 0.563146\n",
      "Train Epoch: 0, mini-batch 15550 of 31, training loss: 0.560336\n",
      "Train Epoch: 0, mini-batch 15560 of 31, training loss: 0.562486\n",
      "Train Epoch: 0, mini-batch 15570 of 31, training loss: 0.564132\n",
      "Train Epoch: 0, mini-batch 15580 of 31, training loss: 0.562586\n",
      "Train Epoch: 0, mini-batch 15590 of 31, training loss: 0.561781\n",
      "Train Epoch: 0, mini-batch 15600 of 31, training loss: 0.561729\n",
      "Train Epoch: 0, mini-batch 15610 of 31, training loss: 0.561307\n",
      "Train Epoch: 0, mini-batch 15620 of 31, training loss: 0.564722\n",
      "Train Epoch: 0, mini-batch 15630 of 31, training loss: 0.563661\n",
      "Train Epoch: 0, mini-batch 15640 of 31, training loss: 0.563353\n",
      "Train Epoch: 0, mini-batch 15650 of 31, training loss: 0.562928\n",
      "Train Epoch: 0, mini-batch 15660 of 31, training loss: 0.560300\n",
      "Train Epoch: 0, mini-batch 15670 of 31, training loss: 0.562643\n",
      "Train Epoch: 0, mini-batch 15680 of 31, training loss: 0.562409\n",
      "Train Epoch: 0, mini-batch 15690 of 31, training loss: 0.562614\n",
      "Train Epoch: 0, mini-batch 15700 of 31, training loss: 0.561924\n",
      "Train Epoch: 0, mini-batch 15710 of 31, training loss: 0.560133\n",
      "Train Epoch: 0, mini-batch 15720 of 31, training loss: 0.563072\n",
      "Train Epoch: 0, mini-batch 15730 of 31, training loss: 0.560407\n",
      "Train Epoch: 0, mini-batch 15740 of 31, training loss: 0.562477\n",
      "Train Epoch: 0, mini-batch 15750 of 31, training loss: 0.563922\n",
      "Train Epoch: 0, mini-batch 15760 of 31, training loss: 0.559797\n",
      "Train Epoch: 0, mini-batch 15770 of 31, training loss: 0.562658\n",
      "Train Epoch: 0, mini-batch 15780 of 31, training loss: 0.561203\n",
      "Train Epoch: 0, mini-batch 15790 of 31, training loss: 0.562725\n",
      "Train Epoch: 0, mini-batch 15800 of 31, training loss: 0.561455\n",
      "Train Epoch: 0, mini-batch 15810 of 31, training loss: 0.560194\n",
      "Train Epoch: 0, mini-batch 15820 of 31, training loss: 0.563381\n",
      "Train Epoch: 0, mini-batch 15830 of 31, training loss: 0.561763\n",
      "Train Epoch: 0, mini-batch 15840 of 31, training loss: 0.562304\n",
      "Train Epoch: 0, mini-batch 15850 of 31, training loss: 0.564073\n",
      "Train Epoch: 0, mini-batch 15860 of 31, training loss: 0.562209\n",
      "Train Epoch: 0, mini-batch 15870 of 31, training loss: 0.561966\n",
      "Train Epoch: 0, mini-batch 15880 of 31, training loss: 0.566841\n",
      "Train Epoch: 0, mini-batch 15890 of 31, training loss: 0.559992\n",
      "Train Epoch: 0, mini-batch 15900 of 31, training loss: 0.564218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 15910 of 31, training loss: 0.563762\n",
      "Train Epoch: 0, mini-batch 15920 of 31, training loss: 0.564815\n",
      "Train Epoch: 0, mini-batch 15930 of 31, training loss: 0.560687\n",
      "Train Epoch: 0, mini-batch 15940 of 31, training loss: 0.563339\n",
      "Train Epoch: 0, mini-batch 15950 of 31, training loss: 0.562106\n",
      "Train Epoch: 0, mini-batch 15960 of 31, training loss: 0.560875\n",
      "Train Epoch: 0, mini-batch 15970 of 31, training loss: 0.561777\n",
      "Train Epoch: 0, mini-batch 15980 of 31, training loss: 0.562904\n",
      "Train Epoch: 0, mini-batch 15990 of 31, training loss: 0.564851\n",
      "Train Epoch: 0, mini-batch 16000 of 31, training loss: 0.561656\n",
      "Train Epoch: 0, mini-batch 16010 of 31, training loss: 0.561866\n",
      "Train Epoch: 0, mini-batch 16020 of 31, training loss: 0.563277\n",
      "Train Epoch: 0, mini-batch 16030 of 31, training loss: 0.564552\n",
      "Train Epoch: 0, mini-batch 16040 of 31, training loss: 0.561850\n",
      "Train Epoch: 0, mini-batch 16050 of 31, training loss: 0.562440\n",
      "Train Epoch: 0, mini-batch 16060 of 31, training loss: 0.561664\n",
      "Train Epoch: 0, mini-batch 16070 of 31, training loss: 0.562839\n",
      "Train Epoch: 0, mini-batch 16080 of 31, training loss: 0.562761\n",
      "Train Epoch: 0, mini-batch 16090 of 31, training loss: 0.562588\n",
      "Train Epoch: 0, mini-batch 16100 of 31, training loss: 0.561192\n",
      "Train Epoch: 0, mini-batch 16110 of 31, training loss: 0.562636\n",
      "Train Epoch: 0, mini-batch 16120 of 31, training loss: 0.561832\n",
      "Train Epoch: 0, mini-batch 16130 of 31, training loss: 0.562604\n",
      "Train Epoch: 0, mini-batch 16140 of 31, training loss: 0.563154\n",
      "Train Epoch: 0, mini-batch 16150 of 31, training loss: 0.562579\n",
      "Train Epoch: 0, mini-batch 16160 of 31, training loss: 0.563205\n",
      "Train Epoch: 0, mini-batch 16170 of 31, training loss: 0.563243\n",
      "Train Epoch: 0, mini-batch 16180 of 31, training loss: 0.562498\n",
      "Train Epoch: 0, mini-batch 16190 of 31, training loss: 0.561087\n",
      "Train Epoch: 0, mini-batch 16200 of 31, training loss: 0.561453\n",
      "Train Epoch: 0, mini-batch 16210 of 31, training loss: 0.563545\n",
      "Train Epoch: 0, mini-batch 16220 of 31, training loss: 0.564762\n",
      "Train Epoch: 0, mini-batch 16230 of 31, training loss: 0.563686\n",
      "Train Epoch: 0, mini-batch 16240 of 31, training loss: 0.562604\n",
      "Train Epoch: 0, mini-batch 16250 of 31, training loss: 0.564932\n",
      "Train Epoch: 0, mini-batch 16260 of 31, training loss: 0.563258\n",
      "Train Epoch: 0, mini-batch 16270 of 31, training loss: 0.562839\n",
      "Train Epoch: 0, mini-batch 16280 of 31, training loss: 0.562558\n",
      "Train Epoch: 0, mini-batch 16290 of 31, training loss: 0.562965\n",
      "Train Epoch: 0, mini-batch 16300 of 31, training loss: 0.561784\n",
      "Train Epoch: 0, mini-batch 16310 of 31, training loss: 0.562074\n",
      "Train Epoch: 0, mini-batch 16320 of 31, training loss: 0.562745\n",
      "Train Epoch: 0, mini-batch 16330 of 31, training loss: 0.562294\n",
      "Train Epoch: 0, mini-batch 16340 of 31, training loss: 0.562257\n",
      "Train Epoch: 0, mini-batch 16350 of 31, training loss: 0.561837\n",
      "Train Epoch: 0, mini-batch 16360 of 31, training loss: 0.563812\n",
      "Train Epoch: 0, mini-batch 16370 of 31, training loss: 0.563166\n",
      "Train Epoch: 0, mini-batch 16380 of 31, training loss: 0.562820\n",
      "Train Epoch: 0, mini-batch 16390 of 31, training loss: 0.563350\n",
      "Train Epoch: 0, mini-batch 16400 of 31, training loss: 0.562207\n",
      "Train Epoch: 0, mini-batch 16410 of 31, training loss: 0.562336\n",
      "Train Epoch: 0, mini-batch 16420 of 31, training loss: 0.562559\n",
      "Train Epoch: 0, mini-batch 16430 of 31, training loss: 0.563020\n",
      "Train Epoch: 0, mini-batch 16440 of 31, training loss: 0.562534\n",
      "Train Epoch: 0, mini-batch 16450 of 31, training loss: 0.562111\n",
      "Train Epoch: 0, mini-batch 16460 of 31, training loss: 0.561466\n",
      "Train Epoch: 0, mini-batch 16470 of 31, training loss: 0.561847\n",
      "Train Epoch: 0, mini-batch 16480 of 31, training loss: 0.561828\n",
      "Train Epoch: 0, mini-batch 16490 of 31, training loss: 0.562389\n",
      "Train Epoch: 0, mini-batch 16500 of 31, training loss: 0.561719\n",
      "Train Epoch: 0, mini-batch 16510 of 31, training loss: 0.563082\n",
      "Train Epoch: 0, mini-batch 16520 of 31, training loss: 0.562274\n",
      "Train Epoch: 0, mini-batch 16530 of 31, training loss: 0.561428\n",
      "Train Epoch: 0, mini-batch 16540 of 31, training loss: 0.562238\n",
      "Train Epoch: 0, mini-batch 16550 of 31, training loss: 0.563446\n",
      "Train Epoch: 0, mini-batch 16560 of 31, training loss: 0.562053\n",
      "Train Epoch: 0, mini-batch 16570 of 31, training loss: 0.559910\n",
      "Train Epoch: 0, mini-batch 16580 of 31, training loss: 0.564494\n",
      "Train Epoch: 0, mini-batch 16590 of 31, training loss: 0.561370\n",
      "Train Epoch: 0, mini-batch 16600 of 31, training loss: 0.562297\n",
      "Train Epoch: 0, mini-batch 16610 of 31, training loss: 0.563025\n",
      "Train Epoch: 0, mini-batch 16620 of 31, training loss: 0.562669\n",
      "Train Epoch: 0, mini-batch 16630 of 31, training loss: 0.563756\n",
      "Train Epoch: 0, mini-batch 16640 of 31, training loss: 0.563727\n",
      "Train Epoch: 0, mini-batch 16650 of 31, training loss: 0.561687\n",
      "Train Epoch: 0, mini-batch 16660 of 31, training loss: 0.561586\n",
      "Train Epoch: 0, mini-batch 16670 of 31, training loss: 0.562698\n",
      "Train Epoch: 0, mini-batch 16680 of 31, training loss: 0.562875\n",
      "Train Epoch: 0, mini-batch 16690 of 31, training loss: 0.563757\n",
      "Train Epoch: 0, mini-batch 16700 of 31, training loss: 0.563082\n",
      "Train Epoch: 0, mini-batch 16710 of 31, training loss: 0.562305\n",
      "Train Epoch: 0, mini-batch 16720 of 31, training loss: 0.561452\n",
      "Train Epoch: 0, mini-batch 16730 of 31, training loss: 0.563038\n",
      "Train Epoch: 0, mini-batch 16740 of 31, training loss: 0.561956\n",
      "Train Epoch: 0, mini-batch 16750 of 31, training loss: 0.563030\n",
      "Train Epoch: 0, mini-batch 16760 of 31, training loss: 0.561511\n",
      "Train Epoch: 0, mini-batch 16770 of 31, training loss: 0.563641\n",
      "Train Epoch: 0, mini-batch 16780 of 31, training loss: 0.562865\n",
      "Train Epoch: 0, mini-batch 16790 of 31, training loss: 0.561671\n",
      "Train Epoch: 0, mini-batch 16800 of 31, training loss: 0.562569\n",
      "Train Epoch: 0, mini-batch 16810 of 31, training loss: 0.561574\n",
      "Train Epoch: 0, mini-batch 16820 of 31, training loss: 0.562253\n",
      "Train Epoch: 0, mini-batch 16830 of 31, training loss: 0.561233\n",
      "Train Epoch: 0, mini-batch 16840 of 31, training loss: 0.561379\n",
      "Train Epoch: 0, mini-batch 16850 of 31, training loss: 0.563062\n",
      "Train Epoch: 0, mini-batch 16860 of 31, training loss: 0.561819\n",
      "Train Epoch: 0, mini-batch 16870 of 31, training loss: 0.564402\n",
      "Train Epoch: 0, mini-batch 16880 of 31, training loss: 0.562006\n",
      "Train Epoch: 0, mini-batch 16890 of 31, training loss: 0.561874\n",
      "Train Epoch: 0, mini-batch 16900 of 31, training loss: 0.561900\n",
      "Train Epoch: 0, mini-batch 16910 of 31, training loss: 0.560229\n",
      "Train Epoch: 0, mini-batch 16920 of 31, training loss: 0.561922\n",
      "Train Epoch: 0, mini-batch 16930 of 31, training loss: 0.563410\n",
      "Train Epoch: 0, mini-batch 16940 of 31, training loss: 0.562783\n",
      "Train Epoch: 0, mini-batch 16950 of 31, training loss: 0.562306\n",
      "Train Epoch: 0, mini-batch 16960 of 31, training loss: 0.561451\n",
      "Train Epoch: 0, mini-batch 16970 of 31, training loss: 0.563379\n",
      "Train Epoch: 0, mini-batch 16980 of 31, training loss: 0.562574\n",
      "Train Epoch: 0, mini-batch 16990 of 31, training loss: 0.560787\n",
      "Train Epoch: 0, mini-batch 17000 of 31, training loss: 0.561395\n",
      "Train Epoch: 0, mini-batch 17010 of 31, training loss: 0.562426\n",
      "Train Epoch: 0, mini-batch 17020 of 31, training loss: 0.561523\n",
      "Train Epoch: 0, mini-batch 17030 of 31, training loss: 0.564822\n",
      "Train Epoch: 0, mini-batch 17040 of 31, training loss: 0.564093\n",
      "Train Epoch: 0, mini-batch 17050 of 31, training loss: 0.563366\n",
      "Train Epoch: 0, mini-batch 17060 of 31, training loss: 0.562234\n",
      "Train Epoch: 0, mini-batch 17070 of 31, training loss: 0.562786\n",
      "Train Epoch: 0, mini-batch 17080 of 31, training loss: 0.562685\n",
      "Train Epoch: 0, mini-batch 17090 of 31, training loss: 0.562503\n",
      "Train Epoch: 0, mini-batch 17100 of 31, training loss: 0.560292\n",
      "Train Epoch: 0, mini-batch 17110 of 31, training loss: 0.562429\n",
      "Train Epoch: 0, mini-batch 17120 of 31, training loss: 0.563877\n",
      "Train Epoch: 0, mini-batch 17130 of 31, training loss: 0.562545\n",
      "Train Epoch: 0, mini-batch 17140 of 31, training loss: 0.562969\n",
      "Train Epoch: 0, mini-batch 17150 of 31, training loss: 0.562413\n",
      "Train Epoch: 0, mini-batch 17160 of 31, training loss: 0.565222\n",
      "Train Epoch: 0, mini-batch 17170 of 31, training loss: 0.564597\n",
      "Train Epoch: 0, mini-batch 17180 of 31, training loss: 0.562007\n",
      "Train Epoch: 0, mini-batch 17190 of 31, training loss: 0.565192\n",
      "Train Epoch: 0, mini-batch 17200 of 31, training loss: 0.559913\n",
      "Train Epoch: 0, mini-batch 17210 of 31, training loss: 0.561414\n",
      "Train Epoch: 0, mini-batch 17220 of 31, training loss: 0.560638\n",
      "Train Epoch: 0, mini-batch 17230 of 31, training loss: 0.561768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 17240 of 31, training loss: 0.564278\n",
      "Train Epoch: 0, mini-batch 17250 of 31, training loss: 0.562488\n",
      "Train Epoch: 0, mini-batch 17260 of 31, training loss: 0.562121\n",
      "Train Epoch: 0, mini-batch 17270 of 31, training loss: 0.562185\n",
      "Train Epoch: 0, mini-batch 17280 of 31, training loss: 0.561381\n",
      "Train Epoch: 0, mini-batch 17290 of 31, training loss: 0.562917\n",
      "Train Epoch: 0, mini-batch 17300 of 31, training loss: 0.563325\n",
      "Train Epoch: 0, mini-batch 17310 of 31, training loss: 0.561971\n",
      "Train Epoch: 0, mini-batch 17320 of 31, training loss: 0.558811\n",
      "Train Epoch: 0, mini-batch 17330 of 31, training loss: 0.562734\n",
      "Train Epoch: 0, mini-batch 17340 of 31, training loss: 0.564817\n",
      "Train Epoch: 0, mini-batch 17350 of 31, training loss: 0.561017\n",
      "Train Epoch: 0, mini-batch 17360 of 31, training loss: 0.563144\n",
      "Train Epoch: 0, mini-batch 17370 of 31, training loss: 0.562660\n",
      "Train Epoch: 0, mini-batch 17380 of 31, training loss: 0.563118\n",
      "Train Epoch: 0, mini-batch 17390 of 31, training loss: 0.564764\n",
      "Train Epoch: 0, mini-batch 17400 of 31, training loss: 0.560192\n",
      "Train Epoch: 0, mini-batch 17410 of 31, training loss: 0.564075\n",
      "Train Epoch: 0, mini-batch 17420 of 31, training loss: 0.561404\n",
      "Train Epoch: 0, mini-batch 17430 of 31, training loss: 0.561288\n",
      "Train Epoch: 0, mini-batch 17440 of 31, training loss: 0.563366\n",
      "Train Epoch: 0, mini-batch 17450 of 31, training loss: 0.561971\n",
      "Train Epoch: 0, mini-batch 17460 of 31, training loss: 0.562562\n",
      "Train Epoch: 0, mini-batch 17470 of 31, training loss: 0.562248\n",
      "Train Epoch: 0, mini-batch 17480 of 31, training loss: 0.561947\n",
      "Train Epoch: 0, mini-batch 17490 of 31, training loss: 0.563291\n",
      "Train Epoch: 0, mini-batch 17500 of 31, training loss: 0.560459\n",
      "Train Epoch: 0, mini-batch 17510 of 31, training loss: 0.562645\n",
      "Train Epoch: 0, mini-batch 17520 of 31, training loss: 0.562949\n",
      "Train Epoch: 0, mini-batch 17530 of 31, training loss: 0.562356\n",
      "Train Epoch: 0, mini-batch 17540 of 31, training loss: 0.562276\n",
      "Train Epoch: 0, mini-batch 17550 of 31, training loss: 0.562085\n",
      "Train Epoch: 0, mini-batch 17560 of 31, training loss: 0.561315\n",
      "Train Epoch: 0, mini-batch 17570 of 31, training loss: 0.562579\n",
      "Train Epoch: 0, mini-batch 17580 of 31, training loss: 0.561552\n",
      "Train Epoch: 0, mini-batch 17590 of 31, training loss: 0.562739\n",
      "Train Epoch: 0, mini-batch 17600 of 31, training loss: 0.560842\n",
      "Train Epoch: 0, mini-batch 17610 of 31, training loss: 0.563830\n",
      "Train Epoch: 0, mini-batch 17620 of 31, training loss: 0.563598\n",
      "Train Epoch: 0, mini-batch 17630 of 31, training loss: 0.560725\n",
      "Train Epoch: 0, mini-batch 17640 of 31, training loss: 0.563168\n",
      "Train Epoch: 0, mini-batch 17650 of 31, training loss: 0.560169\n",
      "Train Epoch: 0, mini-batch 17660 of 31, training loss: 0.564825\n",
      "Train Epoch: 0, mini-batch 17670 of 31, training loss: 0.563068\n",
      "Train Epoch: 0, mini-batch 17680 of 31, training loss: 0.563195\n",
      "Train Epoch: 0, mini-batch 17690 of 31, training loss: 0.560378\n",
      "Train Epoch: 0, mini-batch 17700 of 31, training loss: 0.561749\n",
      "Train Epoch: 0, mini-batch 17710 of 31, training loss: 0.565573\n",
      "Train Epoch: 0, mini-batch 17720 of 31, training loss: 0.561201\n",
      "Train Epoch: 0, mini-batch 17730 of 31, training loss: 0.564248\n",
      "Train Epoch: 0, mini-batch 17740 of 31, training loss: 0.561211\n",
      "Train Epoch: 0, mini-batch 17750 of 31, training loss: 0.563769\n",
      "Train Epoch: 0, mini-batch 17760 of 31, training loss: 0.561815\n",
      "Train Epoch: 0, mini-batch 17770 of 31, training loss: 0.562101\n",
      "Train Epoch: 0, mini-batch 17780 of 31, training loss: 0.564024\n",
      "Train Epoch: 0, mini-batch 17790 of 31, training loss: 0.562138\n",
      "Train Epoch: 0, mini-batch 17800 of 31, training loss: 0.562623\n",
      "Train Epoch: 0, mini-batch 17810 of 31, training loss: 0.561385\n",
      "Train Epoch: 0, mini-batch 17820 of 31, training loss: 0.561790\n",
      "Train Epoch: 0, mini-batch 17830 of 31, training loss: 0.563957\n",
      "Train Epoch: 0, mini-batch 17840 of 31, training loss: 0.563535\n",
      "Train Epoch: 0, mini-batch 17850 of 31, training loss: 0.561593\n",
      "Train Epoch: 0, mini-batch 17860 of 31, training loss: 0.564319\n",
      "Train Epoch: 0, mini-batch 17870 of 31, training loss: 0.562952\n",
      "Train Epoch: 0, mini-batch 17880 of 31, training loss: 0.561364\n",
      "Train Epoch: 0, mini-batch 17890 of 31, training loss: 0.560518\n",
      "Train Epoch: 0, mini-batch 17900 of 31, training loss: 0.563149\n",
      "Train Epoch: 0, mini-batch 17910 of 31, training loss: 0.561062\n",
      "Train Epoch: 0, mini-batch 17920 of 31, training loss: 0.563113\n",
      "Train Epoch: 0, mini-batch 17930 of 31, training loss: 0.563435\n",
      "Train Epoch: 0, mini-batch 17940 of 31, training loss: 0.562950\n",
      "Train Epoch: 0, mini-batch 17950 of 31, training loss: 0.561690\n",
      "Train Epoch: 0, mini-batch 17960 of 31, training loss: 0.565319\n",
      "Train Epoch: 0, mini-batch 17970 of 31, training loss: 0.564134\n",
      "Train Epoch: 0, mini-batch 17980 of 31, training loss: 0.561967\n",
      "Train Epoch: 0, mini-batch 17990 of 31, training loss: 0.562365\n",
      "Train Epoch: 0, mini-batch 18000 of 31, training loss: 0.563396\n",
      "Train Epoch: 0, mini-batch 18010 of 31, training loss: 0.562664\n",
      "Train Epoch: 0, mini-batch 18020 of 31, training loss: 0.563061\n",
      "Train Epoch: 0, mini-batch 18030 of 31, training loss: 0.561982\n",
      "Train Epoch: 0, mini-batch 18040 of 31, training loss: 0.561572\n",
      "Train Epoch: 0, mini-batch 18050 of 31, training loss: 0.562192\n",
      "Train Epoch: 0, mini-batch 18060 of 31, training loss: 0.562965\n",
      "Train Epoch: 0, mini-batch 18070 of 31, training loss: 0.562152\n",
      "Train Epoch: 0, mini-batch 18080 of 31, training loss: 0.562083\n",
      "Train Epoch: 0, mini-batch 18090 of 31, training loss: 0.562705\n",
      "Train Epoch: 0, mini-batch 18100 of 31, training loss: 0.562944\n",
      "Train Epoch: 0, mini-batch 18110 of 31, training loss: 0.563705\n",
      "Train Epoch: 0, mini-batch 18120 of 31, training loss: 0.564406\n",
      "Train Epoch: 0, mini-batch 18130 of 31, training loss: 0.561598\n",
      "Train Epoch: 0, mini-batch 18140 of 31, training loss: 0.561395\n",
      "Train Epoch: 0, mini-batch 18150 of 31, training loss: 0.560423\n",
      "Train Epoch: 0, mini-batch 18160 of 31, training loss: 0.562152\n",
      "Train Epoch: 0, mini-batch 18170 of 31, training loss: 0.562250\n",
      "Train Epoch: 0, mini-batch 18180 of 31, training loss: 0.562638\n",
      "Train Epoch: 0, mini-batch 18190 of 31, training loss: 0.562477\n",
      "Train Epoch: 0, mini-batch 18200 of 31, training loss: 0.562311\n",
      "Train Epoch: 0, mini-batch 18210 of 31, training loss: 0.562664\n",
      "Train Epoch: 0, mini-batch 18220 of 31, training loss: 0.559803\n",
      "Train Epoch: 0, mini-batch 18230 of 31, training loss: 0.563579\n",
      "Train Epoch: 0, mini-batch 18240 of 31, training loss: 0.563959\n",
      "Train Epoch: 0, mini-batch 18250 of 31, training loss: 0.561840\n",
      "Train Epoch: 0, mini-batch 18260 of 31, training loss: 0.561171\n",
      "Train Epoch: 0, mini-batch 18270 of 31, training loss: 0.562766\n",
      "Train Epoch: 0, mini-batch 18280 of 31, training loss: 0.562441\n",
      "Train Epoch: 0, mini-batch 18290 of 31, training loss: 0.560638\n",
      "Train Epoch: 0, mini-batch 18300 of 31, training loss: 0.562614\n",
      "Train Epoch: 0, mini-batch 18310 of 31, training loss: 0.559818\n",
      "Train Epoch: 0, mini-batch 18320 of 31, training loss: 0.566138\n",
      "Train Epoch: 0, mini-batch 18330 of 31, training loss: 0.558053\n",
      "Train Epoch: 0, mini-batch 18340 of 31, training loss: 0.562189\n",
      "Train Epoch: 0, mini-batch 18350 of 31, training loss: 0.562906\n",
      "Train Epoch: 0, mini-batch 18360 of 31, training loss: 0.562313\n",
      "Train Epoch: 0, mini-batch 18370 of 31, training loss: 0.561042\n",
      "Train Epoch: 0, mini-batch 18380 of 31, training loss: 0.561438\n",
      "Train Epoch: 0, mini-batch 18390 of 31, training loss: 0.561728\n",
      "Train Epoch: 0, mini-batch 18400 of 31, training loss: 0.561829\n",
      "Train Epoch: 0, mini-batch 18410 of 31, training loss: 0.564025\n",
      "Train Epoch: 0, mini-batch 18420 of 31, training loss: 0.562265\n",
      "Train Epoch: 0, mini-batch 18430 of 31, training loss: 0.565596\n",
      "Train Epoch: 0, mini-batch 18440 of 31, training loss: 0.563573\n",
      "Train Epoch: 0, mini-batch 18450 of 31, training loss: 0.563941\n",
      "Train Epoch: 0, mini-batch 18460 of 31, training loss: 0.563305\n",
      "Train Epoch: 0, mini-batch 18470 of 31, training loss: 0.559362\n",
      "Train Epoch: 0, mini-batch 18480 of 31, training loss: 0.562920\n",
      "Train Epoch: 0, mini-batch 18490 of 31, training loss: 0.562181\n",
      "Train Epoch: 0, mini-batch 18500 of 31, training loss: 0.563377\n",
      "Train Epoch: 0, mini-batch 18510 of 31, training loss: 0.564650\n",
      "Train Epoch: 0, mini-batch 18520 of 31, training loss: 0.564094\n",
      "Train Epoch: 0, mini-batch 18530 of 31, training loss: 0.561329\n",
      "Train Epoch: 0, mini-batch 18540 of 31, training loss: 0.562107\n",
      "Train Epoch: 0, mini-batch 18550 of 31, training loss: 0.564131\n",
      "Train Epoch: 0, mini-batch 18560 of 31, training loss: 0.562165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 18570 of 31, training loss: 0.564935\n",
      "Train Epoch: 0, mini-batch 18580 of 31, training loss: 0.561687\n",
      "Train Epoch: 0, mini-batch 18590 of 31, training loss: 0.562282\n",
      "Train Epoch: 0, mini-batch 18600 of 31, training loss: 0.561456\n",
      "Train Epoch: 0, mini-batch 18610 of 31, training loss: 0.560350\n",
      "Train Epoch: 0, mini-batch 18620 of 31, training loss: 0.564556\n",
      "Train Epoch: 0, mini-batch 18630 of 31, training loss: 0.562691\n",
      "Train Epoch: 0, mini-batch 18640 of 31, training loss: 0.561143\n",
      "Train Epoch: 0, mini-batch 18650 of 31, training loss: 0.562367\n",
      "Train Epoch: 0, mini-batch 18660 of 31, training loss: 0.563929\n",
      "Train Epoch: 0, mini-batch 18670 of 31, training loss: 0.560522\n",
      "Train Epoch: 0, mini-batch 18680 of 31, training loss: 0.562579\n",
      "Train Epoch: 0, mini-batch 18690 of 31, training loss: 0.561760\n",
      "Train Epoch: 0, mini-batch 18700 of 31, training loss: 0.561985\n",
      "Train Epoch: 0, mini-batch 18710 of 31, training loss: 0.563120\n",
      "Train Epoch: 0, mini-batch 18720 of 31, training loss: 0.562476\n",
      "Train Epoch: 0, mini-batch 18730 of 31, training loss: 0.561678\n",
      "Train Epoch: 0, mini-batch 18740 of 31, training loss: 0.562023\n",
      "Train Epoch: 0, mini-batch 18750 of 31, training loss: 0.563795\n",
      "Train Epoch: 0, mini-batch 18760 of 31, training loss: 0.562227\n",
      "Train Epoch: 0, mini-batch 18770 of 31, training loss: 0.561707\n",
      "Train Epoch: 0, mini-batch 18780 of 31, training loss: 0.562682\n",
      "Train Epoch: 0, mini-batch 18790 of 31, training loss: 0.563460\n",
      "Train Epoch: 0, mini-batch 18800 of 31, training loss: 0.562544\n",
      "Train Epoch: 0, mini-batch 18810 of 31, training loss: 0.561186\n",
      "Train Epoch: 0, mini-batch 18820 of 31, training loss: 0.562885\n",
      "Train Epoch: 0, mini-batch 18830 of 31, training loss: 0.560701\n",
      "Train Epoch: 0, mini-batch 18840 of 31, training loss: 0.562301\n",
      "Train Epoch: 0, mini-batch 18850 of 31, training loss: 0.561050\n",
      "Train Epoch: 0, mini-batch 18860 of 31, training loss: 0.561679\n",
      "Train Epoch: 0, mini-batch 18870 of 31, training loss: 0.562295\n",
      "Train Epoch: 0, mini-batch 18880 of 31, training loss: 0.563190\n",
      "Train Epoch: 0, mini-batch 18890 of 31, training loss: 0.560287\n",
      "Train Epoch: 0, mini-batch 18900 of 31, training loss: 0.562832\n",
      "Train Epoch: 0, mini-batch 18910 of 31, training loss: 0.561188\n",
      "Train Epoch: 0, mini-batch 18920 of 31, training loss: 0.563505\n",
      "Train Epoch: 0, mini-batch 18930 of 31, training loss: 0.560722\n",
      "Train Epoch: 0, mini-batch 18940 of 31, training loss: 0.561507\n",
      "Train Epoch: 0, mini-batch 18950 of 31, training loss: 0.562719\n",
      "Train Epoch: 0, mini-batch 18960 of 31, training loss: 0.563551\n",
      "Train Epoch: 0, mini-batch 18970 of 31, training loss: 0.560773\n",
      "Train Epoch: 0, mini-batch 18980 of 31, training loss: 0.560327\n",
      "Train Epoch: 0, mini-batch 18990 of 31, training loss: 0.561546\n",
      "Train Epoch: 0, mini-batch 19000 of 31, training loss: 0.564943\n",
      "Train Epoch: 0, mini-batch 19010 of 31, training loss: 0.560979\n",
      "Train Epoch: 0, mini-batch 19020 of 31, training loss: 0.562940\n",
      "Train Epoch: 0, mini-batch 19030 of 31, training loss: 0.560994\n",
      "Train Epoch: 0, mini-batch 19040 of 31, training loss: 0.562260\n",
      "Train Epoch: 0, mini-batch 19050 of 31, training loss: 0.562569\n",
      "Train Epoch: 0, mini-batch 19060 of 31, training loss: 0.562415\n",
      "Train Epoch: 0, mini-batch 19070 of 31, training loss: 0.561506\n",
      "Train Epoch: 0, mini-batch 19080 of 31, training loss: 0.562701\n",
      "Train Epoch: 0, mini-batch 19090 of 31, training loss: 0.561183\n",
      "Train Epoch: 0, mini-batch 19100 of 31, training loss: 0.562077\n",
      "Train Epoch: 0, mini-batch 19110 of 31, training loss: 0.563170\n",
      "Train Epoch: 0, mini-batch 19120 of 31, training loss: 0.562206\n",
      "Train Epoch: 0, mini-batch 19130 of 31, training loss: 0.562604\n",
      "Train Epoch: 0, mini-batch 19140 of 31, training loss: 0.562743\n",
      "Train Epoch: 0, mini-batch 19150 of 31, training loss: 0.562355\n",
      "Train Epoch: 0, mini-batch 19160 of 31, training loss: 0.562430\n",
      "Train Epoch: 0, mini-batch 19170 of 31, training loss: 0.562834\n",
      "Train Epoch: 0, mini-batch 19180 of 31, training loss: 0.561044\n",
      "Train Epoch: 0, mini-batch 19190 of 31, training loss: 0.562326\n",
      "Train Epoch: 0, mini-batch 19200 of 31, training loss: 0.562018\n",
      "Train Epoch: 0, mini-batch 19210 of 31, training loss: 0.562323\n",
      "Train Epoch: 0, mini-batch 19220 of 31, training loss: 0.561937\n",
      "Train Epoch: 0, mini-batch 19230 of 31, training loss: 0.562537\n",
      "Train Epoch: 0, mini-batch 19240 of 31, training loss: 0.561383\n",
      "Train Epoch: 0, mini-batch 19250 of 31, training loss: 0.561420\n",
      "Train Epoch: 0, mini-batch 19260 of 31, training loss: 0.562136\n",
      "Train Epoch: 0, mini-batch 19270 of 31, training loss: 0.562579\n",
      "Train Epoch: 0, mini-batch 19280 of 31, training loss: 0.563161\n",
      "Train Epoch: 0, mini-batch 19290 of 31, training loss: 0.561902\n",
      "Train Epoch: 0, mini-batch 19300 of 31, training loss: 0.560897\n",
      "Train Epoch: 0, mini-batch 19310 of 31, training loss: 0.562530\n",
      "Train Epoch: 0, mini-batch 19320 of 31, training loss: 0.562509\n",
      "Train Epoch: 0, mini-batch 19330 of 31, training loss: 0.563200\n",
      "Train Epoch: 0, mini-batch 19340 of 31, training loss: 0.563373\n",
      "Train Epoch: 0, mini-batch 19350 of 31, training loss: 0.560917\n",
      "Train Epoch: 0, mini-batch 19360 of 31, training loss: 0.563376\n",
      "Train Epoch: 0, mini-batch 19370 of 31, training loss: 0.562244\n",
      "Train Epoch: 0, mini-batch 19380 of 31, training loss: 0.563518\n",
      "Train Epoch: 0, mini-batch 19390 of 31, training loss: 0.559686\n",
      "Train Epoch: 0, mini-batch 19400 of 31, training loss: 0.562390\n",
      "Train Epoch: 0, mini-batch 19410 of 31, training loss: 0.558871\n",
      "Train Epoch: 0, mini-batch 19420 of 31, training loss: 0.560508\n",
      "Train Epoch: 0, mini-batch 19430 of 31, training loss: 0.559726\n",
      "Train Epoch: 0, mini-batch 19440 of 31, training loss: 0.563488\n",
      "Train Epoch: 0, mini-batch 19450 of 31, training loss: 0.565321\n",
      "Train Epoch: 0, mini-batch 19460 of 31, training loss: 0.559038\n",
      "Train Epoch: 0, mini-batch 19470 of 31, training loss: 0.558309\n",
      "Train Epoch: 0, mini-batch 19480 of 31, training loss: 0.560080\n",
      "Train Epoch: 0, mini-batch 19490 of 31, training loss: 0.565523\n",
      "Train Epoch: 0, mini-batch 19500 of 31, training loss: 0.560628\n",
      "Train Epoch: 0, mini-batch 19510 of 31, training loss: 0.561893\n",
      "Train Epoch: 0, mini-batch 19520 of 31, training loss: 0.563048\n",
      "Train Epoch: 0, mini-batch 19530 of 31, training loss: 0.562314\n",
      "Train Epoch: 0, mini-batch 19540 of 31, training loss: 0.562136\n",
      "Train Epoch: 0, mini-batch 19550 of 31, training loss: 0.562910\n",
      "Train Epoch: 0, mini-batch 19560 of 31, training loss: 0.562197\n",
      "Train Epoch: 0, mini-batch 19570 of 31, training loss: 0.563585\n",
      "Train Epoch: 0, mini-batch 19580 of 31, training loss: 0.562054\n",
      "Train Epoch: 0, mini-batch 19590 of 31, training loss: 0.562527\n",
      "Train Epoch: 0, mini-batch 19600 of 31, training loss: 0.562582\n",
      "Train Epoch: 0, mini-batch 19610 of 31, training loss: 0.562248\n",
      "Train Epoch: 0, mini-batch 19620 of 31, training loss: 0.561755\n",
      "Train Epoch: 0, mini-batch 19630 of 31, training loss: 0.561239\n",
      "Train Epoch: 0, mini-batch 19640 of 31, training loss: 0.560566\n",
      "Train Epoch: 0, mini-batch 19650 of 31, training loss: 0.561920\n",
      "Train Epoch: 0, mini-batch 19660 of 31, training loss: 0.562619\n",
      "Train Epoch: 0, mini-batch 19670 of 31, training loss: 0.564774\n",
      "Train Epoch: 0, mini-batch 19680 of 31, training loss: 0.562964\n",
      "Train Epoch: 0, mini-batch 19690 of 31, training loss: 0.561210\n",
      "Train Epoch: 0, mini-batch 19700 of 31, training loss: 0.563431\n",
      "Train Epoch: 0, mini-batch 19710 of 31, training loss: 0.561532\n",
      "Train Epoch: 0, mini-batch 19720 of 31, training loss: 0.563305\n",
      "Train Epoch: 0, mini-batch 19730 of 31, training loss: 0.562504\n",
      "Train Epoch: 0, mini-batch 19740 of 31, training loss: 0.562410\n",
      "Train Epoch: 0, mini-batch 19750 of 31, training loss: 0.563242\n",
      "Train Epoch: 0, mini-batch 19760 of 31, training loss: 0.563000\n",
      "Train Epoch: 0, mini-batch 19770 of 31, training loss: 0.561438\n",
      "Train Epoch: 0, mini-batch 19780 of 31, training loss: 0.563710\n",
      "Train Epoch: 0, mini-batch 19790 of 31, training loss: 0.563294\n",
      "Train Epoch: 0, mini-batch 19800 of 31, training loss: 0.562099\n",
      "Train Epoch: 0, mini-batch 19810 of 31, training loss: 0.561347\n",
      "Train Epoch: 0, mini-batch 19820 of 31, training loss: 0.561803\n",
      "Train Epoch: 0, mini-batch 19830 of 31, training loss: 0.561669\n",
      "Train Epoch: 0, mini-batch 19840 of 31, training loss: 0.560889\n",
      "Train Epoch: 0, mini-batch 19850 of 31, training loss: 0.559920\n",
      "Train Epoch: 0, mini-batch 19860 of 31, training loss: 0.562862\n",
      "Train Epoch: 0, mini-batch 19870 of 31, training loss: 0.563640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 19880 of 31, training loss: 0.563103\n",
      "Train Epoch: 0, mini-batch 19890 of 31, training loss: 0.562253\n",
      "Train Epoch: 0, mini-batch 19900 of 31, training loss: 0.562274\n",
      "Train Epoch: 0, mini-batch 19910 of 31, training loss: 0.562265\n",
      "Train Epoch: 0, mini-batch 19920 of 31, training loss: 0.561568\n",
      "Train Epoch: 0, mini-batch 19930 of 31, training loss: 0.562672\n",
      "Train Epoch: 0, mini-batch 19940 of 31, training loss: 0.561263\n",
      "Train Epoch: 0, mini-batch 19950 of 31, training loss: 0.562630\n",
      "Train Epoch: 0, mini-batch 19960 of 31, training loss: 0.563988\n",
      "Train Epoch: 0, mini-batch 19970 of 31, training loss: 0.561589\n",
      "Train Epoch: 0, mini-batch 19980 of 31, training loss: 0.563076\n",
      "Train Epoch: 0, mini-batch 19990 of 31, training loss: 0.561641\n",
      "Train Epoch: 0, mini-batch 20000 of 31, training loss: 0.559435\n",
      "Train Epoch: 0, mini-batch 20010 of 31, training loss: 0.562477\n",
      "Train Epoch: 0, mini-batch 20020 of 31, training loss: 0.564490\n",
      "Train Epoch: 0, mini-batch 20030 of 31, training loss: 0.563543\n",
      "Train Epoch: 0, mini-batch 20040 of 31, training loss: 0.562952\n",
      "Train Epoch: 0, mini-batch 20050 of 31, training loss: 0.561947\n",
      "Train Epoch: 0, mini-batch 20060 of 31, training loss: 0.559611\n",
      "Train Epoch: 0, mini-batch 20070 of 31, training loss: 0.564045\n",
      "Train Epoch: 0, mini-batch 20080 of 31, training loss: 0.559829\n",
      "Train Epoch: 0, mini-batch 20090 of 31, training loss: 0.562322\n",
      "Train Epoch: 0, mini-batch 20100 of 31, training loss: 0.564282\n",
      "Train Epoch: 0, mini-batch 20110 of 31, training loss: 0.563899\n",
      "Train Epoch: 0, mini-batch 20120 of 31, training loss: 0.562255\n",
      "Train Epoch: 0, mini-batch 20130 of 31, training loss: 0.562291\n",
      "Train Epoch: 0, mini-batch 20140 of 31, training loss: 0.562646\n",
      "Train Epoch: 0, mini-batch 20150 of 31, training loss: 0.562583\n",
      "Train Epoch: 0, mini-batch 20160 of 31, training loss: 0.561878\n",
      "Train Epoch: 0, mini-batch 20170 of 31, training loss: 0.562464\n",
      "Train Epoch: 0, mini-batch 20180 of 31, training loss: 0.561453\n",
      "Train Epoch: 0, mini-batch 20190 of 31, training loss: 0.562841\n",
      "Train Epoch: 0, mini-batch 20200 of 31, training loss: 0.563293\n",
      "Train Epoch: 0, mini-batch 20210 of 31, training loss: 0.561954\n",
      "Train Epoch: 0, mini-batch 20220 of 31, training loss: 0.562225\n",
      "Train Epoch: 0, mini-batch 20230 of 31, training loss: 0.562022\n",
      "Train Epoch: 0, mini-batch 20240 of 31, training loss: 0.561982\n",
      "Train Epoch: 0, mini-batch 20250 of 31, training loss: 0.561358\n",
      "Train Epoch: 0, mini-batch 20260 of 31, training loss: 0.562152\n",
      "Train Epoch: 0, mini-batch 20270 of 31, training loss: 0.561927\n",
      "Train Epoch: 0, mini-batch 20280 of 31, training loss: 0.562328\n",
      "Train Epoch: 0, mini-batch 20290 of 31, training loss: 0.562276\n",
      "Train Epoch: 0, mini-batch 20300 of 31, training loss: 0.562268\n",
      "Train Epoch: 0, mini-batch 20310 of 31, training loss: 0.561799\n",
      "Train Epoch: 0, mini-batch 20320 of 31, training loss: 0.562863\n",
      "Train Epoch: 0, mini-batch 20330 of 31, training loss: 0.561523\n",
      "Train Epoch: 0, mini-batch 20340 of 31, training loss: 0.562220\n",
      "Train Epoch: 0, mini-batch 20350 of 31, training loss: 0.563360\n",
      "Train Epoch: 0, mini-batch 20360 of 31, training loss: 0.562328\n",
      "Train Epoch: 0, mini-batch 20370 of 31, training loss: 0.562883\n",
      "Train Epoch: 0, mini-batch 20380 of 31, training loss: 0.563260\n",
      "Train Epoch: 0, mini-batch 20390 of 31, training loss: 0.562396\n",
      "Train Epoch: 0, mini-batch 20400 of 31, training loss: 0.563604\n",
      "Train Epoch: 0, mini-batch 20410 of 31, training loss: 0.563710\n",
      "Train Epoch: 0, mini-batch 20420 of 31, training loss: 0.562062\n",
      "Train Epoch: 0, mini-batch 20430 of 31, training loss: 0.562194\n",
      "Train Epoch: 0, mini-batch 20440 of 31, training loss: 0.563606\n",
      "Train Epoch: 0, mini-batch 20450 of 31, training loss: 0.561549\n",
      "Train Epoch: 0, mini-batch 20460 of 31, training loss: 0.563843\n",
      "Train Epoch: 0, mini-batch 20470 of 31, training loss: 0.560709\n",
      "Train Epoch: 0, mini-batch 20480 of 31, training loss: 0.563210\n",
      "Train Epoch: 0, mini-batch 20490 of 31, training loss: 0.562423\n",
      "Train Epoch: 0, mini-batch 20500 of 31, training loss: 0.562816\n",
      "Train Epoch: 0, mini-batch 20510 of 31, training loss: 0.561340\n",
      "Train Epoch: 0, mini-batch 20520 of 31, training loss: 0.563539\n",
      "Train Epoch: 0, mini-batch 20530 of 31, training loss: 0.562573\n",
      "Train Epoch: 0, mini-batch 20540 of 31, training loss: 0.563090\n",
      "Train Epoch: 0, mini-batch 20550 of 31, training loss: 0.563083\n",
      "Train Epoch: 0, mini-batch 20560 of 31, training loss: 0.561459\n",
      "Train Epoch: 0, mini-batch 20570 of 31, training loss: 0.563353\n",
      "Train Epoch: 0, mini-batch 20580 of 31, training loss: 0.561832\n",
      "Train Epoch: 0, mini-batch 20590 of 31, training loss: 0.562975\n",
      "Train Epoch: 0, mini-batch 20600 of 31, training loss: 0.562208\n",
      "Train Epoch: 0, mini-batch 20610 of 31, training loss: 0.564297\n",
      "Train Epoch: 0, mini-batch 20620 of 31, training loss: 0.561749\n",
      "Train Epoch: 0, mini-batch 20630 of 31, training loss: 0.560823\n",
      "Train Epoch: 0, mini-batch 20640 of 31, training loss: 0.562991\n",
      "Train Epoch: 0, mini-batch 20650 of 31, training loss: 0.566233\n",
      "Train Epoch: 0, mini-batch 20660 of 31, training loss: 0.562597\n",
      "Train Epoch: 0, mini-batch 20670 of 31, training loss: 0.564188\n",
      "Train Epoch: 0, mini-batch 20680 of 31, training loss: 0.562622\n",
      "Train Epoch: 0, mini-batch 20690 of 31, training loss: 0.562151\n",
      "Train Epoch: 0, mini-batch 20700 of 31, training loss: 0.562448\n",
      "Train Epoch: 0, mini-batch 20710 of 31, training loss: 0.562407\n",
      "Train Epoch: 0, mini-batch 20720 of 31, training loss: 0.562982\n",
      "Train Epoch: 0, mini-batch 20730 of 31, training loss: 0.562856\n",
      "Train Epoch: 0, mini-batch 20740 of 31, training loss: 0.561416\n",
      "Train Epoch: 0, mini-batch 20750 of 31, training loss: 0.562146\n",
      "Train Epoch: 0, mini-batch 20760 of 31, training loss: 0.564334\n",
      "Train Epoch: 0, mini-batch 20770 of 31, training loss: 0.562616\n",
      "Train Epoch: 0, mini-batch 20780 of 31, training loss: 0.562416\n",
      "Train Epoch: 0, mini-batch 20790 of 31, training loss: 0.565074\n",
      "Train Epoch: 0, mini-batch 20800 of 31, training loss: 0.564130\n",
      "Train Epoch: 0, mini-batch 20810 of 31, training loss: 0.561565\n",
      "Train Epoch: 0, mini-batch 20820 of 31, training loss: 0.562729\n",
      "Train Epoch: 0, mini-batch 20830 of 31, training loss: 0.562747\n",
      "Train Epoch: 0, mini-batch 20840 of 31, training loss: 0.563576\n",
      "Train Epoch: 0, mini-batch 20850 of 31, training loss: 0.561940\n",
      "Train Epoch: 0, mini-batch 20860 of 31, training loss: 0.561011\n",
      "Train Epoch: 0, mini-batch 20870 of 31, training loss: 0.561845\n",
      "Train Epoch: 0, mini-batch 20880 of 31, training loss: 0.560028\n",
      "Train Epoch: 0, mini-batch 20890 of 31, training loss: 0.562261\n",
      "Train Epoch: 0, mini-batch 20900 of 31, training loss: 0.563227\n",
      "Train Epoch: 0, mini-batch 20910 of 31, training loss: 0.560453\n",
      "Train Epoch: 0, mini-batch 20920 of 31, training loss: 0.561091\n",
      "Train Epoch: 0, mini-batch 20930 of 31, training loss: 0.564357\n",
      "Train Epoch: 0, mini-batch 20940 of 31, training loss: 0.562937\n",
      "Train Epoch: 0, mini-batch 20950 of 31, training loss: 0.562099\n",
      "Train Epoch: 0, mini-batch 20960 of 31, training loss: 0.562676\n",
      "Train Epoch: 0, mini-batch 20970 of 31, training loss: 0.561086\n",
      "Train Epoch: 0, mini-batch 20980 of 31, training loss: 0.562583\n",
      "Train Epoch: 0, mini-batch 20990 of 31, training loss: 0.562032\n",
      "Train Epoch: 0, mini-batch 21000 of 31, training loss: 0.560932\n",
      "Train Epoch: 0, mini-batch 21010 of 31, training loss: 0.561956\n",
      "Train Epoch: 0, mini-batch 21020 of 31, training loss: 0.561455\n",
      "Train Epoch: 0, mini-batch 21030 of 31, training loss: 0.560569\n",
      "Train Epoch: 0, mini-batch 21040 of 31, training loss: 0.561620\n",
      "Train Epoch: 0, mini-batch 21050 of 31, training loss: 0.561118\n",
      "Train Epoch: 0, mini-batch 21060 of 31, training loss: 0.561361\n",
      "Train Epoch: 0, mini-batch 21070 of 31, training loss: 0.562869\n",
      "Train Epoch: 0, mini-batch 21080 of 31, training loss: 0.562916\n",
      "Train Epoch: 0, mini-batch 21090 of 31, training loss: 0.563160\n",
      "Train Epoch: 0, mini-batch 21100 of 31, training loss: 0.560860\n",
      "Train Epoch: 0, mini-batch 21110 of 31, training loss: 0.560478\n",
      "Train Epoch: 0, mini-batch 21120 of 31, training loss: 0.564434\n",
      "Train Epoch: 0, mini-batch 21130 of 31, training loss: 0.563420\n",
      "Train Epoch: 0, mini-batch 21140 of 31, training loss: 0.558978\n",
      "Train Epoch: 0, mini-batch 21150 of 31, training loss: 0.563020\n",
      "Train Epoch: 0, mini-batch 21160 of 31, training loss: 0.564341\n",
      "Train Epoch: 0, mini-batch 21170 of 31, training loss: 0.564188\n",
      "Train Epoch: 0, mini-batch 21180 of 31, training loss: 0.562238\n",
      "Train Epoch: 0, mini-batch 21190 of 31, training loss: 0.565836\n",
      "Train Epoch: 0, mini-batch 21200 of 31, training loss: 0.562590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 21210 of 31, training loss: 0.562122\n",
      "Train Epoch: 0, mini-batch 21220 of 31, training loss: 0.561078\n",
      "Train Epoch: 0, mini-batch 21230 of 31, training loss: 0.563606\n",
      "Train Epoch: 0, mini-batch 21240 of 31, training loss: 0.562511\n",
      "Train Epoch: 0, mini-batch 21250 of 31, training loss: 0.561447\n",
      "Train Epoch: 0, mini-batch 21260 of 31, training loss: 0.563294\n",
      "Train Epoch: 0, mini-batch 21270 of 31, training loss: 0.561855\n",
      "Train Epoch: 0, mini-batch 21280 of 31, training loss: 0.563440\n",
      "Train Epoch: 0, mini-batch 21290 of 31, training loss: 0.562407\n",
      "Train Epoch: 0, mini-batch 21300 of 31, training loss: 0.561514\n",
      "Train Epoch: 0, mini-batch 21310 of 31, training loss: 0.561526\n",
      "Train Epoch: 0, mini-batch 21320 of 31, training loss: 0.562638\n",
      "Train Epoch: 0, mini-batch 21330 of 31, training loss: 0.562246\n",
      "Train Epoch: 0, mini-batch 21340 of 31, training loss: 0.561148\n",
      "Train Epoch: 0, mini-batch 21350 of 31, training loss: 0.562629\n",
      "Train Epoch: 0, mini-batch 21360 of 31, training loss: 0.562879\n",
      "Train Epoch: 0, mini-batch 21370 of 31, training loss: 0.561757\n",
      "Train Epoch: 0, mini-batch 21380 of 31, training loss: 0.562528\n",
      "Train Epoch: 0, mini-batch 21390 of 31, training loss: 0.564189\n",
      "Train Epoch: 0, mini-batch 21400 of 31, training loss: 0.560830\n",
      "Train Epoch: 0, mini-batch 21410 of 31, training loss: 0.562741\n",
      "Train Epoch: 0, mini-batch 21420 of 31, training loss: 0.563137\n",
      "Train Epoch: 0, mini-batch 21430 of 31, training loss: 0.561160\n",
      "Train Epoch: 0, mini-batch 21440 of 31, training loss: 0.561463\n",
      "Train Epoch: 0, mini-batch 21450 of 31, training loss: 0.563890\n",
      "Train Epoch: 0, mini-batch 21460 of 31, training loss: 0.561250\n",
      "Train Epoch: 0, mini-batch 21470 of 31, training loss: 0.564490\n",
      "Train Epoch: 0, mini-batch 21480 of 31, training loss: 0.561077\n",
      "Train Epoch: 0, mini-batch 21490 of 31, training loss: 0.564417\n",
      "Train Epoch: 0, mini-batch 21500 of 31, training loss: 0.561633\n",
      "Train Epoch: 0, mini-batch 21510 of 31, training loss: 0.561870\n",
      "Train Epoch: 0, mini-batch 21520 of 31, training loss: 0.562182\n",
      "Train Epoch: 0, mini-batch 21530 of 31, training loss: 0.563130\n",
      "Train Epoch: 0, mini-batch 21540 of 31, training loss: 0.559686\n",
      "Train Epoch: 0, mini-batch 21550 of 31, training loss: 0.562191\n",
      "Train Epoch: 0, mini-batch 21560 of 31, training loss: 0.560986\n",
      "Train Epoch: 0, mini-batch 21570 of 31, training loss: 0.563399\n",
      "Train Epoch: 0, mini-batch 21580 of 31, training loss: 0.562206\n",
      "Train Epoch: 0, mini-batch 21590 of 31, training loss: 0.561982\n",
      "Train Epoch: 0, mini-batch 21600 of 31, training loss: 0.563453\n",
      "Train Epoch: 0, mini-batch 21610 of 31, training loss: 0.562667\n",
      "Train Epoch: 0, mini-batch 21620 of 31, training loss: 0.562161\n",
      "Train Epoch: 0, mini-batch 21630 of 31, training loss: 0.562445\n",
      "Train Epoch: 0, mini-batch 21640 of 31, training loss: 0.562362\n",
      "Train Epoch: 0, mini-batch 21650 of 31, training loss: 0.561723\n",
      "Train Epoch: 0, mini-batch 21660 of 31, training loss: 0.561905\n",
      "Train Epoch: 0, mini-batch 21670 of 31, training loss: 0.562775\n",
      "Train Epoch: 0, mini-batch 21680 of 31, training loss: 0.563652\n",
      "Train Epoch: 0, mini-batch 21690 of 31, training loss: 0.560500\n",
      "Train Epoch: 0, mini-batch 21700 of 31, training loss: 0.562486\n",
      "Train Epoch: 0, mini-batch 21710 of 31, training loss: 0.562468\n",
      "Train Epoch: 0, mini-batch 21720 of 31, training loss: 0.562059\n",
      "Train Epoch: 0, mini-batch 21730 of 31, training loss: 0.560462\n",
      "Train Epoch: 0, mini-batch 21740 of 31, training loss: 0.563925\n",
      "Train Epoch: 0, mini-batch 21750 of 31, training loss: 0.562279\n",
      "Train Epoch: 0, mini-batch 21760 of 31, training loss: 0.563864\n",
      "Train Epoch: 0, mini-batch 21770 of 31, training loss: 0.563691\n",
      "Train Epoch: 0, mini-batch 21780 of 31, training loss: 0.561738\n",
      "Train Epoch: 0, mini-batch 21790 of 31, training loss: 0.563211\n",
      "Train Epoch: 0, mini-batch 21800 of 31, training loss: 0.561181\n",
      "Train Epoch: 0, mini-batch 21810 of 31, training loss: 0.562213\n",
      "Train Epoch: 0, mini-batch 21820 of 31, training loss: 0.561516\n",
      "Train Epoch: 0, mini-batch 21830 of 31, training loss: 0.562910\n",
      "Train Epoch: 0, mini-batch 21840 of 31, training loss: 0.561323\n",
      "Train Epoch: 0, mini-batch 21850 of 31, training loss: 0.561861\n",
      "Train Epoch: 0, mini-batch 21860 of 31, training loss: 0.561375\n",
      "Train Epoch: 0, mini-batch 21870 of 31, training loss: 0.563053\n",
      "Train Epoch: 0, mini-batch 21880 of 31, training loss: 0.561262\n",
      "Train Epoch: 0, mini-batch 21890 of 31, training loss: 0.563587\n",
      "Train Epoch: 0, mini-batch 21900 of 31, training loss: 0.563452\n",
      "Train Epoch: 0, mini-batch 21910 of 31, training loss: 0.562755\n",
      "Train Epoch: 0, mini-batch 21920 of 31, training loss: 0.561355\n",
      "Train Epoch: 0, mini-batch 21930 of 31, training loss: 0.562311\n",
      "Train Epoch: 0, mini-batch 21940 of 31, training loss: 0.562757\n",
      "Train Epoch: 0, mini-batch 21950 of 31, training loss: 0.562367\n",
      "Train Epoch: 0, mini-batch 21960 of 31, training loss: 0.560620\n",
      "Train Epoch: 0, mini-batch 21970 of 31, training loss: 0.563195\n",
      "Train Epoch: 0, mini-batch 21980 of 31, training loss: 0.562804\n",
      "Train Epoch: 0, mini-batch 21990 of 31, training loss: 0.562491\n",
      "Train Epoch: 0, mini-batch 22000 of 31, training loss: 0.562780\n",
      "Train Epoch: 0, mini-batch 22010 of 31, training loss: 0.563064\n",
      "Train Epoch: 0, mini-batch 22020 of 31, training loss: 0.562786\n",
      "Train Epoch: 0, mini-batch 22030 of 31, training loss: 0.562319\n",
      "Train Epoch: 0, mini-batch 22040 of 31, training loss: 0.562526\n",
      "Train Epoch: 0, mini-batch 22050 of 31, training loss: 0.562537\n",
      "Train Epoch: 0, mini-batch 22060 of 31, training loss: 0.563220\n",
      "Train Epoch: 0, mini-batch 22070 of 31, training loss: 0.562956\n",
      "Train Epoch: 0, mini-batch 22080 of 31, training loss: 0.562908\n",
      "Train Epoch: 0, mini-batch 22090 of 31, training loss: 0.562821\n",
      "Train Epoch: 0, mini-batch 22100 of 31, training loss: 0.562984\n",
      "Train Epoch: 0, mini-batch 22110 of 31, training loss: 0.561545\n",
      "Train Epoch: 0, mini-batch 22120 of 31, training loss: 0.562168\n",
      "Train Epoch: 0, mini-batch 22130 of 31, training loss: 0.563528\n",
      "Train Epoch: 0, mini-batch 22140 of 31, training loss: 0.563721\n",
      "Train Epoch: 0, mini-batch 22150 of 31, training loss: 0.562201\n",
      "Train Epoch: 0, mini-batch 22160 of 31, training loss: 0.563291\n",
      "Train Epoch: 0, mini-batch 22170 of 31, training loss: 0.563734\n",
      "Train Epoch: 0, mini-batch 22180 of 31, training loss: 0.560732\n",
      "Train Epoch: 0, mini-batch 22190 of 31, training loss: 0.561346\n",
      "Train Epoch: 0, mini-batch 22200 of 31, training loss: 0.563832\n",
      "Train Epoch: 0, mini-batch 22210 of 31, training loss: 0.563116\n",
      "Train Epoch: 0, mini-batch 22220 of 31, training loss: 0.563822\n",
      "Train Epoch: 0, mini-batch 22230 of 31, training loss: 0.562913\n",
      "Train Epoch: 0, mini-batch 22240 of 31, training loss: 0.561059\n",
      "Train Epoch: 0, mini-batch 22250 of 31, training loss: 0.560758\n",
      "Train Epoch: 0, mini-batch 22260 of 31, training loss: 0.562733\n",
      "Train Epoch: 0, mini-batch 22270 of 31, training loss: 0.562314\n",
      "Train Epoch: 0, mini-batch 22280 of 31, training loss: 0.562173\n",
      "Train Epoch: 0, mini-batch 22290 of 31, training loss: 0.562597\n",
      "Train Epoch: 0, mini-batch 22300 of 31, training loss: 0.562977\n",
      "Train Epoch: 0, mini-batch 22310 of 31, training loss: 0.562428\n",
      "Train Epoch: 0, mini-batch 22320 of 31, training loss: 0.562086\n",
      "Train Epoch: 0, mini-batch 22330 of 31, training loss: 0.562151\n",
      "Train Epoch: 0, mini-batch 22340 of 31, training loss: 0.561806\n",
      "Train Epoch: 0, mini-batch 22350 of 31, training loss: 0.562096\n",
      "Train Epoch: 0, mini-batch 22360 of 31, training loss: 0.564276\n",
      "Train Epoch: 0, mini-batch 22370 of 31, training loss: 0.562257\n",
      "Train Epoch: 0, mini-batch 22380 of 31, training loss: 0.561560\n",
      "Train Epoch: 0, mini-batch 22390 of 31, training loss: 0.561902\n",
      "Train Epoch: 0, mini-batch 22400 of 31, training loss: 0.562769\n",
      "Train Epoch: 0, mini-batch 22410 of 31, training loss: 0.562102\n",
      "Train Epoch: 0, mini-batch 22420 of 31, training loss: 0.561943\n",
      "Train Epoch: 0, mini-batch 22430 of 31, training loss: 0.561831\n",
      "Train Epoch: 0, mini-batch 22440 of 31, training loss: 0.562181\n",
      "Train Epoch: 0, mini-batch 22450 of 31, training loss: 0.562491\n",
      "Train Epoch: 0, mini-batch 22460 of 31, training loss: 0.561854\n",
      "Train Epoch: 0, mini-batch 22470 of 31, training loss: 0.562247\n",
      "Train Epoch: 0, mini-batch 22480 of 31, training loss: 0.561298\n",
      "Train Epoch: 0, mini-batch 22490 of 31, training loss: 0.563155\n",
      "Train Epoch: 0, mini-batch 22500 of 31, training loss: 0.562204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 22510 of 31, training loss: 0.562570\n",
      "Train Epoch: 0, mini-batch 22520 of 31, training loss: 0.562681\n",
      "Train Epoch: 0, mini-batch 22530 of 31, training loss: 0.562586\n",
      "Train Epoch: 0, mini-batch 22540 of 31, training loss: 0.562702\n",
      "Train Epoch: 0, mini-batch 22550 of 31, training loss: 0.561631\n",
      "Train Epoch: 0, mini-batch 22560 of 31, training loss: 0.562016\n",
      "Train Epoch: 0, mini-batch 22570 of 31, training loss: 0.564240\n",
      "Train Epoch: 0, mini-batch 22580 of 31, training loss: 0.562823\n",
      "Train Epoch: 0, mini-batch 22590 of 31, training loss: 0.561974\n",
      "Train Epoch: 0, mini-batch 22600 of 31, training loss: 0.561466\n",
      "Train Epoch: 0, mini-batch 22610 of 31, training loss: 0.561943\n",
      "Train Epoch: 0, mini-batch 22620 of 31, training loss: 0.562197\n",
      "Train Epoch: 0, mini-batch 22630 of 31, training loss: 0.561879\n",
      "Train Epoch: 0, mini-batch 22640 of 31, training loss: 0.562528\n",
      "Train Epoch: 0, mini-batch 22650 of 31, training loss: 0.561751\n",
      "Train Epoch: 0, mini-batch 22660 of 31, training loss: 0.563321\n",
      "Train Epoch: 0, mini-batch 22670 of 31, training loss: 0.562328\n",
      "Train Epoch: 0, mini-batch 22680 of 31, training loss: 0.562776\n",
      "Train Epoch: 0, mini-batch 22690 of 31, training loss: 0.562831\n",
      "Train Epoch: 0, mini-batch 22700 of 31, training loss: 0.563094\n",
      "Train Epoch: 0, mini-batch 22710 of 31, training loss: 0.561942\n",
      "Train Epoch: 0, mini-batch 22720 of 31, training loss: 0.562802\n",
      "Train Epoch: 0, mini-batch 22730 of 31, training loss: 0.562002\n",
      "Train Epoch: 0, mini-batch 22740 of 31, training loss: 0.562124\n",
      "Train Epoch: 0, mini-batch 22750 of 31, training loss: 0.561977\n",
      "Train Epoch: 0, mini-batch 22760 of 31, training loss: 0.564250\n",
      "Train Epoch: 0, mini-batch 22770 of 31, training loss: 0.563011\n",
      "Train Epoch: 0, mini-batch 22780 of 31, training loss: 0.562393\n",
      "Train Epoch: 0, mini-batch 22790 of 31, training loss: 0.564128\n",
      "Train Epoch: 0, mini-batch 22800 of 31, training loss: 0.561869\n",
      "Train Epoch: 0, mini-batch 22810 of 31, training loss: 0.564016\n",
      "Train Epoch: 0, mini-batch 22820 of 31, training loss: 0.561880\n",
      "Train Epoch: 0, mini-batch 22830 of 31, training loss: 0.561925\n",
      "Train Epoch: 0, mini-batch 22840 of 31, training loss: 0.561542\n",
      "Train Epoch: 0, mini-batch 22850 of 31, training loss: 0.562813\n",
      "Train Epoch: 0, mini-batch 22860 of 31, training loss: 0.562704\n",
      "Train Epoch: 0, mini-batch 22870 of 31, training loss: 0.562187\n",
      "Train Epoch: 0, mini-batch 22880 of 31, training loss: 0.562775\n",
      "Train Epoch: 0, mini-batch 22890 of 31, training loss: 0.562130\n",
      "Train Epoch: 0, mini-batch 22900 of 31, training loss: 0.562337\n",
      "Train Epoch: 0, mini-batch 22910 of 31, training loss: 0.562606\n",
      "Train Epoch: 0, mini-batch 22920 of 31, training loss: 0.561488\n",
      "Train Epoch: 0, mini-batch 22930 of 31, training loss: 0.562417\n",
      "Train Epoch: 0, mini-batch 22940 of 31, training loss: 0.562461\n",
      "Train Epoch: 0, mini-batch 22950 of 31, training loss: 0.562669\n",
      "Train Epoch: 0, mini-batch 22960 of 31, training loss: 0.561279\n",
      "Train Epoch: 0, mini-batch 22970 of 31, training loss: 0.563391\n",
      "Train Epoch: 0, mini-batch 22980 of 31, training loss: 0.561143\n",
      "Train Epoch: 0, mini-batch 22990 of 31, training loss: 0.561735\n",
      "Train Epoch: 0, mini-batch 23000 of 31, training loss: 0.563240\n",
      "Train Epoch: 0, mini-batch 23010 of 31, training loss: 0.562328\n",
      "Train Epoch: 0, mini-batch 23020 of 31, training loss: 0.562762\n",
      "Train Epoch: 0, mini-batch 23030 of 31, training loss: 0.563096\n",
      "Train Epoch: 0, mini-batch 23040 of 31, training loss: 0.561610\n",
      "Train Epoch: 0, mini-batch 23050 of 31, training loss: 0.562214\n",
      "Train Epoch: 0, mini-batch 23060 of 31, training loss: 0.562417\n",
      "Train Epoch: 0, mini-batch 23070 of 31, training loss: 0.561305\n",
      "Train Epoch: 0, mini-batch 23080 of 31, training loss: 0.562267\n",
      "Train Epoch: 0, mini-batch 23090 of 31, training loss: 0.561958\n",
      "Train Epoch: 0, mini-batch 23100 of 31, training loss: 0.563293\n",
      "Train Epoch: 0, mini-batch 23110 of 31, training loss: 0.563695\n",
      "Train Epoch: 0, mini-batch 23120 of 31, training loss: 0.564841\n",
      "Train Epoch: 0, mini-batch 23130 of 31, training loss: 0.562585\n",
      "Train Epoch: 0, mini-batch 23140 of 31, training loss: 0.562292\n",
      "Train Epoch: 0, mini-batch 23150 of 31, training loss: 0.562456\n",
      "Train Epoch: 0, mini-batch 23160 of 31, training loss: 0.561435\n",
      "Train Epoch: 0, mini-batch 23170 of 31, training loss: 0.562630\n",
      "Train Epoch: 0, mini-batch 23180 of 31, training loss: 0.563367\n",
      "Train Epoch: 0, mini-batch 23190 of 31, training loss: 0.561423\n",
      "Train Epoch: 0, mini-batch 23200 of 31, training loss: 0.561951\n",
      "Train Epoch: 0, mini-batch 23210 of 31, training loss: 0.562757\n",
      "Train Epoch: 0, mini-batch 23220 of 31, training loss: 0.560440\n",
      "Train Epoch: 0, mini-batch 23230 of 31, training loss: 0.562591\n",
      "Train Epoch: 0, mini-batch 23240 of 31, training loss: 0.563008\n",
      "Train Epoch: 0, mini-batch 23250 of 31, training loss: 0.563166\n",
      "Train Epoch: 0, mini-batch 23260 of 31, training loss: 0.563845\n",
      "Train Epoch: 0, mini-batch 23270 of 31, training loss: 0.562468\n",
      "Train Epoch: 0, mini-batch 23280 of 31, training loss: 0.562924\n",
      "Train Epoch: 0, mini-batch 23290 of 31, training loss: 0.562591\n",
      "Train Epoch: 0, mini-batch 23300 of 31, training loss: 0.561635\n",
      "Train Epoch: 0, mini-batch 23310 of 31, training loss: 0.563013\n",
      "Train Epoch: 0, mini-batch 23320 of 31, training loss: 0.561101\n",
      "Train Epoch: 0, mini-batch 23330 of 31, training loss: 0.561759\n",
      "Train Epoch: 0, mini-batch 23340 of 31, training loss: 0.562069\n",
      "Train Epoch: 0, mini-batch 23350 of 31, training loss: 0.563017\n",
      "Train Epoch: 0, mini-batch 23360 of 31, training loss: 0.563100\n",
      "Train Epoch: 0, mini-batch 23370 of 31, training loss: 0.562384\n",
      "Train Epoch: 0, mini-batch 23380 of 31, training loss: 0.563060\n",
      "Train Epoch: 0, mini-batch 23390 of 31, training loss: 0.562666\n",
      "Train Epoch: 0, mini-batch 23400 of 31, training loss: 0.562176\n",
      "Train Epoch: 0, mini-batch 23410 of 31, training loss: 0.562450\n",
      "Train Epoch: 0, mini-batch 23420 of 31, training loss: 0.562747\n",
      "Train Epoch: 0, mini-batch 23430 of 31, training loss: 0.562461\n",
      "Train Epoch: 0, mini-batch 23440 of 31, training loss: 0.561539\n",
      "Train Epoch: 0, mini-batch 23450 of 31, training loss: 0.562570\n",
      "Train Epoch: 0, mini-batch 23460 of 31, training loss: 0.560273\n",
      "Train Epoch: 0, mini-batch 23470 of 31, training loss: 0.560018\n",
      "Train Epoch: 0, mini-batch 23480 of 31, training loss: 0.562318\n",
      "Train Epoch: 0, mini-batch 23490 of 31, training loss: 0.564442\n",
      "Train Epoch: 0, mini-batch 23500 of 31, training loss: 0.564184\n",
      "Train Epoch: 0, mini-batch 23510 of 31, training loss: 0.563688\n",
      "Train Epoch: 0, mini-batch 23520 of 31, training loss: 0.563125\n",
      "Train Epoch: 0, mini-batch 23530 of 31, training loss: 0.563779\n",
      "Train Epoch: 0, mini-batch 23540 of 31, training loss: 0.562930\n",
      "Train Epoch: 0, mini-batch 23550 of 31, training loss: 0.561102\n",
      "Train Epoch: 0, mini-batch 23560 of 31, training loss: 0.562413\n",
      "Train Epoch: 0, mini-batch 23570 of 31, training loss: 0.562854\n",
      "Train Epoch: 0, mini-batch 23580 of 31, training loss: 0.562798\n",
      "Train Epoch: 0, mini-batch 23590 of 31, training loss: 0.562922\n",
      "Train Epoch: 0, mini-batch 23600 of 31, training loss: 0.561176\n",
      "Train Epoch: 0, mini-batch 23610 of 31, training loss: 0.562515\n",
      "Train Epoch: 0, mini-batch 23620 of 31, training loss: 0.563375\n",
      "Train Epoch: 0, mini-batch 23630 of 31, training loss: 0.563265\n",
      "Train Epoch: 0, mini-batch 23640 of 31, training loss: 0.562129\n",
      "Train Epoch: 0, mini-batch 23650 of 31, training loss: 0.563295\n",
      "Train Epoch: 0, mini-batch 23660 of 31, training loss: 0.562861\n",
      "Train Epoch: 0, mini-batch 23670 of 31, training loss: 0.562887\n",
      "Train Epoch: 0, mini-batch 23680 of 31, training loss: 0.562629\n",
      "Train Epoch: 0, mini-batch 23690 of 31, training loss: 0.563323\n",
      "Train Epoch: 0, mini-batch 23700 of 31, training loss: 0.561915\n",
      "Train Epoch: 0, mini-batch 23710 of 31, training loss: 0.562509\n",
      "Train Epoch: 0, mini-batch 23720 of 31, training loss: 0.562112\n",
      "Train Epoch: 0, mini-batch 23730 of 31, training loss: 0.561779\n",
      "Train Epoch: 0, mini-batch 23740 of 31, training loss: 0.562034\n",
      "Train Epoch: 0, mini-batch 23750 of 31, training loss: 0.562353\n",
      "Train Epoch: 0, mini-batch 23760 of 31, training loss: 0.561073\n",
      "Train Epoch: 0, mini-batch 23770 of 31, training loss: 0.562532\n",
      "Train Epoch: 0, mini-batch 23780 of 31, training loss: 0.560675\n",
      "Train Epoch: 0, mini-batch 23790 of 31, training loss: 0.564603\n",
      "Train Epoch: 0, mini-batch 23800 of 31, training loss: 0.562903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 23810 of 31, training loss: 0.560927\n",
      "Train Epoch: 0, mini-batch 23820 of 31, training loss: 0.560053\n",
      "Train Epoch: 0, mini-batch 23830 of 31, training loss: 0.561743\n",
      "Train Epoch: 0, mini-batch 23840 of 31, training loss: 0.563076\n",
      "Train Epoch: 0, mini-batch 23850 of 31, training loss: 0.562173\n",
      "Train Epoch: 0, mini-batch 23860 of 31, training loss: 0.563554\n",
      "Train Epoch: 0, mini-batch 23870 of 31, training loss: 0.561512\n",
      "Train Epoch: 0, mini-batch 23880 of 31, training loss: 0.562672\n",
      "Train Epoch: 0, mini-batch 23890 of 31, training loss: 0.563040\n",
      "Train Epoch: 0, mini-batch 23900 of 31, training loss: 0.562249\n",
      "Train Epoch: 0, mini-batch 23910 of 31, training loss: 0.561392\n",
      "Train Epoch: 0, mini-batch 23920 of 31, training loss: 0.561835\n",
      "Train Epoch: 0, mini-batch 23930 of 31, training loss: 0.562578\n",
      "Train Epoch: 0, mini-batch 23940 of 31, training loss: 0.562621\n",
      "Train Epoch: 0, mini-batch 23950 of 31, training loss: 0.562091\n",
      "Train Epoch: 0, mini-batch 23960 of 31, training loss: 0.561653\n",
      "Train Epoch: 0, mini-batch 23970 of 31, training loss: 0.563525\n",
      "Train Epoch: 0, mini-batch 23980 of 31, training loss: 0.562130\n",
      "Train Epoch: 0, mini-batch 23990 of 31, training loss: 0.560913\n",
      "Train Epoch: 0, mini-batch 24000 of 31, training loss: 0.561764\n",
      "Train Epoch: 0, mini-batch 24010 of 31, training loss: 0.563814\n",
      "Train Epoch: 0, mini-batch 24020 of 31, training loss: 0.562682\n",
      "Train Epoch: 0, mini-batch 24030 of 31, training loss: 0.562761\n",
      "Train Epoch: 0, mini-batch 24040 of 31, training loss: 0.562305\n",
      "Train Epoch: 0, mini-batch 24050 of 31, training loss: 0.561064\n",
      "Train Epoch: 0, mini-batch 24060 of 31, training loss: 0.562915\n",
      "Train Epoch: 0, mini-batch 24070 of 31, training loss: 0.562277\n",
      "Train Epoch: 0, mini-batch 24080 of 31, training loss: 0.563080\n",
      "Train Epoch: 0, mini-batch 24090 of 31, training loss: 0.562683\n",
      "Train Epoch: 0, mini-batch 24100 of 31, training loss: 0.562748\n",
      "Train Epoch: 0, mini-batch 24110 of 31, training loss: 0.562328\n",
      "Train Epoch: 0, mini-batch 24120 of 31, training loss: 0.562161\n",
      "Train Epoch: 0, mini-batch 24130 of 31, training loss: 0.564662\n",
      "Train Epoch: 0, mini-batch 24140 of 31, training loss: 0.562842\n",
      "Train Epoch: 0, mini-batch 24150 of 31, training loss: 0.561830\n",
      "Train Epoch: 0, mini-batch 24160 of 31, training loss: 0.562015\n",
      "Train Epoch: 0, mini-batch 24170 of 31, training loss: 0.561774\n",
      "Train Epoch: 0, mini-batch 24180 of 31, training loss: 0.561583\n",
      "Train Epoch: 0, mini-batch 24190 of 31, training loss: 0.562994\n",
      "Train Epoch: 0, mini-batch 24200 of 31, training loss: 0.562559\n",
      "Train Epoch: 0, mini-batch 24210 of 31, training loss: 0.561416\n",
      "Train Epoch: 0, mini-batch 24220 of 31, training loss: 0.562112\n",
      "Train Epoch: 0, mini-batch 24230 of 31, training loss: 0.563189\n",
      "Train Epoch: 0, mini-batch 24240 of 31, training loss: 0.562350\n",
      "Train Epoch: 0, mini-batch 24250 of 31, training loss: 0.563140\n",
      "Train Epoch: 0, mini-batch 24260 of 31, training loss: 0.562581\n",
      "Train Epoch: 0, mini-batch 24270 of 31, training loss: 0.561741\n",
      "Train Epoch: 0, mini-batch 24280 of 31, training loss: 0.562516\n",
      "Train Epoch: 0, mini-batch 24290 of 31, training loss: 0.564369\n",
      "Train Epoch: 0, mini-batch 24300 of 31, training loss: 0.562502\n",
      "Train Epoch: 0, mini-batch 24310 of 31, training loss: 0.562306\n",
      "Train Epoch: 0, mini-batch 24320 of 31, training loss: 0.561687\n",
      "Train Epoch: 0, mini-batch 24330 of 31, training loss: 0.561598\n",
      "Train Epoch: 0, mini-batch 24340 of 31, training loss: 0.561893\n",
      "Train Epoch: 0, mini-batch 24350 of 31, training loss: 0.561176\n",
      "Train Epoch: 0, mini-batch 24360 of 31, training loss: 0.562660\n",
      "Train Epoch: 0, mini-batch 24370 of 31, training loss: 0.562862\n",
      "Train Epoch: 0, mini-batch 24380 of 31, training loss: 0.560997\n",
      "Train Epoch: 0, mini-batch 24390 of 31, training loss: 0.562910\n",
      "Train Epoch: 0, mini-batch 24400 of 31, training loss: 0.561828\n",
      "Train Epoch: 0, mini-batch 24410 of 31, training loss: 0.562784\n",
      "Train Epoch: 0, mini-batch 24420 of 31, training loss: 0.558916\n",
      "Train Epoch: 0, mini-batch 24430 of 31, training loss: 0.562642\n",
      "Train Epoch: 0, mini-batch 24440 of 31, training loss: 0.563597\n",
      "Train Epoch: 0, mini-batch 24450 of 31, training loss: 0.561988\n",
      "Train Epoch: 0, mini-batch 24460 of 31, training loss: 0.560422\n",
      "Train Epoch: 0, mini-batch 24470 of 31, training loss: 0.562872\n",
      "Train Epoch: 0, mini-batch 24480 of 31, training loss: 0.561186\n",
      "Train Epoch: 0, mini-batch 24490 of 31, training loss: 0.562681\n",
      "Train Epoch: 0, mini-batch 24500 of 31, training loss: 0.560658\n",
      "Train Epoch: 0, mini-batch 24510 of 31, training loss: 0.561349\n",
      "Train Epoch: 0, mini-batch 24520 of 31, training loss: 0.562857\n",
      "Train Epoch: 0, mini-batch 24530 of 31, training loss: 0.562751\n",
      "Train Epoch: 0, mini-batch 24540 of 31, training loss: 0.561975\n",
      "Train Epoch: 0, mini-batch 24550 of 31, training loss: 0.563015\n",
      "Train Epoch: 0, mini-batch 24560 of 31, training loss: 0.563104\n",
      "Train Epoch: 0, mini-batch 24570 of 31, training loss: 0.562955\n",
      "Train Epoch: 0, mini-batch 24580 of 31, training loss: 0.562436\n",
      "Train Epoch: 0, mini-batch 24590 of 31, training loss: 0.562167\n",
      "Train Epoch: 0, mini-batch 24600 of 31, training loss: 0.562884\n",
      "Train Epoch: 0, mini-batch 24610 of 31, training loss: 0.561948\n",
      "Train Epoch: 0, mini-batch 24620 of 31, training loss: 0.564070\n",
      "Train Epoch: 0, mini-batch 24630 of 31, training loss: 0.561663\n",
      "Train Epoch: 0, mini-batch 24640 of 31, training loss: 0.562364\n",
      "Train Epoch: 0, mini-batch 24650 of 31, training loss: 0.563029\n",
      "Train Epoch: 0, mini-batch 24660 of 31, training loss: 0.563841\n",
      "Train Epoch: 0, mini-batch 24670 of 31, training loss: 0.561904\n",
      "Train Epoch: 0, mini-batch 24680 of 31, training loss: 0.562120\n",
      "Train Epoch: 0, mini-batch 24690 of 31, training loss: 0.562669\n",
      "Train Epoch: 0, mini-batch 24700 of 31, training loss: 0.561345\n",
      "Train Epoch: 0, mini-batch 24710 of 31, training loss: 0.562695\n",
      "Train Epoch: 0, mini-batch 24720 of 31, training loss: 0.562015\n",
      "Train Epoch: 0, mini-batch 24730 of 31, training loss: 0.562681\n",
      "Train Epoch: 0, mini-batch 24740 of 31, training loss: 0.563020\n",
      "Train Epoch: 0, mini-batch 24750 of 31, training loss: 0.562125\n",
      "Train Epoch: 0, mini-batch 24760 of 31, training loss: 0.563563\n",
      "Train Epoch: 0, mini-batch 24770 of 31, training loss: 0.560522\n",
      "Train Epoch: 0, mini-batch 24780 of 31, training loss: 0.565012\n",
      "Train Epoch: 0, mini-batch 24790 of 31, training loss: 0.563297\n",
      "Train Epoch: 0, mini-batch 24800 of 31, training loss: 0.563321\n",
      "Train Epoch: 0, mini-batch 24810 of 31, training loss: 0.559736\n",
      "Train Epoch: 0, mini-batch 24820 of 31, training loss: 0.564646\n",
      "Train Epoch: 0, mini-batch 24830 of 31, training loss: 0.562650\n",
      "Train Epoch: 0, mini-batch 24840 of 31, training loss: 0.563770\n",
      "Train Epoch: 0, mini-batch 24850 of 31, training loss: 0.562220\n",
      "Train Epoch: 0, mini-batch 24860 of 31, training loss: 0.562514\n",
      "Train Epoch: 0, mini-batch 24870 of 31, training loss: 0.562566\n",
      "Train Epoch: 0, mini-batch 24880 of 31, training loss: 0.562138\n",
      "Train Epoch: 0, mini-batch 24890 of 31, training loss: 0.562623\n",
      "Train Epoch: 0, mini-batch 24900 of 31, training loss: 0.562588\n",
      "Train Epoch: 0, mini-batch 24910 of 31, training loss: 0.562944\n",
      "Train Epoch: 0, mini-batch 24920 of 31, training loss: 0.562662\n",
      "Train Epoch: 0, mini-batch 24930 of 31, training loss: 0.561739\n",
      "Train Epoch: 0, mini-batch 24940 of 31, training loss: 0.561200\n",
      "Train Epoch: 0, mini-batch 24950 of 31, training loss: 0.562793\n",
      "Train Epoch: 0, mini-batch 24960 of 31, training loss: 0.563189\n",
      "Train Epoch: 0, mini-batch 24970 of 31, training loss: 0.563458\n",
      "Train Epoch: 0, mini-batch 24980 of 31, training loss: 0.561517\n",
      "Train Epoch: 0, mini-batch 24990 of 31, training loss: 0.562610\n",
      "Train Epoch: 0, mini-batch 25000 of 31, training loss: 0.562406\n",
      "Train Epoch: 0, mini-batch 25010 of 31, training loss: 0.565160\n",
      "Train Epoch: 0, mini-batch 25020 of 31, training loss: 0.561954\n",
      "Train Epoch: 0, mini-batch 25030 of 31, training loss: 0.562246\n",
      "Train Epoch: 0, mini-batch 25040 of 31, training loss: 0.562865\n",
      "Train Epoch: 0, mini-batch 25050 of 31, training loss: 0.561539\n",
      "Train Epoch: 0, mini-batch 25060 of 31, training loss: 0.560069\n",
      "Train Epoch: 0, mini-batch 25070 of 31, training loss: 0.562433\n",
      "Train Epoch: 0, mini-batch 25080 of 31, training loss: 0.561206\n",
      "Train Epoch: 0, mini-batch 25090 of 31, training loss: 0.562616\n",
      "Train Epoch: 0, mini-batch 25100 of 31, training loss: 0.562029\n",
      "Train Epoch: 0, mini-batch 25110 of 31, training loss: 0.563539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 25120 of 31, training loss: 0.564556\n",
      "Train Epoch: 0, mini-batch 25130 of 31, training loss: 0.562788\n",
      "Train Epoch: 0, mini-batch 25140 of 31, training loss: 0.562046\n",
      "Train Epoch: 0, mini-batch 25150 of 31, training loss: 0.562181\n",
      "Train Epoch: 0, mini-batch 25160 of 31, training loss: 0.561667\n",
      "Train Epoch: 0, mini-batch 25170 of 31, training loss: 0.564103\n",
      "Train Epoch: 0, mini-batch 25180 of 31, training loss: 0.563208\n",
      "Train Epoch: 0, mini-batch 25190 of 31, training loss: 0.562054\n",
      "Train Epoch: 0, mini-batch 25200 of 31, training loss: 0.562211\n",
      "Train Epoch: 0, mini-batch 25210 of 31, training loss: 0.560144\n",
      "Train Epoch: 0, mini-batch 25220 of 31, training loss: 0.563472\n",
      "Train Epoch: 0, mini-batch 25230 of 31, training loss: 0.563647\n",
      "Train Epoch: 0, mini-batch 25240 of 31, training loss: 0.562368\n",
      "Train Epoch: 0, mini-batch 25250 of 31, training loss: 0.563182\n",
      "Train Epoch: 0, mini-batch 25260 of 31, training loss: 0.561094\n",
      "Train Epoch: 0, mini-batch 25270 of 31, training loss: 0.560941\n",
      "Train Epoch: 0, mini-batch 25280 of 31, training loss: 0.564703\n",
      "Train Epoch: 0, mini-batch 25290 of 31, training loss: 0.562223\n",
      "Train Epoch: 0, mini-batch 25300 of 31, training loss: 0.563811\n",
      "Train Epoch: 0, mini-batch 25310 of 31, training loss: 0.561795\n",
      "Train Epoch: 0, mini-batch 25320 of 31, training loss: 0.562692\n",
      "Train Epoch: 0, mini-batch 25330 of 31, training loss: 0.562679\n",
      "Train Epoch: 0, mini-batch 25340 of 31, training loss: 0.561871\n",
      "Train Epoch: 0, mini-batch 25350 of 31, training loss: 0.561096\n",
      "Train Epoch: 0, mini-batch 25360 of 31, training loss: 0.562626\n",
      "Train Epoch: 0, mini-batch 25370 of 31, training loss: 0.559036\n",
      "Train Epoch: 0, mini-batch 25380 of 31, training loss: 0.564755\n",
      "Train Epoch: 0, mini-batch 25390 of 31, training loss: 0.562712\n",
      "Train Epoch: 0, mini-batch 25400 of 31, training loss: 0.563223\n",
      "Train Epoch: 0, mini-batch 25410 of 31, training loss: 0.562703\n",
      "Train Epoch: 0, mini-batch 25420 of 31, training loss: 0.562481\n",
      "Train Epoch: 0, mini-batch 25430 of 31, training loss: 0.563860\n",
      "Train Epoch: 0, mini-batch 25440 of 31, training loss: 0.562742\n",
      "Train Epoch: 0, mini-batch 25450 of 31, training loss: 0.562921\n",
      "Train Epoch: 0, mini-batch 25460 of 31, training loss: 0.563034\n",
      "Train Epoch: 0, mini-batch 25470 of 31, training loss: 0.562731\n",
      "Train Epoch: 0, mini-batch 25480 of 31, training loss: 0.562540\n",
      "Train Epoch: 0, mini-batch 25490 of 31, training loss: 0.562265\n",
      "Train Epoch: 0, mini-batch 25500 of 31, training loss: 0.562835\n",
      "Train Epoch: 0, mini-batch 25510 of 31, training loss: 0.562503\n",
      "Train Epoch: 0, mini-batch 25520 of 31, training loss: 0.562517\n",
      "Train Epoch: 0, mini-batch 25530 of 31, training loss: 0.561836\n",
      "Train Epoch: 0, mini-batch 25540 of 31, training loss: 0.563577\n",
      "Train Epoch: 0, mini-batch 25550 of 31, training loss: 0.563124\n",
      "Train Epoch: 0, mini-batch 25560 of 31, training loss: 0.563589\n",
      "Train Epoch: 0, mini-batch 25570 of 31, training loss: 0.562856\n",
      "Train Epoch: 0, mini-batch 25580 of 31, training loss: 0.563049\n",
      "Train Epoch: 0, mini-batch 25590 of 31, training loss: 0.562781\n",
      "Train Epoch: 0, mini-batch 25600 of 31, training loss: 0.563227\n",
      "Train Epoch: 0, mini-batch 25610 of 31, training loss: 0.562325\n",
      "Train Epoch: 0, mini-batch 25620 of 31, training loss: 0.562006\n",
      "Train Epoch: 0, mini-batch 25630 of 31, training loss: 0.563444\n",
      "Train Epoch: 0, mini-batch 25640 of 31, training loss: 0.561865\n",
      "Train Epoch: 0, mini-batch 25650 of 31, training loss: 0.561427\n",
      "Train Epoch: 0, mini-batch 25660 of 31, training loss: 0.560827\n",
      "Train Epoch: 0, mini-batch 25670 of 31, training loss: 0.563873\n",
      "Train Epoch: 0, mini-batch 25680 of 31, training loss: 0.561165\n",
      "Train Epoch: 0, mini-batch 25690 of 31, training loss: 0.562296\n",
      "Train Epoch: 0, mini-batch 25700 of 31, training loss: 0.562412\n",
      "Train Epoch: 0, mini-batch 25710 of 31, training loss: 0.562959\n",
      "Train Epoch: 0, mini-batch 25720 of 31, training loss: 0.562442\n",
      "Train Epoch: 0, mini-batch 25730 of 31, training loss: 0.561865\n",
      "Train Epoch: 0, mini-batch 25740 of 31, training loss: 0.565199\n",
      "Train Epoch: 0, mini-batch 25750 of 31, training loss: 0.562011\n",
      "Train Epoch: 0, mini-batch 25760 of 31, training loss: 0.562740\n",
      "Train Epoch: 0, mini-batch 25770 of 31, training loss: 0.562839\n",
      "Train Epoch: 0, mini-batch 25780 of 31, training loss: 0.561762\n",
      "Train Epoch: 0, mini-batch 25790 of 31, training loss: 0.562893\n",
      "Train Epoch: 0, mini-batch 25800 of 31, training loss: 0.561801\n",
      "Train Epoch: 0, mini-batch 25810 of 31, training loss: 0.561604\n",
      "Train Epoch: 0, mini-batch 25820 of 31, training loss: 0.560138\n",
      "Train Epoch: 0, mini-batch 25830 of 31, training loss: 0.561106\n",
      "Train Epoch: 0, mini-batch 25840 of 31, training loss: 0.562945\n",
      "Train Epoch: 0, mini-batch 25850 of 31, training loss: 0.561276\n",
      "Train Epoch: 0, mini-batch 25860 of 31, training loss: 0.561925\n",
      "Train Epoch: 0, mini-batch 25870 of 31, training loss: 0.562714\n",
      "Train Epoch: 0, mini-batch 25880 of 31, training loss: 0.562453\n",
      "Train Epoch: 0, mini-batch 25890 of 31, training loss: 0.563645\n",
      "Train Epoch: 0, mini-batch 25900 of 31, training loss: 0.562510\n",
      "Train Epoch: 0, mini-batch 25910 of 31, training loss: 0.562847\n",
      "Train Epoch: 0, mini-batch 25920 of 31, training loss: 0.563315\n",
      "Train Epoch: 0, mini-batch 25930 of 31, training loss: 0.560783\n",
      "Train Epoch: 0, mini-batch 25940 of 31, training loss: 0.562683\n",
      "Train Epoch: 0, mini-batch 25950 of 31, training loss: 0.561683\n",
      "Train Epoch: 0, mini-batch 25960 of 31, training loss: 0.567653\n",
      "Train Epoch: 0, mini-batch 25970 of 31, training loss: 0.561850\n",
      "Train Epoch: 0, mini-batch 25980 of 31, training loss: 0.559479\n",
      "Train Epoch: 0, mini-batch 25990 of 31, training loss: 0.564087\n",
      "Train Epoch: 0, mini-batch 26000 of 31, training loss: 0.563877\n",
      "Train Epoch: 0, mini-batch 26010 of 31, training loss: 0.561624\n",
      "Train Epoch: 0, mini-batch 26020 of 31, training loss: 0.562234\n",
      "Train Epoch: 0, mini-batch 26030 of 31, training loss: 0.562590\n",
      "Train Epoch: 0, mini-batch 26040 of 31, training loss: 0.560741\n",
      "Train Epoch: 0, mini-batch 26050 of 31, training loss: 0.558939\n",
      "Train Epoch: 0, mini-batch 26060 of 31, training loss: 0.561441\n",
      "Train Epoch: 0, mini-batch 26070 of 31, training loss: 0.563489\n",
      "Train Epoch: 0, mini-batch 26080 of 31, training loss: 0.563078\n",
      "Train Epoch: 0, mini-batch 26090 of 31, training loss: 0.562550\n",
      "Train Epoch: 0, mini-batch 26100 of 31, training loss: 0.564098\n",
      "Train Epoch: 0, mini-batch 26110 of 31, training loss: 0.561273\n",
      "Train Epoch: 0, mini-batch 26120 of 31, training loss: 0.564199\n",
      "Train Epoch: 0, mini-batch 26130 of 31, training loss: 0.563178\n",
      "Train Epoch: 0, mini-batch 26140 of 31, training loss: 0.562861\n",
      "Train Epoch: 0, mini-batch 26150 of 31, training loss: 0.561667\n",
      "Train Epoch: 0, mini-batch 26160 of 31, training loss: 0.561757\n",
      "Train Epoch: 0, mini-batch 26170 of 31, training loss: 0.563309\n",
      "Train Epoch: 0, mini-batch 26180 of 31, training loss: 0.562201\n",
      "Train Epoch: 0, mini-batch 26190 of 31, training loss: 0.561144\n",
      "Train Epoch: 0, mini-batch 26200 of 31, training loss: 0.562294\n",
      "Train Epoch: 0, mini-batch 26210 of 31, training loss: 0.562214\n",
      "Train Epoch: 0, mini-batch 26220 of 31, training loss: 0.562313\n",
      "Train Epoch: 0, mini-batch 26230 of 31, training loss: 0.562021\n",
      "Train Epoch: 0, mini-batch 26240 of 31, training loss: 0.562383\n",
      "Train Epoch: 0, mini-batch 26250 of 31, training loss: 0.562682\n",
      "Train Epoch: 0, mini-batch 26260 of 31, training loss: 0.561883\n",
      "Train Epoch: 0, mini-batch 26270 of 31, training loss: 0.562291\n",
      "Train Epoch: 0, mini-batch 26280 of 31, training loss: 0.562163\n",
      "Train Epoch: 0, mini-batch 26290 of 31, training loss: 0.563619\n",
      "Train Epoch: 0, mini-batch 26300 of 31, training loss: 0.561788\n",
      "Train Epoch: 0, mini-batch 26310 of 31, training loss: 0.562169\n",
      "Train Epoch: 0, mini-batch 26320 of 31, training loss: 0.561143\n",
      "Train Epoch: 0, mini-batch 26330 of 31, training loss: 0.562761\n",
      "Train Epoch: 0, mini-batch 26340 of 31, training loss: 0.563105\n",
      "Train Epoch: 0, mini-batch 26350 of 31, training loss: 0.561955\n",
      "Train Epoch: 0, mini-batch 26360 of 31, training loss: 0.562513\n",
      "Train Epoch: 0, mini-batch 26370 of 31, training loss: 0.562937\n",
      "Train Epoch: 0, mini-batch 26380 of 31, training loss: 0.561362\n",
      "Train Epoch: 0, mini-batch 26390 of 31, training loss: 0.561756\n",
      "Train Epoch: 0, mini-batch 26400 of 31, training loss: 0.561930\n",
      "Train Epoch: 0, mini-batch 26410 of 31, training loss: 0.559628\n",
      "Train Epoch: 0, mini-batch 26420 of 31, training loss: 0.564165\n",
      "Train Epoch: 0, mini-batch 26430 of 31, training loss: 0.563161\n",
      "Train Epoch: 0, mini-batch 26440 of 31, training loss: 0.561260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 26450 of 31, training loss: 0.559494\n",
      "Train Epoch: 0, mini-batch 26460 of 31, training loss: 0.564203\n",
      "Train Epoch: 0, mini-batch 26470 of 31, training loss: 0.562104\n",
      "Train Epoch: 0, mini-batch 26480 of 31, training loss: 0.566260\n",
      "Train Epoch: 0, mini-batch 26490 of 31, training loss: 0.563691\n",
      "Train Epoch: 0, mini-batch 26500 of 31, training loss: 0.563927\n",
      "Train Epoch: 0, mini-batch 26510 of 31, training loss: 0.564028\n",
      "Train Epoch: 0, mini-batch 26520 of 31, training loss: 0.564199\n",
      "Train Epoch: 0, mini-batch 26530 of 31, training loss: 0.561424\n",
      "Train Epoch: 0, mini-batch 26540 of 31, training loss: 0.561606\n",
      "Train Epoch: 0, mini-batch 26550 of 31, training loss: 0.562555\n",
      "Train Epoch: 0, mini-batch 26560 of 31, training loss: 0.562814\n",
      "Train Epoch: 0, mini-batch 26570 of 31, training loss: 0.562176\n",
      "Train Epoch: 0, mini-batch 26580 of 31, training loss: 0.561097\n",
      "Train Epoch: 0, mini-batch 26590 of 31, training loss: 0.562921\n",
      "Train Epoch: 0, mini-batch 26600 of 31, training loss: 0.564558\n",
      "Train Epoch: 0, mini-batch 26610 of 31, training loss: 0.563230\n",
      "Train Epoch: 0, mini-batch 26620 of 31, training loss: 0.562459\n",
      "Train Epoch: 0, mini-batch 26630 of 31, training loss: 0.561939\n",
      "Train Epoch: 0, mini-batch 26640 of 31, training loss: 0.561198\n",
      "Train Epoch: 0, mini-batch 26650 of 31, training loss: 0.561023\n",
      "Train Epoch: 0, mini-batch 26660 of 31, training loss: 0.563518\n",
      "Train Epoch: 0, mini-batch 26670 of 31, training loss: 0.562405\n",
      "Train Epoch: 0, mini-batch 26680 of 31, training loss: 0.561848\n",
      "Train Epoch: 0, mini-batch 26690 of 31, training loss: 0.562159\n",
      "Train Epoch: 0, mini-batch 26700 of 31, training loss: 0.560421\n",
      "Train Epoch: 0, mini-batch 26710 of 31, training loss: 0.562218\n",
      "Train Epoch: 0, mini-batch 26720 of 31, training loss: 0.563840\n",
      "Train Epoch: 0, mini-batch 26730 of 31, training loss: 0.563564\n",
      "Train Epoch: 0, mini-batch 26740 of 31, training loss: 0.561723\n",
      "Train Epoch: 0, mini-batch 26750 of 31, training loss: 0.562331\n",
      "Train Epoch: 0, mini-batch 26760 of 31, training loss: 0.562704\n",
      "Train Epoch: 0, mini-batch 26770 of 31, training loss: 0.560515\n",
      "Train Epoch: 0, mini-batch 26780 of 31, training loss: 0.562206\n",
      "Train Epoch: 0, mini-batch 26790 of 31, training loss: 0.562418\n",
      "Train Epoch: 0, mini-batch 26800 of 31, training loss: 0.560014\n",
      "Train Epoch: 0, mini-batch 26810 of 31, training loss: 0.562860\n",
      "Train Epoch: 0, mini-batch 26820 of 31, training loss: 0.562964\n",
      "Train Epoch: 0, mini-batch 26830 of 31, training loss: 0.563023\n",
      "Train Epoch: 0, mini-batch 26840 of 31, training loss: 0.562242\n",
      "Train Epoch: 0, mini-batch 26850 of 31, training loss: 0.561585\n",
      "Train Epoch: 0, mini-batch 26860 of 31, training loss: 0.562392\n",
      "Train Epoch: 0, mini-batch 26870 of 31, training loss: 0.561406\n",
      "Train Epoch: 0, mini-batch 26880 of 31, training loss: 0.564084\n",
      "Train Epoch: 0, mini-batch 26890 of 31, training loss: 0.561556\n",
      "Train Epoch: 0, mini-batch 26900 of 31, training loss: 0.562394\n",
      "Train Epoch: 0, mini-batch 26910 of 31, training loss: 0.561603\n",
      "Train Epoch: 0, mini-batch 26920 of 31, training loss: 0.563040\n",
      "Train Epoch: 0, mini-batch 26930 of 31, training loss: 0.562447\n",
      "Train Epoch: 0, mini-batch 26940 of 31, training loss: 0.561333\n",
      "Train Epoch: 0, mini-batch 26950 of 31, training loss: 0.563127\n",
      "Train Epoch: 0, mini-batch 26960 of 31, training loss: 0.561125\n",
      "Train Epoch: 0, mini-batch 26970 of 31, training loss: 0.562378\n",
      "Train Epoch: 0, mini-batch 26980 of 31, training loss: 0.562056\n",
      "Train Epoch: 0, mini-batch 26990 of 31, training loss: 0.562714\n",
      "Train Epoch: 0, mini-batch 27000 of 31, training loss: 0.563145\n",
      "Train Epoch: 0, mini-batch 27010 of 31, training loss: 0.562249\n",
      "Train Epoch: 0, mini-batch 27020 of 31, training loss: 0.562534\n",
      "Train Epoch: 0, mini-batch 27030 of 31, training loss: 0.560363\n",
      "Train Epoch: 0, mini-batch 27040 of 31, training loss: 0.563566\n",
      "Train Epoch: 0, mini-batch 27050 of 31, training loss: 0.560444\n",
      "Train Epoch: 0, mini-batch 27060 of 31, training loss: 0.563266\n",
      "Train Epoch: 0, mini-batch 27070 of 31, training loss: 0.564198\n",
      "Train Epoch: 0, mini-batch 27080 of 31, training loss: 0.563087\n",
      "Train Epoch: 0, mini-batch 27090 of 31, training loss: 0.561360\n",
      "Train Epoch: 0, mini-batch 27100 of 31, training loss: 0.563109\n",
      "Train Epoch: 0, mini-batch 27110 of 31, training loss: 0.563822\n",
      "Train Epoch: 0, mini-batch 27120 of 31, training loss: 0.562527\n",
      "Train Epoch: 0, mini-batch 27130 of 31, training loss: 0.563496\n",
      "Train Epoch: 0, mini-batch 27140 of 31, training loss: 0.561866\n",
      "Train Epoch: 0, mini-batch 27150 of 31, training loss: 0.563261\n",
      "Train Epoch: 0, mini-batch 27160 of 31, training loss: 0.562752\n",
      "Train Epoch: 0, mini-batch 27170 of 31, training loss: 0.561408\n",
      "Train Epoch: 0, mini-batch 27180 of 31, training loss: 0.561807\n",
      "Train Epoch: 0, mini-batch 27190 of 31, training loss: 0.561471\n",
      "Train Epoch: 0, mini-batch 27200 of 31, training loss: 0.563109\n",
      "Train Epoch: 0, mini-batch 27210 of 31, training loss: 0.561962\n",
      "Train Epoch: 0, mini-batch 27220 of 31, training loss: 0.564916\n",
      "Train Epoch: 0, mini-batch 27230 of 31, training loss: 0.561778\n",
      "Train Epoch: 0, mini-batch 27240 of 31, training loss: 0.563120\n",
      "Train Epoch: 0, mini-batch 27250 of 31, training loss: 0.562716\n",
      "Train Epoch: 0, mini-batch 27260 of 31, training loss: 0.561979\n",
      "Train Epoch: 0, mini-batch 27270 of 31, training loss: 0.563230\n",
      "Train Epoch: 0, mini-batch 27280 of 31, training loss: 0.561633\n",
      "Train Epoch: 0, mini-batch 27290 of 31, training loss: 0.562349\n",
      "Train Epoch: 0, mini-batch 27300 of 31, training loss: 0.563223\n",
      "Train Epoch: 0, mini-batch 27310 of 31, training loss: 0.562473\n",
      "Train Epoch: 0, mini-batch 27320 of 31, training loss: 0.561734\n",
      "Train Epoch: 0, mini-batch 27330 of 31, training loss: 0.562471\n",
      "Train Epoch: 0, mini-batch 27340 of 31, training loss: 0.564857\n",
      "Train Epoch: 0, mini-batch 27350 of 31, training loss: 0.561939\n",
      "Train Epoch: 0, mini-batch 27360 of 31, training loss: 0.563275\n",
      "Train Epoch: 0, mini-batch 27370 of 31, training loss: 0.561889\n",
      "Train Epoch: 0, mini-batch 27380 of 31, training loss: 0.562722\n",
      "Train Epoch: 0, mini-batch 27390 of 31, training loss: 0.561123\n",
      "Train Epoch: 0, mini-batch 27400 of 31, training loss: 0.561876\n",
      "Train Epoch: 0, mini-batch 27410 of 31, training loss: 0.564855\n",
      "Train Epoch: 0, mini-batch 27420 of 31, training loss: 0.564879\n",
      "Train Epoch: 0, mini-batch 27430 of 31, training loss: 0.561711\n",
      "Train Epoch: 0, mini-batch 27440 of 31, training loss: 0.562072\n",
      "Train Epoch: 0, mini-batch 27450 of 31, training loss: 0.562284\n",
      "Train Epoch: 0, mini-batch 27460 of 31, training loss: 0.562910\n",
      "Train Epoch: 0, mini-batch 27470 of 31, training loss: 0.561304\n",
      "Train Epoch: 0, mini-batch 27480 of 31, training loss: 0.561079\n",
      "Train Epoch: 0, mini-batch 27490 of 31, training loss: 0.561751\n",
      "Train Epoch: 0, mini-batch 27500 of 31, training loss: 0.562972\n",
      "Train Epoch: 0, mini-batch 27510 of 31, training loss: 0.562323\n",
      "Train Epoch: 0, mini-batch 27520 of 31, training loss: 0.563353\n",
      "Train Epoch: 0, mini-batch 27530 of 31, training loss: 0.563060\n",
      "Train Epoch: 0, mini-batch 27540 of 31, training loss: 0.562140\n",
      "Train Epoch: 0, mini-batch 27550 of 31, training loss: 0.563128\n",
      "Train Epoch: 0, mini-batch 27560 of 31, training loss: 0.562644\n",
      "Train Epoch: 0, mini-batch 27570 of 31, training loss: 0.562163\n",
      "Train Epoch: 0, mini-batch 27580 of 31, training loss: 0.562631\n",
      "Train Epoch: 0, mini-batch 27590 of 31, training loss: 0.563675\n",
      "Train Epoch: 0, mini-batch 27600 of 31, training loss: 0.562274\n",
      "Train Epoch: 0, mini-batch 27610 of 31, training loss: 0.561571\n",
      "Train Epoch: 0, mini-batch 27620 of 31, training loss: 0.561803\n",
      "Train Epoch: 0, mini-batch 27630 of 31, training loss: 0.562024\n",
      "Train Epoch: 0, mini-batch 27640 of 31, training loss: 0.563357\n",
      "Train Epoch: 0, mini-batch 27650 of 31, training loss: 0.561526\n",
      "Train Epoch: 0, mini-batch 27660 of 31, training loss: 0.561476\n",
      "Train Epoch: 0, mini-batch 27670 of 31, training loss: 0.562251\n",
      "Train Epoch: 0, mini-batch 27680 of 31, training loss: 0.561027\n",
      "Train Epoch: 0, mini-batch 27690 of 31, training loss: 0.564541\n",
      "Train Epoch: 0, mini-batch 27700 of 31, training loss: 0.562920\n",
      "Train Epoch: 0, mini-batch 27710 of 31, training loss: 0.562816\n",
      "Train Epoch: 0, mini-batch 27720 of 31, training loss: 0.562843\n",
      "Train Epoch: 0, mini-batch 27730 of 31, training loss: 0.562251\n",
      "Train Epoch: 0, mini-batch 27740 of 31, training loss: 0.562605\n",
      "Train Epoch: 0, mini-batch 27750 of 31, training loss: 0.561442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 27760 of 31, training loss: 0.561935\n",
      "Train Epoch: 0, mini-batch 27770 of 31, training loss: 0.562040\n",
      "Train Epoch: 0, mini-batch 27780 of 31, training loss: 0.561014\n",
      "Train Epoch: 0, mini-batch 27790 of 31, training loss: 0.561541\n",
      "Train Epoch: 0, mini-batch 27800 of 31, training loss: 0.561498\n",
      "Train Epoch: 0, mini-batch 27810 of 31, training loss: 0.561306\n",
      "Train Epoch: 0, mini-batch 27820 of 31, training loss: 0.561098\n",
      "Train Epoch: 0, mini-batch 27830 of 31, training loss: 0.563575\n",
      "Train Epoch: 0, mini-batch 27840 of 31, training loss: 0.560221\n",
      "Train Epoch: 0, mini-batch 27850 of 31, training loss: 0.559628\n",
      "Train Epoch: 0, mini-batch 27860 of 31, training loss: 0.560706\n",
      "Train Epoch: 0, mini-batch 27870 of 31, training loss: 0.561824\n",
      "Train Epoch: 0, mini-batch 27880 of 31, training loss: 0.560933\n",
      "Train Epoch: 0, mini-batch 27890 of 31, training loss: 0.560678\n",
      "Train Epoch: 0, mini-batch 27900 of 31, training loss: 0.562795\n",
      "Train Epoch: 0, mini-batch 27910 of 31, training loss: 0.561734\n",
      "Train Epoch: 0, mini-batch 27920 of 31, training loss: 0.562704\n",
      "Train Epoch: 0, mini-batch 27930 of 31, training loss: 0.561148\n",
      "Train Epoch: 0, mini-batch 27940 of 31, training loss: 0.563536\n",
      "Train Epoch: 0, mini-batch 27950 of 31, training loss: 0.561998\n",
      "Train Epoch: 0, mini-batch 27960 of 31, training loss: 0.560526\n",
      "Train Epoch: 0, mini-batch 27970 of 31, training loss: 0.560029\n",
      "Train Epoch: 0, mini-batch 27980 of 31, training loss: 0.563172\n",
      "Train Epoch: 0, mini-batch 27990 of 31, training loss: 0.561533\n",
      "Train Epoch: 0, mini-batch 28000 of 31, training loss: 0.562187\n",
      "Train Epoch: 0, mini-batch 28010 of 31, training loss: 0.561619\n",
      "Train Epoch: 0, mini-batch 28020 of 31, training loss: 0.562199\n",
      "Train Epoch: 0, mini-batch 28030 of 31, training loss: 0.562448\n",
      "Train Epoch: 0, mini-batch 28040 of 31, training loss: 0.564803\n",
      "Train Epoch: 0, mini-batch 28050 of 31, training loss: 0.563924\n",
      "Train Epoch: 0, mini-batch 28060 of 31, training loss: 0.560901\n",
      "Train Epoch: 0, mini-batch 28070 of 31, training loss: 0.561182\n",
      "Train Epoch: 0, mini-batch 28080 of 31, training loss: 0.563028\n",
      "Train Epoch: 0, mini-batch 28090 of 31, training loss: 0.561700\n",
      "Train Epoch: 0, mini-batch 28100 of 31, training loss: 0.562311\n",
      "Train Epoch: 0, mini-batch 28110 of 31, training loss: 0.565515\n",
      "Train Epoch: 0, mini-batch 28120 of 31, training loss: 0.562794\n",
      "Train Epoch: 0, mini-batch 28130 of 31, training loss: 0.562672\n",
      "Train Epoch: 0, mini-batch 28140 of 31, training loss: 0.564762\n",
      "Train Epoch: 0, mini-batch 28150 of 31, training loss: 0.559905\n",
      "Train Epoch: 0, mini-batch 28160 of 31, training loss: 0.561766\n",
      "Train Epoch: 0, mini-batch 28170 of 31, training loss: 0.561185\n",
      "Train Epoch: 0, mini-batch 28180 of 31, training loss: 0.556826\n",
      "Train Epoch: 0, mini-batch 28190 of 31, training loss: 0.563765\n",
      "Train Epoch: 0, mini-batch 28200 of 31, training loss: 0.565366\n",
      "Train Epoch: 0, mini-batch 28210 of 31, training loss: 0.561765\n",
      "Train Epoch: 0, mini-batch 28220 of 31, training loss: 0.563124\n",
      "Train Epoch: 0, mini-batch 28230 of 31, training loss: 0.564406\n",
      "Train Epoch: 0, mini-batch 28240 of 31, training loss: 0.561712\n",
      "Train Epoch: 0, mini-batch 28250 of 31, training loss: 0.564806\n",
      "Train Epoch: 0, mini-batch 28260 of 31, training loss: 0.563350\n",
      "Train Epoch: 0, mini-batch 28270 of 31, training loss: 0.563745\n",
      "Train Epoch: 0, mini-batch 28280 of 31, training loss: 0.562789\n",
      "Train Epoch: 0, mini-batch 28290 of 31, training loss: 0.561954\n",
      "Train Epoch: 0, mini-batch 28300 of 31, training loss: 0.562474\n",
      "Train Epoch: 0, mini-batch 28310 of 31, training loss: 0.562316\n",
      "Train Epoch: 0, mini-batch 28320 of 31, training loss: 0.563188\n",
      "Train Epoch: 0, mini-batch 28330 of 31, training loss: 0.560846\n",
      "Train Epoch: 0, mini-batch 28340 of 31, training loss: 0.561648\n",
      "Train Epoch: 0, mini-batch 28350 of 31, training loss: 0.563118\n",
      "Train Epoch: 0, mini-batch 28360 of 31, training loss: 0.561909\n",
      "Train Epoch: 0, mini-batch 28370 of 31, training loss: 0.562567\n",
      "Train Epoch: 0, mini-batch 28380 of 31, training loss: 0.561675\n",
      "Train Epoch: 0, mini-batch 28390 of 31, training loss: 0.562320\n",
      "Train Epoch: 0, mini-batch 28400 of 31, training loss: 0.562731\n",
      "Train Epoch: 0, mini-batch 28410 of 31, training loss: 0.562597\n",
      "Train Epoch: 0, mini-batch 28420 of 31, training loss: 0.563754\n",
      "Train Epoch: 0, mini-batch 28430 of 31, training loss: 0.561955\n",
      "Train Epoch: 0, mini-batch 28440 of 31, training loss: 0.561968\n",
      "Train Epoch: 0, mini-batch 28450 of 31, training loss: 0.561430\n",
      "Train Epoch: 0, mini-batch 28460 of 31, training loss: 0.561984\n",
      "Train Epoch: 0, mini-batch 28470 of 31, training loss: 0.561917\n",
      "Train Epoch: 0, mini-batch 28480 of 31, training loss: 0.561973\n",
      "Train Epoch: 0, mini-batch 28490 of 31, training loss: 0.562349\n",
      "Train Epoch: 0, mini-batch 28500 of 31, training loss: 0.562208\n",
      "Train Epoch: 0, mini-batch 28510 of 31, training loss: 0.562411\n",
      "Train Epoch: 0, mini-batch 28520 of 31, training loss: 0.562506\n",
      "Train Epoch: 0, mini-batch 28530 of 31, training loss: 0.562369\n",
      "Train Epoch: 0, mini-batch 28540 of 31, training loss: 0.562663\n",
      "Train Epoch: 0, mini-batch 28550 of 31, training loss: 0.562511\n",
      "Train Epoch: 0, mini-batch 28560 of 31, training loss: 0.561954\n",
      "Train Epoch: 0, mini-batch 28570 of 31, training loss: 0.562584\n",
      "Train Epoch: 0, mini-batch 28580 of 31, training loss: 0.562731\n",
      "Train Epoch: 0, mini-batch 28590 of 31, training loss: 0.562121\n",
      "Train Epoch: 0, mini-batch 28600 of 31, training loss: 0.560562\n",
      "Train Epoch: 0, mini-batch 28610 of 31, training loss: 0.562240\n",
      "Train Epoch: 0, mini-batch 28620 of 31, training loss: 0.562645\n",
      "Train Epoch: 0, mini-batch 28630 of 31, training loss: 0.562019\n",
      "Train Epoch: 0, mini-batch 28640 of 31, training loss: 0.562207\n",
      "Train Epoch: 0, mini-batch 28650 of 31, training loss: 0.562117\n",
      "Train Epoch: 0, mini-batch 28660 of 31, training loss: 0.562997\n",
      "Train Epoch: 0, mini-batch 28670 of 31, training loss: 0.562870\n",
      "Train Epoch: 0, mini-batch 28680 of 31, training loss: 0.561843\n",
      "Train Epoch: 0, mini-batch 28690 of 31, training loss: 0.560785\n",
      "Train Epoch: 0, mini-batch 28700 of 31, training loss: 0.561355\n",
      "Train Epoch: 0, mini-batch 28710 of 31, training loss: 0.564141\n",
      "Train Epoch: 0, mini-batch 28720 of 31, training loss: 0.562875\n",
      "Train Epoch: 0, mini-batch 28730 of 31, training loss: 0.561262\n",
      "Train Epoch: 0, mini-batch 28740 of 31, training loss: 0.562836\n",
      "Train Epoch: 0, mini-batch 28750 of 31, training loss: 0.560317\n",
      "Train Epoch: 0, mini-batch 28760 of 31, training loss: 0.565427\n",
      "Train Epoch: 0, mini-batch 28770 of 31, training loss: 0.561870\n",
      "Train Epoch: 0, mini-batch 28780 of 31, training loss: 0.562891\n",
      "Train Epoch: 0, mini-batch 28790 of 31, training loss: 0.562452\n",
      "Train Epoch: 0, mini-batch 28800 of 31, training loss: 0.559692\n",
      "Train Epoch: 0, mini-batch 28810 of 31, training loss: 0.563602\n",
      "Train Epoch: 0, mini-batch 28820 of 31, training loss: 0.561898\n",
      "Train Epoch: 0, mini-batch 28830 of 31, training loss: 0.563496\n",
      "Train Epoch: 0, mini-batch 28840 of 31, training loss: 0.563071\n",
      "Train Epoch: 0, mini-batch 28850 of 31, training loss: 0.561374\n",
      "Train Epoch: 0, mini-batch 28860 of 31, training loss: 0.561492\n",
      "Train Epoch: 0, mini-batch 28870 of 31, training loss: 0.562797\n",
      "Train Epoch: 0, mini-batch 28880 of 31, training loss: 0.563561\n",
      "Train Epoch: 0, mini-batch 28890 of 31, training loss: 0.563742\n",
      "Train Epoch: 0, mini-batch 28900 of 31, training loss: 0.560854\n",
      "Train Epoch: 0, mini-batch 28910 of 31, training loss: 0.563967\n",
      "Train Epoch: 0, mini-batch 28920 of 31, training loss: 0.562995\n",
      "Train Epoch: 0, mini-batch 28930 of 31, training loss: 0.561934\n",
      "Train Epoch: 0, mini-batch 28940 of 31, training loss: 0.562075\n",
      "Train Epoch: 0, mini-batch 28950 of 31, training loss: 0.562076\n",
      "Train Epoch: 0, mini-batch 28960 of 31, training loss: 0.562128\n",
      "Train Epoch: 0, mini-batch 28970 of 31, training loss: 0.561477\n",
      "Train Epoch: 0, mini-batch 28980 of 31, training loss: 0.562402\n",
      "Train Epoch: 0, mini-batch 28990 of 31, training loss: 0.562693\n",
      "Train Epoch: 0, mini-batch 29000 of 31, training loss: 0.562407\n",
      "Train Epoch: 0, mini-batch 29010 of 31, training loss: 0.562564\n",
      "Train Epoch: 0, mini-batch 29020 of 31, training loss: 0.562583\n",
      "Train Epoch: 0, mini-batch 29030 of 31, training loss: 0.562009\n",
      "Train Epoch: 0, mini-batch 29040 of 31, training loss: 0.561973\n",
      "Train Epoch: 0, mini-batch 29050 of 31, training loss: 0.562588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 29060 of 31, training loss: 0.562778\n",
      "Train Epoch: 0, mini-batch 29070 of 31, training loss: 0.562371\n",
      "Train Epoch: 0, mini-batch 29080 of 31, training loss: 0.562436\n",
      "Train Epoch: 0, mini-batch 29090 of 31, training loss: 0.562857\n",
      "Train Epoch: 0, mini-batch 29100 of 31, training loss: 0.562229\n",
      "Train Epoch: 0, mini-batch 29110 of 31, training loss: 0.563046\n",
      "Train Epoch: 0, mini-batch 29120 of 31, training loss: 0.562419\n",
      "Train Epoch: 0, mini-batch 29130 of 31, training loss: 0.562772\n",
      "Train Epoch: 0, mini-batch 29140 of 31, training loss: 0.562734\n",
      "Train Epoch: 0, mini-batch 29150 of 31, training loss: 0.562606\n",
      "Train Epoch: 0, mini-batch 29160 of 31, training loss: 0.562097\n",
      "Train Epoch: 0, mini-batch 29170 of 31, training loss: 0.562841\n",
      "Train Epoch: 0, mini-batch 29180 of 31, training loss: 0.562430\n",
      "Train Epoch: 0, mini-batch 29190 of 31, training loss: 0.561584\n",
      "Train Epoch: 0, mini-batch 29200 of 31, training loss: 0.563248\n",
      "Train Epoch: 0, mini-batch 29210 of 31, training loss: 0.560783\n",
      "Train Epoch: 0, mini-batch 29220 of 31, training loss: 0.562412\n",
      "Train Epoch: 0, mini-batch 29230 of 31, training loss: 0.562801\n",
      "Train Epoch: 0, mini-batch 29240 of 31, training loss: 0.563787\n",
      "Train Epoch: 0, mini-batch 29250 of 31, training loss: 0.565225\n",
      "Train Epoch: 0, mini-batch 29260 of 31, training loss: 0.562901\n",
      "Train Epoch: 0, mini-batch 29270 of 31, training loss: 0.562569\n",
      "Train Epoch: 0, mini-batch 29280 of 31, training loss: 0.561667\n",
      "Train Epoch: 0, mini-batch 29290 of 31, training loss: 0.562906\n",
      "Train Epoch: 0, mini-batch 29300 of 31, training loss: 0.562948\n",
      "Train Epoch: 0, mini-batch 29310 of 31, training loss: 0.562587\n",
      "Train Epoch: 0, mini-batch 29320 of 31, training loss: 0.560775\n",
      "Train Epoch: 0, mini-batch 29330 of 31, training loss: 0.563740\n",
      "Train Epoch: 0, mini-batch 29340 of 31, training loss: 0.564342\n",
      "Train Epoch: 0, mini-batch 29350 of 31, training loss: 0.562632\n",
      "Train Epoch: 0, mini-batch 29360 of 31, training loss: 0.562316\n",
      "Train Epoch: 0, mini-batch 29370 of 31, training loss: 0.562313\n",
      "Train Epoch: 0, mini-batch 29380 of 31, training loss: 0.561321\n",
      "Train Epoch: 0, mini-batch 29390 of 31, training loss: 0.561676\n",
      "Train Epoch: 0, mini-batch 29400 of 31, training loss: 0.563388\n",
      "Train Epoch: 0, mini-batch 29410 of 31, training loss: 0.562015\n",
      "Train Epoch: 0, mini-batch 29420 of 31, training loss: 0.562283\n",
      "Train Epoch: 0, mini-batch 29430 of 31, training loss: 0.562292\n",
      "Train Epoch: 0, mini-batch 29440 of 31, training loss: 0.561495\n",
      "Train Epoch: 0, mini-batch 29450 of 31, training loss: 0.562234\n",
      "Train Epoch: 0, mini-batch 29460 of 31, training loss: 0.563723\n",
      "Train Epoch: 0, mini-batch 29470 of 31, training loss: 0.563825\n",
      "Train Epoch: 0, mini-batch 29480 of 31, training loss: 0.563162\n",
      "Train Epoch: 0, mini-batch 29490 of 31, training loss: 0.561819\n",
      "Train Epoch: 0, mini-batch 29500 of 31, training loss: 0.563392\n",
      "Train Epoch: 0, mini-batch 29510 of 31, training loss: 0.562756\n",
      "Train Epoch: 0, mini-batch 29520 of 31, training loss: 0.562259\n",
      "Train Epoch: 0, mini-batch 29530 of 31, training loss: 0.562670\n",
      "Train Epoch: 0, mini-batch 29540 of 31, training loss: 0.563628\n",
      "Train Epoch: 0, mini-batch 29550 of 31, training loss: 0.563198\n",
      "Train Epoch: 0, mini-batch 29560 of 31, training loss: 0.562705\n",
      "Train Epoch: 0, mini-batch 29570 of 31, training loss: 0.563099\n",
      "Train Epoch: 0, mini-batch 29580 of 31, training loss: 0.562618\n",
      "Train Epoch: 0, mini-batch 29590 of 31, training loss: 0.561645\n",
      "Train Epoch: 0, mini-batch 29600 of 31, training loss: 0.561510\n",
      "Train Epoch: 0, mini-batch 29610 of 31, training loss: 0.562102\n",
      "Train Epoch: 0, mini-batch 29620 of 31, training loss: 0.561796\n",
      "Train Epoch: 0, mini-batch 29630 of 31, training loss: 0.563432\n",
      "Train Epoch: 0, mini-batch 29640 of 31, training loss: 0.562154\n",
      "Train Epoch: 0, mini-batch 29650 of 31, training loss: 0.561131\n",
      "Train Epoch: 0, mini-batch 29660 of 31, training loss: 0.562107\n",
      "Train Epoch: 0, mini-batch 29670 of 31, training loss: 0.563274\n",
      "Train Epoch: 0, mini-batch 29680 of 31, training loss: 0.561218\n",
      "Train Epoch: 0, mini-batch 29690 of 31, training loss: 0.561823\n",
      "Train Epoch: 0, mini-batch 29700 of 31, training loss: 0.562043\n",
      "Train Epoch: 0, mini-batch 29710 of 31, training loss: 0.562009\n",
      "Train Epoch: 0, mini-batch 29720 of 31, training loss: 0.563606\n",
      "Train Epoch: 0, mini-batch 29730 of 31, training loss: 0.561305\n",
      "Train Epoch: 0, mini-batch 29740 of 31, training loss: 0.563340\n",
      "Train Epoch: 0, mini-batch 29750 of 31, training loss: 0.562267\n",
      "Train Epoch: 0, mini-batch 29760 of 31, training loss: 0.563833\n",
      "Train Epoch: 0, mini-batch 29770 of 31, training loss: 0.563320\n",
      "Train Epoch: 0, mini-batch 29780 of 31, training loss: 0.561206\n",
      "Train Epoch: 0, mini-batch 29790 of 31, training loss: 0.560812\n",
      "Train Epoch: 0, mini-batch 29800 of 31, training loss: 0.561959\n",
      "Train Epoch: 0, mini-batch 29810 of 31, training loss: 0.562367\n",
      "Train Epoch: 0, mini-batch 29820 of 31, training loss: 0.562503\n",
      "Train Epoch: 0, mini-batch 29830 of 31, training loss: 0.562807\n",
      "Train Epoch: 0, mini-batch 29840 of 31, training loss: 0.562874\n",
      "Train Epoch: 0, mini-batch 29850 of 31, training loss: 0.562264\n",
      "Train Epoch: 0, mini-batch 29860 of 31, training loss: 0.562263\n",
      "Train Epoch: 0, mini-batch 29870 of 31, training loss: 0.561394\n",
      "Train Epoch: 0, mini-batch 29880 of 31, training loss: 0.561822\n",
      "Train Epoch: 0, mini-batch 29890 of 31, training loss: 0.562101\n",
      "Train Epoch: 0, mini-batch 29900 of 31, training loss: 0.561544\n",
      "Train Epoch: 0, mini-batch 29910 of 31, training loss: 0.562707\n",
      "Train Epoch: 0, mini-batch 29920 of 31, training loss: 0.562177\n",
      "Train Epoch: 0, mini-batch 29930 of 31, training loss: 0.560271\n",
      "Train Epoch: 0, mini-batch 29940 of 31, training loss: 0.559274\n",
      "Train Epoch: 0, mini-batch 29950 of 31, training loss: 0.560722\n",
      "Train Epoch: 0, mini-batch 29960 of 31, training loss: 0.562321\n",
      "Train Epoch: 0, mini-batch 29970 of 31, training loss: 0.563148\n",
      "Train Epoch: 0, mini-batch 29980 of 31, training loss: 0.562517\n",
      "Train Epoch: 0, mini-batch 29990 of 31, training loss: 0.561461\n",
      "Train Epoch: 0, mini-batch 30000 of 31, training loss: 0.560673\n",
      "Train Epoch: 0, mini-batch 30010 of 31, training loss: 0.561839\n",
      "Train Epoch: 0, mini-batch 30020 of 31, training loss: 0.561280\n",
      "Train Epoch: 0, mini-batch 30030 of 31, training loss: 0.561931\n",
      "Train Epoch: 0, mini-batch 30040 of 31, training loss: 0.559826\n",
      "Train Epoch: 0, mini-batch 30050 of 31, training loss: 0.562857\n",
      "Train Epoch: 0, mini-batch 30060 of 31, training loss: 0.562825\n",
      "Train Epoch: 0, mini-batch 30070 of 31, training loss: 0.563606\n",
      "Train Epoch: 0, mini-batch 30080 of 31, training loss: 0.562591\n",
      "Train Epoch: 0, mini-batch 30090 of 31, training loss: 0.561553\n",
      "Train Epoch: 0, mini-batch 30100 of 31, training loss: 0.562170\n",
      "Train Epoch: 0, mini-batch 30110 of 31, training loss: 0.561081\n",
      "Train Epoch: 0, mini-batch 30120 of 31, training loss: 0.562580\n",
      "Train Epoch: 0, mini-batch 30130 of 31, training loss: 0.562049\n",
      "Train Epoch: 0, mini-batch 30140 of 31, training loss: 0.563018\n",
      "Train Epoch: 0, mini-batch 30150 of 31, training loss: 0.562574\n",
      "Train Epoch: 0, mini-batch 30160 of 31, training loss: 0.562282\n",
      "Train Epoch: 0, mini-batch 30170 of 31, training loss: 0.562580\n",
      "Train Epoch: 0, mini-batch 30180 of 31, training loss: 0.563334\n",
      "Train Epoch: 0, mini-batch 30190 of 31, training loss: 0.561567\n",
      "Train Epoch: 0, mini-batch 30200 of 31, training loss: 0.562205\n",
      "Train Epoch: 0, mini-batch 30210 of 31, training loss: 0.562331\n",
      "Train Epoch: 0, mini-batch 30220 of 31, training loss: 0.561263\n",
      "Train Epoch: 0, mini-batch 30230 of 31, training loss: 0.560188\n",
      "Train Epoch: 0, mini-batch 30240 of 31, training loss: 0.561621\n",
      "Train Epoch: 0, mini-batch 30250 of 31, training loss: 0.561323\n",
      "Train Epoch: 0, mini-batch 30260 of 31, training loss: 0.561498\n",
      "Train Epoch: 0, mini-batch 30270 of 31, training loss: 0.561387\n",
      "Train Epoch: 0, mini-batch 30280 of 31, training loss: 0.562606\n",
      "Train Epoch: 0, mini-batch 30290 of 31, training loss: 0.560131\n",
      "Train Epoch: 0, mini-batch 30300 of 31, training loss: 0.561845\n",
      "Train Epoch: 0, mini-batch 30310 of 31, training loss: 0.560946\n",
      "Train Epoch: 0, mini-batch 30320 of 31, training loss: 0.563552\n",
      "Train Epoch: 0, mini-batch 30330 of 31, training loss: 0.563246\n",
      "Train Epoch: 0, mini-batch 30340 of 31, training loss: 0.561245\n",
      "Train Epoch: 0, mini-batch 30350 of 31, training loss: 0.562003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 30360 of 31, training loss: 0.559908\n",
      "Train Epoch: 0, mini-batch 30370 of 31, training loss: 0.562644\n",
      "Train Epoch: 0, mini-batch 30380 of 31, training loss: 0.561080\n",
      "Train Epoch: 0, mini-batch 30390 of 31, training loss: 0.565258\n",
      "Train Epoch: 0, mini-batch 30400 of 31, training loss: 0.563976\n",
      "Train Epoch: 0, mini-batch 30410 of 31, training loss: 0.562737\n",
      "Train Epoch: 0, mini-batch 30420 of 31, training loss: 0.561400\n",
      "Train Epoch: 0, mini-batch 30430 of 31, training loss: 0.561978\n",
      "Train Epoch: 0, mini-batch 30440 of 31, training loss: 0.561217\n",
      "Train Epoch: 0, mini-batch 30450 of 31, training loss: 0.562777\n",
      "Train Epoch: 0, mini-batch 30460 of 31, training loss: 0.561701\n",
      "Train Epoch: 0, mini-batch 30470 of 31, training loss: 0.561834\n",
      "Train Epoch: 0, mini-batch 30480 of 31, training loss: 0.562559\n",
      "Train Epoch: 0, mini-batch 30490 of 31, training loss: 0.562371\n",
      "Train Epoch: 0, mini-batch 30500 of 31, training loss: 0.563052\n",
      "Train Epoch: 0, mini-batch 30510 of 31, training loss: 0.561511\n",
      "Train Epoch: 0, mini-batch 30520 of 31, training loss: 0.562528\n",
      "Train Epoch: 0, mini-batch 30530 of 31, training loss: 0.562087\n",
      "Train Epoch: 0, mini-batch 30540 of 31, training loss: 0.562618\n",
      "Train Epoch: 0, mini-batch 30550 of 31, training loss: 0.563047\n",
      "Train Epoch: 0, mini-batch 30560 of 31, training loss: 0.561719\n",
      "Train Epoch: 0, mini-batch 30570 of 31, training loss: 0.561413\n",
      "Train Epoch: 0, mini-batch 30580 of 31, training loss: 0.562224\n",
      "Train Epoch: 0, mini-batch 30590 of 31, training loss: 0.563058\n",
      "Train Epoch: 0, mini-batch 30600 of 31, training loss: 0.563127\n",
      "Train Epoch: 0, mini-batch 30610 of 31, training loss: 0.562443\n",
      "Train Epoch: 0, mini-batch 30620 of 31, training loss: 0.562091\n",
      "Train Epoch: 0, mini-batch 30630 of 31, training loss: 0.564073\n",
      "Train Epoch: 0, mini-batch 30640 of 31, training loss: 0.562194\n",
      "Train Epoch: 0, mini-batch 30650 of 31, training loss: 0.562496\n",
      "Train Epoch: 0, mini-batch 30660 of 31, training loss: 0.562588\n",
      "Train Epoch: 0, mini-batch 30670 of 31, training loss: 0.562001\n",
      "Train Epoch: 0, mini-batch 30680 of 31, training loss: 0.563276\n",
      "Train Epoch: 0, mini-batch 30690 of 31, training loss: 0.563376\n",
      "Train Epoch: 0, mini-batch 30700 of 31, training loss: 0.563545\n",
      "Train Epoch: 0, mini-batch 30710 of 31, training loss: 0.562598\n",
      "Train Epoch: 0, mini-batch 30720 of 31, training loss: 0.562818\n",
      "Train Epoch: 0, mini-batch 30730 of 31, training loss: 0.563963\n",
      "Train Epoch: 0, mini-batch 30740 of 31, training loss: 0.563308\n",
      "Train Epoch: 0, mini-batch 30750 of 31, training loss: 0.560244\n",
      "Train Epoch: 0, mini-batch 30760 of 31, training loss: 0.563815\n",
      "Train Epoch: 0, mini-batch 30770 of 31, training loss: 0.562864\n",
      "Train Epoch: 0, mini-batch 30780 of 31, training loss: 0.561282\n",
      "Train Epoch: 0, mini-batch 30790 of 31, training loss: 0.562658\n",
      "Train Epoch: 0, mini-batch 30800 of 31, training loss: 0.562043\n",
      "Train Epoch: 0, mini-batch 30810 of 31, training loss: 0.562153\n",
      "Train Epoch: 0, mini-batch 30820 of 31, training loss: 0.561480\n",
      "Train Epoch: 0, mini-batch 30830 of 31, training loss: 0.562646\n",
      "Train Epoch: 0, mini-batch 30840 of 31, training loss: 0.561972\n",
      "Train Epoch: 0, mini-batch 30850 of 31, training loss: 0.563179\n",
      "Train Epoch: 0, mini-batch 30860 of 31, training loss: 0.561958\n",
      "Train Epoch: 0, mini-batch 30870 of 31, training loss: 0.562360\n",
      "Train Epoch: 0, mini-batch 30880 of 31, training loss: 0.562728\n",
      "Train Epoch: 0, mini-batch 30890 of 31, training loss: 0.561722\n",
      "Train Epoch: 0, mini-batch 30900 of 31, training loss: 0.563057\n",
      "Train Epoch: 0, mini-batch 30910 of 31, training loss: 0.562860\n",
      "Train Epoch: 0, mini-batch 30920 of 31, training loss: 0.562371\n",
      "Train Epoch: 0, mini-batch 30930 of 31, training loss: 0.562466\n",
      "Train Epoch: 0, mini-batch 30940 of 31, training loss: 0.562884\n",
      "Train Epoch: 0, mini-batch 30950 of 31, training loss: 0.562045\n",
      "Train Epoch: 0, mini-batch 30960 of 31, training loss: 0.562682\n",
      "Train Epoch: 0, mini-batch 30970 of 31, training loss: 0.563610\n",
      "Train Epoch: 0, mini-batch 30980 of 31, training loss: 0.562165\n",
      "Train Epoch: 0, mini-batch 30990 of 31, training loss: 0.563608\n",
      "Train Epoch: 0, mini-batch 31000 of 31, training loss: 0.562167\n",
      "Train Epoch: 0, mini-batch 31010 of 31, training loss: 0.561630\n",
      "Train Epoch: 0, mini-batch 31020 of 31, training loss: 0.561102\n",
      "Train Epoch: 0, mini-batch 31030 of 31, training loss: 0.561477\n",
      "Train Epoch: 0, mini-batch 31040 of 31, training loss: 0.561527\n",
      "Train Epoch: 0, mini-batch 31050 of 31, training loss: 0.560798\n",
      "Train Epoch: 0, mini-batch 31060 of 31, training loss: 0.561703\n",
      "Train Epoch: 0, mini-batch 31070 of 31, training loss: 0.562833\n",
      "Train Epoch: 0, mini-batch 31080 of 31, training loss: 0.561925\n",
      "Train Epoch: 0, mini-batch 31090 of 31, training loss: 0.560076\n",
      "Train Epoch: 0, mini-batch 31100 of 31, training loss: 0.561737\n",
      "Train Epoch: 0, mini-batch 31110 of 31, training loss: 0.561694\n",
      "Train Epoch: 0, mini-batch 31120 of 31, training loss: 0.561863\n",
      "Train Epoch: 0, mini-batch 31130 of 31, training loss: 0.562215\n",
      "Train Epoch: 0, mini-batch 31140 of 31, training loss: 0.562267\n",
      "Train Epoch: 0, mini-batch 31150 of 31, training loss: 0.562111\n",
      "Train Epoch: 0, mini-batch 31160 of 31, training loss: 0.562738\n",
      "Train Epoch: 0, mini-batch 31170 of 31, training loss: 0.562595\n",
      "Train Epoch: 0, mini-batch 31180 of 31, training loss: 0.563053\n",
      "Train Epoch: 0, mini-batch 31190 of 31, training loss: 0.561927\n",
      "Train Epoch: 0, mini-batch 31200 of 31, training loss: 0.562205\n",
      "Train Epoch: 0, mini-batch 31210 of 31, training loss: 0.562826\n",
      "Train Epoch: 0, mini-batch 31220 of 31, training loss: 0.562716\n",
      "Train Epoch: 0, mini-batch 31230 of 31, training loss: 0.562898\n",
      "Train Epoch: 0, mini-batch 31240 of 31, training loss: 0.561943\n",
      "Train Epoch: 0, mini-batch 31250 of 31, training loss: 0.561190\n",
      "Train Epoch: 0, mini-batch 31260 of 31, training loss: 0.561582\n",
      "Train Epoch: 0, mini-batch 31270 of 31, training loss: 0.562859\n",
      "Train Epoch: 0, mini-batch 31280 of 31, training loss: 0.561703\n",
      "Train Epoch: 0, mini-batch 31290 of 31, training loss: 0.562674\n",
      "Train Epoch: 0, mini-batch 31300 of 31, training loss: 0.564011\n",
      "Train Epoch: 0, mini-batch 31310 of 31, training loss: 0.561926\n",
      "Train Epoch: 0, mini-batch 31320 of 31, training loss: 0.560856\n",
      "Train Epoch: 0, mini-batch 31330 of 31, training loss: 0.561105\n",
      "Train Epoch: 0, mini-batch 31340 of 31, training loss: 0.564855\n",
      "Train Epoch: 0, mini-batch 31350 of 31, training loss: 0.561651\n",
      "Train Epoch: 0, mini-batch 31360 of 31, training loss: 0.565866\n",
      "Train Epoch: 0, mini-batch 31370 of 31, training loss: 0.560409\n",
      "Train Epoch: 0, mini-batch 31380 of 31, training loss: 0.563339\n",
      "Train Epoch: 0, mini-batch 31390 of 31, training loss: 0.561848\n",
      "Train Epoch: 0, mini-batch 31400 of 31, training loss: 0.562034\n",
      "Train Epoch: 0, mini-batch 31410 of 31, training loss: 0.560217\n",
      "Train Epoch: 0, mini-batch 31420 of 31, training loss: 0.565487\n",
      "Train Epoch: 0, mini-batch 31430 of 31, training loss: 0.562618\n",
      "Train Epoch: 0, mini-batch 31440 of 31, training loss: 0.564249\n",
      "Train Epoch: 0, mini-batch 31450 of 31, training loss: 0.563275\n",
      "Train Epoch: 0, mini-batch 31460 of 31, training loss: 0.561373\n",
      "Train Epoch: 0, mini-batch 31470 of 31, training loss: 0.563211\n",
      "Train Epoch: 0, mini-batch 31480 of 31, training loss: 0.562027\n",
      "Train Epoch: 0, mini-batch 31490 of 31, training loss: 0.561035\n",
      "Train Epoch: 0, mini-batch 31500 of 31, training loss: 0.561809\n",
      "Train Epoch: 0, mini-batch 31510 of 31, training loss: 0.562766\n",
      "Train Epoch: 0, mini-batch 31520 of 31, training loss: 0.561854\n",
      "Train Epoch: 0, mini-batch 31530 of 31, training loss: 0.561799\n",
      "Train Epoch: 0, mini-batch 31540 of 31, training loss: 0.562149\n",
      "Train Epoch: 0, mini-batch 31550 of 31, training loss: 0.562748\n",
      "Train Epoch: 0, mini-batch 31560 of 31, training loss: 0.563813\n",
      "Train Epoch: 0, mini-batch 31570 of 31, training loss: 0.562639\n",
      "Train Epoch: 0, mini-batch 31580 of 31, training loss: 0.562222\n",
      "Train Epoch: 0, mini-batch 31590 of 31, training loss: 0.560403\n",
      "Train Epoch: 0, mini-batch 31600 of 31, training loss: 0.562655\n",
      "Train Epoch: 0, mini-batch 31610 of 31, training loss: 0.562545\n",
      "Train Epoch: 0, mini-batch 31620 of 31, training loss: 0.562949\n",
      "Train Epoch: 0, mini-batch 31630 of 31, training loss: 0.562368\n",
      "Train Epoch: 0, mini-batch 31640 of 31, training loss: 0.561269\n",
      "Train Epoch: 0, mini-batch 31650 of 31, training loss: 0.561679\n",
      "Train Epoch: 0, mini-batch 31660 of 31, training loss: 0.562343\n",
      "Train Epoch: 0, mini-batch 31670 of 31, training loss: 0.563565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 31680 of 31, training loss: 0.562926\n",
      "Train Epoch: 0, mini-batch 31690 of 31, training loss: 0.564243\n",
      "Train Epoch: 0, mini-batch 31700 of 31, training loss: 0.563769\n",
      "Train Epoch: 0, mini-batch 31710 of 31, training loss: 0.561688\n",
      "Train Epoch: 0, mini-batch 31720 of 31, training loss: 0.562754\n",
      "Train Epoch: 0, mini-batch 31730 of 31, training loss: 0.563013\n",
      "Train Epoch: 0, mini-batch 31740 of 31, training loss: 0.561404\n",
      "Train Epoch: 0, mini-batch 31750 of 31, training loss: 0.562542\n",
      "Train Epoch: 0, mini-batch 31760 of 31, training loss: 0.562241\n",
      "Train Epoch: 0, mini-batch 31770 of 31, training loss: 0.563554\n",
      "Train Epoch: 0, mini-batch 31780 of 31, training loss: 0.562730\n",
      "Train Epoch: 0, mini-batch 31790 of 31, training loss: 0.562538\n",
      "Train Epoch: 0, mini-batch 31800 of 31, training loss: 0.563599\n",
      "Train Epoch: 0, mini-batch 31810 of 31, training loss: 0.560992\n",
      "Train Epoch: 0, mini-batch 31820 of 31, training loss: 0.562521\n",
      "Train Epoch: 0, mini-batch 31830 of 31, training loss: 0.561368\n",
      "Train Epoch: 0, mini-batch 31840 of 31, training loss: 0.562009\n",
      "Train Epoch: 0, mini-batch 31850 of 31, training loss: 0.562571\n",
      "Train Epoch: 0, mini-batch 31860 of 31, training loss: 0.563201\n",
      "Train Epoch: 0, mini-batch 31870 of 31, training loss: 0.562697\n",
      "Train Epoch: 0, mini-batch 31880 of 31, training loss: 0.562066\n",
      "Train Epoch: 0, mini-batch 31890 of 31, training loss: 0.562478\n",
      "Train Epoch: 0, mini-batch 31900 of 31, training loss: 0.561650\n",
      "Train Epoch: 0, mini-batch 31910 of 31, training loss: 0.563133\n",
      "Train Epoch: 0, mini-batch 31920 of 31, training loss: 0.562356\n",
      "Train Epoch: 0, mini-batch 31930 of 31, training loss: 0.562074\n",
      "Train Epoch: 0, mini-batch 31940 of 31, training loss: 0.562986\n",
      "Train Epoch: 0, mini-batch 31950 of 31, training loss: 0.561544\n",
      "Train Epoch: 0, mini-batch 31960 of 31, training loss: 0.562828\n",
      "Train Epoch: 0, mini-batch 31970 of 31, training loss: 0.562838\n",
      "Train Epoch: 0, mini-batch 31980 of 31, training loss: 0.562258\n",
      "Train Epoch: 0, mini-batch 31990 of 31, training loss: 0.562371\n",
      "Train Epoch: 0, mini-batch 32000 of 31, training loss: 0.562506\n",
      "Train Epoch: 0, mini-batch 32010 of 31, training loss: 0.562374\n",
      "Train Epoch: 0, mini-batch 32020 of 31, training loss: 0.562492\n",
      "Train Epoch: 0, mini-batch 32030 of 31, training loss: 0.562096\n",
      "Train Epoch: 0, mini-batch 32040 of 31, training loss: 0.562673\n",
      "Train Epoch: 0, mini-batch 32050 of 31, training loss: 0.563067\n",
      "Train Epoch: 0, mini-batch 32060 of 31, training loss: 0.561795\n",
      "Train Epoch: 0, mini-batch 32070 of 31, training loss: 0.562902\n",
      "Train Epoch: 0, mini-batch 32080 of 31, training loss: 0.562683\n",
      "Train Epoch: 0, mini-batch 32090 of 31, training loss: 0.562629\n",
      "Train Epoch: 0, mini-batch 32100 of 31, training loss: 0.562339\n",
      "Train Epoch: 0, mini-batch 32110 of 31, training loss: 0.561010\n",
      "Train Epoch: 0, mini-batch 32120 of 31, training loss: 0.563196\n",
      "Train Epoch: 0, mini-batch 32130 of 31, training loss: 0.562478\n",
      "Train Epoch: 0, mini-batch 32140 of 31, training loss: 0.561483\n",
      "Train Epoch: 0, mini-batch 32150 of 31, training loss: 0.562624\n",
      "Train Epoch: 0, mini-batch 32160 of 31, training loss: 0.562553\n",
      "Train Epoch: 0, mini-batch 32170 of 31, training loss: 0.562159\n",
      "Train Epoch: 0, mini-batch 32180 of 31, training loss: 0.562559\n",
      "Train Epoch: 0, mini-batch 32190 of 31, training loss: 0.562199\n",
      "Train Epoch: 0, mini-batch 32200 of 31, training loss: 0.561810\n",
      "Train Epoch: 0, mini-batch 32210 of 31, training loss: 0.563564\n",
      "Train Epoch: 0, mini-batch 32220 of 31, training loss: 0.562002\n",
      "Train Epoch: 0, mini-batch 32230 of 31, training loss: 0.561966\n",
      "Train Epoch: 0, mini-batch 32240 of 31, training loss: 0.563248\n",
      "Train Epoch: 0, mini-batch 32250 of 31, training loss: 0.563001\n",
      "Train Epoch: 0, mini-batch 32260 of 31, training loss: 0.562779\n",
      "Train Epoch: 0, mini-batch 32270 of 31, training loss: 0.562569\n",
      "Train Epoch: 0, mini-batch 32280 of 31, training loss: 0.562546\n",
      "Train Epoch: 0, mini-batch 32290 of 31, training loss: 0.562950\n",
      "Train Epoch: 0, mini-batch 32300 of 31, training loss: 0.560957\n",
      "Train Epoch: 0, mini-batch 32310 of 31, training loss: 0.560848\n",
      "Train Epoch: 0, mini-batch 32320 of 31, training loss: 0.561700\n",
      "Train Epoch: 0, mini-batch 32330 of 31, training loss: 0.561384\n",
      "Train Epoch: 0, mini-batch 32340 of 31, training loss: 0.560791\n",
      "Train Epoch: 0, mini-batch 32350 of 31, training loss: 0.563076\n",
      "Train Epoch: 0, mini-batch 32360 of 31, training loss: 0.561472\n",
      "Train Epoch: 0, mini-batch 32370 of 31, training loss: 0.562283\n",
      "Train Epoch: 0, mini-batch 32380 of 31, training loss: 0.559936\n",
      "Train Epoch: 0, mini-batch 32390 of 31, training loss: 0.562694\n",
      "Train Epoch: 0, mini-batch 32400 of 31, training loss: 0.562312\n",
      "Train Epoch: 0, mini-batch 32410 of 31, training loss: 0.560902\n",
      "Train Epoch: 0, mini-batch 32420 of 31, training loss: 0.564315\n",
      "Train Epoch: 0, mini-batch 32430 of 31, training loss: 0.560418\n",
      "Train Epoch: 0, mini-batch 32440 of 31, training loss: 0.559186\n",
      "Train Epoch: 0, mini-batch 32450 of 31, training loss: 0.565960\n",
      "Train Epoch: 0, mini-batch 32460 of 31, training loss: 0.565358\n",
      "Train Epoch: 0, mini-batch 32470 of 31, training loss: 0.562961\n",
      "Train Epoch: 0, mini-batch 32480 of 31, training loss: 0.565262\n",
      "Train Epoch: 0, mini-batch 32490 of 31, training loss: 0.559862\n",
      "Train Epoch: 0, mini-batch 32500 of 31, training loss: 0.561552\n",
      "Train Epoch: 0, mini-batch 32510 of 31, training loss: 0.562837\n",
      "Train Epoch: 0, mini-batch 32520 of 31, training loss: 0.565396\n",
      "Train Epoch: 0, mini-batch 32530 of 31, training loss: 0.562237\n",
      "Train Epoch: 0, mini-batch 32540 of 31, training loss: 0.563722\n",
      "Train Epoch: 0, mini-batch 32550 of 31, training loss: 0.561264\n",
      "Train Epoch: 0, mini-batch 32560 of 31, training loss: 0.559723\n",
      "Train Epoch: 0, mini-batch 32570 of 31, training loss: 0.563805\n",
      "Train Epoch: 0, mini-batch 32580 of 31, training loss: 0.562800\n",
      "Train Epoch: 0, mini-batch 32590 of 31, training loss: 0.563734\n",
      "Train Epoch: 0, mini-batch 32600 of 31, training loss: 0.562509\n",
      "Train Epoch: 0, mini-batch 32610 of 31, training loss: 0.563041\n",
      "Train Epoch: 0, mini-batch 32620 of 31, training loss: 0.562452\n",
      "Train Epoch: 0, mini-batch 32630 of 31, training loss: 0.562843\n",
      "Train Epoch: 0, mini-batch 32640 of 31, training loss: 0.562362\n",
      "Train Epoch: 0, mini-batch 32650 of 31, training loss: 0.562196\n",
      "Train Epoch: 0, mini-batch 32660 of 31, training loss: 0.561474\n",
      "Train Epoch: 0, mini-batch 32670 of 31, training loss: 0.561456\n",
      "Train Epoch: 0, mini-batch 32680 of 31, training loss: 0.561781\n",
      "Train Epoch: 0, mini-batch 32690 of 31, training loss: 0.561713\n",
      "Train Epoch: 0, mini-batch 32700 of 31, training loss: 0.562012\n",
      "Train Epoch: 0, mini-batch 32710 of 31, training loss: 0.561773\n",
      "Train Epoch: 0, mini-batch 32720 of 31, training loss: 0.561554\n",
      "Train Epoch: 0, mini-batch 32730 of 31, training loss: 0.561984\n",
      "Train Epoch: 0, mini-batch 32740 of 31, training loss: 0.561485\n",
      "Train Epoch: 0, mini-batch 32750 of 31, training loss: 0.562093\n",
      "Train Epoch: 0, mini-batch 32760 of 31, training loss: 0.561013\n",
      "Train Epoch: 0, mini-batch 32770 of 31, training loss: 0.563000\n",
      "Train Epoch: 0, mini-batch 32780 of 31, training loss: 0.561130\n",
      "Train Epoch: 0, mini-batch 32790 of 31, training loss: 0.559510\n",
      "Train Epoch: 0, mini-batch 32800 of 31, training loss: 0.559032\n",
      "Train Epoch: 0, mini-batch 32810 of 31, training loss: 0.561347\n",
      "Train Epoch: 0, mini-batch 32820 of 31, training loss: 0.563242\n",
      "Train Epoch: 0, mini-batch 32830 of 31, training loss: 0.559884\n",
      "Train Epoch: 0, mini-batch 32840 of 31, training loss: 0.564064\n",
      "Train Epoch: 0, mini-batch 32850 of 31, training loss: 0.564592\n",
      "Train Epoch: 0, mini-batch 32860 of 31, training loss: 0.564484\n",
      "Train Epoch: 0, mini-batch 32870 of 31, training loss: 0.565309\n",
      "Train Epoch: 0, mini-batch 32880 of 31, training loss: 0.562538\n",
      "Train Epoch: 0, mini-batch 32890 of 31, training loss: 0.560640\n",
      "Train Epoch: 0, mini-batch 32900 of 31, training loss: 0.562586\n",
      "Train Epoch: 0, mini-batch 32910 of 31, training loss: 0.559653\n",
      "Train Epoch: 0, mini-batch 32920 of 31, training loss: 0.563707\n",
      "Train Epoch: 0, mini-batch 32930 of 31, training loss: 0.560424\n",
      "Train Epoch: 0, mini-batch 32940 of 31, training loss: 0.564544\n",
      "Train Epoch: 0, mini-batch 32950 of 31, training loss: 0.564319\n",
      "Train Epoch: 0, mini-batch 32960 of 31, training loss: 0.565717\n",
      "Train Epoch: 0, mini-batch 32970 of 31, training loss: 0.565008\n",
      "Train Epoch: 0, mini-batch 32980 of 31, training loss: 0.562857\n",
      "Train Epoch: 0, mini-batch 32990 of 31, training loss: 0.560727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 33000 of 31, training loss: 0.560288\n",
      "Train Epoch: 0, mini-batch 33010 of 31, training loss: 0.564290\n",
      "Train Epoch: 0, mini-batch 33020 of 31, training loss: 0.559521\n",
      "Train Epoch: 0, mini-batch 33030 of 31, training loss: 0.562920\n",
      "Train Epoch: 0, mini-batch 33040 of 31, training loss: 0.560678\n",
      "Train Epoch: 0, mini-batch 33050 of 31, training loss: 0.561277\n",
      "Train Epoch: 0, mini-batch 33060 of 31, training loss: 0.559191\n",
      "Train Epoch: 0, mini-batch 33070 of 31, training loss: 0.563562\n",
      "Train Epoch: 0, mini-batch 33080 of 31, training loss: 0.560737\n",
      "Train Epoch: 0, mini-batch 33090 of 31, training loss: 0.564203\n",
      "Train Epoch: 0, mini-batch 33100 of 31, training loss: 0.560770\n",
      "Train Epoch: 0, mini-batch 33110 of 31, training loss: 0.562448\n",
      "Train Epoch: 0, mini-batch 33120 of 31, training loss: 0.561523\n",
      "Train Epoch: 0, mini-batch 33130 of 31, training loss: 0.558756\n",
      "Train Epoch: 0, mini-batch 33140 of 31, training loss: 0.565608\n",
      "Train Epoch: 0, mini-batch 33150 of 31, training loss: 0.562638\n",
      "Train Epoch: 0, mini-batch 33160 of 31, training loss: 0.561869\n",
      "Train Epoch: 0, mini-batch 33170 of 31, training loss: 0.560445\n",
      "Train Epoch: 0, mini-batch 33180 of 31, training loss: 0.562280\n",
      "Train Epoch: 0, mini-batch 33190 of 31, training loss: 0.565255\n",
      "Train Epoch: 0, mini-batch 33200 of 31, training loss: 0.560845\n",
      "Train Epoch: 0, mini-batch 33210 of 31, training loss: 0.561489\n",
      "Train Epoch: 0, mini-batch 33220 of 31, training loss: 0.562368\n",
      "Train Epoch: 0, mini-batch 33230 of 31, training loss: 0.561707\n",
      "Train Epoch: 0, mini-batch 33240 of 31, training loss: 0.562388\n",
      "Train Epoch: 0, mini-batch 33250 of 31, training loss: 0.562808\n",
      "Train Epoch: 0, mini-batch 33260 of 31, training loss: 0.559358\n",
      "Train Epoch: 0, mini-batch 33270 of 31, training loss: 0.560945\n",
      "Train Epoch: 0, mini-batch 33280 of 31, training loss: 0.561662\n",
      "Train Epoch: 0, mini-batch 33290 of 31, training loss: 0.564508\n",
      "Train Epoch: 0, mini-batch 33300 of 31, training loss: 0.562724\n",
      "Train Epoch: 0, mini-batch 33310 of 31, training loss: 0.558577\n",
      "Train Epoch: 0, mini-batch 33320 of 31, training loss: 0.564429\n",
      "Train Epoch: 0, mini-batch 33330 of 31, training loss: 0.561760\n",
      "Train Epoch: 0, mini-batch 33340 of 31, training loss: 0.565100\n",
      "Train Epoch: 0, mini-batch 33350 of 31, training loss: 0.562594\n",
      "Train Epoch: 0, mini-batch 33360 of 31, training loss: 0.562622\n",
      "Train Epoch: 0, mini-batch 33370 of 31, training loss: 0.559889\n",
      "Train Epoch: 0, mini-batch 33380 of 31, training loss: 0.565372\n",
      "Train Epoch: 0, mini-batch 33390 of 31, training loss: 0.562472\n",
      "Train Epoch: 0, mini-batch 33400 of 31, training loss: 0.562509\n",
      "Train Epoch: 0, mini-batch 33410 of 31, training loss: 0.562659\n",
      "Train Epoch: 0, mini-batch 33420 of 31, training loss: 0.562265\n",
      "Train Epoch: 0, mini-batch 33430 of 31, training loss: 0.562388\n",
      "Train Epoch: 0, mini-batch 33440 of 31, training loss: 0.561281\n",
      "Train Epoch: 0, mini-batch 33450 of 31, training loss: 0.561399\n",
      "Train Epoch: 0, mini-batch 33460 of 31, training loss: 0.562301\n",
      "Train Epoch: 0, mini-batch 33470 of 31, training loss: 0.562411\n",
      "Train Epoch: 0, mini-batch 33480 of 31, training loss: 0.561870\n",
      "Train Epoch: 0, mini-batch 33490 of 31, training loss: 0.562418\n",
      "Train Epoch: 0, mini-batch 33500 of 31, training loss: 0.561689\n",
      "Train Epoch: 0, mini-batch 33510 of 31, training loss: 0.561955\n",
      "Train Epoch: 0, mini-batch 33520 of 31, training loss: 0.562122\n",
      "Train Epoch: 0, mini-batch 33530 of 31, training loss: 0.563654\n",
      "Train Epoch: 0, mini-batch 33540 of 31, training loss: 0.561551\n",
      "Train Epoch: 0, mini-batch 33550 of 31, training loss: 0.562488\n",
      "Train Epoch: 0, mini-batch 33560 of 31, training loss: 0.562476\n",
      "Train Epoch: 0, mini-batch 33570 of 31, training loss: 0.563065\n",
      "Train Epoch: 0, mini-batch 33580 of 31, training loss: 0.562919\n",
      "Train Epoch: 0, mini-batch 33590 of 31, training loss: 0.562463\n",
      "Train Epoch: 0, mini-batch 33600 of 31, training loss: 0.562679\n",
      "Train Epoch: 0, mini-batch 33610 of 31, training loss: 0.562062\n",
      "Train Epoch: 0, mini-batch 33620 of 31, training loss: 0.563593\n",
      "Train Epoch: 0, mini-batch 33630 of 31, training loss: 0.561428\n",
      "Train Epoch: 0, mini-batch 33640 of 31, training loss: 0.561291\n",
      "Train Epoch: 0, mini-batch 33650 of 31, training loss: 0.563810\n",
      "Train Epoch: 0, mini-batch 33660 of 31, training loss: 0.562111\n",
      "Train Epoch: 0, mini-batch 33670 of 31, training loss: 0.561875\n",
      "Train Epoch: 0, mini-batch 33680 of 31, training loss: 0.561598\n",
      "Train Epoch: 0, mini-batch 33690 of 31, training loss: 0.562321\n",
      "Train Epoch: 0, mini-batch 33700 of 31, training loss: 0.563051\n",
      "Train Epoch: 0, mini-batch 33710 of 31, training loss: 0.562801\n",
      "Train Epoch: 0, mini-batch 33720 of 31, training loss: 0.563041\n",
      "Train Epoch: 0, mini-batch 33730 of 31, training loss: 0.562792\n",
      "Train Epoch: 0, mini-batch 33740 of 31, training loss: 0.564301\n",
      "Train Epoch: 0, mini-batch 33750 of 31, training loss: 0.562461\n",
      "Train Epoch: 0, mini-batch 33760 of 31, training loss: 0.562996\n",
      "Train Epoch: 0, mini-batch 33770 of 31, training loss: 0.563189\n",
      "Train Epoch: 0, mini-batch 33780 of 31, training loss: 0.563982\n",
      "Train Epoch: 0, mini-batch 33790 of 31, training loss: 0.562059\n",
      "Train Epoch: 0, mini-batch 33800 of 31, training loss: 0.563178\n",
      "Train Epoch: 0, mini-batch 33810 of 31, training loss: 0.562510\n",
      "Train Epoch: 0, mini-batch 33820 of 31, training loss: 0.562001\n",
      "Train Epoch: 0, mini-batch 33830 of 31, training loss: 0.562912\n",
      "Train Epoch: 0, mini-batch 33840 of 31, training loss: 0.561839\n",
      "Train Epoch: 0, mini-batch 33850 of 31, training loss: 0.561470\n",
      "Train Epoch: 0, mini-batch 33860 of 31, training loss: 0.561456\n",
      "Train Epoch: 0, mini-batch 33870 of 31, training loss: 0.563835\n",
      "Train Epoch: 0, mini-batch 33880 of 31, training loss: 0.562208\n",
      "Train Epoch: 0, mini-batch 33890 of 31, training loss: 0.562291\n",
      "Train Epoch: 0, mini-batch 33900 of 31, training loss: 0.562938\n",
      "Train Epoch: 0, mini-batch 33910 of 31, training loss: 0.564002\n",
      "Train Epoch: 0, mini-batch 33920 of 31, training loss: 0.562372\n",
      "Train Epoch: 0, mini-batch 33930 of 31, training loss: 0.561292\n",
      "Train Epoch: 0, mini-batch 33940 of 31, training loss: 0.563053\n",
      "Train Epoch: 0, mini-batch 33950 of 31, training loss: 0.563080\n",
      "Train Epoch: 0, mini-batch 33960 of 31, training loss: 0.561436\n",
      "Train Epoch: 0, mini-batch 33970 of 31, training loss: 0.562767\n",
      "Train Epoch: 0, mini-batch 33980 of 31, training loss: 0.563131\n",
      "Train Epoch: 0, mini-batch 33990 of 31, training loss: 0.561906\n",
      "Train Epoch: 0, mini-batch 34000 of 31, training loss: 0.561735\n",
      "Train Epoch: 0, mini-batch 34010 of 31, training loss: 0.562298\n",
      "Train Epoch: 0, mini-batch 34020 of 31, training loss: 0.562199\n",
      "Train Epoch: 0, mini-batch 34030 of 31, training loss: 0.561996\n",
      "Train Epoch: 0, mini-batch 34040 of 31, training loss: 0.562438\n",
      "Train Epoch: 0, mini-batch 34050 of 31, training loss: 0.562293\n",
      "Train Epoch: 0, mini-batch 34060 of 31, training loss: 0.563016\n",
      "Train Epoch: 0, mini-batch 34070 of 31, training loss: 0.562706\n",
      "Train Epoch: 0, mini-batch 34080 of 31, training loss: 0.562834\n",
      "Train Epoch: 0, mini-batch 34090 of 31, training loss: 0.562921\n",
      "Train Epoch: 0, mini-batch 34100 of 31, training loss: 0.562071\n",
      "Train Epoch: 0, mini-batch 34110 of 31, training loss: 0.562300\n",
      "Train Epoch: 0, mini-batch 34120 of 31, training loss: 0.562707\n",
      "Train Epoch: 0, mini-batch 34130 of 31, training loss: 0.561954\n",
      "Train Epoch: 0, mini-batch 34140 of 31, training loss: 0.562627\n",
      "Train Epoch: 0, mini-batch 34150 of 31, training loss: 0.562669\n",
      "Train Epoch: 0, mini-batch 34160 of 31, training loss: 0.562551\n",
      "Train Epoch: 0, mini-batch 34170 of 31, training loss: 0.561782\n",
      "Train Epoch: 0, mini-batch 34180 of 31, training loss: 0.560877\n",
      "Train Epoch: 0, mini-batch 34190 of 31, training loss: 0.563615\n",
      "Train Epoch: 0, mini-batch 34200 of 31, training loss: 0.562274\n",
      "Train Epoch: 0, mini-batch 34210 of 31, training loss: 0.562745\n",
      "Train Epoch: 0, mini-batch 34220 of 31, training loss: 0.560994\n",
      "Train Epoch: 0, mini-batch 34230 of 31, training loss: 0.562696\n",
      "Train Epoch: 0, mini-batch 34240 of 31, training loss: 0.561969\n",
      "Train Epoch: 0, mini-batch 34250 of 31, training loss: 0.563306\n",
      "Train Epoch: 0, mini-batch 34260 of 31, training loss: 0.561571\n",
      "Train Epoch: 0, mini-batch 34270 of 31, training loss: 0.562730\n",
      "Train Epoch: 0, mini-batch 34280 of 31, training loss: 0.562050\n",
      "Train Epoch: 0, mini-batch 34290 of 31, training loss: 0.564347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, mini-batch 34300 of 31, training loss: 0.561946\n",
      "Train Epoch: 0, mini-batch 34310 of 31, training loss: 0.563246\n",
      "Train Epoch: 0, mini-batch 34320 of 31, training loss: 0.563768\n",
      "Train Epoch: 0, mini-batch 34330 of 31, training loss: 0.562655\n",
      "Train Epoch: 0, mini-batch 34340 of 31, training loss: 0.562917\n",
      "Train Epoch: 0, mini-batch 34350 of 31, training loss: 0.563216\n",
      "Train Epoch: 0, mini-batch 34360 of 31, training loss: 0.562174\n",
      "Train Epoch: 0, mini-batch 34370 of 31, training loss: 0.561127\n",
      "Train Epoch: 0, mini-batch 34380 of 31, training loss: 0.560015\n",
      "Train Epoch: 0, mini-batch 34390 of 31, training loss: 0.563529\n",
      "Train Epoch: 0, mini-batch 34400 of 31, training loss: 0.562895\n",
      "Train Epoch: 0, mini-batch 34410 of 31, training loss: 0.561903\n",
      "Train Epoch: 0, mini-batch 34420 of 31, training loss: 0.562056\n",
      "Train Epoch: 0, mini-batch 34430 of 31, training loss: 0.562076\n",
      "Train Epoch: 0, mini-batch 34440 of 31, training loss: 0.563070\n",
      "Train Epoch: 0, mini-batch 34450 of 31, training loss: 0.562735\n",
      "Train Epoch: 0, mini-batch 34460 of 31, training loss: 0.562901\n",
      "Train Epoch: 0, mini-batch 34470 of 31, training loss: 0.562180\n",
      "Train Epoch: 0, mini-batch 34480 of 31, training loss: 0.562995\n",
      "Train Epoch: 0, mini-batch 34490 of 31, training loss: 0.561730\n",
      "Train Epoch: 0, mini-batch 34500 of 31, training loss: 0.562832\n",
      "Train Epoch: 0, mini-batch 34510 of 31, training loss: 0.560928\n",
      "Train Epoch: 0, mini-batch 34520 of 31, training loss: 0.561918\n",
      "Train Epoch: 0, mini-batch 34530 of 31, training loss: 0.562370\n",
      "Train Epoch: 0, mini-batch 34540 of 31, training loss: 0.562056\n",
      "Train Epoch: 0, mini-batch 34550 of 31, training loss: 0.561801\n",
      "Train Epoch: 0, mini-batch 34560 of 31, training loss: 0.561958\n",
      "Train Epoch: 0, mini-batch 34570 of 31, training loss: 0.562784\n",
      "Train Epoch: 0, mini-batch 34580 of 31, training loss: 0.562683\n",
      "Train Epoch: 0, mini-batch 34590 of 31, training loss: 0.562629\n",
      "Train Epoch: 0, mini-batch 34600 of 31, training loss: 0.562641\n",
      "Train Epoch: 0, mini-batch 34610 of 31, training loss: 0.562632\n",
      "Train Epoch: 0, mini-batch 34620 of 31, training loss: 0.562593\n",
      "Train Epoch: 0, mini-batch 34630 of 31, training loss: 0.562289\n",
      "Train Epoch: 0, mini-batch 34640 of 31, training loss: 0.562156\n",
      "Train Epoch: 0, mini-batch 34650 of 31, training loss: 0.561341\n",
      "Train Epoch: 0, mini-batch 34660 of 31, training loss: 0.563180\n",
      "Train Epoch: 0, mini-batch 34670 of 31, training loss: 0.562611\n",
      "Train Epoch: 0, mini-batch 34680 of 31, training loss: 0.563288\n",
      "Train Epoch: 0, mini-batch 34690 of 31, training loss: 0.561995\n",
      "Train Epoch: 0, mini-batch 34700 of 31, training loss: 0.562589\n",
      "Train Epoch: 0, mini-batch 34710 of 31, training loss: 0.561567\n",
      "Train Epoch: 0, mini-batch 34720 of 31, training loss: 0.562867\n",
      "Train Epoch: 0, mini-batch 34730 of 31, training loss: 0.562797\n",
      "Train Epoch: 0, mini-batch 34740 of 31, training loss: 0.563217\n",
      "Train Epoch: 0, mini-batch 34750 of 31, training loss: 0.565020\n",
      "Train Epoch: 0, mini-batch 34760 of 31, training loss: 0.561665\n",
      "Train Epoch: 0, mini-batch 34770 of 31, training loss: 0.562580\n",
      "Train Epoch: 0, mini-batch 34780 of 31, training loss: 0.561230\n",
      "Train Epoch: 0, mini-batch 34790 of 31, training loss: 0.563013\n",
      "Train Epoch: 0, mini-batch 34800 of 31, training loss: 0.563142\n",
      "Train Epoch: 0, mini-batch 34810 of 31, training loss: 0.562371\n",
      "Train Epoch: 0, mini-batch 34820 of 31, training loss: 0.563260\n",
      "Train Epoch: 0, mini-batch 34830 of 31, training loss: 0.563526\n",
      "Train Epoch: 0, mini-batch 34840 of 31, training loss: 0.562200\n",
      "Train Epoch: 0, mini-batch 34850 of 31, training loss: 0.563368\n",
      "Train Epoch: 0, mini-batch 34860 of 31, training loss: 0.561584\n",
      "Train Epoch: 0, mini-batch 34870 of 31, training loss: 0.562674\n",
      "Train Epoch: 0, mini-batch 34880 of 31, training loss: 0.562734\n",
      "Train Epoch: 0, mini-batch 34890 of 31, training loss: 0.562064\n",
      "Train Epoch: 0, mini-batch 34900 of 31, training loss: 0.562043\n",
      "Train Epoch: 0, mini-batch 34910 of 31, training loss: 0.562338\n",
      "Train Epoch: 0, mini-batch 34920 of 31, training loss: 0.560909\n",
      "Train Epoch: 0, mini-batch 34930 of 31, training loss: 0.563033\n",
      "Train Epoch: 0, mini-batch 34940 of 31, training loss: 0.562229\n",
      "Train Epoch: 0, mini-batch 34950 of 31, training loss: 0.562835\n",
      "Train Epoch: 0, mini-batch 34960 of 31, training loss: 0.562252\n",
      "Train Epoch: 0, mini-batch 34970 of 31, training loss: 0.561928\n",
      "Train Epoch: 0, mini-batch 34980 of 31, training loss: 0.562546\n",
      "Train Epoch: 0, mini-batch 34990 of 31, training loss: 0.562012\n",
      "Train Epoch: 0, mini-batch 35000 of 31, training loss: 0.562388\n",
      "Train Epoch: 0, mini-batch 35010 of 31, training loss: 0.562505\n",
      "Train Epoch: 0, mini-batch 35020 of 31, training loss: 0.562771\n",
      "Train Epoch: 0, mini-batch 35030 of 31, training loss: 0.562553\n",
      "Train Epoch: 0, mini-batch 35040 of 31, training loss: 0.562462\n",
      "Train Epoch: 0, mini-batch 35050 of 31, training loss: 0.559753\n",
      "Train Epoch: 0, mini-batch 35060 of 31, training loss: 0.564405\n",
      "Train Epoch: 0, mini-batch 35070 of 31, training loss: 0.561200\n",
      "Train Epoch: 0, mini-batch 35080 of 31, training loss: 0.561326\n",
      "Train Epoch: 0, mini-batch 35090 of 31, training loss: 0.562235\n",
      "Train Epoch: 0, mini-batch 35100 of 31, training loss: 0.562683\n",
      "Train Epoch: 0, mini-batch 35110 of 31, training loss: 0.559005\n",
      "Train Epoch: 0, mini-batch 35120 of 31, training loss: 0.563469\n",
      "Train Epoch: 0, mini-batch 35130 of 31, training loss: 0.561866\n",
      "Train Epoch: 0, mini-batch 35140 of 31, training loss: 0.561128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-31a71f0ec186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp6a_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-67dfb34e1b33>\u001b[0m in \u001b[0;36mexp6a_experiment\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m#nn.utils.clip_grad_norm(model.parameters(), 0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/CodasML/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/CodasML/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# experiments settings\n",
    "params = {\n",
    "    \"difficulty\": TemporalOrderExp6aSequence.DifficultyLevel.EASY,\n",
    "    \"batch_size\": 32,\n",
    "    \"h_units\": 4,\n",
    "    \"max_epochs\": 30,\n",
    "    \"log_interval\": 10\n",
    "}\n",
    "\n",
    "acc = exp6a_experiment(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acc = {:.2f}%.'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codas ML",
   "language": "python",
   "name": "codasml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
