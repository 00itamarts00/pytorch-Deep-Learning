{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start doing anything, I think it's important to understand for NLP, this is the intuitive process on what we are trying to do when we are processing our data in the IMDB dataset:\n",
    "1. Tokenization: break sentence into individual words\n",
    "    - Before: `\"PyTorch seems really easy to use!\"`\n",
    "    - After: `[\"PyTorch\", \"seems\", \"really\", \"easy\", \"to\", \"use\", \"!\"]`\n",
    "2. Building vocabulary: build an index of words associated with unique numbers\n",
    "    - Before: `[\"PyTorch\", \"seems\", \"really\", \"easy\", \"to\", \"use\", \"!\"]`\n",
    "    - After: `{\"Pytorch: 0, \"seems\": 1, \"really\": 2, ...}`\n",
    "3. Convert to numerals: map words to unique numbers (indices)\n",
    "    - Before: `{\"Pytorch: 0, \"seems\": 1, \"really\": 2, ...}`\n",
    "    - After: `[0, 1, 2, ...]`\n",
    "4. Embedding look-up: map sentences (indices now) to fixed matrices\n",
    "    - ```[[0.1, 0.4, 0.3],\n",
    "       [0.8, 0.1, 0.5],\n",
    "       ...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical imports\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(1337)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting style\n",
    "plt.style.use(('dark_background', 'bmh'))\n",
    "plt.rc('axes', facecolor='none')\n",
    "plt.rc('figure', figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "import torch\n",
    "\n",
    "# Create instances of fields\n",
    "# The important field here is fix_length: all examples using this field will be padded to, or None for flexible sequence lengths\n",
    "# We are fixing this because we will be using a FNN not an LSTM/RNN/GRU where we can go through uneven sequence lengths\n",
    "max_len = 80\n",
    "text = data.Field(sequential=True, fix_length=max_len, batch_first=True, lower=True, dtype=torch.long)\n",
    "label = data.LabelField(sequential=False, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling splits() class method of datasets.IMDB to return a torchtext.data.Dataset object\n",
    "from torchtext import datasets\n",
    "ds_train, ds_test = datasets.IMDB.splits(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  25000\n",
      "test :  25000\n",
      "train.fields : {'label': <torchtext.data.field.LabelField object at 0x7f6494375978>, 'text': <torchtext.data.field.Field object at 0x7f6494375940>}\n"
     ]
    }
   ],
   "source": [
    "# Training and test set each 25k samples\n",
    "# 2 fields due to the way we split above\n",
    "print('train : ', len(ds_train))\n",
    "print('test : ', len(ds_test))\n",
    "print('train.fields :', ds_train.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation set\n",
    "import random\n",
    "seed_num = 1337\n",
    "ds_train, ds_valid = ds_train.split(random_state=random.seed(seed_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  17500\n",
      "valid :  7500\n",
      "valid :  25000\n"
     ]
    }
   ],
   "source": [
    "# Now we've training, validation and test set\n",
    "print('train : ', len(ds_train))\n",
    "print('valid : ', len(ds_valid))\n",
    "print('valid : ', len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "# num_words = 25000\n",
    "num_words = 25000\n",
    "text.build_vocab(ds_train, max_size=num_words)\n",
    "label.build_vocab(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 25002\n",
      "Label size: 2\n"
     ]
    }
   ],
   "source": [
    "# Print vocab size\n",
    "print('Vocabulary size: {}'.format(len(text.vocab)))\n",
    "print('Label size: {}'.format(len(label.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 225938), ('a', 112571), ('and', 111513), ('of', 101389), ('to', 94175), ('is', 72550), ('in', 63886), ('i', 49428), ('this', 49096), ('that', 46809)]\n"
     ]
    }
   ],
   "source": [
    "# Print most common vocabulary text\n",
    "most_common_samples = 10\n",
    "print(text.vocab.freqs.most_common(most_common_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('neg', 8835), ('pos', 8665)]\n"
     ]
    }
   ],
   "source": [
    "# Print most common labels\n",
    "print(label.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 0 label\n",
    "ds_train[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'of',\n",
       " 'all',\n",
       " 'i',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'say',\n",
       " 'that',\n",
       " 'i',\n",
       " 'love',\n",
       " 'this',\n",
       " 'show!!!',\n",
       " 'but',\n",
       " 'this',\n",
       " 'episode...this',\n",
       " 'episode',\n",
       " 'makes',\n",
       " 'a',\n",
       " 'mockery',\n",
       " 'of',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'show.<br',\n",
       " '/><br',\n",
       " '/>i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'with',\n",
       " 'this',\n",
       " 'episode',\n",
       " 'but',\n",
       " 'they',\n",
       " 'successfully',\n",
       " 'created',\n",
       " 'the',\n",
       " 'worst',\n",
       " 'episode',\n",
       " 'in',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'series.<br',\n",
       " '/><br',\n",
       " '/>there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'story',\n",
       " 'line,',\n",
       " 'everything',\n",
       " 'is',\n",
       " 'chaotic',\n",
       " 'and',\n",
       " 'the',\n",
       " 'jokes.....are',\n",
       " 'crap.<br',\n",
       " '/><br',\n",
       " '/>the',\n",
       " 'way',\n",
       " 'they',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'answer',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'remaining',\n",
       " 'questions',\n",
       " 'in',\n",
       " 'the',\n",
       " 'game.....',\n",
       " 'for',\n",
       " 'example',\n",
       " '\"how',\n",
       " 'do',\n",
       " 'the',\n",
       " 'furlings',\n",
       " 'look',\n",
       " 'like\"',\n",
       " 'by',\n",
       " 'creating',\n",
       " 'that',\n",
       " 'stupid',\n",
       " '\"previously',\n",
       " 'on...\"......is',\n",
       " 'simply',\n",
       " 'embarrassing.<br',\n",
       " '/><br',\n",
       " '/>its',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'the',\n",
       " 'writers',\n",
       " 'are',\n",
       " 'running',\n",
       " 'out',\n",
       " 'of',\n",
       " 'ideas',\n",
       " 'and',\n",
       " 'that',\n",
       " 'is',\n",
       " 'really',\n",
       " 'too',\n",
       " 'bad.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 0 text: broken down into individual portions\n",
    "ds_train[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first of all i just want to say that i love this show!!! but this episode...this episode makes a mockery of the entire show.<br /><br />i don't know what they tried to achieve with this episode but they successfully created the worst episode in the entire series.<br /><br />there is no story line, everything is chaotic and the jokes.....are crap.<br /><br />the way they tried to answer some of the remaining questions in the game..... for example \"how do the furlings look like\" by creating that stupid \"previously on...\"......is simply embarrassing.<br /><br />its clear that the writers are running out of ideas and that is really too bad.\n"
     ]
    }
   ],
   "source": [
    "# Sample 0 text: human readeable sample\n",
    "def show_text(sample):\n",
    "    print(' '.join(word for word in sample))\n",
    "    \n",
    "show_text(ds_train[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and iterable object for our training, validation and testing datasets\n",
    "# Batches examples of similar lengths together that minimizes amount of padding needed\n",
    "batch_size = 64  # Change batch size from 1 to bigger number once explanation is done\n",
    "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
    "    (ds_train, ds_valid, ds_test), batch_size=batch_size, sort_key=lambda x: len(x.text), repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if iterator above is an iterable which should show True\n",
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.label]:[torch.FloatTensor of size 64]\n",
       "\t[.text]:[torch.LongTensor of size 64x80]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's inside this iteratable object? Our text and label although now everything is in machine format (not \"words\") but in numbers!\n",
    "# The text we saw above becomes a matrix of size 1 x 80 represented by the fixed length we defined before that\n",
    "list(train_loader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.label]:[torch.FloatTensor of size 64]\n",
       "\t[.text]:[torch.LongTensor of size 64x80]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative to above, this is much faster but the above code is easy to understand and implement\n",
    "next(train_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(train_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'text'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What methods can we call on this batch object? Text and label\n",
    "test_batch.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     9,     61,    222,  ...,     37,      2,   2411],\n",
       "        [ 17715,    173,      6,  ...,      1,      1,      1],\n",
       "        [   944,   1341,    397,  ...,     44,   8097,   5461],\n",
       "        ...,\n",
       "        [     9,     54,    499,  ...,   6908,     11,    112],\n",
       "        [     9,    222,      3,  ...,    161,     14,      8],\n",
       "        [    49,      9,     82,  ...,      3,     56,   2888]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's break this down to check what's in a batch\n",
    "test_batch.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 80])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 comment per batch, each comment is limited to a size of 80 as we've defined\n",
    "test_batch.text.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "         1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "         1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,\n",
       "         0.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "         0.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extremely weird problem in torchtext where BucketIterator returns a Batch object versus just a simple tuple of tensors containing our text index and labels\n",
    "# So let's fix this with a new class FixBatchGenerator\n",
    "\n",
    "class FixBatchGenerator:\n",
    "    def __init__(self, dl, x_field, y_field):\n",
    "        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x_field)\n",
    "            y = getattr(batch, self.y_field)\n",
    "            yield (X,y)\n",
    "            \n",
    "train_loader, valid_loader, test_loader = FixBatchGenerator(train_loader, 'text', 'label'), FixBatchGenerator(valid_loader, 'text', 'label'), FixBatchGenerator(test_loader, 'text', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   441,    103,    581,  ...,      1,      1,      1],\n",
      "        [ 24336,    224,    399,  ...,    229,      3,   5546],\n",
      "        [    49,     25,    208,  ...,    599,  11505,  17935],\n",
      "        ...,\n",
      "        [     9,     14,     23,  ...,   1069,     14,     50],\n",
      "        [    10,      7,      3,  ...,      0,     38,    284],\n",
      "        [   194,     71,      3,  ...,    186,      4,    312]])\n",
      "tensor([ 1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
      "         1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,\n",
      "         1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
      "         0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,\n",
      "         1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
      "         1.,  0.,  1.,  0.])\n"
     ]
    }
   ],
   "source": [
    "# Text index\n",
    "print(next(train_loader.__iter__())[0])\n",
    "\n",
    "# Text label\n",
    "print(next(train_loader.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "   \n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(embedding_dim*embedding_dim, hidden_dim) \n",
    "\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.view(-1, embedding_dim*embedding_dim)\n",
    "        # Linear function  # LINEAR\n",
    "        out = self.fc1(embedded)\n",
    "\n",
    "        # Non-linearity  # NON-LINEAR\n",
    "        out = F.relu(out)\n",
    "\n",
    "        # Linear function (readout)  # LINEAR\n",
    "        out = self.fc2(out)\n",
    "        out = F.sigmoid(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(max_len)\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = num_words + 2\n",
    "embedding_dim = max_len\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "\n",
    "# Instantiate model class and assign to object\n",
    "model = FeedforwardNeuralNetModel(input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Push model to CUDA device if available\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "# learning_rate = 0.01\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Number of groups of parameters\n",
    "print(len(list(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 80])\n",
      "torch.Size([128, 6400])\n",
      "torch.Size([128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Print parameters\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500 Val Loss: 0.5102349519729614 val Accuracy: 59.27\n",
      "Iter: 1000 Val Loss: 0.0062254564836621284 val Accuracy: 60.49\n",
      "Iter: 1500 Val Loss: 0.0006345253204926848 val Accuracy: 61.76\n",
      "Iter: 2000 Val Loss: 0.0003830529167316854 val Accuracy: 61.91\n",
      "Iter: 2500 Val Loss: 0.00028136116452515125 val Accuracy: 62.09\n",
      "Iter: 3000 Val Loss: 0.00015922222519293427 val Accuracy: 62.27\n",
      "Iter: 3500 Val Loss: 0.00014949310570955276 val Accuracy: 62.32\n",
      "Iter: 4000 Val Loss: 7.680547423660755e-05 val Accuracy: 62.41\n",
      "Iter: 4500 Val Loss: 5.3643689170712605e-05 val Accuracy: 62.51\n",
      "Iter: 5000 Val Loss: 4.4746782805304974e-05 val Accuracy: 62.48\n",
      "Iter: 5500 Val Loss: 2.787000084936153e-05 val Accuracy: 62.57\n",
      "Iter: 6000 Val Loss: 2.1936943085165694e-05 val Accuracy: 62.56\n",
      "Iter: 6500 Val Loss: 1.6642119589960203e-05 val Accuracy: 62.56\n",
      "Iter: 7000 Val Loss: 1.2138345482526347e-05 val Accuracy: 62.6\n",
      "Iter: 7500 Val Loss: 8.753620932111517e-06 val Accuracy: 62.68\n",
      "Iter: 8000 Val Loss: 9.394418157171458e-06 val Accuracy: 62.69\n",
      "Iter: 8500 Val Loss: 5.610380867437925e-06 val Accuracy: 62.8\n",
      "Iter: 9000 Val Loss: 3.67594884664868e-06 val Accuracy: 62.83\n",
      "Iter: 9500 Val Loss: 2.1848914002475794e-06 val Accuracy: 62.89\n",
      "Iter: 10000 Val Loss: 2.33762671086879e-06 val Accuracy: 62.88\n",
      "Iter: 10500 Val Loss: 2.162538748962106e-06 val Accuracy: 62.8\n",
      "Iter: 11000 Val Loss: 1.358802137474413e-06 val Accuracy: 62.85\n",
      "Iter: 11500 Val Loss: 9.5833229352138e-07 val Accuracy: 62.89\n",
      "Iter: 12000 Val Loss: 9.192174275085563e-07 val Accuracy: 62.92\n",
      "Iter: 12500 Val Loss: 5.029145313528716e-07 val Accuracy: 62.84\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d38ed9d24bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Calculate Loss: softmax --> cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Getting gradients w.r.t. parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/amn/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/amn/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    431\u001b[0m         return F.binary_cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m    432\u001b[0m                                       \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                                       reduce=self.reduce)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/amn/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "#     print('-'*50)\n",
    "#     print('Epoch {}'.format(epoch))\n",
    "    for i, (samples, labels) in enumerate(train_loader):\n",
    "        # Training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Load samples\n",
    "        samples = samples.view(-1, max_len).to(device)\n",
    "        labels = labels.view(-1, 1).to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(samples)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Testing mode\n",
    "            model.eval()\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for samples, labels in valid_loader:\n",
    "                # Load samples\n",
    "                samples = samples.view(-1, max_len).to(device)\n",
    "                labels = labels.view(-1).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(samples)\n",
    "\n",
    "                # This only works for one-hot encoded labels\n",
    "                # _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # We use a threshold to define \n",
    "                predicted = outputs.ge(0.5).view(-1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "            \n",
    "            accuracy = 100. * correct.item() / total\n",
    "            # Print Loss\n",
    "            print('Iter: {} Val Loss: {} val Accuracy: {}'.format(iter, loss.item(), round(accuracy, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
